{
  "hash": "aec368b4df9c111eaeedd4943315ff97",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Model Comparison\"\ndate-modified: last-modified\nformat: metropolis-revealjs\n---\n\n\n\n\n\n## Guiding Questions\n\n- What is *overfitting* and why is it problematic?\n- How to measure *closeness* of a model to the true model?\n    * What do *information criteria* do?\n\n## In-Sample and Out-Of-Sample Prediction\n\n\n\n::: {.cell}\n\n:::\n\n\n\n- Randomly sample 10 states\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](model_comparison_files/figure-revealjs/unnamed-chunk-2-1.png){fig-align='center' width=480}\n:::\n:::\n\n\n\n## Underfitting and Overfitting\n\n::: {.callout-note}\n\n## Complex models require more data\n\n- Too few data for a complex model: **overfitting**\n- A model being too simple: **underfitting**\n\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](model_comparison_files/figure-revealjs/unnamed-chunk-3-1.png){fig-align='center' width=816}\n:::\n:::\n\n\n\n---\n\n## Prediction of Future Observations\n\n- The more a model captures the noise in the original data, the less likely it predicts future observations well\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](model_comparison_files/figure-revealjs/unnamed-chunk-4-1.png){fig-align='center' width=816}\n:::\n:::\n\n\n\n## What Is A Good Model?\n\n- Closeness from the proposed model ($M_1$) to a \"true\" model ($M_0$)\n    * *Kullback-Leibler Divergence* ($D_\\textrm{KL}$)  \n    = $\\text{Entropy of }M_0 - \\text{elpd of }M_1$\n    * elpd: expected log predictive density: $E_{M_0}[\\log P_{M_1}(\\tilde {\\mathbf{y}})]$\n\n. . .\n\n- Choose a model with *smallest $D_\\textrm{KL}$*\n    * When $M_0 = M_1$, $D_\\textrm{KL} = 0$\n    * $\\Rightarrow$ choose a model with largest elpd\n\n---\n\n### Example\n\n- True model of data: $M_0$: $y \\sim N(3, 2)$\n- $M_1$: $y \\sim N(3.5, 2.5)$\n- $M_2$: $y \\sim \\mathrm{Cauchy}(3, 2)$\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](model_comparison_files/figure-revealjs/unnamed-chunk-5-1.png){fig-align='center' width=384}\n:::\n:::\n\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n\n\n::: {.cell}\n\n:::\n\n\n\nEntropy of $M_0$ = -2.112\n\n|       | elpd        | $D_\\textrm{KL}(M_0 \\mid M_.)$ |\n|-------|:----------- |:------------------------:|\n| $M_1$ | -2.175 | 0.063 |\n| $M_2$ | -2.371 | 0.259 |\n\n:::\n\n::::\n\n---\n\nExpected log *pointwise* predictive density\n\n$$\n\\sum_i \\log P_{M_1} (y_i)\n$$\n\nNote: elpd is a function of sample size\n\n. . .\n\n- Problem: elpd depends on $M_0$, which is unknown\n    * Estimate elpd using the current sample $\\rightarrow$ underestimate discrepancy\n    * Need to estimate elpd using an *independent sample*\n\n## Overfitting\n\nTraining set: 25 states; Test set: 25 remaining states\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](model_comparison_files/figure-revealjs/unnamed-chunk-7-1.png){fig-align='center' width=480}\n:::\n:::\n\n\n\n. . .\n\n- More complex model = more discrepancy between in-sample and out-of-sample elpd\n\n---\n\n## Information Criteria (IC)\n\nApproximate discrepancy between in-sample and out-of-sample elpd\n\nIC = -2 $\\times$ (in-sample elpd - $p$)\n\n$p$ = penalty for model complexity\n- function of number of parameters\n\n. . .\n\nChoose a model with **smaller** IC\n\n. . .\n\nBayesian ICs: DIC, WAIC, etc\n\n## Cross-Validation\n\n- Split the sample into $K$ parts\n\n- Fit a model with $K$ - 1 parts, and obtain elpd for the \"hold-out\" part\n\n. . .\n\nLeave-one-out: $K$ = $N$\n\n- Very computationally intensive\n\n- `loo` package: approximation using Pareto smoothed importance sampling\n\n---\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloo(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nComputed from 8000 by 50 log-likelihood matrix\n\n         Estimate  SE\nelpd_loo     15.0 5.0\np_loo         3.4 1.0\nlooic       -30.1 9.9\n------\nMonte Carlo SE of elpd_loo is 0.0.\n\nAll Pareto k estimates are good (k < 0.5).\nSee help('pareto-k-diagnostic') for details.\n```\n\n\n:::\n:::\n\n\n\n## Comparing Models\n\n$$\n\\texttt{Divorce}_i \\sim N(\\mu_i, \\sigma)\n$$\n\n- M1: `Marriage`\n- M2: `Marriage`, `South`, `Marriage` $\\times$ `South`\n- M3: `South`, smoothing spline of `Marriage` by `South`\n- M4: `Marriage`, `South`, `MedianAgeMarriage`, `Marriage` $\\times$ `South`, `Marriage` $\\times$ `MedianAgeMarriage`, `South` $\\times$ `MedianAgeMarriage`, `Marriage` $\\times$ `South` $\\times$ `MedianAgeMarriage`\n\n---\n\n## {.smaller}\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:center;\"> M1 </th>\n   <th style=\"text-align:center;\">  M2 </th>\n   <th style=\"text-align:center;\">  M3 </th>\n   <th style=\"text-align:center;\">  M4 </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> b_Intercept </td>\n   <td style=\"text-align:center;\"> 0.61 </td>\n   <td style=\"text-align:center;\"> 0.67 </td>\n   <td style=\"text-align:center;\"> 0.94 </td>\n   <td style=\"text-align:center;\"> 5.52 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_Marriage </td>\n   <td style=\"text-align:center;\"> 0.18 </td>\n   <td style=\"text-align:center;\"> 0.13 </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> −1.20 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_Southsouth </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> −0.63 </td>\n   <td style=\"text-align:center;\"> 0.10 </td>\n   <td style=\"text-align:center;\"> 0.31 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_Marriage × Southsouth </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> 0.37 </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> 0.54 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> bs_sMarriage × SouthnonMsouth_1 </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> −0.47 </td>\n   <td style=\"text-align:center;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> bs_sMarriage × Southsouth_1 </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> 1.21 </td>\n   <td style=\"text-align:center;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> sds_sMarriageSouthnonMsouth_1 </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> 0.87 </td>\n   <td style=\"text-align:center;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> sds_sMarriageSouthsouth_1 </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> 0.50 </td>\n   <td style=\"text-align:center;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_MedianAgeMarriage </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> −1.72 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_Marriage × MedianAgeMarriage </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> 0.45 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_MedianAgeMarriage × Southsouth </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> −0.34 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;box-shadow: 0px 1.5px\"> b_Marriage × MedianAgeMarriage × Southsouth </td>\n   <td style=\"text-align:center;box-shadow: 0px 1.5px\">  </td>\n   <td style=\"text-align:center;box-shadow: 0px 1.5px\">  </td>\n   <td style=\"text-align:center;box-shadow: 0px 1.5px\">  </td>\n   <td style=\"text-align:center;box-shadow: 0px 1.5px\"> −0.09 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> ELPD </td>\n   <td style=\"text-align:center;\"> 15.0 </td>\n   <td style=\"text-align:center;\"> 18.2 </td>\n   <td style=\"text-align:center;\"> 17.7 </td>\n   <td style=\"text-align:center;\"> 23.5 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> ELPD s.e. </td>\n   <td style=\"text-align:center;\"> 5.0 </td>\n   <td style=\"text-align:center;\"> 5.5 </td>\n   <td style=\"text-align:center;\"> 5.9 </td>\n   <td style=\"text-align:center;\"> 6.2 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> LOOIC </td>\n   <td style=\"text-align:center;\"> −30.1 </td>\n   <td style=\"text-align:center;\"> −36.5 </td>\n   <td style=\"text-align:center;\"> −35.3 </td>\n   <td style=\"text-align:center;\"> −47.1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> LOOIC s.e. </td>\n   <td style=\"text-align:center;\"> 9.9 </td>\n   <td style=\"text-align:center;\"> 11.0 </td>\n   <td style=\"text-align:center;\"> 11.7 </td>\n   <td style=\"text-align:center;\"> 12.3 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> RMSE </td>\n   <td style=\"text-align:center;\"> 0.17 </td>\n   <td style=\"text-align:center;\"> 0.15 </td>\n   <td style=\"text-align:center;\"> 0.14 </td>\n   <td style=\"text-align:center;\"> 0.13 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n## Notes for Using ICs\n\n- Same outcome variable and transformation\n- Same sample size\n    * Sample size could change when adding a predictor that has missing values\n- Cannot compare discrete and continuous models\n    * E.g., Poisson vs. normal\n\n## Other Techniques\n\nSee notes on stacking and regularization\n\n- Stacking: average predictions from multiple models\n- Regularization: using sparsity-inducing priors to identify major predictors\n- Variable selection: using projection-based methods",
    "supporting": [
      "model_comparison_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}