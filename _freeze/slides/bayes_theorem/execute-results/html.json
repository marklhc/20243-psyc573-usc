{
  "hash": "997a343650ec439bfc18131ddece6b20",
  "result": {
    "engine": "knitr",
    "markdown": "\n\n\n\n\n\n::: {.content-hidden unless-profile=\"class\"}\n\n##\n\n- HW 1 Recap\n\n## Quiz\n\nIn a population, 20% of people carries a gene that makes them more prone to disease X. 10% of the people with the gene gets disease X, whereas only 5% of those without the gene gets disease X. What is the probability that a random person gets disease X?\n\n:::\n\n##\n\n::: {.callout-important}\n\n## Bayes Theorem\n\nGiven $P(A, B) = P(A \\mid B) P(B) = P(B \\mid A) P(A)$ (joint = conditional $\\times$ marginal)\n\n$$\nP(B \\mid A) = \\dfrac{P(A \\mid B) P(B)}{P(A)}\n$$\n\nWhich says how we can go from $P(A \\mid B)$ to $P(B \\mid A)$\n\n:::\n\n::: {.callout-important appearance=\"simple\"}\n\nConsider $B_i$ $(i = 1, \\ldots, n)$ as one of the many possible mutually exclusive events\n\n$$\n\\begin{aligned}\n  P(B_i \\mid A) & = \\frac{P(A \\mid B_i) P(B_i)}{P(A)}  \\\\\n             & = \\frac{P(A \\mid B_i) P(B_i)}{\\sum_{k = 1}^n P(A \\mid B_k)P(B_k)}\n\\end{aligned}\n$$\n\n:::\n\n## Example\n\nA police officer stops a driver *at random* and does a breathalyzer test for the driver. The breathalyzer is known to detect true drunkenness 100% of the time, but in **1%** of the cases, it gives a *false positive* when the driver is sober. We also know that in general, for every **1,000** drivers passing through that spot, **one** is driving drunk. Suppose that the breathalyzer shows positive for the driver. What is the probability that the driver is truly drunk?\n\n:::: {.content-hidden unless-profile=\"class\"}\n\n##\n\n:::: {.columns}\n\n::: {.columns width=\"50%\"}\n$P(\\text{positive} \\mid \\text{drunk}) = 1$  \n$P(\\text{positive} \\mid \\text{sober}) = 0.01$  \n:::\n\n::: {.columns width=\"50%\"}\n$P(\\text{drunk}) = 1 / 1000$  \n$P(\\text{sober}) = 999 / 1000$\n:::\n\n::::\n\n. . .\n\nUsing Bayes Theorem, \n\n$$\n\\begin{aligned}\n  & \\quad\\; P(\\text{drunk} \\mid \\text{positive})  \\\\\n  & = \\frac{P(\\text{positive} \\mid \\text{drunk}) P(\\text{drunk})}\n           {P(\\text{positive} \\mid \\text{drunk}) P(\\text{drunk}) + \n            P(\\text{positive} \\mid \\text{sober}) P(\\text{sober})}  \\\\\n  & = \\frac{1 \\times 0.001}{1 \\times 0.001 + 0.01 \\times 0.999} \\\\\n  & = 100 / 1099 \\approx 0.091\n\\end{aligned}\n$$\n\n---\n\nSo there is less than 10% chance that the driver is drunk even when the \nbreathalyzer shows positive.\n\n::: {.callout appearance=\"simple\"}\nA. Even with the breathalyzer showing positive, it is still very likely that the driver is not drunk\n:::\n\n::: {.callout appearance=\"simple\"}\nB. On the other hand, before the breathalyzer result, the person only has a 0.1% chance of being drunk. The breathalyzer result increases that probability to 9.1% (i.e., 91 times bigger)\n:::\n\n. . .\n\nBoth (A) and (B) are true. It just means that there is still much uncertainty after one positive test\n\n::: {.notes}\nHaving a second test may be helpful, assuming that what causes a false positive in the first test does not guarantee a false positive in the second test (otherwise, the second test is useless). That's one reason for not having consecutive tests too close in time.\n:::\n\n::::\n\n::: {visibility=\"hidden\"}\n\n## Gigerenzer (2004)\n\n$p$ value = $P$(data | hypothesis), not $P$(hypothesis | data)\n\n. . .\n\nConsider:\n\n- $H_0$: the person is sober (not drunk)\n- data: breathalyzer result\n\n$p$ = $P$(positive | sober) = 0.01 $\\rightarrow$ reject $H_0$ at .05 level\n\n. . .\n\nHowever, as we have seen, given that $P(H_0)$ is small, $P(H_0 \\mid \\text{data})$ is still small\n\n:::\n\n# Bayesian Data Analysis\n\n## Bayes Theorem in Data Analysis\n\n- Bayesian statistics\n    * more than applying Bayes theorem\n    * a way to quantify the plausibility of every possible value of some parameter $\\theta$\n        * E.g., population mean, regression coefficient, etc\n    * Goal: **update one's Belief about $\\theta$ based on the observed data $D$**\n\n## Going back to the example\n\nGoal: Find the probability that the person is drunk, given the test result\n\nParameter ($\\theta$): drunk (values: drunk, sober)\n\nData ($D$): test (possible values: positive, negative)\n\n. . .\n\nBayes theorem: $\\underbrace{P(\\theta \\mid D)}_{\\text{posterior}} = \\underbrace{P(D \\mid \\theta)}_{\\text{likelihood}} \\underbrace{P(\\theta)}_{\\text{prior}} / \\underbrace{P(D)}_{\\text{marginal}}$\n\n##\n\nUsually, the marginal is not given, so\n\n$$\nP(\\theta \\mid D) = \\frac{P(D \\mid \\theta)P(\\theta)}{\\sum_{\\theta^*} P(D \\mid \\theta^*)P(\\theta^*)}\n$$\n\n- $P(D)$ is also called *evidence*, or the *prior predictive distribution*\n    * E.g., probability of a positive test, regardless of the drunk status\n\n## Example 2\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshiny::runGitHub(\"plane_search\", \"marklhc\")\n```\n:::\n\n\n\n\n\n- Try choosing different priors. How does your choice affect the posterior?\n- Try adding more data. How does the number of data points affect the posterior?\n\n##\n\nThe posterior is a synthesis of two sources of information: prior and data (likelihood)\n\nGenerally speaking, a narrower distribution (i.e., smaller variance) means more/stronger information\n\n- Prior: narrower = more informative/strong\n- Likelihood: narrower = more data/more informative\n\n::: {.content-hidden unless-profile=\"class\"}\n\n## Q1\n\nThe posterior distribution describes the\n\nA. conditional probability of the parameters given the data\n\nB. joint probability of the parameters and the data\n\nC. conditional probability of the data given the parameters\n\nD. marginal probability of the data\n\n## Q2\n\nWhich of the following is a weak prior, compared to the other?\n\n\n\n\n\n::: {.cell layout-ncol=\"2\"}\n::: {.cell-output-display}\n![](bayes_theorem_files/figure-html/unnamed-chunk-3-1.png){width=432}\n:::\n\n::: {.cell-output-display}\n![](bayes_theorem_files/figure-html/unnamed-chunk-3-2.png){width=432}\n:::\n:::\n\n\n\n\n\n##\n\nExercise:\n\n- Shiny app with a parameter (fixed)\n- Ask students to formulate a prior distribution\n- Flip a coin, and compute the posterior by hand (with R)\n- Use the posterior as prior, flip again, and obtain the posterior again\n- Compare to use the original prior with two coin flips (both numbers and plots)\n- Flip 10 times, and show how the posterior change (using animation in `knitr`)\n:::\n\n## Priors\n\n*Prior beliefs used in data analysis must be admissible by a skeptical scientific audience (Kruschke, 2015, p. 115)*\n\n. . . \n\n- **Flat**, noninformative, vague\n- **Weakly informative**: common sense, logic\n- **Informative**: publicly agreed facts or theories\n\n\n\n\n\n::: {.cell layout-ncol=\"3\"}\n\n```{.r .cell-code}\nsource(\"_common_dnorm_trunc.R\")\nggplot(tibble(x = c(0, 1)), aes(x = x)) +\n    stat_function(fun = dunif) +\n    ylim(0, 5) +\n    labs(y = \"\", x = expression(theta), title = \"Flat\")\n```\n\n::: {.cell-output-display}\n![](bayes_theorem_files/figure-html/unnamed-chunk-4-1.png){width=95%}\n:::\n\n```{.r .cell-code}\nggplot(tibble(x = c(0, 1)), aes(x = x)) +\n    stat_function(fun = dnorm_trunc, args = list(mean = .8, sd = .5)) +\n    ylim(0, 5) +\n    labs(y = \"\", x = expression(theta), title = \"Weakly informative\")\n```\n\n::: {.cell-output-display}\n![](bayes_theorem_files/figure-html/unnamed-chunk-4-2.png){width=95%}\n:::\n\n```{.r .cell-code}\nggplot(tibble(x = c(0, 1)), aes(x = x)) +\n    stat_function(fun = dnorm_trunc, args = list(mean = .8, sd = .1)) +\n    ylim(0, 5) +\n    labs(y = \"\", x = expression(theta), title = \"Informative\")\n```\n\n::: {.cell-output-display}\n![](bayes_theorem_files/figure-html/unnamed-chunk-4-3.png){width=95%}\n:::\n:::\n\n\n\n\n\n## Likelihood/Model/Data $P(D \\mid \\theta, M)$\n\n*Probability of observing the data **as a function of the parameter(s)***\n\n- Also written as $L(\\theta \\mid D)$ or $L(\\theta; D)$ to emphasize it is a function of $\\theta$\n- Also depends on a chosen model $M$: $P(D \\mid \\theta, M)$\n\n\n\n\n\n::: {.cell layout-ncol=\"2\"}\n\n```{.r .cell-code}\nset.seed(1535)\nngrid <- 101\ngrid <- seq(0, 1, length.out = ngrid)\nx <- rnorm_trunc(10, mean = 0.3, sd = 0.2)\nx1 <- x[1:2]\nlik_x1 <- compute_lik(x1)\nlik_x <- compute_lik(x)\nggplot(\n    tibble(x = grid, dens = lik_x1),\n    aes(x = x, y = dens)\n) +\n    geom_line() +\n    labs(\n        x = expression(theta), y = \"Likelihood (Scaled)\",\n        title = \"2 data points\"\n    ) +\n    geom_point(\n        data = tibble(x = x1), aes(x = x), y = 0,\n        shape = 1\n    )\n```\n\n::: {.cell-output-display}\n![](bayes_theorem_files/figure-html/unnamed-chunk-5-1.png){width=90%}\n:::\n\n```{.r .cell-code}\nggplot(\n    tibble(x = grid, dens = lik_x),\n    aes(x = x, y = dens)\n) +\n    geom_line() +\n    labs(\n        x = expression(theta), y = \"Likelihood (Scaled)\",\n        title = \"10 data points\"\n    ) +\n    geom_point(\n        data = tibble(x = x), aes(x = x), y = 0,\n        shape = 1\n    )\n```\n\n::: {.cell-output-display}\n![](bayes_theorem_files/figure-html/unnamed-chunk-5-2.png){width=90%}\n:::\n:::\n\n\n\n\n\n## Likelihood of Multiple Data Points\n\n1. Given $D_1$, obtain *posterior* $P(\\theta \\mid D_1)$\n2. Use $P(\\theta \\mid D_1)$ as *prior*, given $D_2$, obtain posterior $P(\\theta \\mid D_1, D_2)$\n\nThe posterior is the same as getting $D_2$ first then $D_1$, or $D_1$ and $D_2$ together, if\n\n- **data-order invariance** is satisfied, which means\n- $D_1$ and $D_2$ are **exchangeable**\n\n##\n\n::: {.callout-important}\n\n## Exchangeability\n\nJoint distribution of the data does not depend on the order of the data\n\nE.g., $P(D_1, D_2, D_3) = P(D_2, D_3, D_1) = P(D_3, D_2, D_1)$\n\n:::\n\n. . .\n\nExample of non-exchangeable data:\n\n- First child = male, second = female vs. first = female, second = male\n- $D_1, D_2$ from School 1; $D_3, D_4$ from School 2 vs. $D_1, D_3$ from School 1; $D_2, D_4$ from School 2\n\n# Bernoulli Example\n\n## Coin Flipping: Binary Outcomes\n\nQ: Estimate the probability that a coin gives a head\n\n- $\\theta$: parameter, probability of a head\n\nFlip a coin, showing head\n\n- $y = 1$ for showing head\n\n## Multiple Binary Outcomes\n\n**Bernoulli model** is natural for binary outcomes\n\nAssume the flips are exchangeable given $\\theta$,\n$$\n\\begin{align}\nP(y_1, \\ldots, y_N \\mid \\theta) &= \\prod_{i = 1}^N P(y_i \\mid \\theta) \\\\\n&= \\theta^z (1 - \\theta)^{N - z}\n\\end{align}\n$$\n\n:::: {.columns}\n\n::: {.column width=45%}\n$z$ = # of heads; $N$ = # of flips\n:::\n\n::: {.column width=55%}\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlik <- function(th, num_flips = 4, num_heads = 1) {\n    th ^ num_heads * (1 - th) ^ (num_flips - num_heads)\n}\n# Plot the likelihood\nggplot(data.frame(th = c(0, 1)), aes(x = th)) +\n    # `stat_function` for plotting a function\n    stat_function(fun = lik) +\n    # use `expression()` to get greek letters\n    labs(x = expression(theta),\n    y = \"Likelihood with N = 4 and z = 1\")\n```\n\n::: {.cell-output-display}\n![](bayes_theorem_files/figure-html/lik-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n:::\n\n::::\n\n## Posterior\n\n### Same posterior, two ways to think about it\n\n:::: {.columns}\n\n::: {.column width=50%}\n\n::: {.callout-note appearance=\"simple\"}\n\n## Prior belief, weighted by the likelihood\n\n$$\nP(\\theta \\mid y) \\propto \\underbrace{P(y \\mid \\theta)}_{\\text{weights}} P(\\theta)\n$$\n\n:::\n\n:::\n\n::: {.column width=50%}\n\n::: {.callout-note appearance=\"simple\"}\n\n## Likelihood, weighted by the strength of prior belief\n\n$$\nP(\\theta \\mid y) \\propto \\underbrace{P(\\theta)}_{\\text{weights}} P(\\theta \\mid y)\n$$\n\n:::\n\n:::\n\n::::\n\n## Grid Approximation\n\nSee Exercise 2\n\nDiscretize a continuous parameter into a finite number of discrete values\n\nFor example, with $\\theta$: [0, 1] $\\to$ [.05, .15, .25, ..., .95]\n\n\n\n\n\n::: {.cell layout-ncol=\"2\" layout-align=\"center\"}\n\n```{.r .cell-code}\nlik <- function(th, num_flips = 4, num_heads = 1) {\n    th ^ num_heads * (1 - th) ^ (num_flips - num_heads)\n}\n# Plot the likelihood\nggplot(data.frame(th = c(0, 1)), aes(x = th)) +\n    # `stat_function` for plotting a function\n    stat_function(fun = lik) +\n    # use `expression()` to get greek letters\n    labs(x = expression(theta),\n    y = \"Likelihood with N = 4 and z = 1\")\n```\n\n::: {.cell-output-display}\n![](bayes_theorem_files/figure-html/unnamed-chunk-7-1.png){fig-align='center' width=90%}\n:::\n\n```{.r .cell-code}\n# Define a grid for the parameter\ngrid_df <- data.frame(th = seq(0, 1, by = 0.05)) |>\n    mutate(\n        # Use our previously defined lik() function\n        py_th = lik(th, num_flips = 4, num_heads = 1)\n    )\nggplot(data = grid_df, aes(x = th)) +\n    geom_col(aes(x = th + 0.005, y = py_th / sum(py_th)), width = 0.01,\n    ) +\n    labs(y = \"Likelihood (in grid)\", x = expression(theta)) +\n    theme(legend.position = \"top\")\n```\n\n::: {.cell-output-display}\n![](bayes_theorem_files/figure-html/unnamed-chunk-7-2.png){fig-align='center' width=90%}\n:::\n:::\n\n\n\n\n\n\n\n# Criticism of Bayesian Methods\n\n## Criticism of \"Subjectivity\"\n\nMain controversy: subjectivity in choosing a prior\n\n- Two people with the same data can get different results because of different chosen priors\n\n::: {.callout-note}\n\n## Counters to the Subjectivity Criticism\n\n- With enough data, different priors hardly make a difference\n- Prior: just a way to express the degree of ignorance\n    * One can choose a weakly informative prior so that the Influence of subjective Belief is small\n\n:::\n\n##\n\n::: {.callout-note}\n\n## Counters to the Subjectivity Criticism 2\n    \nSubjectivity in choosing a prior is\n\n- Same as in choosing a model, which is also done in frequentist statistics\n- Relatively strong prior needs to be justified, \n    * Open to critique from other researchers\n- Inter-subjectivity $\\rightarrow$ Objectivity\n\n:::\n\n::: {.callout-note}\n\n## Counters to the Subjectivity Criticism 3\n    \nThe prior is a way to incorporate previous research efforts to accumulate scientific evidence\n\n> Why should we ignore all previous literature every time we conduct a new study?\n\n:::",
    "supporting": [
      "bayes_theorem_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}