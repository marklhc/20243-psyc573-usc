{
  "hash": "5c69e78e9fffcc0e0f764703e2cbed10",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Introduction\"\ndate: \"August 27, 2024\"\ndate-modified: \"August 27, 2024\"\nformat: metropolis-revealjs\n---\n\n\n\n\n\n\n::: {.content-hidden unless-profile=\"class\"}\n\n## Introduction\n\n- Name\n- Department & Year\n- Research Interest\n- Reason for taking this class\n\n## Navigate the Course\n\n- Course website: <https://marklhc.quarto.pub/psyc573-2024fall/>\n- Brightspace (for assignment submission)\n\n## Quiz\n\nComplete \"Self-test: Bayesian vs. Frequentist\" on Brightspace\n\n. . .\n\nAnswer key: <https://www.bayesrulesbook.com/chapter-1.html#fn1>\n\n:::\n\n## History of Bayesian Statistics\n\n\n\n\n{{< video https://www.youtube.com/embed/BcvLAw-JRss width=\"480\" height=\"270\" >}}\n\n\n\n\n\n\ncf. A nice popular science book by Sharon Bertsch McGrayne: *The theory that would not die*\n\n::: {.content-hidden unless-profile=\"class\"}\n![](https://yalebooks.yale.edu/sites/default/files/styles/book_jacket/public/imagecache/external/2b431d126e7aea1707e695a3b54860f9.jpg){fig-align=\"right\"}\n:::\n\n## Historical Figures\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\nThomas Bayes (1701--1762)\n\n![](https://upload.wikimedia.org/wikipedia/commons/d/d4/Thomas_Bayes.gif){height=\"250px\"}\n\n- English Presbyterian minister\n- \"An Essay towards solving a Problem in the Doctrine of Chances\", edited by Richard Price after Bayes's death\n\n:::\n\n::: {.column width=\"50%\"}\n\nPierre-Simon Laplace (1749--1827)\n\n![](https://upload.wikimedia.org/wikipedia/commons/e/e3/Pierre-Simon_Laplace.jpg){height=\"250px\"}\n\n- French Mathematician\n- Formalize Bayesian interpretation of probability, and most of the machinery for Bayesian statistics\n\n:::\n\n::::\n\n::: {.notes}\nImage credit: [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Thomas_Bayes.gif), [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Pierre-Simon_Laplace.jpg)\n:::\n\n## In the 20th Century\n\n- Bayesian is the main way to do statistics until early 1920s\n\n- Ronald Fisher and Frequentist scholars took over \n    \n    > \"The theory of inverse probability is founded upon an error, and must be wholly rejected\" [(Fisher, 1925, p. 10)](https://link.springer.com/chapter/10.1007/978-1-4612-4380-9_6) [^1]\n\n[^1]: Aldrich, J. (2008). R. A. Fisher on Bayes and Bayes' theorem. *Bayesian Analysis, 3*(1), 161--170.\n\n## Resurrection\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n::: {.content-hidden unless-profile=\"class\"}\n[![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT83UaQCpOJKYEyfsqihnshU9lO3NepAJ3JQQ&s)](https://www.linkedin.com/pulse/book-movie-review-alan-turing-imitation-game-nirav-parekh)\n:::\n:::\n\n::: {.column width=\"60%\"}\n\n- Alan Turing's algorithms in code breaking in World War II\n\n- *Markov Chain Monte Carlo* (MCMC) algorithms\n    * Bring Bayesian back to the main stream of statistics\n    \n:::\n\n::::\n\n::: aside\nOne early version of MCMC algorithms was developed to solve problems in the Manhattan Project for building the first atomic bomb. See [@hitchcock2003](https://www.jstor.org/stable/30037292) for a brief history.\n:::\n\n## Why Should You Learn About the Bayesian Way?\n\n- @gigerenzer2004: It is one tool of your statistical toolbox\n\n. . .\n\n- Increasingly used as alternative to frequentist statistics\n\n. . .\n\n- Computationally more stable for complex models\n\n. . .\n\n- A coherent way of incorporating prior information\n    * Common sense knowledge, previous literature, sequential experiments, etc\n\n. . .\n\n- More comprehensive tools for understanding your data and models\n\n# Bayesian Ideas\n\n## Reallocation of credibility across possibilities\n\nHypothetical example: How effective is a vaccine?\n\n. . .\n\nPrior (before collecting data)\n\n\n\n\n::: {.cell layout-ncol=\"2\"}\n::: {.cell-output-display}\n![](intro_files/figure-revealjs/unnamed-chunk-2-1.png){width=90%}\n:::\n\n::: {.cell-output-display}\n![](intro_files/figure-revealjs/unnamed-chunk-2-2.png){width=90%}\n:::\n:::\n\n\n\n\n## Updating Beliefs\n\nAfter seeing results of a trial\n\n- 4/5 with the vaccince improved\n- 2/5 without the vaccine improved\n\n. . .\n\n\n\n\n::: {.cell layout-ncol=\"2\"}\n::: {.cell-output-display}\n![](intro_files/figure-revealjs/unnamed-chunk-3-1.png){width=90%}\n:::\n\n::: {.cell-output-display}\n![](intro_files/figure-revealjs/unnamed-chunk-3-2.png){width=90%}\n:::\n:::\n\n\n\n\n## Possibilities = Parameter Values\n\n::: {.callout-tip}\n\n## A Discrete Parameter\n\n- Parameter: Effectiveness of the vaccine\n- Possibilities: Not effective, mildly effective, very effective\n\n:::\n\n. . .\n\n::: {.callout-tip}\n\n## A Continuous Parameter\n\n- Parameter: Risk reduction by taking the vaccine\n- Possibilities: $(-\\infty, \\infty)$ (Any real number)\n\n:::\n\n---\n\nUsing Bayesian analysis, one obtains updated/**posterior probability** for every possibility of a parameter, given the **prior** belief and the **data**\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](intro_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n\n\n## Steps of Bayesian Data Analysis\n\n::: {.callout-note}\n\n## \"Turning the Bayesian crank\"\n\n1. Define a mathematical model with parameters\n2. Specify priors on parameters\n3. Check priors\n4. Fit model to data\n5. Check for convergence\n6. Evaluate the model using posterior predictive check\n7. Modify the model and repeat 3-6\n8. Obtain and interpret posterior distributions of the parameters\n\n:::\n\n## Example: @frank2019 [Cognition and Emotion]\n\n\n\n\n\n\n\n\n\n- Response time for 2 (Dutch--native vs. English--foreign) $\\times$ 2 (lie vs. truth) experimental conditions\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](intro_files/figure-revealjs/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n\n\n\n## Posterior of Mean RTs by Conditions\n\nL = Lie, T = Truth; D = Dutch, E = English\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](intro_files/figure-revealjs/unnamed-chunk-7-1.png){width=960}\n:::\n:::\n\n\n\n\n---\n\n### Accepting the Null\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](intro_files/figure-revealjs/unnamed-chunk-8-1.png){width=960}\n:::\n:::\n\n\n\n\n::: {.fragment}\n### Posterior Predictive Check\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](intro_files/figure-revealjs/unnamed-chunk-9-1.png){width=960}\n:::\n:::\n\n\n\n:::\n\n## Multiple Experiments\n\n@kay2016, Figure 2\n\n::: {.content-hidden unless-profile=\"class\"}\n![](/images/Kay_etal_2016_fig2.png)\n:::\n\n::: {.content-hidden unless-profile=\"class\"}\n## Syllabus\n\n- Learning objectives\n- Readings\n- Class structure & assessment\n    * Exercises due Friday\n    * Homework due Monday\n    * Final project\n- Use of AI\n\n# R, RStudio, and Quarto\n\n# Homework 1\n\n## Quiz Q1\n\nWhen was Thomas Bayes' work on Bayes' theorem published posthumously?\n\na. around 1760s\nb. around 1920s\nc. around 1950s\nd. around 1980s\n\n## Quiz Q2\n\nIn a Bayesian data analysis, which of the following contains the main result?\n\na. Prior\nb. Likelihood\nc. Posterior\n\n## Quiz Q3\n\nWhat is the posterior distribution?\n\na. The distribution of the data given the parameters.\nb. The distribution of the parameters before observing the data.\nc. The distribution of the parameters after observing the data.\nd. The distribution of the data alone.\n\nP.S.: Parameter = unknown quantity/attribute of interest (e.g., effectiveness of vaccine)\n\n:::\n\n## Bibliography",
    "supporting": [
      "intro_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}