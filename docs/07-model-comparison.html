<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.33">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>11&nbsp; Model Comparison – PSYC 573 Bayesian Data Analysis (2024 Fall): Course Notes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./07b-stacking-and-regularization.html" rel="next">
<link href="./06c-regression-diagnostics.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-07ba0ad10f5680c660e360ac31d2f3b6.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-6d9163938730c4bb45bb2ddd9242afb9.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script type="text/javascript">

(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-225295148', 'auto');

ga('send', {
  hitType: 'pageview',
  'anonymizeIp': true,
});
</script><script src="site_libs/kePrint-0.0.1/kePrint.js"></script><link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet">
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script><script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>
</head>
<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="navbar navbar-expand-lg " data-bs-theme="dark"><div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">PSYC 573 Bayesian Data Analysis (2024 Fall): Course Notes</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
<li class="nav-item">
    <a class="nav-link" href="./../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./../modules.html"> 
<span class="menu-text">Modules</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./../docs/index.html"> 
<span class="menu-text">Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./../exercises/index.html"> 
<span class="menu-text">Exercises</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./../syllabus/index.html"> 
<span class="menu-text">Syllabus</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./../resources.html"> 
<span class="menu-text">Resources</span></a>
  </li>  
</ul>
</div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
    <a href="https://github.com/marklhc/usc-psyc573-notes" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./PSYC-573-Bayesian-Data-Analysis--2024-Fall---Course-Notes.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./07-model-comparison.html">Week 7</a></li><li class="breadcrumb-item"><a href="./07-model-comparison.html"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Model Comparison</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Week 1</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Week 2</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-bayes-theorem.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Bayes’s Theorem</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Week 3</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-beta-bernoulli-model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Beta-Bernoulli Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04b-beta-bernoulli-stan.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Beta-Bernoulli Model With Stan</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04c-poisson-model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Poisson Model</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Week 4</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-hierarchical-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Hierarchical Models</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Week 5–6</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-linear-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Linear Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06b-multiple-predictors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Multiple Predictors</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06c-regression-diagnostics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Model Diagnostics</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Week 7</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-model-comparison.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Model Comparison</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07b-stacking-and-regularization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Stacking, Regularization, and Variable Selection</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Week 9</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-causal-inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Causal Inference</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08b-mediation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Mediation</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">Week 10–11</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-mcmc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Markov Chain Monte Carlo</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09b-gibbs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Gibbs Sampling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09c-hmc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Hamiltonian Monte Carlo</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true">
 <span class="menu-text">Week 12</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-glm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Generalized Linear Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10b-glm2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Generalized Linear Model (II)</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li><a href="#overfitting-and-underfitting" id="toc-overfitting-and-underfitting" class="nav-link active" data-scroll-target="#overfitting-and-underfitting"><span class="header-section-number">11.1</span> Overfitting and Underfitting</a></li>
  <li><a href="#kullback-leibler-divergence" id="toc-kullback-leibler-divergence" class="nav-link" data-scroll-target="#kullback-leibler-divergence"><span class="header-section-number">11.2</span> Kullback-Leibler Divergence</a></li>
  <li>
<a href="#deviance" id="toc-deviance" class="nav-link" data-scroll-target="#deviance"><span class="header-section-number">11.3</span> Deviance</a>
  <ul class="collapse">
<li><a href="#experiment-on-deviance" id="toc-experiment-on-deviance" class="nav-link" data-scroll-target="#experiment-on-deviance"><span class="header-section-number">11.3.1</span> Experiment on Deviance</a></li>
  </ul>
</li>
  <li>
<a href="#information-criteria" id="toc-information-criteria" class="nav-link" data-scroll-target="#information-criteria"><span class="header-section-number">11.4</span> Information Criteria</a>
  <ul class="collapse">
<li><a href="#akaike-information-criteria-aic" id="toc-akaike-information-criteria-aic" class="nav-link" data-scroll-target="#akaike-information-criteria-aic"><span class="header-section-number">11.4.1</span> Akaike Information Criteria (AIC)</a></li>
  <li><a href="#deviance-information-criteria-dic" id="toc-deviance-information-criteria-dic" class="nav-link" data-scroll-target="#deviance-information-criteria-dic"><span class="header-section-number">11.4.2</span> Deviance Information Criteria (DIC)</a></li>
  <li><a href="#watanabe-akaike-information-criteria-waic" id="toc-watanabe-akaike-information-criteria-waic" class="nav-link" data-scroll-target="#watanabe-akaike-information-criteria-waic"><span class="header-section-number">11.4.3</span> Watanabe-Akaike Information Criteria (WAIC)</a></li>
  <li><a href="#leave-one-out-cross-validation" id="toc-leave-one-out-cross-validation" class="nav-link" data-scroll-target="#leave-one-out-cross-validation"><span class="header-section-number">11.4.4</span> Leave-One-Out Cross-Validation</a></li>
  <li><a href="#example" id="toc-example" class="nav-link" data-scroll-target="#example"><span class="header-section-number">11.4.5</span> Example</a></li>
  </ul>
</li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./07-model-comparison.html">Week 7</a></li><li class="breadcrumb-item"><a href="./07-model-comparison.html"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Model Comparison</span></a></li></ol></nav><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">
<span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Model Comparison</span>
</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><section id="overfitting-and-underfitting" class="level2" data-number="11.1"><h2 data-number="11.1" class="anchored" data-anchor-id="overfitting-and-underfitting">
<span class="header-section-number">11.1</span> Overfitting and Underfitting</h2>
<p>In statistical modeling, a more complex model almost always results in a better fit to the data. Roughly speaking, a more complex model means a model with more parameters. However, as you will see later, determining the number of parameters in Bayesian analyses is not straightforward. On the extreme side, if one has 10 observations, a model with 10 parameters will perfectly predict every single data point (by just having a parameter to predict each data point). However, there are two problems with too complex a model. First, an increasingly complex model makes it increasingly hard to extract useful information from the data. Instead of describing the relationship between two variables, like <code>Marriage</code> and <code>Divorce</code>, by a straight line, one ends up with a crazy model that is difficult to make sense of. Second, as you will also see, the more complex a model, the more is the risk that it <em>overfits</em> the current data, such that it does not work for future observations.</p>
<p>For example, let’s randomly sample 10 states in the <code>waffle_divorce</code> data set and build some models.</p>
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">waffle_divorce</span> <span class="op">&lt;-</span> <span class="fu">read_delim</span><span class="op">(</span>  <span class="co"># read delimited files</span></span>
<span>    <span class="st">"data/WaffleDivorce.csv"</span>,</span>
<span>    delim <span class="op">=</span> <span class="st">";"</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Rows: 50 Columns: 13
── Column specification ────────────────────────────────────────────────────────
Delimiter: ";"
chr  (2): Location, Loc
dbl (11): Population, MedianAgeMarriage, Marriage, Marriage SE, Divorce, Div...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
</div>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Rescale Marriage and Divorce by dividing by 10</span></span>
<span><span class="va">waffle_divorce</span><span class="op">$</span><span class="va">Marriage</span> <span class="op">&lt;-</span> <span class="va">waffle_divorce</span><span class="op">$</span><span class="va">Marriage</span> <span class="op">/</span> <span class="fl">10</span></span>
<span><span class="va">waffle_divorce</span><span class="op">$</span><span class="va">Divorce</span> <span class="op">&lt;-</span> <span class="va">waffle_divorce</span><span class="op">$</span><span class="va">Divorce</span> <span class="op">/</span> <span class="fl">10</span></span>
<span><span class="va">waffle_divorce</span><span class="op">$</span><span class="va">MedianAgeMarriage</span> <span class="op">&lt;-</span> <span class="va">waffle_divorce</span><span class="op">$</span><span class="va">MedianAgeMarriage</span> <span class="op">/</span> <span class="fl">10</span></span>
<span><span class="co"># Recode `South` to a factor variable</span></span>
<span><span class="va">waffle_divorce</span><span class="op">$</span><span class="va">South</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">waffle_divorce</span><span class="op">$</span><span class="va">South</span>,</span>
<span>    levels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>,</span>
<span>    labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"non-south"</span>, <span class="st">"south"</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1547</span><span class="op">)</span>  <span class="co"># set the seed for reproducibility</span></span>
<span><span class="co"># Sample 10 observations</span></span>
<span><span class="va">train</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample.int</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">waffle_divorce</span><span class="op">)</span>, <span class="fl">10L</span><span class="op">)</span></span>
<span><span class="va">wd_sub</span> <span class="op">&lt;-</span> <span class="va">waffle_divorce</span><span class="op">[</span><span class="va">train</span>, <span class="op">]</span></span>
<span><span class="va">base</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">Marriage</span>, y <span class="op">=</span> <span class="va">Divorce</span><span class="op">)</span>,</span>
<span>               data <span class="op">=</span> <span class="va">wd_sub</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">geom_point</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">coord_cartesian</span><span class="op">(</span>ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.6</span>, <span class="fl">1.4</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">xlim</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">waffle_divorce</span><span class="op">$</span><span class="va">Marriage</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="va">waffle_divorce</span>,</span>
<span>       <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">Marriage</span>, y <span class="op">=</span> <span class="va">Divorce</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>    <span class="fu">geom_point</span><span class="op">(</span>col <span class="op">=</span> <span class="st">"lightblue"</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">geom_point</span><span class="op">(</span>size <span class="op">=</span> <span class="fl">1.5</span>, data <span class="op">=</span> <span class="va">wd_sub</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">coord_cartesian</span><span class="op">(</span>ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.6</span>, <span class="fl">1.4</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">xlim</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">waffle_divorce</span><span class="op">$</span><span class="va">Marriage</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="07-model-comparison_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>When using <code>Marriage</code> to predict <code>Divorce</code>, we can use beyond a linear regression line by using higher-order <em>polynomials</em>. For example, a second-order polynomial represents a quadratic effect (with one turning point); it goes to cubic, quartic, and more. The figure below shows the fit from a linear effect of <code>Marriage</code>, a quadratic effect, and increasingly complex models up to a sixth-degree polynomial. As you can see, as the model gets more complex, the fitted line tries to capture all the 10 points really well, with an increasing <span class="math inline">\(R^2\)</span>. However, the standard error around the fitted line also gets larger and bizarre, meaning more uncertainty in the model parameters.</p>
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">r2</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">object</span>, <span class="va">newresp</span>, <span class="va">newdata</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="co"># Function for computing R^2</span></span>
<span>    <span class="va">ypred</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">object</span>, newdata <span class="op">=</span> <span class="va">newdata</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span><span class="va">ypred</span>, <span class="va">newresp</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span></span>
<span><span class="op">}</span></span>
<span><span class="va">rmse</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">object</span>, <span class="va">newresp</span>, <span class="va">newdata</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="co"># Function for RMSE</span></span>
<span>    <span class="va">ypred</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">object</span>, newdata <span class="op">=</span> <span class="va">newdata</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">ypred</span> <span class="op">-</span> <span class="va">newresp</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="co"># Create six plots through a loop</span></span>
<span><span class="va">p_list</span> <span class="op">&lt;-</span> <span class="fu">map</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">6</span>, <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="co"># Use frequentist analyses for speed</span></span>
<span>    <span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Divorce</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">Marriage</span>, degree <span class="op">=</span> <span class="va">i</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">wd_sub</span><span class="op">)</span></span>
<span>    <span class="va">base</span> <span class="op">+</span></span>
<span>        <span class="fu">geom_smooth</span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">i</span><span class="op">)</span>, level <span class="op">=</span> <span class="fl">.80</span>,</span>
<span>                    fullrange <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">+</span></span>
<span>        <span class="fu">annotate</span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="fl">1.7</span>, y <span class="op">=</span> <span class="fl">1.4</span>,</span>
<span>                 label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"italic(R)^2 == "</span>,</span>
<span>                                <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu">r2</span><span class="op">(</span><span class="va">mod</span>, <span class="va">wd_sub</span><span class="op">$</span><span class="va">Divorce</span><span class="op">)</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                 parse <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">+</span></span>
<span>        <span class="fu">annotate</span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="fl">1.7</span>, y <span class="op">=</span> <span class="fl">1.2</span>,</span>
<span>                 label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"RMSE == "</span>,</span>
<span>                                <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu">rmse</span><span class="op">(</span><span class="va">mod</span>, <span class="va">wd_sub</span><span class="op">$</span><span class="va">Divorce</span><span class="op">)</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                 parse <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/do.call.html">do.call</a></span><span class="op">(</span><span class="va">grid.arrange</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">p_list</span>, nrow <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div id="fig-overfit" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-overfit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="07-model-comparison_files/figure-html/fig-overfit-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-overfit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11.1: Fit of models on the 10 random cases. Top panel: linear, quadratic, and cubic; bottom panel: 4th, 5th, and 6th degree polynomials
</figcaption></figure>
</div>
</div>
</div>
<p>Another way to look at model accuracy is the <em>Root Mean Squared Error</em> (RMSE), defined as the square root of the average squared prediction error. RMSE is a measure of prediction error. The smaller the RMSE, the better the prediction is. As you can see in the above figure, more complex models always reduce the RMSE in the data we use to fit the model (also called training data).</p>
<p>However, if I take the estimated regression line/curve based on the subsample of 10 observations, and predict the remaining cases in the data set, things will be different. As you can see in the figure below, whereas prediction error is comparable for the linear and the quadratic model, polynomials of higher degrees predict the data really badly. When you use a complex model in a data set, it tailors the coefficients to any sampling errors and noise in the data such that it will not generalize to new observations. Therefore, our goal in model comparison is to choose a model complex enough to capture the essence of the data generation process (and thus avoid <em>underfitting</em>), but not too complex such that it suffers from <em>overfitting</em>.</p>
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">base2</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">Marriage</span>, y <span class="op">=</span> <span class="va">Divorce</span><span class="op">)</span>,</span>
<span>               data <span class="op">=</span> <span class="va">waffle_divorce</span><span class="op">[</span><span class="op">-</span><span class="va">train</span>, <span class="op">]</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">geom_point</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">coord_cartesian</span><span class="op">(</span>ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.6</span>, <span class="fl">1.4</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">xlim</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">waffle_divorce</span><span class="op">$</span><span class="va">Marriage</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># Create six plots through a loop</span></span>
<span><span class="va">p_list2</span> <span class="op">&lt;-</span> <span class="fu">map</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">6</span>, <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="co"># Use frequentist analyses for speed</span></span>
<span>    <span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Divorce</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">Marriage</span>, degree <span class="op">=</span> <span class="va">i</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">wd_sub</span><span class="op">)</span></span>
<span>    <span class="co"># New data and response</span></span>
<span>    <span class="va">test_dat</span> <span class="op">&lt;-</span> <span class="va">waffle_divorce</span><span class="op">[</span><span class="op">-</span><span class="va">train</span>, <span class="op">]</span></span>
<span>    <span class="va">ynew</span> <span class="op">&lt;-</span> <span class="va">test_dat</span><span class="op">$</span><span class="va">Divorce</span></span>
<span>    <span class="va">base2</span> <span class="op">+</span></span>
<span>        <span class="fu">geom_smooth</span><span class="op">(</span>data <span class="op">=</span> <span class="va">wd_sub</span>, method <span class="op">=</span> <span class="st">"lm"</span>, formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">i</span><span class="op">)</span>,</span>
<span>                    level <span class="op">=</span> <span class="fl">.80</span>, fullrange <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">+</span></span>
<span>        <span class="fu">annotate</span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="fl">1.7</span>, y <span class="op">=</span> <span class="fl">1.4</span>,</span>
<span>                 label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"italic(R)^2 == "</span>,</span>
<span>                                <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu">r2</span><span class="op">(</span><span class="va">mod</span>, <span class="va">ynew</span>, <span class="va">test_dat</span><span class="op">)</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                 parse <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">+</span></span>
<span>        <span class="fu">annotate</span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="fl">1.7</span>, y <span class="op">=</span> <span class="fl">1.2</span>,</span>
<span>                 label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"RMSE == "</span>,</span>
<span>                                <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu">rmse</span><span class="op">(</span><span class="va">mod</span>, <span class="va">ynew</span>, <span class="va">test_dat</span><span class="op">)</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                 parse <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/do.call.html">do.call</a></span><span class="op">(</span><span class="va">grid.arrange</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">p_list2</span>, nrow <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div id="fig-overfit-generalize" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-overfit-generalize-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="07-model-comparison_files/figure-html/fig-overfit-generalize-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-overfit-generalize-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11.2: Using the regression lines based on 10 random cases to predict the remaining 40 cases. Top panel: linear, quadratic, and cubic; bottom panel: 4th, 5th, and 6th degree polynomials
</figcaption></figure>
</div>
</div>
</div>
<p>The goal of statistical modeling is to choose an optimal model between the overfitting/underfitting dichotomy. In machine learning, this is also commonly referred to as the bias-variance trade-off, as a model that is too simple tends to produce biased predictions because it does not capture the essence of the data generating process. In contrast, a overly complex model is unbiased but results in a lot of uncertainty in the prediction because there are too many unnecessary components that can affect predictions, as indicated in the confidence bands around the 6th-degree polynomial line.</p>
<p>Polynomials of varying degrees are merely one example of comparing simple to complex models. You can think about:</p>
<ul>
<li>models with and without interactions,</li>
<li>models with a few predictors versus hundreds of predictors,</li>
<li>regression analyses versus multilevel models, etc.</li>
</ul>
<p>Whereas one can always avoid underfitting by fitting a more and more complex model, we need tools to keep us from overfitting. This lecture is about finding an optimal model that avoids overfitting and avoids underfitting. You will learn to perform model comparisons with information criteria to find a model that has a better balance between overfitting and underfitting.</p>
</section><section id="kullback-leibler-divergence" class="level2" data-number="11.2"><h2 data-number="11.2" class="anchored" data-anchor-id="kullback-leibler-divergence">
<span class="header-section-number">11.2</span> Kullback-Leibler Divergence</h2>
<p>When comparing models (e.g., linear vs.&nbsp;quadratic), we prefer models closer to the “true” data-generating process. To do so, we need some ways to quantify the degree of “closeness” to the true model. In this context, models comprise both the distributional family <em>and</em> the parameter values. For example, the model <span class="math inline">\(y_i \sim N(5, 2)\)</span> is a different model than <span class="math inline">\(y_i \sim N(3, 2)\)</span>, which is a different model than <span class="math inline">\(y_i \sim \mathrm{Gamma}(2, 2)\)</span>. The first two have the same family but different parameter values (different means, same <span class="math inline">\(\mathit{SD}\)</span>). In contrast, the last two have different distributional families (Normal vs.&nbsp;Gamma).</p>
<p>To measure the degree of “closeness” between two models, <span class="math inline">\(M_0\)</span> and <span class="math inline">\(M_1\)</span>, by far the most popular metric in statistics is the <em>Kullback-Liebler Divergence</em> (or Kullback-Liebler discrepancy; <span class="math inline">\(D_\textrm{KL}\)</span>). By definition,</p>
<p><span class="math display">\[
\begin{aligned}
D_\textrm{KL}(M_0 \mid M_1) &amp; = \int_{-\infty}^\infty p_{M_0} (\boldsymbol{\mathbf{y}})
                    \log \frac{p_{M_0}(\boldsymbol{\mathbf{y}})}{p_{M_1}(\boldsymbol{\mathbf{y}})} \; \mathrm{d}\boldsymbol{\mathbf{y}} \\
                &amp; = \int_{-\infty}^\infty p_{M_0} (\boldsymbol{\mathbf{y}})
                          \log p_{M_0}(\boldsymbol{\mathbf{y}}) \; \mathrm{d}\boldsymbol{\mathbf{y}} -
                    \int_{-\infty}^\infty p_{M_0} (\boldsymbol{\mathbf{y}})
                          \log p_{M_1}(\boldsymbol{\mathbf{y}}) \; \mathrm{d}\boldsymbol{\mathbf{y}}.
\end{aligned}
\]</span></p>
<p>Note that strictly speaking, <span class="math inline">\(D_\textrm{KL}\)</span> cannot be called a “distance” between two models because in general, <span class="math inline">\(D_\textrm{KL}(M_0 \mid M_1) \neq D_\textrm{KL}(M_1 \mid M_0)\)</span>. As an example, assume that the data are generated by a true model <span class="math inline">\(M_0\)</span>, and we have two candidate models <span class="math inline">\(M_1\)</span> and <span class="math inline">\(M_2\)</span>, where</p>
<ul>
<li><span class="math inline">\(M_0: y \sim N(3, 2)\)</span></li>
<li><span class="math inline">\(M_1: y \sim N(3.5, 2.5)\)</span></li>
<li><span class="math inline">\(M_2: y \sim \mathrm{Cauchy}(3, 2)\)</span></li>
</ul>
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">ggplot</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">3</span>, <span class="fl">9</span><span class="op">)</span><span class="op">)</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">stat_function</span><span class="op">(</span>fun <span class="op">=</span> <span class="va">dnorm</span>, args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>mean <span class="op">=</span> <span class="fl">3</span>, sd <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>,</span>
<span>                  <span class="fu">aes</span><span class="op">(</span>col <span class="op">=</span> <span class="st">"M0"</span><span class="op">)</span>, linewidth <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">stat_function</span><span class="op">(</span>fun <span class="op">=</span> <span class="va">dnorm</span>, args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>mean <span class="op">=</span> <span class="fl">3.5</span>, sd <span class="op">=</span> <span class="fl">2.5</span><span class="op">)</span>,</span>
<span>                  <span class="fu">aes</span><span class="op">(</span>col <span class="op">=</span> <span class="st">"M1"</span><span class="op">)</span>, linewidth <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">stat_function</span><span class="op">(</span>fun <span class="op">=</span> <span class="va">dcauchy</span>, args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>location <span class="op">=</span> <span class="fl">3</span>, scale <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>,</span>
<span>                  <span class="fu">aes</span><span class="op">(</span>col <span class="op">=</span> <span class="st">"M2"</span><span class="op">)</span>, linewidth <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">scale_color_manual</span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"black"</span>, <span class="st">"red"</span>, <span class="st">"blue"</span><span class="op">)</span>,</span>
<span>                       labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"M0"</span>, <span class="st">"M1"</span>, <span class="st">"M2"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"y"</span>, y <span class="op">=</span> <span class="st">"density"</span>, col <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div id="fig-divergence" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-divergence-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="07-model-comparison_files/figure-html/fig-divergence-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-divergence-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11.3: Density for <span class="math inline">\(M_0\)</span>, <span class="math inline">\(M_1\)</span>, and <span class="math inline">\(M_2\)</span>
</figcaption></figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">f1</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">x</span>, <span class="fl">3</span>, <span class="fl">2</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">x</span>, <span class="fl">3</span>, <span class="fl">2</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">-</span></span>
<span>        <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">x</span>, <span class="fl">3.5</span>, <span class="fl">2.5</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="va">f2</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">x</span>, <span class="fl">3</span>, <span class="fl">2</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">x</span>, <span class="fl">3</span>, <span class="fl">2</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">-</span></span>
<span>        <span class="fu"><a href="https://rdrr.io/r/stats/Cauchy.html">dcauchy</a></span><span class="op">(</span><span class="va">x</span>, <span class="fl">3</span>, <span class="fl">2</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>One can compute that <span class="math inline">\(D_\textrm{KL}(M_0 \mid M_1) = 0.0631436\)</span> and <span class="math inline">\(D_\textrm{KL}(M_0 \mid M_1) = 0.2592445\)</span>, and so <span class="math inline">\(M_1\)</span> is a better model than <span class="math inline">\(M_2\)</span>.</p>
<p>Note that in the expression of <span class="math inline">\(D_\textrm{KL}\)</span>, when talking about the same target model, the first term is always the same and describes the “true” model, <span class="math inline">\(M_0\)</span>. Therefore, it is sufficient to compare models on the second term, <span class="math inline">\(\int_{-\infty}^\infty p_{M_0} (\boldsymbol{\mathbf{y}}) \log p_{M_1}(\boldsymbol{\mathbf{y}}) \; \mathrm{d}\boldsymbol{\mathbf{y}}\)</span>, which can also be written as <span class="math inline">\(\mathrm{E}=[\log p_{M_1} (\boldsymbol{\mathbf{y}})]\)</span>, i.e., the <em>expected log predictive density</em> (<em>elpd</em>). In other words, a model with a larger elpd is preferred over a model with a smaller elpd.</p>
<p>However, we don’t know what <span class="math inline">\(M_0\)</span> is in real data analysis. If we knew, then we would just need to choose <span class="math inline">\(M_0\)</span> as our model, and there will be no need for model comparisons. In addition, even if we know that the true model is, e.g., a normal model (which never happens in real data analysis), we still need to estimate the parameter values, and the estimates will not be exactly the same as the true parameter values. However, elpd is defined as the expected value over the true predictive distribution, <span class="math inline">\(p_{M_0}(y)\)</span>, which cannot be obtained without knowing what <span class="math inline">\(M_0\)</span> is.</p>
<p>So instead, we need to estimate the elpd. A naive way to estimate it is to use the data distribution in place of the true model, but that will lead to an overly optimistic estimate as the sample data are noisy. Computing elpd this way will always favor a more complex model. The ideal way is to collect data on a new, independent sample that share the same data generating process as the current sample, and estimate elpd on the new sample. This is called <em>out-of-sample validation</em>. The problem, of course, is that we usually do not have the resources to collect a new sample.</p>
<p>Therefore, statisticians have worked hard to find ways to estimate elpd from the current sample, and there are two broad approaches:</p>
<ul>
<li>Information criteria: AIC, DIC, and WAIC, which estimate the elpd in the current sample, minus a correction factor</li>
<li>Cross-validation, which splits the current sample into <span class="math inline">\(K\)</span> parts, estimates the parameters in <span class="math inline">\(K - 1\)</span> parts, and estimates the elpd in the remaining part. A special case is when <span class="math inline">\(K\)</span> = <span class="math inline">\(N\)</span>, each time one uses <span class="math inline">\(N\)</span> - 1 data points to estimate the model parameters, and estimate the elpd for the observation that was left out. This is called <em>leave-one-out</em> cross-validation (LOO-CV).</li>
</ul></section><section id="deviance" class="level2" data-number="11.3"><h2 data-number="11.3" class="anchored" data-anchor-id="deviance">
<span class="header-section-number">11.3</span> Deviance</h2>
<p>Without going too deep into the underlying math, it can be shown that a good estimate of elpd is</p>
<p><span class="math display">\[
\sum_{i = 1}^n \log p_{M_1}(y_i) - p,
\]</span></p>
<p>where <span class="math inline">\(p\)</span> is some measure of the number of parameters in <span class="math inline">\(M_1\)</span>. The first term is the likelihood of the model in the current sample. The second term is an adjustment factor so that the quantity above represents the average likelihood of the model <em>in a new sample</em>. It is more common to work with <em>deviance</em> by multiplying the log-likelihood by <span class="math inline">\(-2\)</span>, i.e.,</p>
<p><span class="math display">\[
D = -2 \sum_{i = 1}^n \log p_{M_1}(y_i).
\]</span></p>
<section id="experiment-on-deviance" class="level3" data-number="11.3.1"><h3 data-number="11.3.1" class="anchored" data-anchor-id="experiment-on-deviance">
<span class="header-section-number">11.3.1</span> Experiment on Deviance</h3>
<p>Now, let’s check the in-sample deviance and out-of-sample deviance of our <code>waffle_divorce</code> data with different polynomial functions. Here is a sample function for computing elpd (with frequentist, just for speed) for polynomials of different degrees:</p>
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Function for computing deviance with different polynomial</span></span>
<span><span class="va">deviance_divorce</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">degree</span> <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                             <span class="va">train</span> <span class="op">=</span> <span class="fl">10</span>,</span>
<span>                             <span class="va">y</span> <span class="op">=</span> <span class="va">waffle_divorce</span><span class="op">$</span><span class="va">Divorce</span>,</span>
<span>                             <span class="va">x</span> <span class="op">=</span> <span class="va">waffle_divorce</span><span class="op">$</span><span class="va">Marriage</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">N</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></span>
<span>    <span class="co"># get training sample</span></span>
<span>    <span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">train</span><span class="op">)</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span> <span class="op">{</span></span>
<span>        <span class="va">train</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample.int</a></span><span class="op">(</span><span class="va">N</span>, <span class="va">train</span><span class="op">)</span></span>
<span>    <span class="op">}</span></span>
<span>    <span class="va">ntrain</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">train</span><span class="op">)</span></span>
<span>    <span class="co"># Obtain design matrix</span></span>
<span>    <span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">degree</span>, simple <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="co"># Get elpd for training sample</span></span>
<span>    <span class="va">Xtrain</span> <span class="op">&lt;-</span> <span class="va">X</span><span class="op">[</span><span class="va">train</span>, <span class="op">]</span></span>
<span>    <span class="va">ytrain</span> <span class="op">&lt;-</span> <span class="va">y</span><span class="op">[</span><span class="va">train</span><span class="op">]</span></span>
<span>    <span class="va">betahat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/qr.html">qr.solve</a></span><span class="op">(</span><span class="va">Xtrain</span>, <span class="va">ytrain</span><span class="op">)</span>  <span class="co"># estimated betas</span></span>
<span>    <span class="va">res_train</span> <span class="op">&lt;-</span> <span class="va">ytrain</span> <span class="op">-</span> <span class="va">Xtrain</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">betahat</span></span>
<span>    <span class="va">sigmahat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">res_train</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span> <span class="op">/</span></span>
<span>        <span class="op">(</span><span class="va">ntrain</span> <span class="op">-</span> <span class="fl">1</span> <span class="op">-</span> <span class="va">degree</span><span class="op">)</span><span class="op">)</span> <span class="co"># estimated sigma</span></span>
<span>    <span class="va">deviance_train</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fl">2</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">res_train</span>, sd <span class="op">=</span> <span class="va">sigmahat</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="va">res_test</span> <span class="op">&lt;-</span> <span class="va">y</span><span class="op">[</span><span class="op">-</span><span class="va">train</span><span class="op">]</span> <span class="op">-</span> <span class="va">X</span><span class="op">[</span><span class="op">-</span><span class="va">train</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">betahat</span></span>
<span>    <span class="va">deviance_test</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fl">2</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">res_test</span>, sd <span class="op">=</span> <span class="va">sigmahat</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>        degree <span class="op">=</span> <span class="va">degree</span>,</span>
<span>        sample <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"in-sample"</span>, <span class="st">"out-of-sample"</span><span class="op">)</span>,</span>
<span>        deviance <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">deviance_train</span> <span class="op">/</span> <span class="va">ntrain</span>,</span>
<span>                     <span class="va">deviance_test</span> <span class="op">/</span> <span class="op">(</span><span class="va">N</span> <span class="op">-</span> <span class="va">ntrain</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Below shows the in-sample and out-of-sample elpd for the linear model:</p>
<div class="cell">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">deviance_divorce</span><span class="op">(</span>degree <span class="op">=</span> <span class="fl">1</span>, train <span class="op">=</span> <span class="va">train</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div data-pagedtable="false">
  <script data-pagedtable-source="" type="application/json">
{"columns":[{"label":["degree"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["sample"],"name":[2],"type":["chr"],"align":["left"]},{"label":["deviance"],"name":[3],"type":["dbl"],"align":["right"]}],"data":[{"1":"1","2":"in-sample","3":"-2.37580"},{"1":"1","2":"out-of-sample","3":"3.78599"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
<p>And for quadratic:</p>
<div class="cell">
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">deviance_divorce</span><span class="op">(</span>degree <span class="op">=</span> <span class="fl">2</span>, train <span class="op">=</span> <span class="va">train</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div data-pagedtable="false">
  <script data-pagedtable-source="" type="application/json">
{"columns":[{"label":["degree"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["sample"],"name":[2],"type":["chr"],"align":["left"]},{"label":["deviance"],"name":[3],"type":["dbl"],"align":["right"]}],"data":[{"1":"2","2":"in-sample","3":"-2.342268"},{"1":"2","2":"out-of-sample","3":"3.048412"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
<p>In general, as you can see, the deviance is smaller for the current data than for the hold-out data. Note that because the training and testing data sets have different sizes, I divided the deviance by the sample size so that they can be compared.</p>
<p>Now let’s run an experiment to check the elpd with different degrees polynomial, with a training sample size of 25:</p>
<div class="cell">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1733</span><span class="op">)</span></span>
<span><span class="co"># Use the `map` function to run different polynomials, and use the `rerun`</span></span>
<span><span class="co"># function run the deviance 100 times. The code below runs `deviance_divorce` by</span></span>
<span><span class="co"># randomly sampling 25 training samples 100 times, and compute the in-sample</span></span>
<span><span class="co"># and out-of-sample deviance for each.</span></span>
<span><span class="co"># rerun(100, deviance_divorce(degree = 1, train = 25L)) |&gt;</span></span>
<span><span class="co">#     bind_rows()</span></span>
<span><span class="co"># Now run 1 to 4 degree polynomial, each 1000 times:</span></span>
<span><span class="va">dev_list</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">4</span>, FUN <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">p</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">replicate</a></span><span class="op">(</span><span class="fl">1000</span>, <span class="fu">deviance_divorce</span><span class="op">(</span>degree <span class="op">=</span> <span class="va">p</span>, train <span class="op">=</span> <span class="fl">25L</span><span class="op">)</span>, simplify <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/do.call.html">do.call</a></span><span class="op">(</span><span class="va">rbind</span>, <span class="va">results</span><span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span></span>
<span><span class="va">dev_df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/do.call.html">do.call</a></span><span class="op">(</span><span class="va">rbind</span>, <span class="va">dev_list</span><span class="op">)</span></span>
<span><span class="co"># Plot the results</span></span>
<span><span class="va">dev_df</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">degree</span>, y <span class="op">=</span> <span class="va">deviance</span>, col <span class="op">=</span> <span class="va">sample</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">stat_summary</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">stat_summary</span><span class="op">(</span>geom <span class="op">=</span> <span class="st">"line"</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">labs</span><span class="op">(</span>col <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>No summary function supplied, defaulting to `mean_se()`
No summary function supplied, defaulting to `mean_se()`</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="07-model-comparison_files/figure-html/dev_df-plot-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>As you can see, the in-sample deviance (red line) keeps decreasing, indicating that a more complex model fits the data better, which is always the case. So if one were to use deviance to determine what model is optimal, one would always choose the most complex model, just like using <span class="math inline">\(R^2\)</span> (indeed, for linear models, deviance is basically the same as <span class="math inline">\(R^2\)</span>).</p>
<p>Now, look at the blue line, which represents the deviance computed using the coefficients obtained from the training set but applied to the remaining data. As you can see, the deviance achieves its minimum around the linear and the quadratic model, and starts to increase, meaning that the more complex models do not fit the hold-out data.</p>
<p>A statistical model is used to learn something from a data set that can generalize to other observations. Therefore, we should care about the blue line, instead of the red one. The indices you will see in the remaining of this note are all attempts to approximate the blue line.</p>
<blockquote class="blockquote">
<p>More complex models always fit the current data better, but may not generalize to other data. In other words, models that are too complex are not generalizable.</p>
</blockquote>
</section></section><section id="information-criteria" class="level2" data-number="11.4"><h2 data-number="11.4" class="anchored" data-anchor-id="information-criteria">
<span class="header-section-number">11.4</span> Information Criteria</h2>
<p>We will illustrate the computation of information criteria with <code>Marriage</code> predicting <code>Divorce</code>:</p>
<div class="cell">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">m1</span> <span class="op">&lt;-</span> <span class="fu">brm</span><span class="op">(</span><span class="va">Divorce</span> <span class="op">~</span> <span class="va">Marriage</span>, data <span class="op">=</span> <span class="va">waffle_divorce</span>,</span>
<span>          prior <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu">prior</span><span class="op">(</span><span class="fu">student_t</span><span class="op">(</span><span class="fl">4</span>, <span class="fl">0</span>, <span class="fl">5</span><span class="op">)</span>, class <span class="op">=</span> <span class="st">"Intercept"</span><span class="op">)</span>,</span>
<span>                    <span class="fu">prior</span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">2</span><span class="op">)</span>, class <span class="op">=</span> <span class="st">"b"</span><span class="op">)</span>,</span>
<span>                    <span class="fu">prior</span><span class="op">(</span><span class="fu">student_t</span><span class="op">(</span><span class="fl">4</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>, class <span class="op">=</span> <span class="st">"sigma"</span><span class="op">)</span><span class="op">)</span>,</span>
<span>          iter <span class="op">=</span> <span class="fl">4000</span>,</span>
<span>          seed <span class="op">=</span> <span class="fl">2302</span>,</span>
<span>          file <span class="op">=</span> <span class="st">"07_m1"</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Start sampling</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: rstan</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: StanHeaders</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
rstan version 2.32.5 (Stan version 2.32.2)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>For execution on a local, multicore CPU with excess RAM we recommend calling
options(mc.cores = parallel::detectCores()).
To avoid recompilation of unchanged Stan programs, we recommend calling
rstan_options(auto_write = TRUE)
For within-chain threading using `reduce_sum()` or `map_rect()` Stan functions,
change `threads_per_chain` option:
rstan_options(threads_per_chain = 1)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'rstan'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following objects are masked from 'package:posterior':

    ess_bulk, ess_tail</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following object is masked from 'package:tidyr':

    extract</code></pre>
</div>
</div>
<section id="akaike-information-criteria-aic" class="level3" data-number="11.4.1"><h3 data-number="11.4.1" class="anchored" data-anchor-id="akaike-information-criteria-aic">
<span class="header-section-number">11.4.1</span> Akaike Information Criteria (AIC)</h3>
<p>Multiplying the quantity of elpd - <span class="math inline">\(p\)</span> by <span class="math inline">\(-2\)</span>, or deviance + 2<span class="math inline">\(p\)</span>, with the deviance obtained using the maximum likelihood estimates (MLEs) for the parameters, gives you the formula for AIC:</p>
<p><span class="math display">\[
\textrm{AIC} = D(\hat \theta) + 2p,
\]</span></p>
<p>and <span class="math inline">\(p\)</span> in AIC is just the number of parameters. As we have multiplied by a negative number, maximizing the estimate of elpd is equivalent to minimizing the AIC, so one would prefer a model with the smallest AIC.</p>
<p>The AIC is not Bayesian because it only uses point estimates (MLEs) of parameters rather than their posterior distributions. Also, it does not take into account any prior information.</p>
<div class="cell">
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Frequentist model</span></span>
<span><span class="va">m1_freq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">m1</span><span class="op">$</span><span class="va">formula</span>, data <span class="op">=</span> <span class="va">m1</span><span class="op">$</span><span class="va">data</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/AIC.html">AIC</a></span><span class="op">(</span><span class="va">m1_freq</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -30.96869</code></pre>
</div>
</div>
</section><section id="deviance-information-criteria-dic" class="level3" data-number="11.4.2"><h3 data-number="11.4.2" class="anchored" data-anchor-id="deviance-information-criteria-dic">
<span class="header-section-number">11.4.2</span> Deviance Information Criteria (DIC)</h3>
<p>The definition of AIC assumes that the parameter estimates are known or are maximum likelihood estimates. The DIC, instead, replaces those with the posterior distribution of the parameters. The general formula for DIC is</p>
<p><span class="math display">\[
\textrm{DIC} = \mathrm{E}(D \mid \boldsymbol{\mathbf{y}}) + 2 p_D,
\]</span></p>
<p>where <span class="math inline">\(p_D\)</span> is the effective number of parameters estimated in the Markov chain. Although DIC does take into account the prior distributions, it does not consider the full posterior distributions of the parameters.</p>
<div class="cell">
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Function to compute DIC</span></span>
<span><span class="va">dic_brmsfit</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">object</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">Dbar</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fl">2</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowSums</a></span><span class="op">(</span><span class="fu">log_lik</span><span class="op">(</span><span class="va">object</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="va">res</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/residuals.html">residuals</a></span><span class="op">(</span><span class="va">object</span><span class="op">)</span><span class="op">[</span> , <span class="st">"Estimate"</span><span class="op">]</span></span>
<span>    <span class="va">sigma</span> <span class="op">&lt;-</span> <span class="fu">posterior_summary</span><span class="op">(</span><span class="va">object</span>, variable <span class="op">=</span> <span class="st">"sigma"</span><span class="op">)</span><span class="op">[</span> , <span class="st">"Estimate"</span><span class="op">]</span></span>
<span>    <span class="va">Dhat</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fl">2</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">res</span>, sd <span class="op">=</span> <span class="va">sigma</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="va">p</span> <span class="op">&lt;-</span> <span class="va">Dbar</span> <span class="op">-</span> <span class="va">Dhat</span></span>
<span>    <span class="va">elpd</span> <span class="op">&lt;-</span> <span class="va">Dhat</span> <span class="op">/</span> <span class="op">-</span><span class="fl">2</span> <span class="op">-</span> <span class="va">p</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>elpd_dic <span class="op">=</span> <span class="va">elpd</span>, p_dic <span class="op">=</span> <span class="va">p</span>, dic <span class="op">=</span> <span class="va">Dhat</span> <span class="op">+</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">p</span>,</span>
<span>               row.names <span class="op">=</span> <span class="st">"Estimate"</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="fu">dic_brmsfit</span><span class="op">(</span><span class="va">m1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div data-pagedtable="false">
  <script data-pagedtable-source="" type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["elpd_dic"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["p_dic"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["dic"],"name":[3],"type":["dbl"],"align":["right"]}],"data":[{"1":"15.35638","2":"3.124112","3":"-30.71276","_rn_":"Estimate"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
</section><section id="watanabe-akaike-information-criteria-waic" class="level3" data-number="11.4.3"><h3 data-number="11.4.3" class="anchored" data-anchor-id="watanabe-akaike-information-criteria-waic">
<span class="header-section-number">11.4.3</span> Watanabe-Akaike Information Criteria (WAIC)</h3>
<p>A further modification is to use the <em>log pointwise posterior predictive density</em>, with the effective number of parameters computed using the posterior variance of the likelihood.</p>
<p><span class="math display">\[
\textrm{WAIC} = -2 \sum_{i = 1}^n \log \mathrm{E}[p(y_i \mid \boldsymbol{\mathbf{\theta}}, \boldsymbol{\mathbf{y}})] +
                  2 p_\textrm{WAIC},
\]</span></p>
<p>where <span class="math inline">\(\mathrm{E}[p(y_i \mid \boldsymbol{\mathbf{\theta}}, \boldsymbol{\mathbf{y}})]\)</span> is the posterior mean of the likelihood of the <span class="math inline">\(i\)</span>th observation. The WAIC incorporates prior information, and the use of pointwise likelihood makes it more robust when the posterior distributions deviate from normality. In general, WAIC is a better estimate of the out-of-sample deviance than AIC and DIC.</p>
<div class="cell">
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">waic</span><span class="op">(</span><span class="va">m1</span><span class="op">)</span>  <span class="co"># built-in function in brms</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: 
1 (2.0%) p_waic estimates greater than 0.4. We recommend trying loo instead.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Computed from 8000 by 50 log-likelihood matrix.

          Estimate  SE
elpd_waic     15.2 4.9
p_waic         3.2 0.9
waic         -30.3 9.9

1 (2.0%) p_waic estimates greater than 0.4. We recommend trying loo instead. </code></pre>
</div>
</div>
</section><section id="leave-one-out-cross-validation" class="level3" data-number="11.4.4"><h3 data-number="11.4.4" class="anchored" data-anchor-id="leave-one-out-cross-validation">
<span class="header-section-number">11.4.4</span> Leave-One-Out Cross-Validation</h3>
<p>The idea of cross-validation is to split the sample so that it imitates the scenario of estimating the parameters in part of the data and predicting the remaining part. The part used for estimation is called the <em>training set</em>, and the part used for prediction is called the <em>validation set</em>. Leave-one-out information criteria (LOO-IC) means that one uses <span class="math inline">\(N - 1\)</span> observations as the training set and 1 observation as the validation sample and repeat the process <span class="math inline">\(N\)</span> times so that a different observation is being predicted each time. Adding up the prediction results will give an estimate of elpd that closely approximates the results that would be obtained by collecting new data and doing the validation. To make it more concrete, we can go back to the <code>waffle_divorce</code> data with <code>Marriage</code> predicting <code>Divorce</code>. We can do this for case #1 (Alabama), as an example:</p>
<div class="cell">
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Estimate the model without case #1</span></span>
<span><span class="va">m1_no1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">m1</span>, newdata <span class="op">=</span> <span class="va">waffle_divorce</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span>, <span class="op">]</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The log predictive density for case #1</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="fu">log_lik</span><span class="op">(</span><span class="va">m1_no1</span>, newdata <span class="op">=</span> <span class="va">waffle_divorce</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -0.8111212</code></pre>
</div>
</div>
<p>Because LOO-IC requires fitting the model <span class="math inline">\(N\)</span> times, it is generally very computationally intensive. There are, however, shortcuts for some models to make the computation faster. WAIC can also be treated as a fast approximation of LOO-IC, although LOO-IC is more robust and will be a better estimate of out-of-sample deviance. The <code>loo</code> package uses the so-called Pareto smoothed importance sampling (PSIS) to approximate LOO-IC without repeating the process <span class="math inline">\(N\)</span> times.</p>
<p>Here is the LOO-IC for the model:</p>
<div class="cell">
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">loo</span><span class="op">(</span><span class="va">m1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Computed from 8000 by 50 log-likelihood matrix.

         Estimate  SE
elpd_loo     15.1 5.0
p_loo         3.3 1.0
looic       -30.2 9.9
------
MCSE of elpd_loo is 0.0.
MCSE and ESS estimates assume MCMC draws (r_eff in [0.7, 1.0]).

All Pareto k estimates are good (k &lt; 0.7).
See help('pareto-k-diagnostic') for details.</code></pre>
</div>
</div>
<p>You can save the WAIC and the LOO-IC information to the fitted result:</p>
<div class="cell">
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">m1</span> <span class="op">&lt;-</span> <span class="fu">add_criterion</span><span class="op">(</span><span class="va">m1</span>, criterion <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"loo"</span>, <span class="st">"waic"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: 
1 (2.0%) p_waic estimates greater than 0.4. We recommend trying loo instead.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Automatically saving the model object in '07_m1.rds'</code></pre>
</div>
</div>
<p>See <span class="citation" data-cites="vehtari2017">Vehtari et al. (<a href="references.html#ref-vehtari2017" role="doc-biblioref">2017</a>)</span> for more discussions on WAIC and LOO-IC.</p>
<hr></section><section id="example" class="level3" data-number="11.4.5"><h3 data-number="11.4.5" class="anchored" data-anchor-id="example">
<span class="header-section-number">11.4.5</span> Example</h3>
<p>Consider four potential models in predicting <code>Divorce</code>:</p>
<p><span class="math display">\[
\texttt{Divorce}_i \sim N(\mu_i, \sigma)
\]</span></p>
<ul>
<li>M1: <code>Marriage</code>
</li>
<li>M2: <code>Marriage</code>, <code>South</code>, <code>Marriage</code> <span class="math inline">\(\times\)</span> <code>South</code>
</li>
<li>M3: <code>South</code>, smoothing spline of <code>Marriage</code> by <code>South</code>
</li>
<li>M4: <code>Marriage</code>, <code>South</code>, <code>MedianAgeMarriage</code>, <code>Marriage</code> <span class="math inline">\(\times\)</span> <code>South</code>, <code>Marriage</code> <span class="math inline">\(\times\)</span> <code>MedianAgeMarriage</code>, <code>South</code> <span class="math inline">\(\times\)</span> <code>MedianAgeMarriage</code>, <code>Marriage</code> <span class="math inline">\(\times\)</span> <code>South</code> <span class="math inline">\(\times\)</span> <code>MedianAgeMarriage</code>
</li>
</ul>
<div class="cell">
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Note, m1 has been fit before; the `update()` function</span></span>
<span><span class="co"># can be used to simply change the formula, and brms will</span></span>
<span><span class="co"># determine whether it needs re-compiling.</span></span>
<span><span class="co"># M2: Add South and interaction</span></span>
<span><span class="va">m2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">m1</span>, formula <span class="op">=</span> <span class="va">Divorce</span> <span class="op">~</span> <span class="va">Marriage</span> <span class="op">*</span> <span class="va">South</span>,</span>
<span>             newdata <span class="op">=</span> <span class="va">waffle_divorce</span><span class="op">)</span></span>
<span><span class="va">m2</span> <span class="op">&lt;-</span> <span class="fu">add_criterion</span><span class="op">(</span><span class="va">m2</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"loo"</span>, <span class="st">"waic"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: 
1 (2.0%) p_waic estimates greater than 0.4. We recommend trying loo instead.</code></pre>
</div>
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># M3: Spline function for Marriage</span></span>
<span><span class="va">m3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">m1</span>, formula <span class="op">=</span> <span class="va">Divorce</span> <span class="op">~</span> <span class="va">South</span> <span class="op">+</span> <span class="fu">s</span><span class="op">(</span><span class="va">Marriage</span>, by <span class="op">=</span> <span class="va">South</span><span class="op">)</span>,</span>
<span>             newdata <span class="op">=</span> <span class="va">waffle_divorce</span>,</span>
<span>             control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>adapt_delta <span class="op">=</span> <span class="fl">.999</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">m3</span> <span class="op">&lt;-</span> <span class="fu">add_criterion</span><span class="op">(</span><span class="va">m3</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"loo"</span>, <span class="st">"waic"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: Found 2 observations with a pareto_k &gt; 0.7 in model 'm3'. We recommend
to set 'moment_match = TRUE' in order to perform moment matching for
problematic observations.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: 
4 (8.0%) p_waic estimates greater than 0.4. We recommend trying loo instead.</code></pre>
</div>
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># M4: Three-way interactions</span></span>
<span><span class="va">m4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">m1</span>, formula <span class="op">=</span> <span class="va">Divorce</span> <span class="op">~</span> <span class="va">Marriage</span> <span class="op">*</span> <span class="va">MedianAgeMarriage</span> <span class="op">*</span> <span class="va">South</span>,</span>
<span>             newdata <span class="op">=</span> <span class="va">waffle_divorce</span>,</span>
<span>             control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>max_treedepth <span class="op">=</span> <span class="fl">12</span><span class="op">)</span><span class="op">)</span>  <span class="co"># increase due to warning</span></span>
<span><span class="va">m4</span> <span class="op">&lt;-</span> <span class="fu">add_criterion</span><span class="op">(</span><span class="va">m4</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"loo"</span>, <span class="st">"waic"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: Found 1 observations with a pareto_k &gt; 0.7 in model 'm4'. We recommend
to set 'moment_match = TRUE' in order to perform moment matching for
problematic observations.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: 
3 (6.0%) p_waic estimates greater than 0.4. We recommend trying loo instead.</code></pre>
</div>
</div>
<p>The first model only has <code>Marriage</code> as a predictor, which means that the coefficients for <code>South</code> and <code>MedianAgeMarriage</code> are assumed to be zero. The second model added <code>South</code> and its interaction with <code>Marriage</code> as a predictor. The third model includes a smoothing spline term (a flexible non-linear function, within the class of linear models), whereas the fourth model also includes <code>MedianAgeMarriage</code> and all two-way and three-way interactions. Now, we can compare the four models:</p>
<div class="cell">
<div class="sourceCode" id="cb45"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">loo_compare</span><span class="op">(</span><span class="va">m1</span>, <span class="va">m2</span>, <span class="va">m3</span>, <span class="va">m4</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   elpd_diff se_diff
m4  0.0       0.0   
m2 -5.3       4.1   
m3 -6.1       4.1   
m1 -8.5       4.3   </code></pre>
</div>
<div class="sourceCode" id="cb47"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># m4 is the best</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb48"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">msummary</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>M1 <span class="op">=</span> <span class="va">m1</span>, M2 <span class="op">=</span> <span class="va">m2</span>, M3 <span class="op">=</span> <span class="va">m3</span>, M4 <span class="op">=</span> <span class="va">m4</span><span class="op">)</span>,</span>
<span>         estimate <span class="op">=</span> <span class="st">"{estimate} [{conf.low}, {conf.high}]"</span>,</span>
<span>         statistic <span class="op">=</span> <span class="cn">NULL</span>, fmt <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: 
`modelsummary` uses the `performance` package to extract goodness-of-fit
statistics from models of this class. You can specify the statistics you wish
to compute by supplying a `metrics` argument to `modelsummary`, which will then
push it forward to `performance`. Acceptable values are: "all", "common",
"none", or a character vector of metrics names. For example: `modelsummary(mod,
metrics = c("RMSE", "R2")` Note that some metrics are computationally
expensive. See `?performance::performance` for details.
 This warning appears once per session.</code></pre>
</div>
<div class="cell-output-display">
<table class="table caption-top table-sm table-striped small" data-quarto-postprocess="true">
<thead><tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th"></th>
<th style="text-align: center;" data-quarto-table-cell-role="th">M1</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">&nbsp;M2</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">&nbsp;M3</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">&nbsp;M4</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">b_Intercept</td>
<td style="text-align: center;">0.61 [0.35, 0.87]</td>
<td style="text-align: center;">0.67 [0.41, 0.92]</td>
<td style="text-align: center;">0.94 [0.89, 0.99]</td>
<td style="text-align: center;">5.50 [1.86, 9.13]</td>
</tr>
<tr class="even">
<td style="text-align: left;">b_Marriage</td>
<td style="text-align: center;">0.18 [0.05, 0.31]</td>
<td style="text-align: center;">0.13 [0.01, 0.26]</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">−1.20 [−2.88, 0.50]</td>
</tr>
<tr class="odd">
<td style="text-align: left;">sigma</td>
<td style="text-align: center;">0.17 [0.14, 0.21]</td>
<td style="text-align: center;">0.16 [0.13, 0.20]</td>
<td style="text-align: center;">0.15 [0.12, 0.19]</td>
<td style="text-align: center;">0.14 [0.11, 0.18]</td>
</tr>
<tr class="even">
<td style="text-align: left;">b_Southsouth</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">−0.62 [−1.44, 0.19]</td>
<td style="text-align: center;">0.10 [−0.03, 0.22]</td>
<td style="text-align: center;">0.34 [−3.00, 3.88]</td>
</tr>
<tr class="odd">
<td style="text-align: left;">b_Marriage × Southsouth</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.36 [−0.03, 0.76]</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.49 [−1.62, 2.81]</td>
</tr>
<tr class="even">
<td style="text-align: left;">bs_sMarriage × SouthnonMsouth_1</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">−0.46 [−3.34, 1.51]</td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">bs_sMarriage × Southsouth_1</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">1.27 [−2.02, 3.54]</td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">sds_sMarriageSouthnonMsouth_1</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.87 [0.05, 2.60]</td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">sds_sMarriageSouthsouth_1</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.48 [0.02, 2.48]</td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">b_MedianAgeMarriage</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">−1.72 [−3.10, −0.32]</td>
</tr>
<tr class="odd">
<td style="text-align: left;">b_Marriage × MedianAgeMarriage</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.45 [−0.22, 1.10]</td>
</tr>
<tr class="even">
<td style="text-align: left;">b_MedianAgeMarriage × Southsouth</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">−0.37 [−1.72, 0.96]</td>
</tr>
<tr class="odd">
<td style="text-align: left; box-shadow: 0px 1.5px;">b_Marriage × MedianAgeMarriage × Southsouth</td>
<td style="text-align: center; box-shadow: 0px 1.5px;"></td>
<td style="text-align: center; box-shadow: 0px 1.5px;"></td>
<td style="text-align: center; box-shadow: 0px 1.5px;"></td>
<td style="text-align: center; box-shadow: 0px 1.5px;">−0.07 [−1.08, 0.88]</td>
</tr>
<tr class="even">
<td style="text-align: left;">Num.Obs.</td>
<td style="text-align: center;">50</td>
<td style="text-align: center;">50</td>
<td style="text-align: center;">50</td>
<td style="text-align: center;">50</td>
</tr>
<tr class="odd">
<td style="text-align: left;">R2</td>
<td style="text-align: center;">0.139</td>
<td style="text-align: center;">0.305</td>
<td style="text-align: center;">0.388</td>
<td style="text-align: center;">0.490</td>
</tr>
<tr class="even">
<td style="text-align: left;">R2 Adj.</td>
<td style="text-align: center;">0.072</td>
<td style="text-align: center;">0.209</td>
<td style="text-align: center;">0.164</td>
<td style="text-align: center;">0.367</td>
</tr>
<tr class="odd">
<td style="text-align: left;">ELPD</td>
<td style="text-align: center;">15.1</td>
<td style="text-align: center;">18.3</td>
<td style="text-align: center;">17.5</td>
<td style="text-align: center;">23.7</td>
</tr>
<tr class="even">
<td style="text-align: left;">ELPD s.e.</td>
<td style="text-align: center;">5.0</td>
<td style="text-align: center;">5.5</td>
<td style="text-align: center;">5.9</td>
<td style="text-align: center;">6.1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">LOOIC</td>
<td style="text-align: center;">−30.2</td>
<td style="text-align: center;">−36.7</td>
<td style="text-align: center;">−35.1</td>
<td style="text-align: center;">−47.3</td>
</tr>
<tr class="even">
<td style="text-align: left;">LOOIC s.e.</td>
<td style="text-align: center;">9.9</td>
<td style="text-align: center;">11.0</td>
<td style="text-align: center;">11.9</td>
<td style="text-align: center;">12.3</td>
</tr>
<tr class="odd">
<td style="text-align: left;">WAIC</td>
<td style="text-align: center;">−30.3</td>
<td style="text-align: center;">−36.8</td>
<td style="text-align: center;">−36.7</td>
<td style="text-align: center;">−48.1</td>
</tr>
<tr class="even">
<td style="text-align: left;">RMSE</td>
<td style="text-align: center;">0.17</td>
<td style="text-align: center;">0.15</td>
<td style="text-align: center;">0.14</td>
<td style="text-align: center;">0.13</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Model 4 has the lowest LOO-IC, so one may conclude that Model 4 is the best model among the four, <strong>for prediction purposes</strong>.</p>
<hr>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list" style="display: none">
<div id="ref-vehtari2017" class="csl-entry" role="listitem">
Vehtari, A., Gelman, A., &amp; Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC. <em>Statistics and Computing</em>, <em>27</em>(5), 1413–1432. <a href="https://doi.org/10.1007/s11222-016-9696-4">https://doi.org/10.1007/s11222-016-9696-4</a>
</div>
</div>
</section></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./06c-regression-diagnostics.html" class="pagination-link" aria-label="Model Diagnostics">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Model Diagnostics</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./07b-stacking-and-regularization.html" class="pagination-link" aria-label="Stacking, Regularization, and Variable Selection">
        <span class="nav-page-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Stacking, Regularization, and Variable Selection</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb50" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Model Comparison</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>\newcommand{\E}{\mathrm{E}}</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>\newcommand{\bv}<span class="co">[</span><span class="ot">1</span><span class="co">]</span>{\boldsymbol{\mathbf{#1}}}</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>\newcommand{\SD}{\mathit{SD}}</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>\newcommand{\DKL}{D_\textrm{KL}}</span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>\newcommand{\dd}{\; \mathrm{d}}</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: false</span></span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a>comma <span class="ot">&lt;-</span> <span class="cf">function</span>(x, <span class="at">digits =</span> <span class="dv">2</span>L) <span class="fu">format</span>(x, <span class="at">digits =</span> digits, <span class="at">big.mark =</span> <span class="st">","</span>)</span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_set</span>(<span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb50-16"><a href="#cb50-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme</span>(<span class="at">panel.grid.major.y =</span> <span class="fu">element_line</span>(<span class="at">color =</span> <span class="st">"grey92"</span>)))</span>
<span id="cb50-17"><a href="#cb50-17" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span>
<span id="cb50-18"><a href="#cb50-18" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(posterior)</span>
<span id="cb50-19"><a href="#cb50-19" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(brms)</span>
<span id="cb50-20"><a href="#cb50-20" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">brms.backend =</span> <span class="st">"cmdstanr"</span>)</span>
<span id="cb50-21"><a href="#cb50-21" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(modelsummary)</span>
<span id="cb50-22"><a href="#cb50-22" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-23"><a href="#cb50-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-24"><a href="#cb50-24" aria-hidden="true" tabindex="-1"></a><span class="fu">## Overfitting and Underfitting</span></span>
<span id="cb50-25"><a href="#cb50-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-26"><a href="#cb50-26" aria-hidden="true" tabindex="-1"></a>In statistical modeling, a more complex model almost always results in a better fit to the data. Roughly speaking, a more complex model means a model with more parameters. However, as you will see later, determining the number of parameters in Bayesian analyses is not straightforward. On the extreme side, if one has 10 observations, a model with 10 parameters will perfectly predict every single data point (by just having a parameter to predict each data point). However, there are two problems with too complex a model. First, an increasingly complex model makes it increasingly hard to extract useful information from the data. Instead of describing the relationship between two variables, like <span class="in">`Marriage`</span> and <span class="in">`Divorce`</span>, by a straight line, one ends up with a crazy model that is difficult to make sense of. Second, as you will also see, the more complex a model, the more is the risk that it *overfits* the current data, such that it does not work for future observations.</span>
<span id="cb50-27"><a href="#cb50-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-28"><a href="#cb50-28" aria-hidden="true" tabindex="-1"></a>For example, let's randomly sample 10 states in the <span class="in">`waffle_divorce`</span> data set and build some models.</span>
<span id="cb50-29"><a href="#cb50-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-32"><a href="#cb50-32" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-33"><a href="#cb50-33" aria-hidden="true" tabindex="-1"></a>waffle_divorce <span class="ot">&lt;-</span> <span class="fu">read_delim</span>(  <span class="co"># read delimited files</span></span>
<span id="cb50-34"><a href="#cb50-34" aria-hidden="true" tabindex="-1"></a>    <span class="st">"data/WaffleDivorce.csv"</span>,</span>
<span id="cb50-35"><a href="#cb50-35" aria-hidden="true" tabindex="-1"></a>    <span class="at">delim =</span> <span class="st">";"</span></span>
<span id="cb50-36"><a href="#cb50-36" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb50-37"><a href="#cb50-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Rescale Marriage and Divorce by dividing by 10</span></span>
<span id="cb50-38"><a href="#cb50-38" aria-hidden="true" tabindex="-1"></a>waffle_divorce<span class="sc">$</span>Marriage <span class="ot">&lt;-</span> waffle_divorce<span class="sc">$</span>Marriage <span class="sc">/</span> <span class="dv">10</span></span>
<span id="cb50-39"><a href="#cb50-39" aria-hidden="true" tabindex="-1"></a>waffle_divorce<span class="sc">$</span>Divorce <span class="ot">&lt;-</span> waffle_divorce<span class="sc">$</span>Divorce <span class="sc">/</span> <span class="dv">10</span></span>
<span id="cb50-40"><a href="#cb50-40" aria-hidden="true" tabindex="-1"></a>waffle_divorce<span class="sc">$</span>MedianAgeMarriage <span class="ot">&lt;-</span> waffle_divorce<span class="sc">$</span>MedianAgeMarriage <span class="sc">/</span> <span class="dv">10</span></span>
<span id="cb50-41"><a href="#cb50-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Recode `South` to a factor variable</span></span>
<span id="cb50-42"><a href="#cb50-42" aria-hidden="true" tabindex="-1"></a>waffle_divorce<span class="sc">$</span>South <span class="ot">&lt;-</span> <span class="fu">factor</span>(waffle_divorce<span class="sc">$</span>South,</span>
<span id="cb50-43"><a href="#cb50-43" aria-hidden="true" tabindex="-1"></a>    <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb50-44"><a href="#cb50-44" aria-hidden="true" tabindex="-1"></a>    <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"non-south"</span>, <span class="st">"south"</span>)</span>
<span id="cb50-45"><a href="#cb50-45" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb50-46"><a href="#cb50-46" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-47"><a href="#cb50-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-50"><a href="#cb50-50" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-51"><a href="#cb50-51" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1547</span>)  <span class="co"># set the seed for reproducibility</span></span>
<span id="cb50-52"><a href="#cb50-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample 10 observations</span></span>
<span id="cb50-53"><a href="#cb50-53" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> <span class="fu">sample.int</span>(<span class="fu">nrow</span>(waffle_divorce), <span class="dv">10</span>L)</span>
<span id="cb50-54"><a href="#cb50-54" aria-hidden="true" tabindex="-1"></a>wd_sub <span class="ot">&lt;-</span> waffle_divorce[train, ]</span>
<span id="cb50-55"><a href="#cb50-55" aria-hidden="true" tabindex="-1"></a>base <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Marriage, <span class="at">y =</span> Divorce),</span>
<span id="cb50-56"><a href="#cb50-56" aria-hidden="true" tabindex="-1"></a>               <span class="at">data =</span> wd_sub) <span class="sc">+</span></span>
<span id="cb50-57"><a href="#cb50-57" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb50-58"><a href="#cb50-58" aria-hidden="true" tabindex="-1"></a>    <span class="fu">coord_cartesian</span>(<span class="at">ylim =</span> <span class="fu">c</span>(<span class="fl">0.6</span>, <span class="fl">1.4</span>)) <span class="sc">+</span></span>
<span id="cb50-59"><a href="#cb50-59" aria-hidden="true" tabindex="-1"></a>    <span class="fu">xlim</span>(<span class="fu">range</span>(waffle_divorce<span class="sc">$</span>Marriage))</span>
<span id="cb50-60"><a href="#cb50-60" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(waffle_divorce,</span>
<span id="cb50-61"><a href="#cb50-61" aria-hidden="true" tabindex="-1"></a>       <span class="fu">aes</span>(<span class="at">x =</span> Marriage, <span class="at">y =</span> Divorce)) <span class="sc">+</span> </span>
<span id="cb50-62"><a href="#cb50-62" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="at">col =</span> <span class="st">"lightblue"</span>) <span class="sc">+</span></span>
<span id="cb50-63"><a href="#cb50-63" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">1.5</span>, <span class="at">data =</span> wd_sub, <span class="at">col =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb50-64"><a href="#cb50-64" aria-hidden="true" tabindex="-1"></a>    <span class="fu">coord_cartesian</span>(<span class="at">ylim =</span> <span class="fu">c</span>(<span class="fl">0.6</span>, <span class="fl">1.4</span>)) <span class="sc">+</span></span>
<span id="cb50-65"><a href="#cb50-65" aria-hidden="true" tabindex="-1"></a>    <span class="fu">xlim</span>(<span class="fu">range</span>(waffle_divorce<span class="sc">$</span>Marriage))</span>
<span id="cb50-66"><a href="#cb50-66" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-67"><a href="#cb50-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-68"><a href="#cb50-68" aria-hidden="true" tabindex="-1"></a>When using <span class="in">`Marriage`</span> to predict <span class="in">`Divorce`</span>, we can use beyond a linear regression line by using higher-order *polynomials*. For example, a second-order polynomial represents a quadratic effect (with one turning point); it goes to cubic, quartic, and more. The figure below shows the fit from a linear effect of <span class="in">`Marriage`</span>, a quadratic effect, and increasingly complex models up to a sixth-degree polynomial. As you can see, as the model gets more complex, the fitted line tries to capture all the 10 points really well, with an increasing $R^2$. However, the standard error around the fitted line also gets larger and bizarre, meaning more uncertainty in the model parameters.</span>
<span id="cb50-69"><a href="#cb50-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-72"><a href="#cb50-72" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-73"><a href="#cb50-73" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-overfit</span></span>
<span id="cb50-74"><a href="#cb50-74" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb50-75"><a href="#cb50-75" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Fit of models on the 10 random cases. Top panel: linear, quadratic, and cubic; bottom panel: 4th, 5th, and 6th degree polynomials"</span></span>
<span id="cb50-76"><a href="#cb50-76" aria-hidden="true" tabindex="-1"></a>r2 <span class="ot">&lt;-</span> <span class="cf">function</span>(object, newresp, newdata) {</span>
<span id="cb50-77"><a href="#cb50-77" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Function for computing R^2</span></span>
<span id="cb50-78"><a href="#cb50-78" aria-hidden="true" tabindex="-1"></a>    ypred <span class="ot">&lt;-</span> <span class="fu">predict</span>(object, <span class="at">newdata =</span> newdata)</span>
<span id="cb50-79"><a href="#cb50-79" aria-hidden="true" tabindex="-1"></a>    <span class="fu">cor</span>(ypred, newresp)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb50-80"><a href="#cb50-80" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb50-81"><a href="#cb50-81" aria-hidden="true" tabindex="-1"></a>rmse <span class="ot">&lt;-</span> <span class="cf">function</span>(object, newresp, newdata) {</span>
<span id="cb50-82"><a href="#cb50-82" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Function for RMSE</span></span>
<span id="cb50-83"><a href="#cb50-83" aria-hidden="true" tabindex="-1"></a>    ypred <span class="ot">&lt;-</span> <span class="fu">predict</span>(object, <span class="at">newdata =</span> newdata)</span>
<span id="cb50-84"><a href="#cb50-84" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sqrt</span>(<span class="fu">mean</span>((ypred <span class="sc">-</span> newresp)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb50-85"><a href="#cb50-85" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb50-86"><a href="#cb50-86" aria-hidden="true" tabindex="-1"></a><span class="co"># Create six plots through a loop</span></span>
<span id="cb50-87"><a href="#cb50-87" aria-hidden="true" tabindex="-1"></a>p_list <span class="ot">&lt;-</span> <span class="fu">map</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, <span class="cf">function</span>(i) {</span>
<span id="cb50-88"><a href="#cb50-88" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Use frequentist analyses for speed</span></span>
<span id="cb50-89"><a href="#cb50-89" aria-hidden="true" tabindex="-1"></a>    mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(Divorce <span class="sc">~</span> <span class="fu">poly</span>(Marriage, <span class="at">degree =</span> i), <span class="at">data =</span> wd_sub)</span>
<span id="cb50-90"><a href="#cb50-90" aria-hidden="true" tabindex="-1"></a>    base <span class="sc">+</span></span>
<span id="cb50-91"><a href="#cb50-91" aria-hidden="true" tabindex="-1"></a>        <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">formula =</span> y <span class="sc">~</span> <span class="fu">poly</span>(x, i), <span class="at">level =</span> .<span class="dv">80</span>,</span>
<span id="cb50-92"><a href="#cb50-92" aria-hidden="true" tabindex="-1"></a>                    <span class="at">fullrange =</span> <span class="cn">TRUE</span>) <span class="sc">+</span></span>
<span id="cb50-93"><a href="#cb50-93" aria-hidden="true" tabindex="-1"></a>        <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="fl">1.7</span>, <span class="at">y =</span> <span class="fl">1.4</span>,</span>
<span id="cb50-94"><a href="#cb50-94" aria-hidden="true" tabindex="-1"></a>                 <span class="at">label =</span> <span class="fu">paste0</span>(<span class="st">"italic(R)^2 == "</span>,</span>
<span id="cb50-95"><a href="#cb50-95" aria-hidden="true" tabindex="-1"></a>                                <span class="fu">round</span>(<span class="fu">r2</span>(mod, wd_sub<span class="sc">$</span>Divorce), <span class="dv">2</span>)),</span>
<span id="cb50-96"><a href="#cb50-96" aria-hidden="true" tabindex="-1"></a>                 <span class="at">parse =</span> <span class="cn">TRUE</span>) <span class="sc">+</span></span>
<span id="cb50-97"><a href="#cb50-97" aria-hidden="true" tabindex="-1"></a>        <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="fl">1.7</span>, <span class="at">y =</span> <span class="fl">1.2</span>,</span>
<span id="cb50-98"><a href="#cb50-98" aria-hidden="true" tabindex="-1"></a>                 <span class="at">label =</span> <span class="fu">paste0</span>(<span class="st">"RMSE == "</span>,</span>
<span id="cb50-99"><a href="#cb50-99" aria-hidden="true" tabindex="-1"></a>                                <span class="fu">round</span>(<span class="fu">rmse</span>(mod, wd_sub<span class="sc">$</span>Divorce), <span class="dv">2</span>)),</span>
<span id="cb50-100"><a href="#cb50-100" aria-hidden="true" tabindex="-1"></a>                 <span class="at">parse =</span> <span class="cn">TRUE</span>)</span>
<span id="cb50-101"><a href="#cb50-101" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb50-102"><a href="#cb50-102" aria-hidden="true" tabindex="-1"></a><span class="fu">do.call</span>(grid.arrange, <span class="fu">c</span>(p_list, <span class="at">nrow =</span> <span class="dv">2</span>))</span>
<span id="cb50-103"><a href="#cb50-103" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-104"><a href="#cb50-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-105"><a href="#cb50-105" aria-hidden="true" tabindex="-1"></a>Another way to look at model accuracy is the *Root Mean Squared Error* (RMSE), defined as the square root of the average squared prediction error. RMSE is a measure of prediction error. The smaller the RMSE, the better the prediction is. As you can see in the above figure, more complex models always reduce the RMSE in the data we use to fit the model (also called training data).</span>
<span id="cb50-106"><a href="#cb50-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-107"><a href="#cb50-107" aria-hidden="true" tabindex="-1"></a>However, if I take the estimated regression line/curve based on the subsample of 10 observations, and predict the remaining cases in the data set, things will be different. As you can see in the figure below, whereas prediction error is comparable for the linear and the quadratic model, polynomials of higher degrees predict the data really badly. When you use a complex model in a data set, it tailors the coefficients to any sampling errors and noise in the data such that it will not generalize to new observations. Therefore, our goal in model comparison is to choose a model complex enough to capture the essence of the data generation process (and thus avoid *underfitting*), but not too complex such that it suffers from *overfitting*.</span>
<span id="cb50-108"><a href="#cb50-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-111"><a href="#cb50-111" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-112"><a href="#cb50-112" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-overfit-generalize</span></span>
<span id="cb50-113"><a href="#cb50-113" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb50-114"><a href="#cb50-114" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Using the regression lines based on 10 random cases to predict the remaining 40 cases. Top panel: linear, quadratic, and cubic; bottom panel: 4th, 5th, and 6th degree polynomials"</span></span>
<span id="cb50-115"><a href="#cb50-115" aria-hidden="true" tabindex="-1"></a>base2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Marriage, <span class="at">y =</span> Divorce),</span>
<span id="cb50-116"><a href="#cb50-116" aria-hidden="true" tabindex="-1"></a>               <span class="at">data =</span> waffle_divorce[<span class="sc">-</span>train, ]) <span class="sc">+</span></span>
<span id="cb50-117"><a href="#cb50-117" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb50-118"><a href="#cb50-118" aria-hidden="true" tabindex="-1"></a>    <span class="fu">coord_cartesian</span>(<span class="at">ylim =</span> <span class="fu">c</span>(<span class="fl">0.6</span>, <span class="fl">1.4</span>)) <span class="sc">+</span></span>
<span id="cb50-119"><a href="#cb50-119" aria-hidden="true" tabindex="-1"></a>    <span class="fu">xlim</span>(<span class="fu">range</span>(waffle_divorce<span class="sc">$</span>Marriage))</span>
<span id="cb50-120"><a href="#cb50-120" aria-hidden="true" tabindex="-1"></a><span class="co"># Create six plots through a loop</span></span>
<span id="cb50-121"><a href="#cb50-121" aria-hidden="true" tabindex="-1"></a>p_list2 <span class="ot">&lt;-</span> <span class="fu">map</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, <span class="cf">function</span>(i) {</span>
<span id="cb50-122"><a href="#cb50-122" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Use frequentist analyses for speed</span></span>
<span id="cb50-123"><a href="#cb50-123" aria-hidden="true" tabindex="-1"></a>    mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(Divorce <span class="sc">~</span> <span class="fu">poly</span>(Marriage, <span class="at">degree =</span> i), <span class="at">data =</span> wd_sub)</span>
<span id="cb50-124"><a href="#cb50-124" aria-hidden="true" tabindex="-1"></a>    <span class="co"># New data and response</span></span>
<span id="cb50-125"><a href="#cb50-125" aria-hidden="true" tabindex="-1"></a>    test_dat <span class="ot">&lt;-</span> waffle_divorce[<span class="sc">-</span>train, ]</span>
<span id="cb50-126"><a href="#cb50-126" aria-hidden="true" tabindex="-1"></a>    ynew <span class="ot">&lt;-</span> test_dat<span class="sc">$</span>Divorce</span>
<span id="cb50-127"><a href="#cb50-127" aria-hidden="true" tabindex="-1"></a>    base2 <span class="sc">+</span></span>
<span id="cb50-128"><a href="#cb50-128" aria-hidden="true" tabindex="-1"></a>        <span class="fu">geom_smooth</span>(<span class="at">data =</span> wd_sub, <span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">formula =</span> y <span class="sc">~</span> <span class="fu">poly</span>(x, i),</span>
<span id="cb50-129"><a href="#cb50-129" aria-hidden="true" tabindex="-1"></a>                    <span class="at">level =</span> .<span class="dv">80</span>, <span class="at">fullrange =</span> <span class="cn">TRUE</span>) <span class="sc">+</span></span>
<span id="cb50-130"><a href="#cb50-130" aria-hidden="true" tabindex="-1"></a>        <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="fl">1.7</span>, <span class="at">y =</span> <span class="fl">1.4</span>,</span>
<span id="cb50-131"><a href="#cb50-131" aria-hidden="true" tabindex="-1"></a>                 <span class="at">label =</span> <span class="fu">paste0</span>(<span class="st">"italic(R)^2 == "</span>,</span>
<span id="cb50-132"><a href="#cb50-132" aria-hidden="true" tabindex="-1"></a>                                <span class="fu">round</span>(<span class="fu">r2</span>(mod, ynew, test_dat), <span class="dv">2</span>)),</span>
<span id="cb50-133"><a href="#cb50-133" aria-hidden="true" tabindex="-1"></a>                 <span class="at">parse =</span> <span class="cn">TRUE</span>) <span class="sc">+</span></span>
<span id="cb50-134"><a href="#cb50-134" aria-hidden="true" tabindex="-1"></a>        <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="fl">1.7</span>, <span class="at">y =</span> <span class="fl">1.2</span>,</span>
<span id="cb50-135"><a href="#cb50-135" aria-hidden="true" tabindex="-1"></a>                 <span class="at">label =</span> <span class="fu">paste0</span>(<span class="st">"RMSE == "</span>,</span>
<span id="cb50-136"><a href="#cb50-136" aria-hidden="true" tabindex="-1"></a>                                <span class="fu">round</span>(<span class="fu">rmse</span>(mod, ynew, test_dat), <span class="dv">2</span>)),</span>
<span id="cb50-137"><a href="#cb50-137" aria-hidden="true" tabindex="-1"></a>                 <span class="at">parse =</span> <span class="cn">TRUE</span>)</span>
<span id="cb50-138"><a href="#cb50-138" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb50-139"><a href="#cb50-139" aria-hidden="true" tabindex="-1"></a><span class="fu">do.call</span>(grid.arrange, <span class="fu">c</span>(p_list2, <span class="at">nrow =</span> <span class="dv">2</span>))</span>
<span id="cb50-140"><a href="#cb50-140" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-141"><a href="#cb50-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-142"><a href="#cb50-142" aria-hidden="true" tabindex="-1"></a>The goal of statistical modeling is to choose an optimal model between the overfitting/underfitting dichotomy. In machine learning, this is also commonly referred to as the bias-variance trade-off, as a model that is too simple tends to produce biased predictions because it does not capture the essence of the data generating process. In contrast, a overly complex model is unbiased but results in a lot of uncertainty in the prediction because there are too many unnecessary components that can affect predictions, as indicated in the confidence bands around the 6th-degree polynomial line.</span>
<span id="cb50-143"><a href="#cb50-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-144"><a href="#cb50-144" aria-hidden="true" tabindex="-1"></a>Polynomials of varying degrees are merely one example of comparing simple to complex models. You can think about:</span>
<span id="cb50-145"><a href="#cb50-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-146"><a href="#cb50-146" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>models with and without interactions, </span>
<span id="cb50-147"><a href="#cb50-147" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>models with a few predictors versus hundreds of predictors, </span>
<span id="cb50-148"><a href="#cb50-148" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>regression analyses versus multilevel models, etc. </span>
<span id="cb50-149"><a href="#cb50-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-150"><a href="#cb50-150" aria-hidden="true" tabindex="-1"></a>Whereas one can always avoid underfitting by fitting a more and more complex model, we need tools to keep us from overfitting. This lecture is about finding an optimal model that avoids overfitting and avoids underfitting. You will learn to perform model comparisons with information criteria to find a model that has a better balance between overfitting and underfitting. </span>
<span id="cb50-151"><a href="#cb50-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-152"><a href="#cb50-152" aria-hidden="true" tabindex="-1"></a><span class="fu">## Kullback-Leibler Divergence</span></span>
<span id="cb50-153"><a href="#cb50-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-154"><a href="#cb50-154" aria-hidden="true" tabindex="-1"></a>When comparing models (e.g., linear vs. quadratic), we prefer models closer to the "true" data-generating process. To do so, we need some ways to quantify the degree of "closeness" to the true model. In this context, models comprise both the distributional family *and* the parameter values. For example, the model $y_i \sim N(5, 2)$ is a different model than $y_i \sim N(3, 2)$, which is a different model than $y_i \sim \mathrm{Gamma}(2, 2)$. The first two have the same family but different parameter values (different means, same $\SD$). In contrast, the last two have different distributional families (Normal vs. Gamma).</span>
<span id="cb50-155"><a href="#cb50-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-156"><a href="#cb50-156" aria-hidden="true" tabindex="-1"></a>To measure the degree of "closeness" between two models, $M_0$ and $M_1$, by far the most popular metric in statistics is the *Kullback-Liebler Divergence* (or Kullback-Liebler discrepancy; $\DKL$). By definition,</span>
<span id="cb50-157"><a href="#cb50-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-158"><a href="#cb50-158" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb50-159"><a href="#cb50-159" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb50-160"><a href="#cb50-160" aria-hidden="true" tabindex="-1"></a>\DKL(M_0 \mid M_1) &amp; = \int_{-\infty}^\infty p_{M_0} (\bv y) </span>
<span id="cb50-161"><a href="#cb50-161" aria-hidden="true" tabindex="-1"></a>                    \log \frac{p_{M_0}(\bv y)}{p_{M_1}(\bv y)} \dd \bv y <span class="sc">\\</span></span>
<span id="cb50-162"><a href="#cb50-162" aria-hidden="true" tabindex="-1"></a>                &amp; = \int_{-\infty}^\infty p_{M_0} (\bv y) </span>
<span id="cb50-163"><a href="#cb50-163" aria-hidden="true" tabindex="-1"></a>                          \log p_{M_0}(\bv y) \dd \bv y - </span>
<span id="cb50-164"><a href="#cb50-164" aria-hidden="true" tabindex="-1"></a>                    \int_{-\infty}^\infty p_{M_0} (\bv y) </span>
<span id="cb50-165"><a href="#cb50-165" aria-hidden="true" tabindex="-1"></a>                          \log p_{M_1}(\bv y) \dd \bv y. </span>
<span id="cb50-166"><a href="#cb50-166" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb50-167"><a href="#cb50-167" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb50-168"><a href="#cb50-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-169"><a href="#cb50-169" aria-hidden="true" tabindex="-1"></a>Note that strictly speaking, $\DKL$ cannot be called a "distance" between two models because in general, $\DKL(M_0 \mid M_1) \neq \DKL(M_1 \mid M_0)$. As an example, assume that the data are generated by a true model $M_0$, and we have two candidate models $M_1$ and $M_2$, where</span>
<span id="cb50-170"><a href="#cb50-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-171"><a href="#cb50-171" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$M_0: y \sim N(3, 2)$</span>
<span id="cb50-172"><a href="#cb50-172" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$M_1: y \sim N(3.5, 2.5)$</span>
<span id="cb50-173"><a href="#cb50-173" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$M_2: y \sim \mathrm{Cauchy}(3, 2)$</span>
<span id="cb50-174"><a href="#cb50-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-177"><a href="#cb50-177" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-178"><a href="#cb50-178" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-divergence</span></span>
<span id="cb50-179"><a href="#cb50-179" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb50-180"><a href="#cb50-180" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Density for $M_0$, $M_1$, and $M_2$</span></span>
<span id="cb50-181"><a href="#cb50-181" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">9</span>)), <span class="fu">aes</span>(<span class="at">x =</span> x)) <span class="sc">+</span></span>
<span id="cb50-182"><a href="#cb50-182" aria-hidden="true" tabindex="-1"></a>    <span class="fu">stat_function</span>(<span class="at">fun =</span> dnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="at">mean =</span> <span class="dv">3</span>, <span class="at">sd =</span> <span class="dv">2</span>),</span>
<span id="cb50-183"><a href="#cb50-183" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">aes</span>(<span class="at">col =</span> <span class="st">"M0"</span>), <span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb50-184"><a href="#cb50-184" aria-hidden="true" tabindex="-1"></a>    <span class="fu">stat_function</span>(<span class="at">fun =</span> dnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="at">mean =</span> <span class="fl">3.5</span>, <span class="at">sd =</span> <span class="fl">2.5</span>),</span>
<span id="cb50-185"><a href="#cb50-185" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">aes</span>(<span class="at">col =</span> <span class="st">"M1"</span>), <span class="at">linewidth =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb50-186"><a href="#cb50-186" aria-hidden="true" tabindex="-1"></a>    <span class="fu">stat_function</span>(<span class="at">fun =</span> dcauchy, <span class="at">args =</span> <span class="fu">list</span>(<span class="at">location =</span> <span class="dv">3</span>, <span class="at">scale =</span> <span class="dv">2</span>),</span>
<span id="cb50-187"><a href="#cb50-187" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">aes</span>(<span class="at">col =</span> <span class="st">"M2"</span>), <span class="at">linewidth =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb50-188"><a href="#cb50-188" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"black"</span>, <span class="st">"red"</span>, <span class="st">"blue"</span>),</span>
<span id="cb50-189"><a href="#cb50-189" aria-hidden="true" tabindex="-1"></a>                       <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"M0"</span>, <span class="st">"M1"</span>, <span class="st">"M2"</span>)) <span class="sc">+</span></span>
<span id="cb50-190"><a href="#cb50-190" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"y"</span>, <span class="at">y =</span> <span class="st">"density"</span>, <span class="at">col =</span> <span class="cn">NULL</span>)</span>
<span id="cb50-191"><a href="#cb50-191" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-192"><a href="#cb50-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-195"><a href="#cb50-195" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-196"><a href="#cb50-196" aria-hidden="true" tabindex="-1"></a>f1 <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb50-197"><a href="#cb50-197" aria-hidden="true" tabindex="-1"></a>    <span class="fu">dnorm</span>(x, <span class="dv">3</span>, <span class="dv">2</span>) <span class="sc">*</span> (<span class="fu">dnorm</span>(x, <span class="dv">3</span>, <span class="dv">2</span>, <span class="at">log =</span> <span class="cn">TRUE</span>) <span class="sc">-</span></span>
<span id="cb50-198"><a href="#cb50-198" aria-hidden="true" tabindex="-1"></a>        <span class="fu">dnorm</span>(x, <span class="fl">3.5</span>, <span class="fl">2.5</span>, <span class="at">log =</span> <span class="cn">TRUE</span>))</span>
<span id="cb50-199"><a href="#cb50-199" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb50-200"><a href="#cb50-200" aria-hidden="true" tabindex="-1"></a>f2 <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb50-201"><a href="#cb50-201" aria-hidden="true" tabindex="-1"></a>    <span class="fu">dnorm</span>(x, <span class="dv">3</span>, <span class="dv">2</span>) <span class="sc">*</span> (<span class="fu">dnorm</span>(x, <span class="dv">3</span>, <span class="dv">2</span>, <span class="at">log =</span> <span class="cn">TRUE</span>) <span class="sc">-</span></span>
<span id="cb50-202"><a href="#cb50-202" aria-hidden="true" tabindex="-1"></a>        <span class="fu">dcauchy</span>(x, <span class="dv">3</span>, <span class="dv">2</span>, <span class="at">log =</span> <span class="cn">TRUE</span>))</span>
<span id="cb50-203"><a href="#cb50-203" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb50-204"><a href="#cb50-204" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-205"><a href="#cb50-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-206"><a href="#cb50-206" aria-hidden="true" tabindex="-1"></a>One can compute that $\DKL(M_0 \mid M_1) = <span class="in">`r integrate(f1, -Inf, Inf)$value`</span>$ and $\DKL(M_0 \mid M_1) = <span class="in">`r integrate(f2, -Inf, Inf)$value`</span>$, and so $M_1$ is a better model than $M_2$. </span>
<span id="cb50-207"><a href="#cb50-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-208"><a href="#cb50-208" aria-hidden="true" tabindex="-1"></a>Note that in the expression of $\DKL$, when talking about the same target model, the first term is always the same and describes the "true" model, $M_0$. Therefore, it is sufficient to compare models on the second term, $\int_{-\infty}^\infty p_{M_0} (\bv y) \log p_{M_1}(\bv y) \dd \bv y$, which can also be written as $\E=<span class="co">[</span><span class="ot">\log p_{M_1} (\bv y)</span><span class="co">]</span>$, i.e., the *expected log predictive density* (*elpd*). In other words, a model with a larger elpd is preferred over a model with a smaller elpd.</span>
<span id="cb50-209"><a href="#cb50-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-210"><a href="#cb50-210" aria-hidden="true" tabindex="-1"></a>However, we don't know what $M_0$ is in real data analysis. If we knew, then we would just need to choose $M_0$ as our model, and there will be no need for model comparisons. In addition, even if we know that the true model is, e.g., a normal model (which never happens in real data analysis), we still need to estimate the parameter values, and the estimates will not be exactly the same as the true parameter values. However, elpd is defined as the expected value over the true predictive distribution, $p_{M_0}(y)$, which cannot be obtained without knowing what $M_0$ is.</span>
<span id="cb50-211"><a href="#cb50-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-212"><a href="#cb50-212" aria-hidden="true" tabindex="-1"></a>So instead, we need to estimate the elpd. A naive way to estimate it is to use the data distribution in place of the true model, but that will lead to an overly optimistic estimate as the sample data are noisy. Computing elpd this way will always favor a more complex model. The ideal way is to collect data on a new, independent sample that share the same data generating process as the current sample, and estimate elpd on the new sample. This is called *out-of-sample validation*. The problem, of course, is that we usually do not have the resources to collect a new sample.</span>
<span id="cb50-213"><a href="#cb50-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-214"><a href="#cb50-214" aria-hidden="true" tabindex="-1"></a>Therefore, statisticians have worked hard to find ways to estimate elpd from the current sample, and there are two broad approaches:</span>
<span id="cb50-215"><a href="#cb50-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-216"><a href="#cb50-216" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Information criteria: AIC, DIC, and WAIC, which estimate the elpd in the current sample, minus a correction factor</span>
<span id="cb50-217"><a href="#cb50-217" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Cross-validation, which splits the current sample into $K$ parts, estimates the parameters in $K - 1$ parts, and estimates the elpd in the remaining part. A special case is when $K$ = $N$, each time one uses $N$ - 1 data points to estimate the model parameters, and estimate the elpd for the observation that was left out. This is called *leave-one-out* cross-validation (LOO-CV).</span>
<span id="cb50-218"><a href="#cb50-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-219"><a href="#cb50-219" aria-hidden="true" tabindex="-1"></a><span class="fu">## Deviance</span></span>
<span id="cb50-220"><a href="#cb50-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-221"><a href="#cb50-221" aria-hidden="true" tabindex="-1"></a>Without going too deep into the underlying math, it can be shown that a good estimate of elpd is </span>
<span id="cb50-222"><a href="#cb50-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-223"><a href="#cb50-223" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb50-224"><a href="#cb50-224" aria-hidden="true" tabindex="-1"></a>\sum_{i = 1}^n \log p_{M_1}(y_i) - p,</span>
<span id="cb50-225"><a href="#cb50-225" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb50-226"><a href="#cb50-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-227"><a href="#cb50-227" aria-hidden="true" tabindex="-1"></a>where $p$ is some measure of the number of parameters in $M_1$. The first term is the likelihood of the model in the current sample. The second term is an adjustment factor so that the quantity above represents the average likelihood of the model *in a new sample*. It is more common to work with *deviance* by multiplying the log-likelihood by $-2$, i.e.,</span>
<span id="cb50-228"><a href="#cb50-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-229"><a href="#cb50-229" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb50-230"><a href="#cb50-230" aria-hidden="true" tabindex="-1"></a>D = -2 \sum_{i = 1}^n \log p_{M_1}(y_i).</span>
<span id="cb50-231"><a href="#cb50-231" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb50-232"><a href="#cb50-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-233"><a href="#cb50-233" aria-hidden="true" tabindex="-1"></a><span class="fu">### Experiment on Deviance</span></span>
<span id="cb50-234"><a href="#cb50-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-235"><a href="#cb50-235" aria-hidden="true" tabindex="-1"></a>Now, let's check the in-sample deviance and out-of-sample deviance of our <span class="in">`waffle_divorce`</span> data with different polynomial functions. Here is a sample function for computing elpd (with frequentist, just for speed) for polynomials of different degrees:</span>
<span id="cb50-236"><a href="#cb50-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-239"><a href="#cb50-239" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-240"><a href="#cb50-240" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb50-241"><a href="#cb50-241" aria-hidden="true" tabindex="-1"></a><span class="co"># Function for computing deviance with different polynomial</span></span>
<span id="cb50-242"><a href="#cb50-242" aria-hidden="true" tabindex="-1"></a>deviance_divorce <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">degree =</span> <span class="dv">1</span>,</span>
<span id="cb50-243"><a href="#cb50-243" aria-hidden="true" tabindex="-1"></a>                             <span class="at">train =</span> <span class="dv">10</span>,</span>
<span id="cb50-244"><a href="#cb50-244" aria-hidden="true" tabindex="-1"></a>                             <span class="at">y =</span> waffle_divorce<span class="sc">$</span>Divorce,</span>
<span id="cb50-245"><a href="#cb50-245" aria-hidden="true" tabindex="-1"></a>                             <span class="at">x =</span> waffle_divorce<span class="sc">$</span>Marriage) {</span>
<span id="cb50-246"><a href="#cb50-246" aria-hidden="true" tabindex="-1"></a>    N <span class="ot">&lt;-</span> <span class="fu">length</span>(y)</span>
<span id="cb50-247"><a href="#cb50-247" aria-hidden="true" tabindex="-1"></a>    <span class="co"># get training sample</span></span>
<span id="cb50-248"><a href="#cb50-248" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (<span class="fu">length</span>(train) <span class="sc">==</span> <span class="dv">1</span>) {</span>
<span id="cb50-249"><a href="#cb50-249" aria-hidden="true" tabindex="-1"></a>        train <span class="ot">&lt;-</span> <span class="fu">sample.int</span>(N, train)</span>
<span id="cb50-250"><a href="#cb50-250" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb50-251"><a href="#cb50-251" aria-hidden="true" tabindex="-1"></a>    ntrain <span class="ot">&lt;-</span> <span class="fu">length</span>(train)</span>
<span id="cb50-252"><a href="#cb50-252" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Obtain design matrix</span></span>
<span id="cb50-253"><a href="#cb50-253" aria-hidden="true" tabindex="-1"></a>    X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, <span class="fu">poly</span>(x, degree, <span class="at">simple =</span> <span class="cn">TRUE</span>))</span>
<span id="cb50-254"><a href="#cb50-254" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get elpd for training sample</span></span>
<span id="cb50-255"><a href="#cb50-255" aria-hidden="true" tabindex="-1"></a>    Xtrain <span class="ot">&lt;-</span> X[train, ]</span>
<span id="cb50-256"><a href="#cb50-256" aria-hidden="true" tabindex="-1"></a>    ytrain <span class="ot">&lt;-</span> y[train]</span>
<span id="cb50-257"><a href="#cb50-257" aria-hidden="true" tabindex="-1"></a>    betahat <span class="ot">&lt;-</span> <span class="fu">qr.solve</span>(Xtrain, ytrain)  <span class="co"># estimated betas</span></span>
<span id="cb50-258"><a href="#cb50-258" aria-hidden="true" tabindex="-1"></a>    res_train <span class="ot">&lt;-</span> ytrain <span class="sc">-</span> Xtrain <span class="sc">%*%</span> betahat</span>
<span id="cb50-259"><a href="#cb50-259" aria-hidden="true" tabindex="-1"></a>    sigmahat <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>(res_train<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span></span>
<span id="cb50-260"><a href="#cb50-260" aria-hidden="true" tabindex="-1"></a>        (ntrain <span class="sc">-</span> <span class="dv">1</span> <span class="sc">-</span> degree)) <span class="co"># estimated sigma</span></span>
<span id="cb50-261"><a href="#cb50-261" aria-hidden="true" tabindex="-1"></a>    deviance_train <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">sum</span>(<span class="fu">dnorm</span>(res_train, <span class="at">sd =</span> sigmahat, <span class="at">log =</span> <span class="cn">TRUE</span>))</span>
<span id="cb50-262"><a href="#cb50-262" aria-hidden="true" tabindex="-1"></a>    res_test <span class="ot">&lt;-</span> y[<span class="sc">-</span>train] <span class="sc">-</span> X[<span class="sc">-</span>train, ] <span class="sc">%*%</span> betahat</span>
<span id="cb50-263"><a href="#cb50-263" aria-hidden="true" tabindex="-1"></a>    deviance_test <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">sum</span>(<span class="fu">dnorm</span>(res_test, <span class="at">sd =</span> sigmahat, <span class="at">log =</span> <span class="cn">TRUE</span>))</span>
<span id="cb50-264"><a href="#cb50-264" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.frame</span>(</span>
<span id="cb50-265"><a href="#cb50-265" aria-hidden="true" tabindex="-1"></a>        <span class="at">degree =</span> degree,</span>
<span id="cb50-266"><a href="#cb50-266" aria-hidden="true" tabindex="-1"></a>        <span class="at">sample =</span> <span class="fu">c</span>(<span class="st">"in-sample"</span>, <span class="st">"out-of-sample"</span>),</span>
<span id="cb50-267"><a href="#cb50-267" aria-hidden="true" tabindex="-1"></a>        <span class="at">deviance =</span> <span class="fu">c</span>(deviance_train <span class="sc">/</span> ntrain,</span>
<span id="cb50-268"><a href="#cb50-268" aria-hidden="true" tabindex="-1"></a>                     deviance_test <span class="sc">/</span> (N <span class="sc">-</span> ntrain))</span>
<span id="cb50-269"><a href="#cb50-269" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb50-270"><a href="#cb50-270" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb50-271"><a href="#cb50-271" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-272"><a href="#cb50-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-273"><a href="#cb50-273" aria-hidden="true" tabindex="-1"></a>Below shows the in-sample and out-of-sample elpd for the linear model:</span>
<span id="cb50-274"><a href="#cb50-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-275"><a href="#cb50-275" aria-hidden="true" tabindex="-1"></a><span class="in">```{r dev1}</span></span>
<span id="cb50-276"><a href="#cb50-276" aria-hidden="true" tabindex="-1"></a><span class="in">deviance_divorce(degree = 1, train = train)</span></span>
<span id="cb50-277"><a href="#cb50-277" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-278"><a href="#cb50-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-279"><a href="#cb50-279" aria-hidden="true" tabindex="-1"></a>And for quadratic:</span>
<span id="cb50-280"><a href="#cb50-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-281"><a href="#cb50-281" aria-hidden="true" tabindex="-1"></a><span class="in">```{r dev2}</span></span>
<span id="cb50-282"><a href="#cb50-282" aria-hidden="true" tabindex="-1"></a><span class="in">deviance_divorce(degree = 2, train = train)</span></span>
<span id="cb50-283"><a href="#cb50-283" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-284"><a href="#cb50-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-285"><a href="#cb50-285" aria-hidden="true" tabindex="-1"></a>In general, as you can see, the deviance is smaller for the current data than for the hold-out data. Note that because the training and testing data sets have different sizes, I divided the deviance by the sample size so that they can be compared. </span>
<span id="cb50-286"><a href="#cb50-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-287"><a href="#cb50-287" aria-hidden="true" tabindex="-1"></a>Now let's run an experiment to check the elpd with different degrees polynomial, with a training sample size of 25:</span>
<span id="cb50-288"><a href="#cb50-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-289"><a href="#cb50-289" aria-hidden="true" tabindex="-1"></a><span class="in">```{r dev_df-plot}</span></span>
<span id="cb50-290"><a href="#cb50-290" aria-hidden="true" tabindex="-1"></a><span class="in">set.seed(1733)</span></span>
<span id="cb50-291"><a href="#cb50-291" aria-hidden="true" tabindex="-1"></a><span class="in"># Use the `map` function to run different polynomials, and use the `rerun`</span></span>
<span id="cb50-292"><a href="#cb50-292" aria-hidden="true" tabindex="-1"></a><span class="in"># function run the deviance 100 times. The code below runs `deviance_divorce` by</span></span>
<span id="cb50-293"><a href="#cb50-293" aria-hidden="true" tabindex="-1"></a><span class="in"># randomly sampling 25 training samples 100 times, and compute the in-sample</span></span>
<span id="cb50-294"><a href="#cb50-294" aria-hidden="true" tabindex="-1"></a><span class="in"># and out-of-sample deviance for each.</span></span>
<span id="cb50-295"><a href="#cb50-295" aria-hidden="true" tabindex="-1"></a><span class="in"># rerun(100, deviance_divorce(degree = 1, train = 25L)) |&gt;</span></span>
<span id="cb50-296"><a href="#cb50-296" aria-hidden="true" tabindex="-1"></a><span class="in">#     bind_rows()</span></span>
<span id="cb50-297"><a href="#cb50-297" aria-hidden="true" tabindex="-1"></a><span class="in"># Now run 1 to 4 degree polynomial, each 1000 times:</span></span>
<span id="cb50-298"><a href="#cb50-298" aria-hidden="true" tabindex="-1"></a><span class="in">dev_list &lt;- lapply(1:4, FUN = function(p) {</span></span>
<span id="cb50-299"><a href="#cb50-299" aria-hidden="true" tabindex="-1"></a><span class="in">    results &lt;- replicate(1000, deviance_divorce(degree = p, train = 25L), simplify = FALSE)</span></span>
<span id="cb50-300"><a href="#cb50-300" aria-hidden="true" tabindex="-1"></a><span class="in">    do.call(rbind, results)</span></span>
<span id="cb50-301"><a href="#cb50-301" aria-hidden="true" tabindex="-1"></a><span class="in">})</span></span>
<span id="cb50-302"><a href="#cb50-302" aria-hidden="true" tabindex="-1"></a><span class="in">dev_df &lt;- do.call(rbind, dev_list)</span></span>
<span id="cb50-303"><a href="#cb50-303" aria-hidden="true" tabindex="-1"></a><span class="in"># Plot the results</span></span>
<span id="cb50-304"><a href="#cb50-304" aria-hidden="true" tabindex="-1"></a><span class="in">dev_df |&gt;</span></span>
<span id="cb50-305"><a href="#cb50-305" aria-hidden="true" tabindex="-1"></a><span class="in">    ggplot(aes(x = degree, y = deviance, col = sample)) +</span></span>
<span id="cb50-306"><a href="#cb50-306" aria-hidden="true" tabindex="-1"></a><span class="in">    stat_summary() +</span></span>
<span id="cb50-307"><a href="#cb50-307" aria-hidden="true" tabindex="-1"></a><span class="in">    stat_summary(geom = "line") +</span></span>
<span id="cb50-308"><a href="#cb50-308" aria-hidden="true" tabindex="-1"></a><span class="in">    labs(col = NULL)</span></span>
<span id="cb50-309"><a href="#cb50-309" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-310"><a href="#cb50-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-311"><a href="#cb50-311" aria-hidden="true" tabindex="-1"></a>As you can see, the in-sample deviance (red line) keeps decreasing, indicating that a more complex model fits the data better, which is always the case. So if one were to use deviance to determine what model is optimal, one would always choose the most complex model, just like using $R^2$ (indeed, for linear models, deviance is basically the same as $R^2$).</span>
<span id="cb50-312"><a href="#cb50-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-313"><a href="#cb50-313" aria-hidden="true" tabindex="-1"></a>Now, look at the blue line, which represents the deviance computed using the coefficients obtained from the training set but applied to the remaining data. As you can see, the deviance achieves its minimum around the linear and the quadratic model, and starts to increase, meaning that the more complex models do not fit the hold-out data. </span>
<span id="cb50-314"><a href="#cb50-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-315"><a href="#cb50-315" aria-hidden="true" tabindex="-1"></a>A statistical model is used to learn something from a data set that can generalize to other observations. Therefore, we should care about the blue line, instead of the red one. The indices you will see in the remaining of this note are all attempts to approximate the blue line. </span>
<span id="cb50-316"><a href="#cb50-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-317"><a href="#cb50-317" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; More complex models always fit the current data better, but may not generalize to other data. In other words, models that are too complex are not generalizable.</span></span>
<span id="cb50-318"><a href="#cb50-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-319"><a href="#cb50-319" aria-hidden="true" tabindex="-1"></a><span class="fu">## Information Criteria</span></span>
<span id="cb50-320"><a href="#cb50-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-321"><a href="#cb50-321" aria-hidden="true" tabindex="-1"></a>We will illustrate the computation of information criteria with <span class="in">`Marriage`</span> predicting <span class="in">`Divorce`</span>:</span>
<span id="cb50-322"><a href="#cb50-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-325"><a href="#cb50-325" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-326"><a href="#cb50-326" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb50-327"><a href="#cb50-327" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">&lt;-</span> <span class="fu">brm</span>(Divorce <span class="sc">~</span> Marriage, <span class="at">data =</span> waffle_divorce,</span>
<span id="cb50-328"><a href="#cb50-328" aria-hidden="true" tabindex="-1"></a>          <span class="at">prior =</span> <span class="fu">c</span>(<span class="fu">prior</span>(<span class="fu">student_t</span>(<span class="dv">4</span>, <span class="dv">0</span>, <span class="dv">5</span>), <span class="at">class =</span> <span class="st">"Intercept"</span>),</span>
<span id="cb50-329"><a href="#cb50-329" aria-hidden="true" tabindex="-1"></a>                    <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">2</span>), <span class="at">class =</span> <span class="st">"b"</span>),</span>
<span id="cb50-330"><a href="#cb50-330" aria-hidden="true" tabindex="-1"></a>                    <span class="fu">prior</span>(<span class="fu">student_t</span>(<span class="dv">4</span>, <span class="dv">0</span>, <span class="dv">1</span>), <span class="at">class =</span> <span class="st">"sigma"</span>)),</span>
<span id="cb50-331"><a href="#cb50-331" aria-hidden="true" tabindex="-1"></a>          <span class="at">iter =</span> <span class="dv">4000</span>,</span>
<span id="cb50-332"><a href="#cb50-332" aria-hidden="true" tabindex="-1"></a>          <span class="at">seed =</span> <span class="dv">2302</span>,</span>
<span id="cb50-333"><a href="#cb50-333" aria-hidden="true" tabindex="-1"></a>          <span class="at">file =</span> <span class="st">"07_m1"</span></span>
<span id="cb50-334"><a href="#cb50-334" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb50-335"><a href="#cb50-335" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-336"><a href="#cb50-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-337"><a href="#cb50-337" aria-hidden="true" tabindex="-1"></a><span class="fu">### Akaike Information Criteria (AIC)</span></span>
<span id="cb50-338"><a href="#cb50-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-339"><a href="#cb50-339" aria-hidden="true" tabindex="-1"></a>Multiplying the quantity of elpd - $p$ by $-2$, or deviance + 2$p$, with the deviance obtained using the maximum likelihood estimates (MLEs) for the parameters, gives you the formula for AIC:</span>
<span id="cb50-340"><a href="#cb50-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-341"><a href="#cb50-341" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb50-342"><a href="#cb50-342" aria-hidden="true" tabindex="-1"></a>\textrm{AIC} = D(\hat \theta) + 2p,</span>
<span id="cb50-343"><a href="#cb50-343" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb50-344"><a href="#cb50-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-345"><a href="#cb50-345" aria-hidden="true" tabindex="-1"></a>and $p$ in AIC is just the number of parameters. As we have multiplied by a negative number, maximizing the estimate of elpd is equivalent to minimizing the AIC, so one would prefer a model with the smallest AIC.</span>
<span id="cb50-346"><a href="#cb50-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-347"><a href="#cb50-347" aria-hidden="true" tabindex="-1"></a>The AIC is not Bayesian because it only uses point estimates (MLEs) of parameters rather than their posterior distributions. Also, it does not take into account any prior information.</span>
<span id="cb50-348"><a href="#cb50-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-351"><a href="#cb50-351" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-352"><a href="#cb50-352" aria-hidden="true" tabindex="-1"></a><span class="co"># Frequentist model</span></span>
<span id="cb50-353"><a href="#cb50-353" aria-hidden="true" tabindex="-1"></a>m1_freq <span class="ot">&lt;-</span> <span class="fu">lm</span>(m1<span class="sc">$</span>formula, <span class="at">data =</span> m1<span class="sc">$</span>data)</span>
<span id="cb50-354"><a href="#cb50-354" aria-hidden="true" tabindex="-1"></a><span class="fu">AIC</span>(m1_freq)</span>
<span id="cb50-355"><a href="#cb50-355" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-356"><a href="#cb50-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-357"><a href="#cb50-357" aria-hidden="true" tabindex="-1"></a><span class="fu">### Deviance Information Criteria (DIC)</span></span>
<span id="cb50-358"><a href="#cb50-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-359"><a href="#cb50-359" aria-hidden="true" tabindex="-1"></a>The definition of AIC assumes that the parameter estimates are known or are maximum likelihood estimates. The DIC, instead, replaces those with the posterior distribution of the parameters. The general formula for DIC is</span>
<span id="cb50-360"><a href="#cb50-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-361"><a href="#cb50-361" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb50-362"><a href="#cb50-362" aria-hidden="true" tabindex="-1"></a>\textrm{DIC} = \E(D \mid \bv y) + 2 p_D,</span>
<span id="cb50-363"><a href="#cb50-363" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb50-364"><a href="#cb50-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-365"><a href="#cb50-365" aria-hidden="true" tabindex="-1"></a>where $p_D$ is the effective number of parameters estimated in the Markov chain. Although DIC does take into account the prior distributions, it does not consider the full posterior distributions of the parameters.</span>
<span id="cb50-366"><a href="#cb50-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-369"><a href="#cb50-369" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-370"><a href="#cb50-370" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to compute DIC</span></span>
<span id="cb50-371"><a href="#cb50-371" aria-hidden="true" tabindex="-1"></a>dic_brmsfit <span class="ot">&lt;-</span> <span class="cf">function</span>(object) {</span>
<span id="cb50-372"><a href="#cb50-372" aria-hidden="true" tabindex="-1"></a>    Dbar <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">mean</span>(<span class="fu">rowSums</span>(<span class="fu">log_lik</span>(object)))</span>
<span id="cb50-373"><a href="#cb50-373" aria-hidden="true" tabindex="-1"></a>    res <span class="ot">&lt;-</span> <span class="fu">residuals</span>(object)[ , <span class="st">"Estimate"</span>]</span>
<span id="cb50-374"><a href="#cb50-374" aria-hidden="true" tabindex="-1"></a>    sigma <span class="ot">&lt;-</span> <span class="fu">posterior_summary</span>(object, <span class="at">variable =</span> <span class="st">"sigma"</span>)[ , <span class="st">"Estimate"</span>]</span>
<span id="cb50-375"><a href="#cb50-375" aria-hidden="true" tabindex="-1"></a>    Dhat <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">sum</span>(<span class="fu">dnorm</span>(res, <span class="at">sd =</span> sigma, <span class="at">log =</span> <span class="cn">TRUE</span>))</span>
<span id="cb50-376"><a href="#cb50-376" aria-hidden="true" tabindex="-1"></a>    p <span class="ot">&lt;-</span> Dbar <span class="sc">-</span> Dhat</span>
<span id="cb50-377"><a href="#cb50-377" aria-hidden="true" tabindex="-1"></a>    elpd <span class="ot">&lt;-</span> Dhat <span class="sc">/</span> <span class="sc">-</span><span class="dv">2</span> <span class="sc">-</span> p</span>
<span id="cb50-378"><a href="#cb50-378" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.frame</span>(<span class="at">elpd_dic =</span> elpd, <span class="at">p_dic =</span> p, <span class="at">dic =</span> Dhat <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> p,</span>
<span id="cb50-379"><a href="#cb50-379" aria-hidden="true" tabindex="-1"></a>               <span class="at">row.names =</span> <span class="st">"Estimate"</span>)</span>
<span id="cb50-380"><a href="#cb50-380" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb50-381"><a href="#cb50-381" aria-hidden="true" tabindex="-1"></a><span class="fu">dic_brmsfit</span>(m1)</span>
<span id="cb50-382"><a href="#cb50-382" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-383"><a href="#cb50-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-384"><a href="#cb50-384" aria-hidden="true" tabindex="-1"></a><span class="fu">### Watanabe-Akaike Information Criteria (WAIC)</span></span>
<span id="cb50-385"><a href="#cb50-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-386"><a href="#cb50-386" aria-hidden="true" tabindex="-1"></a>A further modification is to use the *log pointwise posterior predictive density*, with the effective number of parameters computed using the posterior variance of the likelihood. </span>
<span id="cb50-387"><a href="#cb50-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-388"><a href="#cb50-388" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb50-389"><a href="#cb50-389" aria-hidden="true" tabindex="-1"></a>\textrm{WAIC} = -2 \sum_{i = 1}^n \log \E<span class="co">[</span><span class="ot">p(y_i \mid \bv \theta, \bv y)</span><span class="co">]</span> + </span>
<span id="cb50-390"><a href="#cb50-390" aria-hidden="true" tabindex="-1"></a>                  2 p_\textrm{WAIC},</span>
<span id="cb50-391"><a href="#cb50-391" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb50-392"><a href="#cb50-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-393"><a href="#cb50-393" aria-hidden="true" tabindex="-1"></a>where $\E<span class="co">[</span><span class="ot">p(y_i \mid \bv \theta, \bv y)</span><span class="co">]</span>$ is the posterior mean of the likelihood of the $i$th observation. The WAIC incorporates prior information, and the use of pointwise likelihood makes it more robust when the posterior distributions deviate from normality. In general, WAIC is a better estimate of the out-of-sample deviance than AIC and DIC.</span>
<span id="cb50-394"><a href="#cb50-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-397"><a href="#cb50-397" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-398"><a href="#cb50-398" aria-hidden="true" tabindex="-1"></a><span class="fu">waic</span>(m1)  <span class="co"># built-in function in brms</span></span>
<span id="cb50-399"><a href="#cb50-399" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-400"><a href="#cb50-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-401"><a href="#cb50-401" aria-hidden="true" tabindex="-1"></a><span class="fu">### Leave-One-Out Cross-Validation</span></span>
<span id="cb50-402"><a href="#cb50-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-403"><a href="#cb50-403" aria-hidden="true" tabindex="-1"></a>The idea of cross-validation is to split the sample so that it imitates the scenario of estimating the parameters in part of the data and predicting the remaining part. The part used for estimation is called the *training set*, and the part used for prediction is called the *validation set*. Leave-one-out information criteria (LOO-IC) means that one uses $N - 1$ observations as the training set and 1 observation as the validation sample and repeat the process $N$ times so that a different observation is being predicted each time. Adding up the prediction results will give an estimate of elpd that closely approximates the results that would be obtained by collecting new data and doing the validation. To make it more concrete, we can go back to the <span class="in">`waffle_divorce`</span> data with <span class="in">`Marriage`</span> predicting <span class="in">`Divorce`</span>. We can do this for case #1 (Alabama), as an example:</span>
<span id="cb50-404"><a href="#cb50-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-407"><a href="#cb50-407" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-408"><a href="#cb50-408" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb50-409"><a href="#cb50-409" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb50-410"><a href="#cb50-410" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate the model without case #1</span></span>
<span id="cb50-411"><a href="#cb50-411" aria-hidden="true" tabindex="-1"></a>m1_no1 <span class="ot">&lt;-</span> <span class="fu">update</span>(m1, <span class="at">newdata =</span> waffle_divorce[<span class="sc">-</span><span class="dv">1</span>, ])</span>
<span id="cb50-412"><a href="#cb50-412" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-413"><a href="#cb50-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-414"><a href="#cb50-414" aria-hidden="true" tabindex="-1"></a><span class="in">```{r loglik_1}</span></span>
<span id="cb50-415"><a href="#cb50-415" aria-hidden="true" tabindex="-1"></a><span class="in"># The log predictive density for case #1</span></span>
<span id="cb50-416"><a href="#cb50-416" aria-hidden="true" tabindex="-1"></a><span class="in">mean(log_lik(m1_no1, newdata = waffle_divorce[1, ]))</span></span>
<span id="cb50-417"><a href="#cb50-417" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-418"><a href="#cb50-418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-419"><a href="#cb50-419" aria-hidden="true" tabindex="-1"></a>Because LOO-IC requires fitting the model $N$ times, it is generally very computationally intensive. There are, however, shortcuts for some models to make the computation faster. WAIC can also be treated as a fast approximation of LOO-IC, although LOO-IC is more robust and will be a better estimate of out-of-sample deviance. The <span class="in">`loo`</span> package uses the so-called Pareto smoothed importance sampling (PSIS) to approximate LOO-IC without repeating the process $N$ times.</span>
<span id="cb50-420"><a href="#cb50-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-421"><a href="#cb50-421" aria-hidden="true" tabindex="-1"></a>Here is the LOO-IC for the model:</span>
<span id="cb50-422"><a href="#cb50-422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-425"><a href="#cb50-425" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-426"><a href="#cb50-426" aria-hidden="true" tabindex="-1"></a><span class="fu">loo</span>(m1)</span>
<span id="cb50-427"><a href="#cb50-427" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-428"><a href="#cb50-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-429"><a href="#cb50-429" aria-hidden="true" tabindex="-1"></a>You can save the WAIC and the LOO-IC information to the fitted result:</span>
<span id="cb50-430"><a href="#cb50-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-433"><a href="#cb50-433" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-434"><a href="#cb50-434" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">&lt;-</span> <span class="fu">add_criterion</span>(m1, <span class="at">criterion =</span> <span class="fu">c</span>(<span class="st">"loo"</span>, <span class="st">"waic"</span>))</span>
<span id="cb50-435"><a href="#cb50-435" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-436"><a href="#cb50-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-437"><a href="#cb50-437" aria-hidden="true" tabindex="-1"></a>See @vehtari2017 for more discussions on WAIC and LOO-IC. </span>
<span id="cb50-438"><a href="#cb50-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-439"><a href="#cb50-439" aria-hidden="true" tabindex="-1"></a>***</span>
<span id="cb50-440"><a href="#cb50-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-441"><a href="#cb50-441" aria-hidden="true" tabindex="-1"></a><span class="fu">### Example</span></span>
<span id="cb50-442"><a href="#cb50-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-443"><a href="#cb50-443" aria-hidden="true" tabindex="-1"></a>Consider four potential models in predicting <span class="in">`Divorce`</span>:</span>
<span id="cb50-444"><a href="#cb50-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-445"><a href="#cb50-445" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb50-446"><a href="#cb50-446" aria-hidden="true" tabindex="-1"></a>\texttt{Divorce}_i \sim N(\mu_i, \sigma)</span>
<span id="cb50-447"><a href="#cb50-447" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb50-448"><a href="#cb50-448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-449"><a href="#cb50-449" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>M1: <span class="in">`Marriage`</span></span>
<span id="cb50-450"><a href="#cb50-450" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>M2: <span class="in">`Marriage`</span>, <span class="in">`South`</span>, <span class="in">`Marriage`</span> $\times$ <span class="in">`South`</span></span>
<span id="cb50-451"><a href="#cb50-451" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>M3: <span class="in">`South`</span>, smoothing spline of <span class="in">`Marriage`</span> by <span class="in">`South`</span></span>
<span id="cb50-452"><a href="#cb50-452" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>M4: <span class="in">`Marriage`</span>, <span class="in">`South`</span>, <span class="in">`MedianAgeMarriage`</span>, <span class="in">`Marriage`</span> $\times$ <span class="in">`South`</span>, <span class="in">`Marriage`</span> $\times$ <span class="in">`MedianAgeMarriage`</span>, <span class="in">`South`</span> $\times$ <span class="in">`MedianAgeMarriage`</span>, <span class="in">`Marriage`</span> $\times$ <span class="in">`South`</span> $\times$ <span class="in">`MedianAgeMarriage`</span></span>
<span id="cb50-453"><a href="#cb50-453" aria-hidden="true" tabindex="-1"></a>                               </span>
<span id="cb50-456"><a href="#cb50-456" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-457"><a href="#cb50-457" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: hide</span></span>
<span id="cb50-458"><a href="#cb50-458" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb50-459"><a href="#cb50-459" aria-hidden="true" tabindex="-1"></a><span class="co"># Note, m1 has been fit before; the `update()` function</span></span>
<span id="cb50-460"><a href="#cb50-460" aria-hidden="true" tabindex="-1"></a><span class="co"># can be used to simply change the formula, and brms will</span></span>
<span id="cb50-461"><a href="#cb50-461" aria-hidden="true" tabindex="-1"></a><span class="co"># determine whether it needs re-compiling.</span></span>
<span id="cb50-462"><a href="#cb50-462" aria-hidden="true" tabindex="-1"></a><span class="co"># M2: Add South and interaction</span></span>
<span id="cb50-463"><a href="#cb50-463" aria-hidden="true" tabindex="-1"></a>m2 <span class="ot">&lt;-</span> <span class="fu">update</span>(m1, <span class="at">formula =</span> Divorce <span class="sc">~</span> Marriage <span class="sc">*</span> South,</span>
<span id="cb50-464"><a href="#cb50-464" aria-hidden="true" tabindex="-1"></a>             <span class="at">newdata =</span> waffle_divorce)</span>
<span id="cb50-465"><a href="#cb50-465" aria-hidden="true" tabindex="-1"></a>m2 <span class="ot">&lt;-</span> <span class="fu">add_criterion</span>(m2, <span class="fu">c</span>(<span class="st">"loo"</span>, <span class="st">"waic"</span>))</span>
<span id="cb50-466"><a href="#cb50-466" aria-hidden="true" tabindex="-1"></a><span class="co"># M3: Spline function for Marriage</span></span>
<span id="cb50-467"><a href="#cb50-467" aria-hidden="true" tabindex="-1"></a>m3 <span class="ot">&lt;-</span> <span class="fu">update</span>(m1, <span class="at">formula =</span> Divorce <span class="sc">~</span> South <span class="sc">+</span> <span class="fu">s</span>(Marriage, <span class="at">by =</span> South),</span>
<span id="cb50-468"><a href="#cb50-468" aria-hidden="true" tabindex="-1"></a>             <span class="at">newdata =</span> waffle_divorce,</span>
<span id="cb50-469"><a href="#cb50-469" aria-hidden="true" tabindex="-1"></a>             <span class="at">control =</span> <span class="fu">list</span>(<span class="at">adapt_delta =</span> .<span class="dv">999</span>))</span>
<span id="cb50-470"><a href="#cb50-470" aria-hidden="true" tabindex="-1"></a>m3 <span class="ot">&lt;-</span> <span class="fu">add_criterion</span>(m3, <span class="fu">c</span>(<span class="st">"loo"</span>, <span class="st">"waic"</span>))</span>
<span id="cb50-471"><a href="#cb50-471" aria-hidden="true" tabindex="-1"></a><span class="co"># M4: Three-way interactions</span></span>
<span id="cb50-472"><a href="#cb50-472" aria-hidden="true" tabindex="-1"></a>m4 <span class="ot">&lt;-</span> <span class="fu">update</span>(m1, <span class="at">formula =</span> Divorce <span class="sc">~</span> Marriage <span class="sc">*</span> MedianAgeMarriage <span class="sc">*</span> South,</span>
<span id="cb50-473"><a href="#cb50-473" aria-hidden="true" tabindex="-1"></a>             <span class="at">newdata =</span> waffle_divorce,</span>
<span id="cb50-474"><a href="#cb50-474" aria-hidden="true" tabindex="-1"></a>             <span class="at">control =</span> <span class="fu">list</span>(<span class="at">max_treedepth =</span> <span class="dv">12</span>))  <span class="co"># increase due to warning</span></span>
<span id="cb50-475"><a href="#cb50-475" aria-hidden="true" tabindex="-1"></a>m4 <span class="ot">&lt;-</span> <span class="fu">add_criterion</span>(m4, <span class="fu">c</span>(<span class="st">"loo"</span>, <span class="st">"waic"</span>))</span>
<span id="cb50-476"><a href="#cb50-476" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-477"><a href="#cb50-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-478"><a href="#cb50-478" aria-hidden="true" tabindex="-1"></a>The first model only has <span class="in">`Marriage`</span> as a predictor, which means that the coefficients for <span class="in">`South`</span> and <span class="in">`MedianAgeMarriage`</span> are assumed to be zero. The second model added <span class="in">`South`</span> and its interaction with <span class="in">`Marriage`</span> as a predictor. The third model includes a smoothing spline term (a flexible non-linear function, within the class of linear models), whereas the fourth model also includes <span class="in">`MedianAgeMarriage`</span> and all two-way and three-way interactions. Now, we can compare the four models:</span>
<span id="cb50-479"><a href="#cb50-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-482"><a href="#cb50-482" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-483"><a href="#cb50-483" aria-hidden="true" tabindex="-1"></a><span class="fu">loo_compare</span>(m1, m2, m3, m4)</span>
<span id="cb50-484"><a href="#cb50-484" aria-hidden="true" tabindex="-1"></a><span class="co"># m4 is the best</span></span>
<span id="cb50-485"><a href="#cb50-485" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-486"><a href="#cb50-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-489"><a href="#cb50-489" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb50-490"><a href="#cb50-490" aria-hidden="true" tabindex="-1"></a><span class="fu">msummary</span>(<span class="fu">list</span>(<span class="at">M1 =</span> m1, <span class="at">M2 =</span> m2, <span class="at">M3 =</span> m3, <span class="at">M4 =</span> m4),</span>
<span id="cb50-491"><a href="#cb50-491" aria-hidden="true" tabindex="-1"></a>         <span class="at">estimate =</span> <span class="st">"{estimate} [{conf.low}, {conf.high}]"</span>,</span>
<span id="cb50-492"><a href="#cb50-492" aria-hidden="true" tabindex="-1"></a>         <span class="at">statistic =</span> <span class="cn">NULL</span>, <span class="at">fmt =</span> <span class="dv">2</span>)</span>
<span id="cb50-493"><a href="#cb50-493" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-494"><a href="#cb50-494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-495"><a href="#cb50-495" aria-hidden="true" tabindex="-1"></a>Model 4 has the lowest LOO-IC, so one may conclude that Model 4 is the best model among the four, **for prediction purposes**.</span>
<span id="cb50-496"><a href="#cb50-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-497"><a href="#cb50-497" aria-hidden="true" tabindex="-1"></a>***</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p>Copyright 2024, Hok Chio (Mark) Lai</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>This book was built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>


</body></html>