[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PSYC 573 Bayesian Data Analysis (2024 Fall): Course Notes",
    "section": "",
    "text": "Preface\nThere will be some math in this notes. Don’t worry if you feel the math is challenging; for applied focused students, it is much more important to understand the concepts of Bayesian methods than to understand the mathematical symbols, as they usually can be handled by the software.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "01-intro.html",
    "href": "01-intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 History of Bayesian Statistics\nHere is a nice brief video that covers some of the 250+ years of history of Bayesian statistics:\nIf you are interested in learning more about the story, check out the popular science book, “The theory that would not die,” by McGrayne (2011)",
    "crumbs": [
      "Week 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#history-of-bayesian-statistics",
    "href": "01-intro.html#history-of-bayesian-statistics",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1.1 Thomas Bayes (1701–1762)\nYou may find a biography of Bayes from https://www.britannica.com/biography/Thomas-Bayes. There is also a nice story in the book by Lambert (2018). He was an English Presbyterian minister. The important work he wrote that founded Bayesian statistics was “An Essay Towards Solving a Problem in the Doctrine of Chances,” which he did not publish and was later discovered and edited by his friend, Richard Price, after Bayes’s death 1\n\n\n1.1.2 Pierre-Simon Laplace (1749–1827)\nLaplace, a French Mathematician, was an important figure in not just Bayesian statistics but other areas of mathematics, astronomy, and physics. We know much more about the work by Laplace than by Bayes, and Laplace has worked independently on the inverse probability problem (i.e., \\(P[\\text{Parameter} | \\text{Data}]\\)). Indeed, he was credited for largely formalizing the Bayesian interpretation of probability and most of the machinery for Bayesian statistics, and making it a useful technique for different problems, despite the discipline being called “Bayesian.” His other contributions include the methods of least squares and the central limit theorem. See a short biography of him at https://www.britannica.com/biography/Pierre-Simon-marquis-de-Laplace.\n\n\n1.1.3 20th Century\nUntil the early 1920s, the inverse probability method, which is based on what is now called Bayes’s Theorem, was pretty much the predominant point of view of statistics. Then a point of view later known as frequentist statistics arrived, and quickly became the mainstream school of thinking for statistical inferences, and is still the primary framework for quantitative research. In the early 1920s, frequentist scholars, most notably R. A. Fisher and Jerzy Neyman, criticized Bayesian inference for using subjective elements in an objective discipline. In Fisher’s words,\n\nThe theory of inverse probability is founded upon an error, and must be wholly rejected—Fisher, 1925\n\nIronically, the term Bayesian was first used in one of Fisher’s works. And interestingly, Fisher actually thought he “[had] been doing almost exactly what Bayes had done in the 18th century.”2\nDespite criticisms from frequentist scholars, Bayesian methods have been used by scholars in the Allies in World War II, such as Alan Turing, in an algorithm to break coded messages in the Enigma machine that the German Navy used to communicate. However, because of the more complex mathematics involved in Bayesian statistics, Bayesian statistics is limited to straight-forward problems and theoretical discussions until the early 1980s, when computing speed increased tremendously and made Markov Chain Monte Carlo—the primary algorithm for Bayesian estimation in modern Bayesian statistics—feasible. With the help of increased computing speed, Bayesian statistics has come back and been used as an alternative way of thinking, especially given the growing dissatisfaction towards the misuse of frequentist statistics by some scholars across disciplines. Bayesian estimation methods have also been applied to many new research questions where frequentist approaches work less well, as well as in big data analytics and machine learning.",
    "crumbs": [
      "Week 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#motivations-for-using-bayesian-methods",
    "href": "01-intro.html#motivations-for-using-bayesian-methods",
    "title": "1  Introduction",
    "section": "1.2 Motivations for Using Bayesian Methods",
    "text": "1.2 Motivations for Using Bayesian Methods\nBased on my personal experience, Bayesian methods are used quite often in statistics and related departments, as it is consistent and coherent, in contrast to frequentist where a new and probably ad hoc procedure needed to be developed to handle a new problem. For Bayesian, as long as you can formulate a model, you just run the analysis the same way as you would for simpler problems, or in Bayesian people’s words “turning the Bayesian crank,” and likely the difficulties would be more technical than theoretical, which is usually solved with better computational speed.\nSocial and behavioral scientists are relatively slow to adopt the Bayesian method, but things have been changing. In a recently accepted paper by Van De Schoot et al. (2017), the authors reviewed papers in psychology between 1990 and 2015 and found that whereas less than 10% of the papers from 1990 to 1996 mentioned “Bayesian”, the proportion increased steadily and was found in close to 45% of the psychology papers in 2015. Among studies using Bayesian methods, more than 1/4 cited computational problems (e.g., nonconvergence) in frequentist methods as a reason, and about 13% cited the need to incorporate prior knowledge into the estimation process. The other reasons included the flexibility of Bayesian methods for complex and nonstandard problems, and the use of techniques traditionally attached to Bayesian such as missing data and model comparisons.\n\n1.2.1 Problem with classical (frequentist) statistics\nThe rise of Bayesian methods is also related to the statistical reform movement in the past two decades. The problem is that applied researchers are obsessed with \\(p &lt; .05\\) and often misinterpreted a small \\(p\\)-value as something that it isn’t (read Gigerenzer, 2004). Some scholars coined the term \\(p\\)-hacking to refer to the practice of obtaining statistical significance by choosing to test the data in a certain way, either consciously or subconsciously (e.g., dichotomizing using mean or median, trying the same hypothesis using different measures of the same variable, etc). This is closely related to the recent “replication crisis” in scientific research, with psychology being in the center under close scrutiny.\nBayesian is no panacea to the problem. Indeed, if misused, it can give rise to the same problems as statistical significance. My goal in this class is to help you appreciate the Bayesian tradition of embracing the uncertainty in your results, and adopt rigorous model checking and comprehensive reporting rather than relying merely on a \\(p\\)-value. I see this as the most important mission for someone teaching statistics.",
    "crumbs": [
      "Week 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#comparing-bayesian-and-frequentist-statistics",
    "href": "01-intro.html#comparing-bayesian-and-frequentist-statistics",
    "title": "1  Introduction",
    "section": "1.3 Comparing Bayesian and Frequentist Statistics",
    "text": "1.3 Comparing Bayesian and Frequentist Statistics\n\n\n\n\n\n\n\n\nAttributes\nFrequentist\nBayesian\n\n\n\n\nInterpretation of probability\nFrequentist\nSubjectivist\n\n\nUncertainty\nHow estimates vary in repeated sampling from the same population\nHow much prior beliefs about parameters change in light of data\n\n\nWhat’s relevant?\nCurrent data set + all that might have been observed\nOnly the data set that is actually observed\n\n\nHow to proceed with analyses\nMLE; ad hoc and depends on problems\n“Turning the Bayesian crank”",
    "crumbs": [
      "Week 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#software-for-bayesian-statistics",
    "href": "01-intro.html#software-for-bayesian-statistics",
    "title": "1  Introduction",
    "section": "1.4 Software for Bayesian Statistics",
    "text": "1.4 Software for Bayesian Statistics\nThe following summarizes some of the most popular Bayesian software. Currently, JAGS and Stan are the most popular. General statistical programs like SPSS, SAS, and Stata also have some support for Bayesian analyses as well.\n\nWinBUGS\n\nBayesian inference Using Gibbs Sampling\nFree, and most popular until late 2000s. Many Bayesian scholars still use WinBUGS\nNo further development\nOne can communicate from R to WinBUGS using the package R2WinBUGS\n\nJAGS\n\nJust Another Gibbs Sampler\nVery similar to WinBUGS, but written in C++, and supports user-defined functionality\nCross-platform compatibility\nOne can communicate from R to JAGS using the package rjags or runjags\n\nStan\n\nNamed in honour of Stanislaw Ulam, who invented the Markov Chain Monte Carlo method\nUses new algorithms that are different from Gibbs sampling\nUnder very active development\nCan interface with R through the package rstan, and the R packages rstanarm and brms automates the procedure for fitting models in Stan for many commonly used models\n\n\n\n\n\n\n\n\nGigerenzer, G. (2004). Mindless statistics. The Journal of Socio-Economics, 33(5), 587–606. https://doi.org/10.1016/j.socec.2004.09.033\n\n\nLambert, B. (2018). A student’s guide to Bayesian statistics. SAGE.\n\n\nMcGrayne, S. B. (2011). The theory that would not die: How Bayes’ rule cracked the enigma code, hunted down Russian submarines, & emerged triumphant from two centuries of controversy. Yale university press.\n\n\nVan De Schoot, R., Winter, S. D., Ryan, O., Zondervan-Zwijnenburg, M., & Depaoli, S. (2017). A systematic review of Bayesian articles in psychology: The last 25 years. Psychological Methods, 22(2), 217–239. https://doi.org/10.1037/met0000100",
    "crumbs": [
      "Week 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#footnotes",
    "href": "01-intro.html#footnotes",
    "title": "1  Introduction",
    "section": "",
    "text": "Price is another important figure in mathematics and philosophy, and had taken Bayes’ theorem and applied it to insurance and moral philosophy.↩︎\nSee the paper by John Aldrich on this.↩︎",
    "crumbs": [
      "Week 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "02-probability.html",
    "href": "02-probability.html",
    "title": "\n2  Probability\n",
    "section": "",
    "text": "2.1 History of Probability",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "02-probability.html#history-of-probability",
    "href": "02-probability.html#history-of-probability",
    "title": "\n2  Probability\n",
    "section": "",
    "text": "2.1.1 Games of chance\nCorrespondence between French Mathematicians (Pierre de Fermat and Blaise Pascal) on gambling problem by Antoine Gombaud, Chevalier de Méré. The problem is roughly of the form1:\n\nImagine two people playing a multi-round game. In each round, each person has an equal chance of winning. The first person who wins six rounds will get a huge cash prize. Now, consider a scenario in which A and B have played six rounds, where A has won five and B has won one. At that time, the game had to be stopped due to a thunderstorm. Since neither A nor B have reached six wins, instead of giving the prize to either one of them, they agree to divide up the prize. What would be a fair way to do so?\n\nThe discussion led to the formalization of using mathematics to solve the problem. Basically, one way is to say if A has a 97% chance of winning the prize eventually and B has a 3% chance, then A should get 97% of the prize.",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "02-probability.html#different-ways-to-interpret-probability",
    "href": "02-probability.html#different-ways-to-interpret-probability",
    "title": "\n2  Probability\n",
    "section": "\n2.2 Different Ways to Interpret Probability",
    "text": "2.2 Different Ways to Interpret Probability\nThere are multiple perspectives for understanding probability.2 What you’ve learned in your statistics training is likely based on the frequentist interpretation of probability (and thus frequentist statistics), whereas the foundation of what you will learn in this class is the subjectivist interpretation of probability. Understanding the different perspectives on probability is helpful for understanding the Bayesian framework.\n\n\n\n\n\n\nYou don’t need to commit to one interpretation of probability in order to conduct Bayesian data analysis.\n\n\n\n\n2.2.1 Classical Interpretation\nThis is an earlier perspective and is based on counting rules. The idea is that probability is equally distributed among all “indifferent” outcomes. “Indifferent” outcomes are those where a person has no evidence to say that one outcome is more likely than another. For example, when one throws a die, one does not think that a certain number is more likely than another unless one knows that the die is biased. In this case, there are six equally likely outcomes, so the probability of each outcome is 1 / 6.\n\n\n2.2.2 Frequentist Interpretation\nThe frequentist interpretation states that probability is essentially the long-run relative frequency of an outcome. For example, to find the probability of getting a “1” when throwing a die, one can repeat the experiment many times, as illustrated below:\n\n\n\n\nTrial\nOutcome\n\n\n\n1\n2\n\n\n2\n3\n\n\n3\n1\n\n\n4\n3\n\n\n5\n1\n\n\n6\n1\n\n\n7\n5\n\n\n8\n6\n\n\n9\n3\n\n\n10\n3\n\n\n\n\n\nAnd we can plot the relative frequency of “1”s in the trials:\n\n\n\n\n\n\n\nFigure 2.1: Relative frequency when repeatedly rolling a die.\n\n\n\n\nAs you can see, with more trials, the relative frequency approaches 1 / 6. It’s the reason why in introductory statistics, many of the concepts require you to think in terms of repeated sampling (e.g., sampling distribution, \\(p\\)-values, standard errors, confidence intervals), because probability in this framework is only possible when the outcome can be repeated. It’s also the reason why we don’t talk about something like:\n\nthe probability of the null hypothesis being true, or\nthe probability that the population mean is in the interval [75.5, 80.5],\n\nbecause the population is fixed and cannot be repeated. Only the samples can be repeated, so probability in frequentist statistics is only about samples.\n\n2.2.2.1 Problem of the single case\nBecause of the frequentist’s reference to long-run relative frequency, it does not make sense to talk about the probability of an event that cannot be repeated under this framework. For example, it does not make sense to talk about\n\nthe probability that the Democrats/Republicans will win the 2028 US Presidential Election, or\nthe probability that the LA Chargers winning the 2024 Super Bowl, or\nthe probability that it will rain on Christmas Day in LA in 2024,\n\nbecause all these are specific events that cannot be repeated. However, it is common for laypeople to talk about probabilities or chances for these events.\n\n2.2.3 Subjectivist Interpretation\nThe frequentist interpretation is sometimes called the “objectivist view,” as the reference of probability is based on empirical evidence of long-run relative frequency (albeit hypothetical in many cases). In contrast, the subjectivist view of probability is based on one’s belief. For example, when I say that the probability of getting a “1” from rolling a die is 1 / 6, it reflects the state of my mind about the die. My belief can arise from different sources: Maybe I make the die and know it is a fair one; maybe I saw someone throwing the die 1,000 times, and the number of “1”s was close to 1,000 / 6, or maybe someone I trust and with authority says that the die has a 1-in-6 chance of showing a “1”.\nThe “subjective” component has been criticized a lot by frequentist scholars, sometimes unfairly. To be clear, what “subjective” here means is that probability reflects the state of one’s mind instead of the state of the world, and so it is totally fine that two people can have different beliefs about the same event. However, it does not mean that probability is arbitrary, as the beliefs are subjected to the constraints of the axioms of probability as well as the condition that the person possessing such beliefs is rational.3 Therefore, if two persons are exposed to the same information, they should form similar, though likely not identical, beliefs about the event.\nThe subjective interpretation works perfectly fine with single events, as one can have a belief about whether it rains on a particular day or a belief about a particular election result.\n\n2.2.3.1 Calibrating a subjective belief\nIn order to represent one’s belief by probability, one needs to assign a nonzero value to every plausible outcome of an event. This has been the job of odds-makers for a long time. Indeed, a lot of the development in the field of probability has to do with coming up with a fair bet. The process of assigning probabilities to outcomes of an event according to one’s belief is called calibration. For example, consider three possible outcomes for tomorrow’s weather. For simplicity, consider three mutually exclusive possible outcomes: sunny, cloudy, and rainy.\nTo calibrate my belief, consider first if you bet $10, and the return is (a) $30 for sunny, (b) $30 for cloudy, and (c) $30 for rainy. Which one will you bet? If you’re like me in LA, I’m pretty sure I’ll bet on (a), as I think that it is more likely to have a sunny day. This means that setting \\(P\\)(sunny) = \\(P\\)(cloudy) = \\(P\\)(rainy) = 1 / 3 is not a good reflection of my belief.\nNow consider the bet with the returns (a) $20 for sunny, (b) $30 for cloudy, and (c) $60 for rainy. This would reflect the belief that there is a 50% chance of a sunny day, 33.33% chance of a cloudy day, and 16.67% chance of a rainy day. Will you take the bet? This is an improvement from the last one, but I would still say a sunny day is a good bet, which suggests that the probability of 50% is too low for a sunny day. The idea is to continue iterating until it is hard to consider (a), (b), or (c) as a clear betting favorite. For me, this would end up being something like (a) $16.7 for sunny, (b) $33.3 for cloudy, and (c) $100 for rainy, which would correspond to 60% sunny, 30% cloudy, and 10% rainy.\nIf it’s hard for you to consider the gambling analogy, an alternative way is to consider how many times is a sunny day more likely than a non-sunny day, and how many times is a cloudy day more likely than a rainy day. For example, I may consider a sunny day to be twice as likely as a non-sunny day, which would give the probability of a sunny day to be 66.67%. Then, if I also think that a cloudy day is three times as likely as a rainy day, I would assign a probability of 33.33% \\(\\times\\) 3 / 4 = 25% for a cloudy day, and a probability of 33.33% \\(\\times\\) 1 / 4 = 8.33% for a rainy day.\nThe process of calibrating one’s belief plays a key role in Bayesian data analysis, namely in the form of formulating a prior probability distribution.",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "02-probability.html#basics-of-probability",
    "href": "02-probability.html#basics-of-probability",
    "title": "\n2  Probability\n",
    "section": "\n2.3 Basics of Probability",
    "text": "2.3 Basics of Probability\n\n\n\n\n\n\nKolmogorov axioms\n\n\n\nFor an event \\(A_i\\) (e.g., getting a “1” from throwing a die)\n\n\n\\(P(A_i) \\geq 0\\) [All probabilities are non-negative]\n\n\\(P(A_1 \\cup A_2 \\cup \\cdots) = 1\\) [Union of all possibilities is 1]\n\n\\(P(A_1) + P(A_2) = P(A_1 \\text{ or } A_2)\\) [Addition rule]\n\n\n\nConsider two events, for example, on throwing a die,\n\n\n\\(A\\): The number is odd\n\n\\(B\\): The number is larger than or equal to 4\n\nAssuming that die is (believed to be) fair, you can verify that the probability of \\(A\\) is \\(P(A)\\) = 3 / 6 = 1 / 2, and the probability of \\(B\\) is also \\(P(B)\\) = 3 / 6 = 1 / 2.\n\n2.3.1 Probability Distributions\n\nDiscrete event (e.g., the outcome of throwing a die or an election): probability mass. The probability is nonzero, at least for some outcomes. The graph below on the left shows the probability mass of the sum of the numbers from two dice.\n\nContinuous event (e.g., temperature): probability density.4 The probability is basically zero for any outcome. Instead, the probability density is approximated by \\(P(A \\leq a \\leq A + h) / h\\) for a very small \\(h\\).\n\nFor example, to find the probability density that a person’s well-being score is 80, we first find the probability that a person scores between 80 and 80.5 (or 80 and 80.0005), and divide that probability by 0.5 (or 0.0005). See the shaded area of the graph below on the right.\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Probability mass\n\n\n\n\n\n\n\n\n\n(b) Probability density\n\n\n\n\n\n\nFigure 2.2: Examples of probability distributions\n\n\n\n\n\n\n\n\nFor this course, as in the textbook, we use \\(P(x)\\) to mean both the probability mass for an outcome \\(x\\) when the event is discrete, and the probability density at an outcome \\(x\\) when the event is continuous.\n\n\n\n\n2.3.1.1 Example: Normal Distribution\n\\[P(x) = \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp\\left(-\\frac{1}{2}\\left[\\frac{x - \\mu}{\\sigma}\\right]^2\\right)\\]\n\n# Write a function to compute the density of an outcome x\n# for a normal distribution\nmy_normal_density &lt;- function(x, mu, sigma) {\n    exp(- ((x - mu) / sigma) ^2 / 2) / (sigma * sqrt(2 * pi))\n}\n# For example, density at x = 36 in a normal distribution\n# with mu = 50 and sigma = 10\nmy_normal_density(36, mu = 50, sigma = 10)\n\n#&gt; [1] 0.01497275\n\n\n\n2.3.2 Summarizing a Probability Distribution\nWhile it is useful to know the probability mass/density of every possible outcome, in many situations, it is helpful to summarize a distribution by some numbers.\n\n2.3.2.1 Central Tendency\n\nMean: \\(E(X) = \\int x \\cdot P(x) d x\\)\n\nMedian: 50th percentile; the median of \\(X\\) is \\(\\mathit{Mdn}_X\\) such that \\(P(X \\leq \\mathit{Mdn}_X)\\) = 1 / 2\nMode: A value with maximum probability mass/density\n\nSee Figure 2.3 (a) for examples.\n\n\n\n\n\n\n\n\n\n(a) Central Tendency\n\n\n\n\n\n\n\n\n\n(b) Interval\n\n\n\n\n\n\nFigure 2.3: Measures of central tendency and interval\n\n\n\n2.3.2.2 Dispersion\n\nVariance: \\(V(X) = E[X - E(X)]^2\\)\n\nStandard deviation: \\(\\sigma(X) = \\sqrt{V(X)}\\)\n\n\n\nMedian absolute deviation (MAD): \\(1.4826 \\times \\mathit{Mdn}(|X - \\mathit{Mdn}_X|)\\)\n\n\n2.3.2.3 Interval\nUse \\(C(X)\\) to denote an interval. A \\(W\\)% interval means \\(P(X \\in C[X]) \\approx W\\%\\)\n\nOne-sided interval: \\(C(X)\\) is half-bounded\nSymmetric \\(W\\)% interval: \\(C(X) = [L(X), U(X)]\\) is bounded, with \\(P(X &lt; L[X]) = P(X &gt; U[X]) \\approx W\\% / 2\\)\n\nAlso called equal-tailed interval\n\n\nHighest density \\(W\\)% interval (HDI): \\(P(x_c) \\geq P(x_o)\\) for every \\(x_c\\) in \\(C(X)\\) and every \\(x_o\\) outside \\(C(X)\\). In general, the HDI is the shortest \\(W\\)% interval.\n\nThe plot in Figure 2.3 (b) shows several 80% intervals.\n\n2.3.2.4 Computing Summaries of Sample Distributions Using R\n\n# Simulate data from a half-Student's t distribution with\n# df = 4, and call it sim_s\nsim_s &lt;- rt(10000, df = 4) # can be both positive and negative\nsim_s &lt;- abs(sim_s) # take the absolute values\nggplot(data.frame(x = sim_s), aes(x = x)) +\n    geom_histogram(binwidth = 0.1)\n\n\n\n\n\n\nFigure 2.4: Simulated density of a half-Student’s t distribution\n\n\n\n\n\n# Central tendency\n# (note: the mode is difficult to compute for continuous\n# variables, and rarely used in this course.)\nc(mean = mean(sim_s),\n  median = median(sim_s),\n  mode = density(sim_s, bw = \"SJ\")$x[\n      which.max(density(sim_s, bw = \"SJ\")$y)\n  ])\n\n#&gt;      mean    median      mode \n#&gt; 1.0082926 0.7426326 0.1021776\n\n# Dispersion\nc(\n    variance = var(sim_s),\n    sd = sd(sim_s),\n    mad = mad(sim_s)\n)\n\n#&gt;  variance        sd       mad \n#&gt; 1.0231058 1.0114869 0.6996741\n\n# 80% Interval\nc(`0%` = 0, quantile(sim_s, probs = .8)) # right-sided\n\n#&gt;     0%    80% \n#&gt; 0.0000 1.5598\n\nc(quantile(sim_s, probs = .2), `100%` = Inf) # left-sided\n\n#&gt;       20%      100% \n#&gt; 0.2680906       Inf\n\nquantile(sim_s, probs = c(.1, .9)) # equal-tailed/symmetric\n\n#&gt;       10%       90% \n#&gt; 0.1299027 2.1371636\n\nHDInterval::hdi(sim_s)\n\n#&gt;        lower        upper \n#&gt; 0.0003616342 2.7992620765 \n#&gt; attr(,\"credMass\")\n#&gt; [1] 0.95\n\n\n\n2.3.3 Multiple Variables\n\nJoint probability: \\(P(X, Y)\\)\n\nMarginal probability: \\[P(X) = \\int P(X, y) dy\\] \\[P(Y) = \\int P(x, Y) dx\\]\n\nThe probability that outcome \\(X\\) happens, regardless of what values \\(Y\\) take.\n\n\n\n\n\n\n\n\n\n\nFigure 2.5: Joint and Marginal Distributions\n\n\n\n\n\n2.3.3.1 Conditional Probability\nConditional probability is the probability of an event given some other information. In the real world, you can say that everything is conditional. For example, the probability of getting an odd number on throwing a die is 1/2 is conditional on the die being fair. We use \\(P(A \\mid B)\\) to represent the the conditional probability of event \\(A\\) given event \\(B\\)..\nContinuing from the previous example, \\(P(A \\mid B)\\) is the conditional probability of getting an odd number, knowing that the number is at least 4. By definition, conditional probability is the probability that both \\(A\\) and \\(B\\) happen, divided by the probability that \\(B\\) happens.\n\n\n\n\n\n\nConditional Probability\n\n\n\n\\(P(A \\mid B) = \\dfrac{P(A, B)}{P(B)}\\)\n\n\nIn the example, \\(P(A, B)\\) = 1 / 6, because 5 is the only even number \\(\\geq\\) 4 when throwing a die. Thus, \\[\n\\begin{aligned}\n    P(A \\mid B) & = 1 / 3 \\\\\n             & = \\frac{P(A, B)}{P(B)} \\\\\n             & = \\frac{1 / 6}{1 / 2}\n\\end{aligned}\n\\]\nThis picture should make it clear:\n\n\n\n\n\n\n\n\n\n\nPlease recognize that \\(P(A \\mid B) \\neq P(B \\mid A)\\). For example, when throwing a die, \\(P\\)(number is six | even number) = 1/3, but \\(P\\)(even number | number is six) is 1.\n\n\n\n\n2.3.3.2 Independence\n\n\n\n\n\n\nTwo events, \\(A\\) and \\(B\\), are independent if \\(P(A \\mid B) = P(A)\\)\n\n\n\nThis means that any knowledge of \\(B\\) does not (or should not) affect one’s belief about \\(A\\). Consider the example:\n\n\n\\(A\\): A die shows five or more\n\n\\(B\\): A die shows an odd number\n\nHere is the joint probability\n\n\n\n&gt;= 5\n&lt;= 4\n\n\n\nodd\n1/6\n2/6\n\n\neven\n1/6\n2/6\n\n\n\nSo the conditional probability of \\(P\\)(&gt;= 5 | odd) = (1/6) / (1/2) = 1/3, which is the same as \\(P\\)(&gt;= 5 | even) = (1/6) / (1/2) = 1/3. Similarly it can be verified that \\(P\\)(&lt;= 4 | odd) = \\(P\\)(&lt;= 4 | even) = 2/3. Therefore, \\(A\\) and \\(B\\) are independent.\nOn the other hand, for the example\n\n\n\\(A\\): A die shows four or more\n\n\\(B\\): A die shows an odd number\n\nthe joint probabilities are\n\n\n\n&gt;= 4\n&lt;= 3\n\n\n\nodd\n1/6\n2/6\n\n\neven\n2/6\n1/6\n\n\n\nObviously, \\(A\\) and \\(B\\) are not independent because once we know that the number is four or above, the probability of whether it is an odd number or not changes.\n\n\n\n\n\n\nIndependence can also be expressed as\n\nIf A and B are independent, \\(P(A, B) = P(A) P(B)\\)\n\n\n\n\n\n2.3.4 Law of Total Probability\nWhen we talk about conditional probability, like \\(B_1\\) = 4 or above and \\(B_2\\) = 3 or below, we can get \\(P(A \\mid B_1)\\) and \\(P(A \\mid B_2)\\) (see the figure below), we refer \\(P(A)\\) as the marginal probability, meaning that the probability of \\(A\\)  without knowledge of \\(B\\).\n\n\n\n\nIf \\(B_1, B_2, \\cdots, B_n\\) are all mutually exclusive possibilities for an event (so they add up to a probability of 1), then\n\n\n\n\n\n\nLaw of Total Probability\n\n\n\n\\[\n\\begin{aligned}\n  P(A) & = P(A, B_1) + P(A, B_2) + \\cdots + P(A, B_n)  \\\\\n       & = P(A \\mid B_1)P(B_1) + P(A \\mid B_2)P(B_2) + \\cdots + P(A \\mid B_n) P(B_n)  \\\\\n       & = \\sum_{k = 1}^n P(A \\mid B_k) P(B_k)\n\\end{aligned}\n\\]",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "02-probability.html#footnotes",
    "href": "02-probability.html#footnotes",
    "title": "\n2  Probability\n",
    "section": "",
    "text": "see the exact form at https://en.wikipedia.org/wiki/Problem_of_points↩︎\nSee http://plato.stanford.edu/entries/probability-interpret/ for more information↩︎\nIn a purely subjectivist view of probability, assigning a probability \\(P\\) to an event does not require any justifications, as long as it follows the axioms of probability. For example, I can say that the probability of me winning the lottery and thus becoming the wealthiest person on earth tomorrow is 95%, which by definition would make the probability of me not winning the lottery 5%. Most Bayesian scholars, however, do not endorse this version of subjectivist probability and require justifications of one’s beliefs (that have some correspondence to the world).↩︎\nFor many problems in the social and behavioral sciences, the measured variables are not truly continuous, but we still use continuous distributions to approximate them.↩︎",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "03-bayes-theorem.html",
    "href": "03-bayes-theorem.html",
    "title": "3  Bayes’s Theorem",
    "section": "",
    "text": "3.1 Example 1: Base rate fallacy (From Wikipedia)\nThe Bayes’s theorem is, surprisingly (or unsurprisingly), very simple:\nMore generally, we can expand it to incorporate the law of total probability to make it more applicable to data analysis. Consider \\(B_i\\) as one of the \\(n\\) many possible mutually exclusive events, then \\[\n\\begin{aligned}\n  P(B_i \\mid A) & = \\frac{P(A \\mid B_i) P(B_i)}{P(A)}  \\\\\n             & = \\frac{P(A \\mid B_i) P(B_i)}\n                      {P(A \\mid B_1)P(B_1) + P(A \\mid B_2)P(B_2) + \\cdots +\n                       P(A \\mid B_n)P(B_n)} \\\\\n             & = \\frac{P(A \\mid B_i) P(B_i)}{\\sum_{k = 1}^n P(A \\mid B_k)P(B_k)}\n\\end{aligned}\n\\]\nIf \\(B_i\\) is a continuous variable, we will replace the sum by an integral, \\[\nP(B_i \\mid A) = \\frac{P(A \\mid B_i) P(B_i)}{\\int_k P(A \\mid B_k)P(B_k)}\n\\] The denominator is not important for practical Bayesian analysis, therefore, it is sufficient to write the above equality as",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes's Theorem</span>"
    ]
  },
  {
    "objectID": "03-bayes-theorem.html#example-1-base-rate-fallacy-from-wikipedia",
    "href": "03-bayes-theorem.html#example-1-base-rate-fallacy-from-wikipedia",
    "title": "3  Bayes’s Theorem",
    "section": "",
    "text": "QuestionSolution\n\n\nA police officer stops a driver at random and does a breathalyzer test for the driver. The breathalyzer is known to detect true drunkenness 100% of the time, but in 1% of the cases, it gives a false positive when the driver is sober. We also know that, in general, for every 1,000 drivers passing through that spot, one is driving drunk. Suppose that the breathalyzer shows positive for the driver. What is the probability that the driver is truly drunk?\n\n\n\\(P(\\text{positive} | \\text{drunk}) = 1\\)\n\\(P(\\text{positive} | \\text{sober}) = 0.01\\)\n\\(P(\\text{drunk}) = 1 / 1000\\)\n\\(P(\\text{sober}) = 999 / 1000\\)\nUsing Bayes’ Theorem,\n\\[\n\\begin{aligned}\n  P(\\text{drunk} | \\text{positive})\n  & = \\frac{P(\\text{positive} | \\text{drunk}) P(\\text{drunk})}\n           {P(\\text{positive} | \\text{drunk}) P(\\text{drunk}) +\n            P(\\text{positive} | \\text{sober}) P(\\text{sober})}  \\\\\n  & = \\frac{1 \\times 0.001}{1 \\times 0.001 + 0.01 \\times 0.999} \\\\\n  & = 100 / 1099 \\approx 0.091\n\\end{aligned}\n\\]\nSo there is less than a 10% chance that the driver is drunk even when the breathalyzer shows positive.\nYou can verify that with a simulation using R:\n\nset.seed(4)\ntruly_drunk &lt;- c(rep(\"drunk\", 100), rep(\"sober\", 100 * 999))\ntable(truly_drunk)\n\n#&gt; truly_drunk\n#&gt; drunk sober \n#&gt;   100 99900\n\nbreathalyzer_test &lt;- ifelse(truly_drunk == \"drunk\",\n    # If drunk, 100% chance of showing positive\n    \"positive\",\n    # If not drunk, 1% chance of showing positive\n    sample(c(\"positive\", \"negative\"), 999000,\n        replace = TRUE, prob = c(.01, .99)\n    )\n)\n# Check the probability p(positive | sober)\ntable(breathalyzer_test[truly_drunk == \"sober\"])\n\n#&gt; \n#&gt; negative positive \n#&gt;    98903      997\n\n# 997 / 99900 = 0.00997998, so the error rate is less than 1%\n# Now, Check the probability p(drunk | positive)\ntable(truly_drunk[breathalyzer_test == \"positive\"])\n\n#&gt; \n#&gt; drunk sober \n#&gt;   100   997\n\n# 100 / (100 + 997) = 0.0911577, which is only 9.1%!",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes's Theorem</span>"
    ]
  },
  {
    "objectID": "03-bayes-theorem.html#bayesian-statistics",
    "href": "03-bayes-theorem.html#bayesian-statistics",
    "title": "3  Bayes’s Theorem",
    "section": "3.2 Bayesian Statistics",
    "text": "3.2 Bayesian Statistics\nBayesian statistics is a way to estimate some parameter \\(\\theta\\) (i.e., some quantities of interest, such as the population mean, regression coefficient, etc) by applying Bayes’ Theorem.\n\n\n\n\n\n\n\\[\nP(\\theta | D) \\propto P(D | \\theta) P(\\theta)\n\\]\n\n\n\nThere are three components in the above equality:\n\n\\(P(D | \\theta)\\), the probability that you observe data \\(D\\), given the parameter \\(\\theta\\); this is called the likelihood (Note: It is the likelihood of \\(\\theta\\), but probability about \\(y\\))\n\\(P(\\theta)\\), the probability distribution \\(\\theta\\), without referring to the data \\(D\\). This usually requires appeals to one’s degree of belief, and so is called the prior\n\\(P(\\theta | y)\\), the updated probability distribution of \\(\\theta\\), after observing the data \\(D\\); this is called the posterior\n\nOn the other hand, classical/frequentist statistics focuses solely on the likelihood function.1 In Bayesian statistics, the goal is to update one’s belief about \\(\\theta\\) based on the observed data \\(D\\).",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes's Theorem</span>"
    ]
  },
  {
    "objectID": "03-bayes-theorem.html#example-2-locating-a-plane",
    "href": "03-bayes-theorem.html#example-2-locating-a-plane",
    "title": "3  Bayes’s Theorem",
    "section": "3.3 Example 2: Locating a Plane",
    "text": "3.3 Example 2: Locating a Plane\nConsider a highly simplified scenario of locating a missing plane in the sea. Assume that we know the plane, before missing, happened to be flying at the same latitude, heading west across the Pacific, so we only need to find its longitude. We want to go out to collect debris (data) so that we can narrow the location (\\(\\theta\\)) of the plane down.\n\nPriorLikelihoodPosterior\n\n\nWe start with our prior. Assume that we have some rough idea where the plane should be, so we express our belief in a probability distribution like the following:\n\n\n\n\n\n\n\n\nFigure 3.1: Prior distribution.\n\n\n\n\n\nwhich says that our belief is that the plane is about twice more likely to be towards the east than towards the west. Below are two other options for priors (out of infinitely many), one providing virtually no information and the other encoding stronger information:\n\n\n\n\n\n\n\n\n\n\n\n(a) Noninformative prior.\n\n\n\n\n\n\n\n\n\n\n\n(b) Informative prior.\n\n\n\n\n\n\n\nFigure 3.2: More options for prior distribution.\n\n\n\nThe prior is chosen to reflect the researcher’s belief, so different researchers will likely formulate a different prior for the same problem, and that’s okay as long as the prior is reasonable and justified. Later, we will learn that in regular Bayesian analyses, with a moderate sample size, different priors generally only make negligible differences.\n\n\nNow, assume that we have collected debris in the locations shown in the graph,\n\n\n\n\n\n\n\n\nFigure 3.3\n\n\n\n\n\n\n\nNow, from Bayes’s Theorem,\n\\[\n\\text{Posterior Probability} \\propto \\text{Prior Probability} \\times\n                                       \\text{Likelihood}\n\\]\nSo we can simply multiply the prior probabilities and the likelihood to get the posterior probability for every location. A rescaling step is needed to ensure that the area under the curve will be 1, which is usually performed by the software.\n\n\n\n\n\n\n\n\nFigure 3.4\n\n\n\n\n\n\n\n\nAs illustrated below, the posterior distribution is a synthesis of (a) the prior and (b) the data (likelihood).\n\nInfluence of PriorInfluence of More Data\n\n\nFigure 3.5 shows what happen with a stronger prior:\n\n\n\n\n\n\n\n\nFigure 3.5\n\n\n\n\n\n\n\nFigure 3.6 shows what happen with 20 more data points:\n\n\n\n\n\n\n\n\nFigure 3.6",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes's Theorem</span>"
    ]
  },
  {
    "objectID": "03-bayes-theorem.html#data-order-invariance",
    "href": "03-bayes-theorem.html#data-order-invariance",
    "title": "3  Bayes’s Theorem",
    "section": "3.4 Data-Order Invariance",
    "text": "3.4 Data-Order Invariance\nIn many data analysis applications, researchers collect some data \\(D_1\\), and then collect some more data \\(D_2\\). An example would be researchers conducting two separate experiments to study the same research question. In Bayesian statistics, one can consider three ways to obtain the posterior:\n\nUpdate the belief with \\(D_1\\), and then with \\(D_2\\)\nUpdate the belief with \\(D_2\\), and then with \\(D_1\\)\nUpdate the belief with both \\(D_1\\) and \\(D_2\\) simultaneously\n\nWhether these three ways give the same posterior depends on whether data-order invariance holds. If the inference of \\(D_1\\) does not depend on \\(D_2\\), or vice versa, then all three ways lead to the same posterior. Specifically, if we have conditional independence such that \\[\nP(D_1, D_2 \\mid \\theta) = P(D_1 \\mid \\theta) P(D_2 \\mid \\theta),\n\\] then one can show all three ways give the same posterior (see section 4.4 and 4.5 of Johnson et al., 2022).\n\n\n\n\n\n\nExchangeability*\n\n\n\nExchangeability is an important concept in Bayesian statistics. Data are exchangeable when the joint distribution, \\(P(D_1, \\ldots, D_N)\\), does not depend on the ordering of the data. A simple way to think about it is if you scramble the order of your outcome variable in your data set and still can obtain the same statistical results, then the data are exchangeable. An example situation where data are not exchangeable is\n\n\\(D_1\\) is from year 1990, \\(D_2\\) is from year 2020, and the parameter \\(\\theta\\) changes from 1990 to 2020\n\nWhen data are exchangeable, conditional independence would generally hold.2",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes's Theorem</span>"
    ]
  },
  {
    "objectID": "03-bayes-theorem.html#bernoulli-likelihood",
    "href": "03-bayes-theorem.html#bernoulli-likelihood",
    "title": "3  Bayes’s Theorem",
    "section": "3.5 Bernoulli Likelihood",
    "text": "3.5 Bernoulli Likelihood\nFor binary data \\(y\\) (e.g., coin flip, pass/fail, diagnosed/not), an intuitive way to analyze is to use a Bernoulli model: \\[\n  \\begin{aligned}\n    P(y = 1 \\mid \\theta) = \\theta \\\\\n    P(y = 0 \\mid \\theta) = 1 - \\theta\n  \\end{aligned},\n\\] which is more compactly written as \\[\nP(y \\mid \\theta) = \\theta^y (1 - \\theta)^{(1 - y)},\n\\] where \\(\\theta \\in [0, 1]\\) is the probability of a “1”. You can verify that the compact form is the same as the longer form.\n\n3.5.1 Multiple Observations\nWhen there are more than one \\(y\\), say \\(y_1, \\ldots, y_N\\), that are conditionally independent, we have \\[\n  \\begin{aligned}\n    P(y_1, \\ldots, y_N \\mid \\theta) & = \\prod_{i = 1}^N P(y_i \\mid \\theta) \\\\\n    & = \\theta^{\\sum_{i = 1}^N y_i} (1 - \\theta)^{\\sum_{i = 1}^N (1 - y_i)} \\\\\n    & = \\theta^z (1 - \\theta)^{N - z}\n  \\end{aligned},\n\\] where \\(z\\) is the number of “1”s (e.g., the number of heads in coin flips). Note that the likelihood only depends on \\(z\\), not the individual \\(y\\)s. In other words, the likelihood is the same as long as there are \\(z\\) heads, regardless of when those heads occur.\nLet’s say \\(N\\) = 4 and \\(z\\) = 1. We can plot the likelihood in R:\n\n# Write the likelihood as a function of theta\nlik &lt;- function(th, num_flips = 4, num_heads = 1) {\n    th ^ num_heads * (1 - th) ^ (num_flips - num_heads)\n}\n# Likelihood of theta = 0.5\nlik(0.5)\n\n#&gt; [1] 0.0625\n\n# Plot the likelihood\nggplot(data.frame(th = c(0, 1)), aes(x = th)) +\n    # `stat_function` for plotting a function\n    stat_function(fun = lik) +\n    # use `expression()` to get greek letters\n    labs(x = expression(theta),\n    y = \"Likelihood with N = 4 and z = 1\")\n\n\n\n\n\n\n\nFigure 3.7: Binomial likelihood function with \\(N\\) = 4 and \\(z\\) = 1\n\n\n\n\n\n\n\n3.5.2 Setting Priors\nRemember again the relationship between the prior and the posterior: \\[P(\\theta | y) \\propto P(y | \\theta) P(\\theta)\\] The posterior distributions are mathematically determined once the priors and the likelihood are set. However, the mathematical form of the posterior is sometimes very difficult to deal with.\nOne straightforward, brute-force method is to discretize the parameter space into a number of points. For example, by taking \\(\\theta\\) = 0, 0.05, 0.10, . . . , 0.90, 0.95, 1.00, one can evaluate the posterior at these 21 grid points.\nLet’s use a prior that peaks at 0.5 and linearly decreases to both sides. I assume that \\(\\theta\\) = 0.5 is twice as likely as \\(\\theta = 0.25\\) or \\(\\theta = 0.75\\) to reflect my belief that the coin is more likely to be fair.\n\n# Define a grid for the parameter\ngrid_df &lt;- data.frame(th = seq(0, 1, by = 0.05))\n# Set the prior mass for each value on the grid\ngrid_df$pth &lt;- c(0:10, 9:0)  # linearly increasing, then decreasing\n# Convert pth to a proper distribution such that the value\n# sum to one\n1grid_df$pth &lt;- grid_df$pth / sum(grid_df$pth)\n# Plot the prior\nggplot(grid_df, aes(x = th, y = pth)) +\n    geom_col(aes(x = th, y = pth),\n        width = 0.01,\n    ) +\n    labs(y = expression(P(theta)), x = expression(theta))\n\n\n1\n\nThis line ensures that the probability values sum to one. This is a trick we will use to obtain the posterior probability.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrior Predictive Distribution\n\n\n\nOne way to check whether the prior is appropriate is to use the prior predictive distribution. Bayesian models are generative because they can be used to simulate data. The prior predictive distribution can be obtained by first simulating some \\(\\theta\\) values from the prior distribution and then simulating a data set for each \\(\\theta\\).\n\n# Draw one theta\nnum_trials &lt;- 4  # number of draws\nsim_th1 &lt;- sample(grid_df$th, size = 1,\n                  # based on prior probability\n                  prob = grid_df$pth)\n# Simulate new data of four flips based on model\nsim_y1 &lt;- rbinom(num_trials, size = 1, prob = sim_th1)\n\n# Repeat many times\n# Set number of simulation draws\nnum_draws &lt;- 1000\nsim_th &lt;- sample(grid_df$th, size = num_draws, replace = TRUE,\n                 # based on prior probability\n                 prob = grid_df$pth)\n# Use a for loop\n# Initialize output\nsim_y &lt;- matrix(NA, nrow = num_trials, ncol = num_draws)\nfor (s in seq_len(num_draws)) {\n    # Store simulated data in the sth column\n    sim_y[, s] &lt;- rbinom(num_trials, size = 1, prob = sim_th[s])\n}\n# Show the first 10 simulated data sets based on prior:\nsim_y[, 1:10]\n\n#&gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n#&gt; [1,]    1    0    0    1    0    1    0    0    0     1\n#&gt; [2,]    0    0    0    1    1    0    1    0    1     1\n#&gt; [3,]    1    0    0    1    0    0    0    1    1     1\n#&gt; [4,]    1    0    1    1    1    0    0    1    1     0\n\n# Show the distribution of number of heads\nsim_heads &lt;- colSums(sim_y)\nggplot(data.frame(z = sim_heads), aes(x = z)) +\n    geom_bar()\n\n\n\n\n\n\n\n\nThe outcome seems to fit our intuition that it’s more likely to be half heads and half tails, but there is a lot of uncertainty.\n\n\n\n\n3.5.3 Summarizing the Posterior\n\ngrid_df &lt;- grid_df |&gt;\n    mutate(\n        # Use our previously defined lik() function\n        py_th = lik(th, num_flips = 4, num_heads = 1),\n        # Product of prior and likelihood\n        `prior x lik` = pth * py_th,\n        # Scaled the posterior\n        pth_y = `prior x lik` / sum(`prior x lik`)\n    )\n# Print a table\nknitr::kable(grid_df)\n\n\n\n\nth\npth\npy_th\nprior x lik\npth_y\n\n\n\n\n0.00\n0.00\n0.0000000\n0.0000000\n0.0000000\n\n\n0.05\n0.01\n0.0428687\n0.0004287\n0.0073359\n\n\n0.10\n0.02\n0.0729000\n0.0014580\n0.0249500\n\n\n0.15\n0.03\n0.0921188\n0.0027636\n0.0472914\n\n\n0.20\n0.04\n0.1024000\n0.0040960\n0.0700927\n\n\n0.25\n0.05\n0.1054688\n0.0052734\n0.0902416\n\n\n0.30\n0.06\n0.1029000\n0.0061740\n0.1056525\n\n\n0.35\n0.07\n0.0961187\n0.0067283\n0.1151381\n\n\n0.40\n0.08\n0.0864000\n0.0069120\n0.1182815\n\n\n0.45\n0.09\n0.0748688\n0.0067382\n0.1153071\n\n\n0.50\n0.10\n0.0625000\n0.0062500\n0.1069530\n\n\n0.55\n0.09\n0.0501187\n0.0045107\n0.0771891\n\n\n0.60\n0.08\n0.0384000\n0.0030720\n0.0525695\n\n\n0.65\n0.07\n0.0278687\n0.0019508\n0.0333832\n\n\n0.70\n0.06\n0.0189000\n0.0011340\n0.0194056\n\n\n0.75\n0.05\n0.0117188\n0.0005859\n0.0100268\n\n\n0.80\n0.04\n0.0064000\n0.0002560\n0.0043808\n\n\n0.85\n0.03\n0.0028687\n0.0000861\n0.0014727\n\n\n0.90\n0.02\n0.0009000\n0.0000180\n0.0003080\n\n\n0.95\n0.01\n0.0001187\n0.0000012\n0.0000203\n\n\n1.00\n0.00\n0.0000000\n0.0000000\n0.0000000\n\n\n\n\n\n\n# Plot the prior/likelihood and the posterior\nggplot(data = grid_df, aes(x = th)) +\n    geom_col(aes(x = th - 0.005, y = pth, fill = \"prior\"),\n        width = 0.01,\n    ) +\n    geom_col(aes(x = th + 0.005, y = py_th / sum(py_th),\n        fill = \"scaled likelihood\"), width = 0.01,\n    ) +\n    labs(fill = NULL, y = NULL, x = expression(theta)) +\n    theme(legend.position = \"top\")\nggplot(data = grid_df, aes(x = th)) +\n    geom_col(aes(x = th, y = pth_y), width = 0.01) +\n    labs(\n        fill = NULL, y = NULL, title = \"Posterior\",\n        x = expression(theta)\n    )\n\n\n\n\n\n\n\n\n\n\n\n(a) Prior and likelihood\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Posterior\n\n\n\n\n\n\n\nFigure 3.8: Bernoulli posterior distribution\n\n\n\n\nFigure 3.8 (b) shows the posterior distribution, which represents our updated belief about \\(\\theta\\). We can summarize it by simulating \\(\\theta\\) values from it and compute summary statistics:\n\n# Define a function for computing posterior summary\nsumm_draw &lt;- function(x) {\n    c(\n        mean = mean(x),\n        median = median(x),\n        sd = sd(x),\n        mad = mad(x),\n        `ci.1` = quantile(x, prob = .1, names = FALSE),\n        `ci.9` = quantile(x, prob = .9, names = FALSE)\n    )\n}\n# Sample from the posterior\npost_samples &lt;- sample(\n    grid_df$th,\n    size = 1000, replace = TRUE,\n    prob = grid_df$pth_y\n)\nsumm_draw(post_samples)\n\n#&gt;      mean    median        sd       mad      ci.1      ci.9 \n#&gt; 0.3848000 0.4000000 0.1538429 0.1482600 0.2000000 0.6000000\n\n# Alternatively, use the `posterior` package\ndata.frame(theta = post_samples) |&gt;\n    posterior::summarize_draws()\n\n\n  \n\n\n\n\nInfluence of Sample SizeInfluence of Prior\n\n\nIf, instead, we have \\(N\\) = 40 and \\(z\\) = 10, the posterior will be more similar to the likelihood.\n\ngrid_df2 &lt;- grid_df |&gt;\n    mutate(\n        # Use our previously defined lik() function\n        py_th = lik(th, num_flips = 40, num_heads = 10),\n        # Product of prior and likelihood\n        `prior x lik` = pth * py_th,\n        # Scaled the posterior\n        pth_y = `prior x lik` / sum(`prior x lik`)\n    )\n# Plot the prior/likelihood and the posterior\nggplot(data = grid_df2, aes(x = th)) +\n    geom_col(aes(x = th - 0.005, y = pth, fill = \"prior\"),\n        width = 0.01,\n    ) +\n    geom_col(aes(x = th + 0.005, y = py_th / sum(py_th),\n        fill = \"scaled likelihood\"), width = 0.01,\n    ) +\n    labs(fill = NULL, y = NULL, x = expression(theta)) +\n    theme(legend.position = \"top\")\n\n\n\n\n\n\n\nggplot(data = grid_df2, aes(x = th)) +\n    geom_col(aes(x = th, y = pth_y), width = 0.01) +\n    labs(\n        fill = NULL, y = NULL, title = \"Posterior\",\n        x = expression(theta)\n    )\n\n\n\n\n\n\n\n\n\n# Sample from the posterior\npost_samples &lt;- sample(\n    grid_df2$th,\n    size = 1000, replace = TRUE,\n    prob = grid_df2$pth_y\n)\nsumm_draw(post_samples)\n\n#&gt;       mean     median         sd        mad       ci.1       ci.9 \n#&gt; 0.28085000 0.30000000 0.06542215 0.07413000 0.20000000 0.35000000\n\n\n\n\nIf we have a very strong prior concentrated at \\(\\theta\\) = .5, but still with \\(N\\) = 40 and \\(z\\) = 10, the posterior will be more similar to the prior.\n\ngrid_df3 &lt;- grid_df |&gt;\n    mutate(\n        # stronger prior\n        pth = pth ^ 3,\n        # scale the prior to sume to 1\n        pth = pth / sum(pth),\n        # Use our previously defined lik() function\n        py_th = lik(th, num_flips = 4, num_heads = 1),\n        # Product of prior and likelihood\n        `prior x lik` = pth * py_th,\n        # Scaled the posterior\n        pth_y = `prior x lik` / sum(`prior x lik`)\n    )\n# Plot the prior/likelihood and the posterior\nggplot(data = grid_df3, aes(x = th)) +\n    geom_col(aes(x = th - 0.005, y = pth, fill = \"prior\"),\n        width = 0.01,\n    ) +\n    geom_col(aes(x = th + 0.005, y = py_th / sum(py_th),\n        fill = \"scaled likelihood\"), width = 0.01,\n    ) +\n    labs(fill = NULL, y = NULL, x = expression(theta)) +\n    theme(legend.position = \"top\")\n\n\n\n\n\n\n\nggplot(data = grid_df3, aes(x = th)) +\n    geom_col(aes(x = th, y = pth_y), width = 0.01) +\n    labs(\n        fill = NULL, y = NULL, title = \"Posterior\",\n        x = expression(theta)\n    )\n\n\n\n\n\n\n\n\n\n# Sample from the posterior\npost_samples &lt;- sample(\n    grid_df3$th,\n    size = 1000, replace = TRUE,\n    prob = grid_df3$pth_y\n)\nsumm_draw(post_samples)\n\n#&gt;      mean    median        sd       mad      ci.1      ci.9 \n#&gt; 0.4493000 0.4500000 0.1096656 0.0741300 0.3000000 0.6000000\n\n# Alternatively, use the `posterior` package\ndata.frame(theta = post_samples) |&gt;\n    posterior::summarize_draws()\n\n\n  \n\n\n\n\n\n\n\n\n3.5.4 Remark on Grid Approximation\nIn this note, we discretized \\(\\theta\\) into a finite number of grid points to compute the posterior, mainly for pedagogical purposes. A big limitation is that our posterior will have no density for values other than the chosen grid points. While increasing the number of grid points (e.g., 1,000) can give more precision, the result is still not truly continuous. A bigger issue is that the computation breaks down when there is more than one parameter; if there are \\(p\\) parameters, with 1,000 grid points per parameter, one needs to evaluate the posterior probability for \\(1,000^p\\) grid points, which is not feasible even with modern computers. So more efficient algorithms, namely Markov chain Monte Carlo (MCMC) methods, will be introduced as we progress in the course.\n\n\n\n\n\n\nJohnson, A. A., Ott, M. Q., & Dogucu, M. (2022). Bayes rules! An introduction to Bayesian modeling with R. CRC Press.",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes's Theorem</span>"
    ]
  },
  {
    "objectID": "03-bayes-theorem.html#footnotes",
    "href": "03-bayes-theorem.html#footnotes",
    "title": "3  Bayes’s Theorem",
    "section": "",
    "text": "The likelihood function in classical/frequentist statistics is usually written as \\(P(y; \\theta)\\). You will notice that here, I write the likelihood for classical/frequentist statistics to be different from the one used in Bayesian statistics. This is intentional: In frequentist conceptualization, \\(\\theta\\) is fixed, and it does not make sense to talk about the probability of \\(\\theta\\). This implies that we cannot condition on \\(\\theta\\), because conditional probability is defined only when \\(P(\\theta)\\) is defined.↩︎\nThe de Finetti’s theorem shows that when the data are exchangeable and can be considered an infinite sequence (i.e., not from a tiny finite population), then the data are conditionally independent given some \\(\\theta\\).↩︎",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes's Theorem</span>"
    ]
  },
  {
    "objectID": "04-beta-bernoulli-model.html",
    "href": "04-beta-bernoulli-model.html",
    "title": "\n4  Beta-Bernoulli Model\n",
    "section": "",
    "text": "4.1 Steps of Bayesian Data Analysis\nSome authors described the process as “turning the Bayesian Crank,” as the same workflow applies to a variety of research scenarios.\nAdapted from Gelman et al. (2020), I conceptualize Bayesian data analysis as the following steps:",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Beta-Bernoulli Model</span>"
    ]
  },
  {
    "objectID": "04-beta-bernoulli-model.html#steps-of-bayesian-data-analysis",
    "href": "04-beta-bernoulli-model.html#steps-of-bayesian-data-analysis",
    "title": "\n4  Beta-Bernoulli Model\n",
    "section": "",
    "text": "Identify/Collect the data required to answer the research questions.\n\nAs a general recommendation, it is helpful to visualize the data to get a sense of how they look, as well as to inspect for potential anomalies in the data collection.\n\n\n\nChoose an initial statistical model for the data in relation to the research questions. The model should have some theoretical justification and have parameters that are meaningful for the research questions. However, it is unlikely that any chosen model will capture everything important in the data, and this initial model will be modified and expanded in later steps.\n\nSpecify prior distributions for the model parameters. Although this is a subjective endeavor, the priors chosen should be sensible to a skeptical audience.\n\nCheck the prior distributions. It is recommended you conduct a prior predictive check, by simulating fake data based on the chosen model and prior distributions. This is especially important for complex models as the parameters are more difficult to interpret.\n\nObtain the posterior distributions for the model parameters. As described below and later in the course, this can be obtained by analytical or various mathematical approximations.\n\nFor mathematical approximations, one should check the algorithms for convergence to make sure the results closely mimic the target posterior distributions.\n\n\nConduct a posterior predictive check to examine the fit between the model and the data, i.e., whether the chosen model with the estimated parameters generates predictions that deviate from the data being analyzed on important features.\nIt is unlikely that your initial model fully describes the major aspects of the data as pertaining to your research questions. Therefore, one should repeat steps 2 to 6 to specify and compare different models.\nIf the fit between the model and the data is deemed satisfactory, one can proceed to interpret the results in the context of the research questions. It is also important to visualize the results in ways that are meaningful for the analysis.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Beta-Bernoulli Model</span>"
    ]
  },
  {
    "objectID": "04-beta-bernoulli-model.html#beta-bernoulli-example",
    "href": "04-beta-bernoulli-model.html#beta-bernoulli-example",
    "title": "\n4  Beta-Bernoulli Model\n",
    "section": "\n4.2 Beta-Bernoulli Example",
    "text": "4.2 Beta-Bernoulli Example\nWe will be using a built-in data set in R about patients diagnosed with AIDS in Australia before July 1, 1991. Here is a description of the variables (from the R documentation):\n\n\nFigure from https://commons.wikimedia.org/wiki/File:Australia_states_1931-present.png\n\n\n\nstate: Grouped state of origin: “NSW”includes ACT and “other” is WA, SA, NT, and TAS.\n\nsex: Sex of patient.\n\ndiag:(Julian) date of diagnosis.\n\ndeath: (Julian) date of death or end of observation.\n\nstatus: “A” (alive) or “D” (dead) at end of observation.\n\nT.categ: Reported transmission category.\n\nage: Age (years) at diagnosis.\n\nYou should always first plot your data and get some summary statistics:\n\ndata(\"Aids2\", package = \"MASS\")\nhead(Aids2)\n\n\n  \n\n\n\n\npairs.panels(Aids2, ellipses = FALSE)\n\n\n\n\n\n\n\nWe will be using the status variable. Our simple research question is:\n\nWhat was the death rate of AIDS in Australia when the data were collected?\n\n\n4.2.1 Bernoulli Model\nIf we assume that the outcomes of the observations are exchangeable, meaning that the observations can be reordered in any way and still give the same inference, then one can choose a model: \\[\ny_i \\sim \\text{Bern}(\\theta) \\text{ for }i = 1, 2, \\ldots, N\n\\]\n\n\n\\(y_i\\) = status of observation \\(i\\) (0 = “A”, 1 = “D”)\n\n\\(N\\) = number of patients in the data set\n\n\\(\\theta\\) = probability of “D”1\n\n\n\nThe model states that: the sample data \\(y\\) follows a Bernoulli distribution with \\(n\\) with a parameter \\(\\theta\\)\n\n\n\n\n\n\n\nWhen the data consist of binary observations, the variable is called a Bernoulli variable. It is conventional to denote one outcome as success and code it as 1, and the other as failure and code it as 0 (poor terminology, maybe, but that’s by convention). Therefore, in the AIDS example, each observation is considered a “Bernoulli” outcome (Alive vs. Dead).\n\n\n\n\n4.2.2 Exchangeability\nTo illustrate exchangeability in an example, say we take 6 rows in our data set:\n\n\n\n  \n\n\n\nNow, when we reorder the column status to something like:\n\n\n\n  \n\n\n\nIf the results are expected to be the same, then we say that the observations are assumed exchangeable. It happens when we assume that all observations have one common mean. However, if we think that there is a mean for females and a different mean for males, we cannot reorder the outcome randomly because they are no longer exchangeable (i.e., you cannot exchange a female score for a male score and expect to get the same results).\n\n\n\n\n\n\nExchangeability\n\n\n\nA set of observations is said to be exchangeable if their joint probability distribution stays the same under all permutations. Roughly speaking, it means that the observations can be reordered and still provide the same inferences.\n\n\n\n4.2.3 Check the Support\nIt is important to identify the support of the parameter, \\(\\theta\\). Because \\(\\theta\\) is a probability, its support is \\([0, 1]\\), meaning it is continuous and can take any value from 0 to 1. For a continuous parameter, there are infinitely many possible values, and it is impossible to specify our beliefs for each value. So, more commonly, we choose a probability density function with the same support as the parameter to express our prior belief.\n\n4.2.4 Conjugate Prior: Beta Distribution\nA commonly used family of prior distributions for a Bernoulli/binomial model is the Beta distribution, which has two parameters. We can write the prior as \\[P(\\theta) \\sim \\text{Beta}(a, b)\\]\n\\(a\\) and \\(b\\) are the two hyperparameters. Here are a few examples:\n\n\n\n\n\n\n\nFigure 4.1: Beta distributions with different a and b values\n\n\n\n\nYou will notice that when \\(a &gt; b\\), there is more density closer to the right region (i.e., larger \\(\\theta\\)), and vice versa. Also, the variance decreases when \\(a\\) and \\(b\\) become larger.2\nA nice interpretation of \\(a\\) and \\(b\\) in a Beta prior distribution is to consider\n\n\n\\(a - 1\\) = number of prior ‘successes’ (e.g., “D”)\n\n\\(b - 1\\) = number of prior ‘failures’ (e.g., “A”)\n\nTherefore, with \\(\\text{Beta}(1, 1)\\), one has seen 0 prior success and 0 failure, meaning that there is no prior information (i.e., noninformative). Therefore, it makes sense that all \\(\\theta\\) values are equally likely. On the other hand, if one chooses \\(\\text{Beta}(10, 20)\\), one has seen 9 prior successes and 19 prior failures, so one has quite a lot of prior information (indeed more than the data with only 10 observations), so this is a strong prior.\n\nThe smaller the variance of the prior distribution, the stronger one’s belief before looking at the data, the more prior information\n\nSo by manipulating the values of \\(a\\) and \\(b\\), which are sometimes called hyperparameters, you can control the shape of the prior distribution as well as its strength, so it is quite flexible. Another advantage of using a beta prior is that it is a conjugate prior of the Bernoulli model, which means that the posterior distribution \\(P(\\theta \\mid y)\\) is also a beta distribution, the same as the prior distribution, although with different parameter values.\n\n\n\n\n\n\nConjugate Prior\n\n\n\nFor a specific model, conjugate priors yield posterior distributions in the same distribution family as the priors\n\n\nConjugacy greatly simplifies the computational burden for Bayesian analyses, so conjugate priors are almost the only ones used in earlier literature. However, this limited the applications of Bayesian methods, as for many problems, no conjugate priors can provide a realistic representation of one’s belief. Modern Bayesian analysis instead relies on simulation-based methods to approximate the posterior distribution, which can accommodate almost any kind of prior distribution. Aside from a few examples in this note, mainly for pedagogical purposes, we will be using simulation-based methods in the coming weeks.\n\n\n\n\n\n\nProof of Conjugacy*\n\n\n\nTo derive the form of the posterior, first recognize that the Beta distribution has the form:\n\\[\n\\begin{aligned}\n  P(\\theta) & = \\mathrm{B}^{-1}(a, b) \\theta^{a - 1} (1 - \\theta)^{b - 1} \\\\\n  & \\propto \\theta^{a - 1} (1 - \\theta)^{b - 1}\n\\end{aligned}\n\\]\nWhere \\(\\mathrm{B}(\\cdot)\\) is the beta function which is not very important for the class. As the density function is a function of \\(\\theta\\), it suffices to write only the terms that involve \\(\\theta\\).\nSimilarly, \\[\nP(\\mathbf{y} \\mid \\theta) \\propto \\theta^z (1 - \\theta)^{N - z}.\n\\]\nTherefore,\n\\[\n\\begin{aligned}\n  P(\\theta \\mid \\mathbf{y}) & \\propto P(y \\mid \\theta) P(\\theta)  \\\\\n                & \\propto \\theta^z (1 - \\theta)^{N - z}\n                          \\theta^{a - 1} (1 - \\theta)^{b - 1}  \\\\\n                & = \\theta^{a + z - 1} (1 - \\theta)^{b + N - z - 1}.\n\\end{aligned}\n\\]\nIf we let \\(a^* = a + z\\), \\(b^* = b + N - z\\), we can see that \\(P(\\theta \\mid \\mathbf{y})\\) is in the same form as the prior with \\(a\\) and \\(b\\) replaced by \\(a^*\\) and \\(b^*\\). Therefore, the posterior is also a beta distribution. So the beta distribution is a conjugate prior for the Bernoulli model.\n\n\nIn this example, we will choose a weakly informative Beta(2, 2) prior, which represents a weak belief as below:\n\nggplot(data.frame(th = c(0, 1)), aes(x = th)) +\n    stat_function(fun = dbeta, args = list(shape1 = 2, shape2 = 2)) +\n    ylim(0, 3) +\n    labs(y = \"\", x = expression(theta), title = \"Beta(2, 2)\")\n\n\n\n\n\n\nFigure 4.2: A weakly informative Beta(2, 2) prior\n\n\n\n\n\n\n\n\n\n\nDon’t Be Stubborn\n\n\n\n\nA good prior should give a non-zero probability/density for all possible values of a parameter\n\nOtherwise, if the prior density for some parameter values is zero, the posterior density will be zero, regardless of how much the data support those parameter values\n\n\n\n4.2.5 Data\n\ncount(Aids2, status)\n\n\n  \n\n\n\nThe likelihood function is highly concentrated. I ran into some numerical issues as the computation gave zero, so I plotted the log-likelihood instead.\n\nloglik &lt;- function(th, N = 1082 + 1761, z = 1761) {\n    z * log(th) + (N - z) * log(1 - th)\n}\nggplot(data.frame(th = c(0.61, 0.63)), aes(x = th)) +\n    stat_function(fun = loglik, n = 501) +\n    labs(x = expression(theta), y = \"Log-likelihood\")\n\n\n\n\n\n\nFigure 4.3: Log-likelihood function of the theta parameter\n\n\n\n\nNote I only show a range of [0.610, 0.630] for the x-axis, which contains where the likelihood (thus also the log-likelihood) peaked.\n\n4.2.6 Posterior\nBased on the conjugacy, the posterior of \\(\\theta\\) is Beta(1,807, 1,116). As we are using a conjugate prior, the posterior is also a Beta distribution: \\[\nP(\\theta \\mid y) \\sim \\text{Beta}(a + z, b + N - z),\n\\] which is a distribution for \\(a + z - 1\\) successes and \\(b + N - z\\) failures. This makes perfect sense as our prior information has \\(a - 1\\) successes and \\(b - 1\\) failures, and from our data, we have \\(y\\) successes and \\(n - y\\) failures, so our updated belief is based on adding up those successes and failures.\n\n4.2.7 Summarize the posterior\n\nset.seed(2119)\nnum_draws &lt;- 1000\nsim_theta &lt;- rbeta(num_draws, shape1 = 1807, shape2 = 1116)\nc(`Bayes estimate` = mean(sim_theta),\n  `Posterior median` = median(sim_theta),\n  `Posterior SD` = sd(sim_theta),\n  `MAD` = mad(sim_theta),\n  `90% Credible interval (equal-tailed)` = quantile(sim_theta, probs = c(.1, .9)),\n  `90% HDI` = HDInterval::hdi(sim_theta, credMass = .9))\n\n                          Bayes estimate \n                             0.618209694 \n                        Posterior median \n                             0.618382945 \n                            Posterior SD \n                             0.008829290 \n                                     MAD \n                             0.009254166 \n90% Credible interval (equal-tailed).10% \n                             0.606862338 \n90% Credible interval (equal-tailed).90% \n                             0.628990588 \n                           90% HDI.lower \n                             0.604051851 \n                           90% HDI.upper \n                             0.632766654 \n\n\n\n4.2.8 Posterior Predictive Check\nNow, we need to know whether the model fits the data well. We do not have much to check for a Bernoulli model if we only have the status variable. However, as there is information for other variables, we can use them to check the exchangeability assumption. For example, we can ask whether the data from different state categories are exchangeable. The death rate across the 4 state categories are\n\n\n       status\nstate      A    D\n  NSW    664 1116\n  Other  107  142\n  QLD     78  148\n  VIC    233  355\n\n\n       status\nstate           A         D\n  NSW   0.3730337 0.6269663\n  Other 0.4297189 0.5702811\n  QLD   0.3451327 0.6548673\n  VIC   0.3962585 0.6037415\n\n\nWe can now generate predictions from our posterior distribution and model.\n\nplist &lt;- vector(\"list\", 12L)\nplist[[1]] &lt;- ggplot(\n    Aids2,\n    aes(x = state, y = mean(status == \"D\"), fill = state)\n) +\n    geom_bar(stat = \"identity\") +\n    guides(fill = \"none\") +\n    labs(x = \"Observed data\", y = \"Number of Deaths\") +\n    theme(axis.title.x = element_text(color = \"red\")) +\n    ylim(0, 1200)\nfor (i in 1:11) {\n    # Get the a value from posterior samples\n    theta_post &lt;- rbeta(1, 1763, 1084)\n    # For each plausible theta value, generate a status variable\n    status_new &lt;- sample(c(\"D\", \"A\"), nrow(Aids2),\n        replace = TRUE,\n        prob = c(theta_post, 1 - theta_post)\n    )\n    df_new &lt;- Aids2 |&gt;\n        mutate(status = factor(status_new))\n    plist[[i + 1]] &lt;- plist[[1]] %+% df_new +\n        labs(x = paste(\"Simulated data\", i)) +\n        theme(axis.title.x = element_text(color = \"black\"))\n}\ngridExtra::grid.arrange(grobs = plist, nrow = 3)\n\n\n\n\n\n\nFigure 4.4: Posterior predictive check by comparing the observed data with 11 simulated data sets based on the model\n\n\n\n\nSo the observed data (the first subplot) look similar to the simulated data. We can also conduct a posterior predictive check by a test statistic for subgroups. Here, we will use the bayesplot package and look at fit across groups:\n\n# Draw posterior samples of theta\npost_sample &lt;- rbeta(1e4, 1807, 1116)\n# Initialize a S by N matrix to store the simulated data\ny_tilde &lt;- matrix(NA,\n                  nrow = length(post_sample),\n                  ncol = length(Aids2$status))\nfor (s in seq_along(post_sample)) {\n    theta_s &lt;- post_sample[s]\n    status_new &lt;- sample(c(\"D\", \"A\"), nrow(Aids2),\n        replace = TRUE,\n        prob = c(theta_s, 1 - theta_s)\n    )\n    y_tilde[s,] &lt;- as.numeric(status_new == \"D\")\n}\nbayesplot::ppc_stat_grouped(\n    as.numeric(Aids2$status == \"D\"),\n    yrep = y_tilde,\n    group = Aids2$state\n)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nFigure 4.5: Posterior predictive check by states\n\n\n\n\nIf the fit is good, the mean, indicated by the darker line, should be within the simulated distribution based on the model. So the model that assumes observations are exchangeable across states is not too off, although it seems fitting less well for Other states.\n\n4.2.8.1 Another check on age\n\n\n# Create an age group indicator\nage50 &lt;- factor(Aids2$age &gt; 50, labels = c(\"&lt;= 50\", \"&gt; 50\"))\n# Draw posterior samples of theta\npost_sample &lt;- rbeta(1e4, 1807, 1116)\n# Initialize a S by N matrix to store the simulated data\ny_tilde &lt;- matrix(NA,\n                  nrow = length(post_sample),\n                  ncol = length(Aids2$status))\nfor (s in seq_along(post_sample)) {\n    theta_s &lt;- post_sample[s]\n    status_new &lt;- sample(c(\"D\", \"A\"), nrow(Aids2),\n        replace = TRUE,\n        prob = c(theta_s, 1 - theta_s)\n    )\n    y_tilde[s,] &lt;- as.numeric(status_new == \"D\")\n}\nbayesplot::ppc_stat_grouped(\n    as.numeric(Aids2$status == \"D\"),\n    yrep = y_tilde,\n    group = age50\n)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nFigure 4.6: Posterior predictive check by age groups (&lt;= 50 vs. &gt; 50)\n\n\n\n\nAs can be seen, the model seems off for those aged 50+.\n\n4.2.9 Comparison to frequentist results\nUsing maximum likelihood, the estimated death rate would be \\(\\hat \\theta = 1761 / 2843 = 0.62\\), with a standard error (SE) of \\(\\sqrt{0.62 (1 - 0.62) / n} = 0.0091\\), with a 90% confidence interval of \\([0.6, 0.63]\\), which is similar to the interval with Bayesian inference.\n\n4.2.10 Sensitivity to different priors\n\n\n\n\n\n\n\nFigure 4.7: Sensitivity of posterior to different priors\n\n\n\n\nYou can see one needs (a) a very strong prior (equivalent to 600 data points) and (b) the prior and the data not agreeing to get a substantially different conclusion.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Beta-Bernoulli Model</span>"
    ]
  },
  {
    "objectID": "04-beta-bernoulli-model.html#footnotes",
    "href": "04-beta-bernoulli-model.html#footnotes",
    "title": "\n4  Beta-Bernoulli Model\n",
    "section": "",
    "text": "An additional thing to note for the Bernoulli/binomial model is that, instead of setting the prior on \\(\\theta\\), sometimes we are more interested in setting the prior for a transformed parameter that has values between \\(-\\infty\\) and \\(\\infty\\), such as one on the logit scale (as related to logistic regression).↩︎\nThe \\(\\mathrm{Beta}(1 / 2, 1 / 2)\\) distribution is called a Jeffreys prior (https://en.wikipedia.org/wiki/Jeffreys_prior), which is derived according to some statistical principles for different models. One big advantage of a Jeffreys prior is that it is invariant, meaning that the prior will stay the same even under reparameterization. However, like conjugate priors, Jeffreys prior limits the choice of prior even when true prior information is available.↩︎",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Beta-Bernoulli Model</span>"
    ]
  },
  {
    "objectID": "04b-beta-bernoulli-stan.html",
    "href": "04b-beta-bernoulli-stan.html",
    "title": "\n5  Beta-Bernoulli Model With Stan\n",
    "section": "",
    "text": "5.1 Installing Stan\nIn the previous lecture, we fitted a Beta-Bernoulli model using Gibbs sampling with our own R code. While this is doable in this relatively simple model (it only has one parameter), for more complex models, Gibbs sampling and other MCMC methods (to be introduced in a later class) require quite a lot of programming. Fortunately for us, we have some readily available software for doing MCMC. While it is probably overkill for the Beta-Bernoulli model, we will learn working with Stan by using it to analyze the Beta-Bernoulli model. Specifically, we will learn to:\nWe will talk about convergence of MCMC, which is an extremely important topic, in a later class.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Beta-Bernoulli Model With Stan</span>"
    ]
  },
  {
    "objectID": "04b-beta-bernoulli-stan.html#installing-stan",
    "href": "04b-beta-bernoulli-stan.html#installing-stan",
    "title": "\n5  Beta-Bernoulli Model With Stan\n",
    "section": "",
    "text": "Follow the steps in https://mc-stan.org/cmdstanr/ to install the cmdstanr package.\nLoad the cmdstanr package, and run install_cmdstan()\n\n\n\nlibrary(cmdstanr)\ninstall_cmdstan()\n\n\nIf you run into an error in the previous step related to C++ toolchain, follow the directions here: https://mc-stan.org/cmdstanr/articles/cmdstanr.html",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Beta-Bernoulli Model With Stan</span>"
    ]
  },
  {
    "objectID": "04b-beta-bernoulli-stan.html#fitting-a-beta-bernoulli-model-in-stan",
    "href": "04b-beta-bernoulli-stan.html#fitting-a-beta-bernoulli-model-in-stan",
    "title": "\n5  Beta-Bernoulli Model With Stan\n",
    "section": "\n5.2 Fitting a Beta-Bernoulli Model in Stan",
    "text": "5.2 Fitting a Beta-Bernoulli Model in Stan\n\n5.2.1 Data Import\nFrom last class:\n\ndata(\"Aids2\", package = \"MASS\")\nhead(Aids2)\n\n\n  \n\n\n\n\n5.2.2 Writing Stan syntax\nStan has its own syntax and is different from R. For example, we want to fit the following Beta-Bernoulli model:\n\\[\n\\begin{aligned}\n  y_i & \\sim \\text{Bern}(\\theta) \\text{ for }i = 1, 2, \\ldots, N \\\\\n  P(\\theta) & \\sim \\text{Beta}(2, 2)\n\\end{aligned}\n\\]\nand the model can be written in Stan as follows:\n\ndata {\n  int&lt;lower=0&gt; N;  // number of observations\n  array[N] int&lt;lower=0,upper=1&gt; y;  // y\n}\nparameters {\n  real&lt;lower=0,upper=1&gt; theta;  // theta parameter\n}\nmodel {\n  theta ~ beta(2,2);  // prior: Beta(2, 2)\n  y ~ bernoulli(theta);  // model: Bernoulli\n}\n\n\n\n\n\n\n\nSave the above model syntax in a separate file ending in .stan. For example, I saved the syntax in the file beta-bernoulli.stan in a folder named stan_code.\n\n\n\nIn Stan, anything after // denotes comments (like # in R) and will be ignored by the program. In each block (e.g., data {}), a statement should end with a semicolon (;). There are several blocks in the above Stan code:\n\n\ndata: The data input for Stan is usually not only an R data frame, but a list that includes other information, such as sample size, number of predictors, and prior scales. Each type of data has an input type, such as\n\nint = integer,\nreal = numbers with decimal places,\nmatrix = 2-dimensional data of real numbers,\nvector = 1-dimensional data of real numbers, and\narray = 1- to many-dimensional data. For example, we use array[N] for the data type of y, because it is a vector, but each element is an integer (and cannot take decimals).\n\nWe can set the lower and upper bounds so that Stan can check the input data. In the above, we used &lt;lower=0,upper=1&gt;.\n\nparameters: The parameters to be estimated\ntransformed parameters: optional variables that are transformations of the model parameters. It is usually used for more advanced models to allow more efficient MCMC sampling.\nmodel: It includes expressions of prior distributions for each parameter and the likelihood for the data. There are many possible distributions that can be used in Stan.\ngenerated quantities: Any quantities that are not part of the model but can be computed from the parameters for every iteration. Examples include posterior generated samples, effect sizes, and log-likelihood (for fit computation). We will see an example later.\n\n5.2.3 Compiling the Stan model from R\nTo compile the model, we can call the cmdstan_model function in cmdstanr:\n\nbern_mod &lt;- cmdstan_model(\"stan_code/beta-bernoulli.stan\")\n\n\n5.2.4 Posterior Sampling\nWe need to first prepare the data for input to Stan. In the Stan code, we have two objects in the data block: N and y, so we need to have a list of two elements in R:\n\nAids2_standata &lt;- list(\n    N = nrow(Aids2),\n    y = as.integer(Aids2$status == \"D\")  # integer\n)\n\nNow we can draw posterior samples:\n\nfit &lt;- bern_mod$sample(Aids2_standata)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.6 seconds.\n\n\nFor this simple model, this takes less than a second.\n\n5.2.5 Summarizing and plotting the posterior samples\n\n# Actual posterior samples\nfit$draws(\"theta\", format = \"draws_df\")\n\n\n  \n\n\n\n\n# Summary table\nfit$summary()\n\n\n  \n\n\n\n\n# Histogram\nfit$draws(\"theta\") |&gt;\n    mcmc_hist()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nFigure 5.1: Posterior distribution of the parameter.\n\n\n\n\nThe results are similar to those in last class.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Beta-Bernoulli Model With Stan</span>"
    ]
  },
  {
    "objectID": "04b-beta-bernoulli-stan.html#prior-predictive-check",
    "href": "04b-beta-bernoulli-stan.html#prior-predictive-check",
    "title": "\n5  Beta-Bernoulli Model With Stan\n",
    "section": "\n5.3 Prior Predictive Check",
    "text": "5.3 Prior Predictive Check\nIn Bayesian analyses, it is recommended to check both the prior and the model. This can be done by\n\nPrior predictive check: Simulating data from the prior distribution, and see if the simulated data fit our prior belief.\nPosterior predictive check: Simulating data from the posterior distribution, and see if the simulated data are comparable to the observed data.\n\nWe will use the following Stan code to do prior and posterior predictive checks, which has an additional generated quantity block to obtain\n\n\nprior_theta: simulated values of \\(\\theta\\) based on the prior distribution\n\nprior_ytilde: simulated data based on the prior distribution of \\(\\theta\\)\n\n\nytilde: simulated data based on the posterior distribution of \\(\\theta\\)\n\n\n\ndata {\n  int&lt;lower=0&gt; N;  // number of observations\n  array[N] int&lt;lower=0,upper=1&gt; y;  // y\n}\nparameters {\n  real&lt;lower=0,upper=1&gt; theta;  // theta parameter\n}\nmodel {\n  theta ~ beta(2, 2);  // prior: Beta(2, 2)\n  y ~ bernoulli(theta);  // model: Bernoulli\n}\ngenerated quantities {\n  real prior_theta = beta_rng(2, 2);\n  array[N] int prior_ytilde;\n  array[N] int ytilde;\n  for (i in 1:N) {\n    ytilde[i] = bernoulli_rng(theta);\n    prior_ytilde[i] = bernoulli_rng(prior_theta);\n  }\n}\n\n\nbern_pp_mod &lt;- cmdstan_model(\"stan_code/beta-bernoulli-pp.stan\")\nbern_pp_fit &lt;- bern_pp_mod$sample(\n    Aids2_standata,\n    refresh = 500  # show progress every 500 iterations\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.9 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.9 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.8 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.9 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.9 seconds.\nTotal execution time: 3.7 seconds.\n\n\nWith Stan, because we obtained 4,000 prior/posterior draws (the software default) of \\(\\theta\\), we also obtained 4,000 simulated data sets. We can see the first one, based on only the prior distribution (i.e., \\(\\theta\\) \\(\\sim\\) \\(\\text{Beta}(2, 2)\\)):\n\nbern_pp_fit$draws(\"prior_ytilde\", format = \"draws_df\")[1, ] |&gt;\n    as.numeric() |&gt;\n    table()\n\n\n   0    1 \n1005 1841 \n\n\n\nNote that the data set has more 1’s than 0’s. Our prior is weak, which means that it allows for a lot of variation in how the data would look.\n\nThe distribution of simulated data based on the prior distribution of the parameters is called the prior predictive distribution. Mathematically, we write it as\n\\[\nP(\\tilde y) = \\int P(\\tilde y | \\theta) P(\\theta) \\; \\mathrm{d}\\theta\n\\]\nBecause we have 4,000 data sets, it is not easy to visualize all individual data points. Instead, we can visualize some summary statistics of the simulated data. Here, we will choose the proportion of deaths (i.e., the mean of the variable) in each simulated data set:\n\nbern_pp_fit$draws(\"prior_ytilde\", format = \"draws_matrix\") |&gt;\n    ppd_stat(stat = \"mean\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nFigure 5.2: Prior predictive distribution of the sample mean.\n\n\n\n\nThis represents our prior belief about the proportion of deaths without looking at the actual data. If this doesn’t seem to match our belief, we may want to modify our prior distribution and do the prior predictive check again, until the simulated data matches our actual prior belief.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Beta-Bernoulli Model With Stan</span>"
    ]
  },
  {
    "objectID": "04b-beta-bernoulli-stan.html#posterior-predictive-check",
    "href": "04b-beta-bernoulli-stan.html#posterior-predictive-check",
    "title": "\n5  Beta-Bernoulli Model With Stan\n",
    "section": "\n5.4 Posterior Predictive Check",
    "text": "5.4 Posterior Predictive Check\n\n5.4.1 Check 1: Sample Mean\n\\[\nP(\\tilde y | y) = \\int P(\\tilde y | \\theta, y) P(\\theta | y) \\; \\mathrm{d}\\theta\n\\]\nThe difference here is that we use the posterior distribution \\(P(\\theta | y)\\) instead of the prior distribution \\(P(\\theta)\\). We can obtain the posterior predictive distribution of the death rate, and indicate the actual data in the plot:\n\nbern_pp_fit$draws(\"ytilde\", format = \"draws_matrix\") |&gt;\n    ppc_stat(y = Aids2_standata$y, stat = \"mean\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nFigure 5.3: Posterior predictive distribution of the sample mean.\n\n\n\n\n\n5.4.2 Check 2: Sample Mean by Age Group\n\n# Create binary indicator of two age groups\nage50 &lt;- factor(Aids2$age &gt; 50, labels = c(\"&lt;= 50\", \"&gt; 50\"))\nbern_pp_fit$draws(\"ytilde\", format = \"draws_matrix\") |&gt;\n    ppc_stat_grouped(y = Aids2_standata$y, group = age50,stat = \"mean\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nFigure 5.4: Posterior predictive distribution of the sample mean by age group.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Beta-Bernoulli Model With Stan</span>"
    ]
  },
  {
    "objectID": "04c-poisson-model.html",
    "href": "04c-poisson-model.html",
    "title": "\n6  Poisson Model\n",
    "section": "",
    "text": "6.1 Research Question\nI came across this data set from https://andrewpwheeler.com/2021/01/11/checking-a-poisson-distribution-fit-an-example-with-officer-involved-shooting-deaths-wapo-data-r-functions/\nAs explained here, the data are by the Washington Post in an effort to record every fatal shooting in the United States by a police officer since January 1, 2015.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Poisson Model</span>"
    ]
  },
  {
    "objectID": "04c-poisson-model.html#research-question",
    "href": "04c-poisson-model.html#research-question",
    "title": "\n6  Poisson Model\n",
    "section": "",
    "text": "What’s the rate of fatal police shootings in the United States per year?",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Poisson Model</span>"
    ]
  },
  {
    "objectID": "04c-poisson-model.html#data-import-and-pre-processing",
    "href": "04c-poisson-model.html#data-import-and-pre-processing",
    "title": "\n6  Poisson Model\n",
    "section": "\n6.2 Data Import and Pre-Processing",
    "text": "6.2 Data Import and Pre-Processing\n\n# Import data\nfps_dat &lt;- read_csv(\n    \"https://github.com/washingtonpost/data-police-shootings/raw/master/v2/fatal-police-shootings-data.csv\"\n)\n\nWe first count the data by year\n\n# Create a year column\nfps_dat &lt;- fps_dat |&gt;\n    mutate(year = format(date, format = \"%Y\"))\n# Filter out the latest year\nfps_1523 &lt;- filter(fps_dat, year != max(year))\ncount(fps_1523, year)\n\n\n  \n\n\n\nOur interest is the rate of occurrence of fatal police shootings per year. Denote this as \\(\\theta\\). The support of \\(\\theta\\) is \\([0, \\infty)\\).\nA Poisson model is usually a starting point for analyzing count data in a fixed amount of time. It assumes that the data follow a Poisson distribution with a fixed rate parameter: \\[P(y \\mid \\theta) \\propto \\theta^y \\exp(- \\theta),\\] where the data can be any non-negative integers (no decimals).",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Poisson Model</span>"
    ]
  },
  {
    "objectID": "04c-poisson-model.html#choosing-a-prior",
    "href": "04c-poisson-model.html#choosing-a-prior",
    "title": "\n6  Poisson Model\n",
    "section": "\n6.3 Choosing a Prior",
    "text": "6.3 Choosing a Prior\nThe Gamma distribution has support: \\([0, \\infty)\\), and is a conjugate family to the Poisson model. The Gamma distribution has the form \\[\nP(\\theta) \\propto \\theta^{a - 1} \\exp(-b \\theta),\n\\] where \\(a\\) is the prior incidence rate, and \\(b\\) is the number of prior data points to control for the prior strength. Here, without much prior knowledge, I would simply guess there is one fatal shooting per state per month, so 600 shootings per year, but my belief is pretty weak, so I will assume a prior \\(b\\) of 1 / 200 (one observation is one year). The \\(a\\) will be 600 * \\(b\\) = 3.\nHere’s a plot:\n\nggplot(data.frame(th = c(0, 2000)), aes(x = th)) +\n    stat_function(fun = dgamma,\n    args = list(shape = 3, rate = 1 / 200)) +\n    labs(y = \"\", x = expression(theta))\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel Fitting in Stan\n\n\n\n\ndata {\n  int&lt;lower=0&gt; N;  // number of observations\n  array[N] int&lt;lower=0&gt; y;  // y\n  real&lt;lower=0&gt; prior_a;  // prior a for gamma\n  real&lt;lower=0&gt; prior_b;  // prior b for gamma\n}\nparameters {\n  real&lt;lower=0&gt; theta;  // theta parameter\n}\nmodel {\n  // prior: Gamma(3, 1 / 200)\n  // using conjugacy\n  theta ~ gamma(prior_a + sum(y), prior_b + N);\n}\ngenerated quantities {\n  real prior_theta = gamma_rng(3, 0.005);\n  array[N] int prior_ytilde;\n  array[N] int ytilde;\n  for (i in 1:N) {\n    ytilde[i] = poisson_rng(theta);\n    prior_ytilde[i] = poisson_rng(prior_theta);\n  }\n}\n\n\n6.3.1 Compiling\n\npois_mod &lt;- cmdstan_model(\"stan_code/gamma-poisson-pp.stan\")\n\n\n6.3.2 Data for Stan\n\nfps_standata &lt;- list(\n    N = length(unique(fps_1523$year)),\n    y = count(fps_1523, year)[, 2, drop = TRUE],  # integer\n    prior_a = 3,\n    prior_b = 1 / 200\n)\nfps_standata\n\n$N\n[1] 9\n\n$y\n[1]  995  959  984  992  994 1021 1050 1097 1164\n\n$prior_a\n[1] 3\n\n$prior_b\n[1] 0.005\n\n\n\n6.3.3 MCMC Sampling\n\nfit &lt;- pois_mod$sample(\n    fps_standata,\n    refresh = 500  # show progress every 500 iterations\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \n\n\nChain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 1 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 1 \n\n\nChain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 1 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 1 \n\n\nChain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 1 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 1 \n\n\nChain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 1 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 1 \n\n\nChain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 1 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 1 \n\n\nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 2 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 2 \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 2 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 2 \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 2 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 2 \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 2 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 2 \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 2 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 2 \n\n\nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \n\n\nChain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 3 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 3 \n\n\nChain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 3 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 3 \n\n\nChain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 3 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 3 \n\n\nChain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 3 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 3 \n\n\nChain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 3 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 3 \n\n\nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \n\n\nChain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 4 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 4 \n\n\nChain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 4 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 4 \n\n\nChain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 4 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 4 \n\n\nChain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 4 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 4 \n\n\nChain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 4 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 4 \n\n\nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.6 seconds.\n\n\n\n\n\n\n6.3.4 Prior predictive check\nHere I plot simulated trends from the prior distribution.\n\n# Extract predicted y from prior\nfit$draws(\"prior_ytilde\", format = \"draws_matrix\") |&gt;\n    ppd_intervals(x = 2015:2023) +\n    labs(x = \"Year\", y = \"Predicted count\")\n\n\n\n\n\n\n\nThe check is on whether the numbers seem reasonably reflective of my knowledge.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Poisson Model</span>"
    ]
  },
  {
    "objectID": "04c-poisson-model.html#posterior",
    "href": "04c-poisson-model.html#posterior",
    "title": "\n6  Poisson Model\n",
    "section": "\n6.4 Posterior",
    "text": "6.4 Posterior\nWith a conjugate prior, the posterior distribution is Gamma(\\(a\\) + \\(\\sum_{i = 1}^N y_i\\), \\(b\\) + \\(N\\)).\n\nggplot(data.frame(th = c(0, 2000)), aes(x = th)) +\n    stat_function(fun = dgamma,\n    args = list(shape = 3 + nrow(fps_1523),\n                rate = 1 / 200 + fps_standata$N), n = 501) +\n    labs(y = \"\", x = expression(theta))",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Poisson Model</span>"
    ]
  },
  {
    "objectID": "04c-poisson-model.html#posterior-predictive-check",
    "href": "04c-poisson-model.html#posterior-predictive-check",
    "title": "\n6  Poisson Model\n",
    "section": "\n6.5 Posterior Predictive Check",
    "text": "6.5 Posterior Predictive Check\nPlot predicted data from the posterior against observed data\n# Extract predicted y from posterior\nfit$draws(\"ytilde\", format = \"draws_matrix\") |&gt;\n    ppc_intervals(\n        y = fps_standata$y,\n        x = 2015:2023\n    ) +\n    labs(x = \"Year\", y = \"Predicted count\")\n# We can also use `bayesplot::ppc_ribbon()`\nfit$draws(\"ytilde\", format = \"draws_matrix\") |&gt;\n    ppc_ribbon(\n        y = fps_standata$y,\n        x = 2015:2023\n    ) +\n    labs(x = \"Year\", y = \"Predicted count\")\n\n\n\n\n\n\n\n\n\n(a) Interval plots.\n\n\n\n\n\n\n\n\n\n(b) Ribbon plots.\n\n\n\n\n\n\nFigure 6.1: Posterior predictive check.\n\n\n\n\n\n\n\n\nFrom Figure 6.1, one can see that the fit is not good, as there is a large gap between the model prediction and the observed data from recent years. This suggests a need to incorporate the time trend in the model.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Poisson Model</span>"
    ]
  },
  {
    "objectID": "04c-poisson-model.html#summary-of-posterior",
    "href": "04c-poisson-model.html#summary-of-posterior",
    "title": "\n6  Poisson Model\n",
    "section": "\n6.6 Summary of Posterior",
    "text": "6.6 Summary of Posterior\nFor now, we will proceed with interpreting the posterior distribution, despite the apparent misfit.\n\n(summ_theta &lt;- fit$summary(\"theta\"))\n\n\n  \n\n\n\nSo the estimated rate is 1,028 per year, with a 90% CI [1,011, 1,046].",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Poisson Model</span>"
    ]
  },
  {
    "objectID": "05-hierarchical-models.html",
    "href": "05-hierarchical-models.html",
    "title": "\n7  Hierarchical Models\n",
    "section": "",
    "text": "7.1 Hierarchical Bernoulli/Binomial\nAlthough many statistical models can be fitted using Bayesian or frequentist methods, some models are more naturally used in the Bayesian framework. One class of such models is the family of hierarchical models. Consider situations when the data contain clusters, such as multiple data points in each of many participants, or multiple participants in each of several treatment conditions. While it is possible to run \\(J\\) Bayesian analyses for the \\(J\\) subsets of the data, it is usually more efficient to pool the data together. In this approach, each cluster \\(j\\) has some parameters \\(\\theta_j\\), and these \\(J\\) \\(\\theta\\) values themselves come from a common distribution. Figure 7.1 shows a graphical representation of the concept of pooling. This is the same idea as multilevel modeling, a topic we will discuss more later in the course.\nIn this note, you will see two examples, one from a textbook (Kruschke, 2015) with a hierarchical Bernoulli/binomial model, and another from a classic data set with eight schools, modelled by a hierarchical normal model.\nWe will first consider a therapeutic touch example (Kruschke, 2015, Chapter 9). Therapeutic touch is a technique in alternative medicine to relieve pain, but scientific evidence does not support its effectiveness. The data here are from an experiment where the experimenter randomly hovered their hand over either the participant’s left or right hand, and the participant had to guess which hand was being hovered without seeing. This is repeated 10 times for each participant. There are a total of 28 participants in the dataset.\nPreviously, we have seen the Bernoulli model for \\(N\\) outcomes (i.e., whether the guess is correct): \\[\ny_i \\sim \\text{Bern}(\\theta), \\text{for }i = 1, \\ldots, N\n\\] We assumed exchangeability with \\(\\theta\\) being the participant’s “ability” to guess correctly.",
    "crumbs": [
      "Week 4",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Hierarchical Models</span>"
    ]
  },
  {
    "objectID": "05-hierarchical-models.html#hierarchical-bernoullibinomial",
    "href": "05-hierarchical-models.html#hierarchical-bernoullibinomial",
    "title": "\n7  Hierarchical Models\n",
    "section": "",
    "text": "Alternative Parameterization of Beta\n\n\n\nIn the last class, we have used the Beta(a, b) prior for a Bernoulli outcome, such that \\[\nP(\\theta \\mid a, b) \\propto \\theta^{a - 1} (1 - \\theta)^{b - 1}.\n\\] However, in hierarchical models to be discussed later, it is beneficial to consider another way to express the Beta distribution, in terms of the prior mean, \\(\\mu = a / (a + b)\\), \\(\\mu \\in [0, 1]\\), and the concentration, \\(\\kappa = a + b\\), \\(\\kappa \\in [0, \\infty)\\). So, instead of the above formula, we can write \\[\nP(\\theta \\mid \\mu, \\kappa) \\propto \\theta^{\\mu \\kappa - 1} (1 - \\theta)^{(1 - \\mu) \\kappa - 1}.\n\\] The two expressions represent exactly the same distribution, but just in terms of parameters of different meanings. Therefore, they are referred to as different parameterization of the Beta distribution.\n\n\n\n\n7.1.1 Multiple Bernoulli = Binomial\nWith \\(N\\) exchangeable Bernoulli observations, an equivalent but more efficient way to code the model is to use the binomial distribution. Let \\(z = \\sum_{i = 1}^N y_i\\), then \\[\nz \\sim \\mathrm{Bin}(N, \\theta)\n\\]\n\n7.1.2 Multiple Binomial Observations\nNow, because we have multiple participants, we could study whether each participant had noticeable differences in their guessing ability. We can use a binomial model for each participant, from participant 1 to participant \\(J\\): \\[\n\\begin{aligned}\n  z_1 \\sim \\mathrm{Bin}(N_1, \\theta_1) \\\\\n  z_2 \\sim \\mathrm{Bin}(N_2, \\theta_2) \\\\\n  \\vdots \\\\\n  z_J \\sim \\mathrm{Bin}(N_J, \\theta_J)\n\\end{aligned}\n\\]\nOr instead of writing \\(J\\) equations, we can use the subscript \\(j\\) to refer to each participant: \\[\nz_{\\textcolor{red}{j}} \\sim \\mathrm{Bin}(N_{\\textcolor{red}{j}}, \\theta_{\\textcolor{red}{j}})\n\\]\nIf we believe that all participants have the same ability, then we could consider the model \\[\nz_j \\sim \\mathrm{Bin}(N_j, \\theta),\n\\] which still contains only one parameter, \\(\\theta\\). However, if we have reason to believe that the coins have different biases, then we should have \\[z_j \\sim \\mathrm{Bin}(N_j, \\theta_{\\color{red}{j}}),\\] with parameters \\(\\theta_1, \\ldots, \\theta_j\\).\nWe can assign priors to each \\(\\theta_j\\). However, suppose our prior belief is that there’s something common among the different participants (e.g., they’re all human beings), so they come from a common distribution. In that case, we can have common parameters for the prior distributions of the \\(\\theta\\)s: \\[\n\\theta_j \\sim \\mathrm{Beta\\_Proportion}(\\mu, \\kappa),\n\\] note I use Beta_Proportion to denote the mean parameterization. Here, we express the prior belief that the mean ability of the different participants is \\(\\mu\\), and how each participant differs from the mean depends on \\(\\kappa\\). Now, \\(\\mu\\) and \\(\\kappa\\) are hyperparameters. We can assign some fixed values to \\(\\mu\\) and \\(\\kappa\\), as if we know what the average ability is. However, the power of the hierarchical model is that we can put priors (or hyper priors) on \\(\\mu\\) and \\(\\kappa\\), and obtain posterior distributions of them, based on what the data say.\nWhat priors to use for \\(\\mu\\) and \\(\\kappa\\)? \\(\\mu\\) is relatively easy because it is the mean ability; if we put a Beta prior for each participant’s ability, we can again use a Beta prior for the mean ability. \\(\\kappa\\) is more challenging. A larger \\(\\kappa\\) means that the participants’ abilities are more similar to each other. We can perform a prior predictive check to see what the data look like. As a starting point, some textbook (e.g., chapter 9 of Kruschke, 2015) suggested using Gamma(0.01, 0.01). So the full model in our case, with a weak Beta(1.5, 1.5) prior on \\(\\mu\\), is\nModel: \\[\n  \\begin{aligned}\n    z_j & \\sim \\mathrm{Bin}(N_j, \\theta_j) \\\\\n    \\theta_j & \\sim \\mathrm{Beta2}(\\mu, \\kappa)\n  \\end{aligned}\n\\] Prior: \\[\n  \\begin{aligned}\n    \\mu & \\sim \\mathrm{Beta}(1.5, 1.5) \\\\\n    \\kappa & \\sim \\mathrm{Gamma}(0.01, 0.01)\n  \\end{aligned}\n\\]\nWe will import the data and fit the model\n\n# Data file from GitHub\ntt_url &lt;- paste0(\n    \"https://github.com/boboppie/kruschke-doing_bayesian_data_analysis/\",\n    \"raw/master/2e/TherapeuticTouchData.csv\"\n)\ntt_dat &lt;- read.csv(tt_url)\n# Get aggregated data by summing the counts\ntt_agg &lt;- tt_dat |&gt;\n    group_by(s) |&gt;\n    summarise(y = sum(y),  # total number of correct\n              n = n())\n# Plot proportion correct distribution\np1 &lt;- ggplot(tt_agg, aes(x = y / n)) +\n    geom_histogram(binwidth = .1) +\n    labs(x = \"Proportion Correct\")\n\n\n\n\n\n\n\n\nFigure 7.2: Distribution of proportions of correct responses across participants.\n\n\n\n\n\n7.1.3 Stan Code\n\ndata {\n  int&lt;lower=0&gt; J;  // number of clusters (e.g., studies, persons)\n  array[J] int y;  // number of \"1\"s in each cluster\n  array[J] int N;  // sample size for each cluster\n}\nparameters {\n  // cluster-specific probabilities\n  vector&lt;lower=0, upper=1&gt;[J] theta;\n  real&lt;lower=0, upper=1&gt; mu;  // overall mean probability\n  real&lt;lower=0&gt; kappa;        // overall concentration\n}\nmodel {\n  y ~ binomial(N, theta);  // each observation is binomial\n  // Priors\n  theta ~ beta_proportion(mu, kappa);\n  mu ~ beta(1.5, 1.5);      // weak prior\n  kappa ~ gamma(.1, .1);  // prior recommended by Kruschke\n}\ngenerated quantities {\n  // Prior and posterior predictive\n  real&lt;lower=0, upper=1&gt; prior_mu = beta_rng(1.5, 1.5);\n  real&lt;lower=0&gt; prior_kappa = gamma_rng(.1, .1);\n  vector&lt;lower=0, upper=1&gt;[J] prior_theta;\n  for (j in 1:J) {\n    prior_theta[j] = beta_proportion_rng(prior_mu, prior_kappa);\n  }\n  array[J] int prior_ytilde = binomial_rng(N, prior_theta);\n  // Posterior predictive\n  array[J] int ytilde = binomial_rng(N, theta);\n}\n\n\nhbin_mod &lt;- cmdstan_model(\"stan_code/hierarchical-binomial.stan\")\n\n\n7.1.4 Prior predictive\nYou can use Stan to sample the prior and obtain the prior predictive distribution; here, I show how to do it in R, with a Gamma(.01, .01) prior on \\(\\kappa\\):\n\nset.seed(1706)\nplist &lt;- vector(\"list\", 12L)\nplist[[1]] &lt;- p1 +\n    labs(x = \"Observed data\") +\n    theme(axis.title.x = element_text(color = \"red\"))\nnum_subjects &lt;- 28\nfor (s in 1:11) {\n    # Get prior values of mu and kappa\n    mu_s &lt;- rbeta(1, shape1 = 1.5, shape2 = 1.5)\n    kappa_s &lt;- rgamma(1, shape = 0.01, rate = 0.01)\n    # Generate theta\n    theta &lt;- rbeta(num_subjects,\n                   shape1 = mu_s * kappa_s,\n                   shape2 = (1 - mu_s) * kappa_s)\n    # Generate data\n    new_y &lt;- rbinom(num_subjects, size = tt_agg$n, prob = theta)\n    plist[[s + 1]] &lt;-\n        p1 %+% mutate(tt_agg, y = new_y) +\n        labs(x = paste(\"Simulated data\", s)) +\n        theme(axis.title.x = element_text(color = \"black\"))\n}\ngridExtra::grid.arrange(grobs = plist, nrow = 3)\n\n\n\n\n\n\nFigure 7.3: Prior predictive distribution.\n\n\n\n\nThe prior on \\(\\kappa\\) is not very realistic because it pushes the bias to either 0 or 1. Using something like Gamma(0.1, 0.1) or Gamma(2, 0.01) may be more reasonable (you can try it out yourself).\n\n7.1.5 Calling Stan\n\ntt_fit &lt;- hbin_mod$sample(\n    data = list(J = nrow(tt_agg),\n                y = tt_agg$y,\n                N = tt_agg$n),\n    seed = 1716,  # for reproducibility\n    refresh = 1000\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.1 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 2 Exception: beta_proportion_lpdf: Location parameter is 1, but must be less than 1.000000 (in '/tmp/RtmpjKgfHa/model-2caa6a28826c92.stan', line 15, column 2 to column 37)\n\n\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 2 \n\n\nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.1 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.1 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \n\n\nChain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 4 Exception: beta_proportion_lpdf: Location parameter is 0, but must be positive! (in '/tmp/RtmpjKgfHa/model-2caa6a28826c92.stan', line 15, column 2 to column 37)\n\n\nChain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 4 \n\n\nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 1.0 seconds.\n\n\nYou can explore the convergence and posterior distributions using the shinystan package\n\nshinystan::launch_shinystan(tt_fit)\n\n\n7.1.6 Table of coefficients\n\ntt_fit$summary(c(\"theta\", \"mu\", \"kappa\")) |&gt;\n    # Use `knitr::kable()` for tabulation\n    knitr::kable(digits = 2)\n\n\nTable 7.1: Posterior summary of hierarchical binomial model for the therapeutic touch example.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\ntheta[1]\n0.31\n0.31\n0.10\n0.10\n0.15\n0.47\n1\n3268.39\n2404.91\n\n\ntheta[2]\n0.35\n0.35\n0.10\n0.10\n0.19\n0.51\n1\n3741.46\n2422.69\n\n\ntheta[3]\n0.39\n0.39\n0.10\n0.10\n0.23\n0.55\n1\n4744.99\n2794.69\n\n\ntheta[4]\n0.39\n0.39\n0.10\n0.10\n0.23\n0.55\n1\n4859.60\n3056.80\n\n\ntheta[5]\n0.39\n0.39\n0.10\n0.10\n0.22\n0.55\n1\n4817.40\n2485.43\n\n\ntheta[6]\n0.39\n0.38\n0.10\n0.10\n0.23\n0.55\n1\n5260.92\n2493.09\n\n\ntheta[7]\n0.39\n0.38\n0.10\n0.10\n0.23\n0.55\n1\n5586.84\n2968.73\n\n\ntheta[8]\n0.39\n0.39\n0.10\n0.10\n0.23\n0.55\n1\n4926.08\n3008.76\n\n\ntheta[9]\n0.39\n0.39\n0.10\n0.10\n0.23\n0.55\n1\n4802.85\n2558.79\n\n\ntheta[10]\n0.39\n0.39\n0.10\n0.10\n0.22\n0.55\n1\n4743.85\n2910.25\n\n\ntheta[11]\n0.43\n0.42\n0.10\n0.09\n0.27\n0.59\n1\n5041.77\n3066.93\n\n\ntheta[12]\n0.42\n0.42\n0.09\n0.10\n0.27\n0.58\n1\n6055.56\n2896.89\n\n\ntheta[13]\n0.43\n0.42\n0.10\n0.10\n0.27\n0.59\n1\n4898.48\n3112.24\n\n\ntheta[14]\n0.43\n0.42\n0.10\n0.10\n0.27\n0.59\n1\n5909.48\n3065.15\n\n\ntheta[15]\n0.43\n0.42\n0.10\n0.10\n0.27\n0.59\n1\n6304.56\n3049.53\n\n\ntheta[16]\n0.46\n0.46\n0.10\n0.10\n0.31\n0.62\n1\n5642.01\n3230.67\n\n\ntheta[17]\n0.46\n0.46\n0.10\n0.10\n0.30\n0.63\n1\n5517.58\n3108.00\n\n\ntheta[18]\n0.46\n0.46\n0.10\n0.10\n0.30\n0.63\n1\n5622.46\n2837.76\n\n\ntheta[19]\n0.46\n0.46\n0.10\n0.09\n0.31\n0.63\n1\n6228.82\n3062.79\n\n\ntheta[20]\n0.46\n0.46\n0.10\n0.10\n0.30\n0.63\n1\n4758.62\n2538.88\n\n\ntheta[21]\n0.46\n0.46\n0.10\n0.10\n0.30\n0.62\n1\n5922.64\n2921.96\n\n\ntheta[22]\n0.46\n0.46\n0.10\n0.10\n0.31\n0.62\n1\n5218.69\n3180.07\n\n\ntheta[23]\n0.50\n0.50\n0.10\n0.10\n0.34\n0.67\n1\n5424.13\n2936.72\n\n\ntheta[24]\n0.50\n0.50\n0.10\n0.10\n0.34\n0.67\n1\n5321.61\n2733.91\n\n\ntheta[25]\n0.54\n0.54\n0.10\n0.10\n0.38\n0.71\n1\n3861.44\n2248.48\n\n\ntheta[26]\n0.54\n0.54\n0.10\n0.10\n0.37\n0.72\n1\n3808.59\n2430.69\n\n\ntheta[27]\n0.54\n0.54\n0.10\n0.10\n0.38\n0.71\n1\n3679.86\n2556.84\n\n\ntheta[28]\n0.58\n0.57\n0.10\n0.11\n0.41\n0.75\n1\n3005.40\n2460.66\n\n\nmu\n0.44\n0.44\n0.04\n0.04\n0.38\n0.50\n1\n2482.91\n2932.61\n\n\nkappa\n18.65\n16.37\n9.63\n7.92\n7.49\n36.92\n1\n992.72\n1793.53\n\n\n\n\n\n\n\n\n\n7.1.7 Posterior Predictive Check\nWith hierarchical models, there are two types of posterior predictive distributions:\n\n\nSame participants but new observations. We can use the model to generate new observations, but the individual parameters (e.g., \\(\\theta_j\\)) remain the same. In our example, this would be the situation where we ask the same 28 participants to each do 10 more trials.\n\nNew participants and new observations. We can use the model to generate new observations with new parameters from the higher-order distribution (e.g., the Beta distribution for \\(\\theta_j\\)). In our example, this would be the situation where we ask a new set of 28 participants to each do 10 more trials.\n\nIn our Stan code, I used (1) to check the fit of the observed data. However, (2) can be helpful when one wants to use the model to make predictions of future data, as future data are unlikely to concern exactly the same participants.\n\n# The bayesplot::ppc_bars() unfortunately contains a bug\n# (https://github.com/stan-dev/bayesplot/issues/266) at\n# the time when I wrote this, so I'll use my own code.\n# tt_fit$draws(\"ytilde\", format = \"draws_matrix\") |&gt;\n#     ppc_bars(y = tt_agg$y)\nyrep &lt;- tt_fit$draws(\"ytilde\", format = \"draws_matrix\")\nyrep_intervals &lt;- apply(\n    yrep, MARGIN = 1, FUN = \\(x) table(factor(x, levels = 0:10))\n    ) |&gt;\n    apply(MARGIN = 1, FUN = \\(x) {\n        c(\n            lo = quantile(x, .05)[[1]],\n            me = median(x),\n            hi = quantile(x, .95)[[1]]\n        )\n    })\ndata.frame(\n    y = table(factor(tt_agg$y, levels = 0:10))\n) |&gt;\n    setNames(c(\"x\", \"y\")) |&gt;\n    cbind(t(yrep_intervals)) |&gt;\n    ggplot(aes(x = x, y = y)) +\n    geom_col(alpha = 0.5) +\n    geom_pointrange(aes(y = me, ymin = lo, ymax = hi)) +\n    labs(y = \"count\", x = NULL)\n\n\n\n\n\n\nFigure 7.4: Posterior predictive check. The bar graph shows the observed data, and the error bars show the 90% posterior predictive interval in replicated data. The dots are the medians in the posterior predictive distribution.\n\n\n\n\n\n7.1.8 Derived coefficients\nOne nice thing about MCMC is that it is straightforward to obtain posterior distributions that are functions of the parameters. For example, even though we only sampled from the posteriors of the \\(\\theta\\)s, we can ask questions like whether there is evidence for a nonzero difference in \\(\\theta\\) between person 1 and person 28.\n\ntt_fit$draws() |&gt;\n    mutate_variables(\n        theta1_minus14 = `theta[1]` - `theta[14]`,\n        theta1_minus28 = `theta[1]` - `theta[28]`,\n        theta14_minus28 = `theta[14]` - `theta[28]`\n    ) |&gt;\n    subset(variable = c(\"theta1_minus14\", \"theta1_minus28\",\n                        \"theta14_minus28\")) |&gt;\n    summarise_draws() |&gt;\n    knitr::kable(digits = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\ntheta1_minus14\n-0.11\n-0.11\n0.13\n0.13\n-0.34\n0.09\n1\n4950.80\n2632.63\n\n\ntheta1_minus28\n-0.27\n-0.26\n0.15\n0.16\n-0.53\n-0.03\n1\n2312.44\n3115.27\n\n\ntheta14_minus28\n-0.15\n-0.15\n0.14\n0.14\n-0.38\n0.06\n1\n4309.81\n3013.97\n\n\n\n\n\n\n7.1.9 Conclusion\nAs 0.5 is included in the 95% CI of \\(\\theta\\) for all participants, there is insufficient evidence that people can sense “therapeutic touch.”\n\n7.1.10 Shrinkage\n\nmcmc_intervals(tt_fit$draws(),\n               # plot only parameters matching \"theta\"\n               regex_pars = \"^theta\") +\n    geom_point(\n        data = tibble(\n            parameter = paste0(\"theta[\", 1:28, \"]\"),\n            x = tt_agg$y / tt_agg$n\n        ),\n        aes(x = x, y = parameter),\n        col = \"red\"\n    ) +\n    xlim(0, 1)\n\nScale for x is already present.\nAdding another scale for x, which will replace the existing scale.\n\n\n\n\nShrinkage effect in a hierarchical model.\n\n\n\nAs can be seen, the posterior distributions are closer to the center than the data (in red). This pooling results from the belief that the participants have something in common.\n\n7.1.11 Multiple Comparisons?\nAnother benefit of a Bayesian hierarchical model is that you don’t need to worry about multiple comparisons. There are multiple angles on why this is the case, but the basic answer is that the use of common prior distributions builds in the prior belief that the clusters/groups are likely to be equal. See discussion here and here.",
    "crumbs": [
      "Week 4",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Hierarchical Models</span>"
    ]
  },
  {
    "objectID": "05-hierarchical-models.html#hierarchical-normal-model",
    "href": "05-hierarchical-models.html#hierarchical-normal-model",
    "title": "\n7  Hierarchical Models\n",
    "section": "\n7.2 Hierarchical Normal Model",
    "text": "7.2 Hierarchical Normal Model\n\n7.2.1 Eight Schools Example\nThis is a classic data set first analyzed by Rubin (1981). It is also the example used in the RStan Getting Started page. The data contains the effect of coaching from randomized experiments in eight schools. The numbers shown (labelled as y) are the mean difference (i.e., effect size) in performance between the treatment and control groups on SAT-V scores.\n\nschools_dat &lt;- list(\n    J = 8,\n    y = c(28, 8, -3, 7, -1, 1, 18, 12),\n    sigma = c(15, 10, 16, 11, 9, 11, 10, 18)\n)\n\nIn the above data, some numbers are positive, and some are negative. Because the sample sizes are different, the data also contained the standard errors (labelled as sigma) of the effect sizes. Generally speaking, a larger sample size corresponds to a smaller standard error. The research question is\n\n\nWhat is the average treatment effect of coaching?\nAre the treatment effects similar across schools?\n\n\n\n7.2.2 Model\nModel: \\[\n  \\begin{aligned}\n    d_j & \\sim N(\\theta_j, s_j) \\\\\n    \\theta_j & \\sim N(\\mu, \\tau)\n  \\end{aligned}\n\\] Prior: \\[\n  \\begin{aligned}\n    \\mu & \\sim N(0, 100) \\\\\n    \\tau & \\sim t^+_4(0, 100)\n  \\end{aligned}\n\\]\nGiven the SAT score range, it is unlikely that a coaching program will improve scores by 100 or so, so we use a prior of \\(\\mu \\sim N(0, 100)\\) and \\(\\tau \\sim t^+_4(0, 100)\\).\n\n\n\n\n\n\nThe model above is the same as one used in a random-effect meta-analysis. See this paper for an introduction.\n\n\n\n\n7.2.3 Non-Centered Parameterization\nThe hierarchical model is known to create issues in MCMC sampling, such that the posterior draws tend to be highly correlated even with more advanced techniques like HMC. One way to alleviate that is to reparameterize the model using what is called the non-centered parameterization. The basic idea is that, instead of treating the \\(\\theta\\)s as parameters, one uses the standardized deviation from the mean to be parameters. You can think about it as converting the \\(\\theta\\)s into \\(z\\) scores, and then sample the \\(z\\) scores instead of the original \\(\\theta\\)s.\nModel: \\[\n  \\begin{aligned}\n    d_j & \\sim N(\\theta_j, s_j) \\\\\n    \\theta_j & = \\mu + \\tau \\eta_j \\\\\n    \\eta_j & \\sim N(0, 1)\n  \\end{aligned}\n\\]\n\ndata {\n  int&lt;lower=0&gt; J;            // number of schools \n  vector[J] y;               // estimated treatment effects\n  vector&lt;lower=0&gt;[J] sigma;  // s.e. of effect estimates \n}\nparameters {\n  real mu;                   // overall mean\n  real&lt;lower=0&gt; tau;         // between-school SD\n  vector[J] eta;             // standardized deviation (z score)\n}\ntransformed parameters {\n  vector[J] theta;\n  theta = mu + tau * eta;    // non-centered parameterization\n}\nmodel {\n  eta ~ std_normal();        // same as eta ~ normal(0, 1);\n  y ~ normal(theta, sigma);\n  // priors\n  mu ~ normal(0, 100);\n  tau ~ student_t(4, 0, 100);\n}\n\n\nhnorm_mod &lt;- cmdstan_model(\"stan_code/hierarchical-normal.stan\")\n\n\nfit &lt;- hnorm_mod$sample(\n    data = schools_dat,\n    seed = 1804,  # for reproducibility\n    refresh = 1000,\n    adapt_delta = 0.9  # to improve convergence\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\n\nTreatment effect estimates of individual schools (\\(\\theta\\)), average treatment effect (\\(\\mu\\)), and treatment effect heterogeneity (\\(\\tau\\)).\n\nfit$summary(c(\"theta\", \"mu\", \"tau\")) |&gt;\n    knitr::kable(digits = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\ntheta[1]\n11.70\n10.60\n8.69\n7.38\n-0.20\n27.60\n1.00\n3475.69\n3347.72\n\n\ntheta[2]\n7.98\n7.93\n6.31\n5.82\n-2.18\n18.34\n1.00\n5870.22\n3353.39\n\n\ntheta[3]\n6.13\n6.77\n7.97\n6.50\n-7.14\n17.85\n1.00\n4318.80\n2941.48\n\n\ntheta[4]\n7.69\n7.75\n6.75\n6.15\n-3.43\n18.53\n1.00\n5452.05\n3268.65\n\n\ntheta[5]\n5.22\n5.53\n6.22\n5.82\n-5.64\n14.70\n1.00\n4118.93\n3165.15\n\n\ntheta[6]\n6.15\n6.52\n6.87\n6.15\n-5.19\n16.86\n1.00\n4526.45\n3352.39\n\n\ntheta[7]\n10.80\n10.14\n6.78\n6.32\n0.88\n23.09\n1.00\n4445.48\n3533.95\n\n\ntheta[8]\n8.55\n8.33\n7.74\n6.42\n-3.59\n21.11\n1.00\n4978.08\n3232.97\n\n\nmu\n7.95\n8.00\n5.26\n4.97\n-0.43\n16.20\n1.00\n2917.45\n1987.36\n\n\ntau\n6.75\n5.31\n5.91\n4.84\n0.55\n17.53\n1.01\n1316.86\n1673.79\n\n\n\n\n\nOn average, based on the 90% CI, coaching seemed to improve SAT-V by -0.43 to 16.2 points. There was substantial heterogeneity across schools.\nWe can also get the probability that the treatment effect was &gt; 0:\n\n# Obtain draws\ndraws_mu &lt;- fit$draws(\"mu\", format = \"draws_matrix\")\nmean(draws_mu &gt; 0)\n\n[1] 0.93975\n\n\nHere are the individual-school treatment effects:\n\nmcmc_areas_ridges(fit$draws(), regex_pars = \"theta\")\n\n\n\n\n\n\nFigure 7.5: Posterior distribution of the true effect size in the eight schools example.\n\n\n\n\n\n7.2.4 Prediction Interval\nPosterior distribution of the true effect size of a new study, \\(\\tilde \\theta\\)\n\n# Prediction Interval\n# (can also be done in Stan, as in the previous example)\nfit$draws(c(\"mu\", \"tau\")) |&gt;\n    mutate_variables(\n        theta_tilde = rnorm(4000, mean = mu, sd = tau)) |&gt;\n    summarise_draws() |&gt;\n    knitr::kable(digits = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\nmu\n7.95\n8.00\n5.26\n4.97\n-0.43\n16.20\n1.00\n2917.45\n1987.36\n\n\ntau\n6.75\n5.31\n5.91\n4.84\n0.55\n17.53\n1.01\n1316.86\n1673.79\n\n\ntheta_tilde\n8.03\n7.87\n10.19\n7.00\n-6.69\n22.89\n1.00\n3947.08\n3042.56\n\n\n\n\n\nThe posterior interval for \\(\\tilde \\theta\\) indicates a range of the treatment effect for a new study.",
    "crumbs": [
      "Week 4",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Hierarchical Models</span>"
    ]
  },
  {
    "objectID": "06-linear-models.html",
    "href": "06-linear-models.html",
    "title": "\n8  Linear Models\n",
    "section": "",
    "text": "8.1 What is Regression?\nRegression is a class of statistical techniques to understand the relationship between an outcome variable (also called a criterion/response/dependent variable) and one or more predictor variables (also called explanatory/independent variables). For example, if we have the following scatter plot between two variables (\\(Y\\) and \\(X\\)):\nset.seed(1)\nx &lt;- round(runif(10, 1, 5), 3)\ny &lt;- 0.7 + 0.5 * log(x - 1) + rnorm(10, sd = 0.2)\ndf &lt;- data.frame(x, y)\nggplot(df, aes(x, y)) +\n    geom_point() +\n    xlim(1, 5) +\n    ylim(-1, 2)\nWe want to find some pattern in this relationship. In conventional regression, we model the conditional distribution of \\(Y\\) given \\(X\\), \\(P(Y \\mid X)\\), by separating the outcome variable \\(Y\\) into (a) a systematic component that depends on the predictor, and (b) a random/probabilistic component that does not depend on the predictor. For example, we can start with a systematic component which only depends on the predictor:\nAs you can see, all the red dots fall exactly on the curve in the graph above, meaning that as long as one knows the \\(X\\) value, one can predict the \\(Y\\) value with 100% accuracy. We can thus write \\(Y^* = f(X)\\) (where \\(Y^*\\) is the systematic component of \\(Y\\)).\nHowever, in almost all scientific inquiries, one can never predict with 100% certainty (e.g., there are measurement errors and college randomness in physics). The uncertainty stems from the fact that we rarely measure all the factors that determine \\(Y\\), and there are genuinely random things (as in quantum physics). Therefore, we need to expand our model to incorporate this randomness by adding a probabilistic component. Therefore, instead of saying that \\(Y\\) depends just on \\(X\\), we say \\(Y\\) is random, but the information about \\(X\\) provides information about how \\(Y\\) is distributed. In regression, one studies the conditional distribution \\(P(Y \\mid X)\\) such that the conditional expectation, \\(E(Y \\mid X)\\), is determined by \\(X\\); on top of the conditional expectation, we assume that the observed \\(Y\\) values scatter around the conditional expectations, like the graph on the left below:\nWe can write the systematic part as:\n\\[E(Y \\mid X) = f(X; \\beta_1, \\beta_2, \\ldots), \\]\nwhere \\(\\beta_1\\), \\(\\beta_2\\), \\(\\ldots\\) are the parameters for some arbitrary function \\(f(\\cdot)\\). The random part is about \\(P(Y \\mid X)\\), which can take some arbitrary distributions. In reality, even if such a model holds, we do not know what \\(f(\\cdot)\\) and the true distribution of \\(Y \\mid X\\) are, as we only have data like those illustrated in the graph on the right above.",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Linear Models</span>"
    ]
  },
  {
    "objectID": "06-linear-models.html#what-is-regression",
    "href": "06-linear-models.html#what-is-regression",
    "title": "\n8  Linear Models\n",
    "section": "",
    "text": "ggplot(df, aes(x, yhat)) +\n    stat_function(fun = function(x) 0.7 + 0.5 * log(x - 1), n = 501) +\n    geom_point(col = \"red\") +\n    xlim(1, 5) +\n    ylim(-1, 2) +\n    ylab(\"y\") +\n    geom_curve(aes(x = x, y = yhat + 0.5, xend = x, yend = yhat - 0.5),\n        curvature = -0.4, col = \"red\", linetype = \"dotdash\"\n    ) +\n    geom_vline(aes(xintercept = x), linetype = \"dotted\") +\n    geom_point(aes(x, y), size = 2)\nggplot(df, aes(x, y)) +\n    geom_point(size = 2) +\n    xlim(1, 5) +\n    ylim(-1, 2)\n\n\n\n\n\n\n\n\n\n(a) With the true underlying relationship shown\n\n\n\n\n\n\n\n\n\n(b) With the true underlying relationship hidden, as is always the case in real life\n\n\n\n\n\n\nFigure 8.1: Sample regression function.",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Linear Models</span>"
    ]
  },
  {
    "objectID": "06-linear-models.html#linear-regression",
    "href": "06-linear-models.html#linear-regression",
    "title": "\n8  Linear Models\n",
    "section": "\n8.2 Linear Regression",
    "text": "8.2 Linear Regression\nThe linear regression model assumes that\n\nthe function for the systematic component, \\(f(\\cdot)\\), is a linear function (in the \\(\\beta\\)s),\n\n\\(Y \\mid X\\) is normally distributed, and\n\n\\(Y_i\\)’s are conditionally exchangeable given \\(X\\) with equal variance \\(\\sigma^2\\) (which can be relaxed).\n\nUnder these conditions, we have a model\n\\[\n  \\begin{aligned}\n    Y_i & \\sim N(\\mu_i, \\sigma)  \\\\\n    \\mu_i & = \\eta_i \\\\\n    \\eta_i & = \\beta_0 + \\beta_1 X_{i}\n  \\end{aligned}\n\\]\nWith parameters:\n\n\n\\(\\beta_0\\): regression intercept; predicted \\(Y\\) value for observations with \\(X\\) = 0\n\n\\(\\beta_1\\): regression slope/coefficient; predicted difference in \\(Y\\) for one unit difference in \\(X\\)\n\n\n\\(\\sigma\\): standard deviation of prediction error; roughly speaking, the margin of error in prediction\n\n\n8.2.1 Example\nWe will use an example based on the “bread and peace” model by political scientist Douglas Hibbs, which can be used to forecast the U.S. presidential election outcome based on some weighted metric of personal income growth. The example is taken from chapter 7 of the book Regression and Other Stories.1\nFigure 8.2 is a graph showing the data from 1952 to 2012, with one variable being personal income growth in the four years prior to an election, and the other being the vote share (in %) of the incumbent’s party.\n\n# Economy and elections data\nif (!file.exists(\"data/hibbs.dat\")) {\n    download.file(\n        \"https://github.com/avehtari/ROS-Examples/raw/master/ElectionsEconomy/data/hibbs.dat\",\n        \"data/hibbs.dat\"\n    )\n}\nhibbs &lt;- read.table(\"data/hibbs.dat\", header = TRUE)\n\n\nggplot(hibbs, aes(x = growth, y = vote, label = year)) +\n    geom_point() +\n    ggrepel::geom_text_repel() +\n    labs(x = \"Average recent growth in personal income\",\n         y = \"Incumbent party's vote share (%)\")\n\n\n\n\n\n\nFigure 8.2: Scatter plot of personal income growth and vote share.",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Linear Models</span>"
    ]
  },
  {
    "objectID": "06-linear-models.html#model-and-priors",
    "href": "06-linear-models.html#model-and-priors",
    "title": "\n8  Linear Models\n",
    "section": "\n8.3 Model and Priors",
    "text": "8.3 Model and Priors\nModel:\n\\[\n\\begin{aligned}\n  \\text{vote}_i & \\sim N(\\mu_i, \\sigma) \\\\\n  \\mu_i & = \\beta_0 + \\beta_1 \\text{growth}_i\n\\end{aligned}\n\\]\n\\(\\sigma\\): SD (margin) of prediction error\nPriors:\n\\[\n\\begin{aligned}\n  \\beta_0 & \\sim N(45, 10)  \\\\\n  \\beta_1 & \\sim N(0, 10)  \\\\\n  \\sigma & \\sim t^+_4(0, 5)\n\\end{aligned}\n\\]",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Linear Models</span>"
    ]
  },
  {
    "objectID": "06-linear-models.html#model-fitting-with-stan",
    "href": "06-linear-models.html#model-fitting-with-stan",
    "title": "\n8  Linear Models\n",
    "section": "\n8.4 Model Fitting With Stan",
    "text": "8.4 Model Fitting With Stan\nOnce you’ve written the model, it’s straightforward to code the model in Stan to perform MCMC sampling, like the code below.\n\ndata {\n  int&lt;lower=0&gt; N;  // number of observations\n  vector[N] y;  // outcome;\n  vector[N] x;  // predictor;\n  int&lt;lower=0,upper=1&gt; prior_only;  // whether to sample prior only\n}\nparameters {\n  real beta0;  // regression intercept\n  real beta1;  // regression coefficient\n  real&lt;lower=0&gt; sigma;  // SD of prediction error\n}\nmodel {\n  // model\n  if (!prior_only) {\n    y ~ normal(beta0 + beta1 * x, sigma);\n  }\n  // prior\n  beta0 ~ normal(45, 10);\n  beta1 ~ normal(0, 10);\n  sigma ~ student_t(4, 0, 5);\n}\ngenerated quantities {\n  // Prior/posterior predictive\n  array[N] real ytilde = normal_rng(beta0 + beta1 * x, sigma);\n}\n\n\nlinear_reg &lt;- cmdstan_model(\"stan_code/linear_reg.stan\")\n\n\n8.4.1 Prior Predictive\n\nm1_prior &lt;- linear_reg$sample(\n    data = list(N = nrow(hibbs),\n                y = hibbs$vote,\n                x = hibbs$growth,\n                prior_only = TRUE),\n    seed = 1227,  # for reproducibility\n    refresh = 1000\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.6 seconds.\n\n\n\nm1_prior$draws(\"ytilde\", format = \"matrix\") |&gt;\n    ppc_ribbon(y = hibbs$vote, x = hibbs$growth,\n               y_draw = \"points\") +\n    labs(x = \"Average recent growth in personal income\",\n         y = \"Incumbent party's vote share (%)\") +\n    coord_cartesian(ylim = c(0, 100))\n\n\n\n\n\n\nFigure 8.3: Prior predictive distribution of the linear regression model for vote share against personal income.\n\n\n\n\nWe can also visualize the prior regression lines based on the prior distributions:\n\nprior_draws_beta &lt;- m1_prior$draws(c(\"beta0\", \"beta1\"), format = \"data.frame\")\nggplot(hibbs, aes(x = growth, y = vote, label = year)) +\n    geom_point() +\n    geom_abline(data = prior_draws_beta, aes(intercept = beta0, slope = beta1),\n    linewidth = 0.1, alpha = 0.1) +\n    ggrepel::geom_text_repel() +\n    labs(x = \"Average recent growth in personal income\",\n         y = \"Incumbent party's vote share (%)\") +\n    coord_cartesian(ylim = c(0, 100))\n\n\n\n\n\n\nFigure 8.4: Prior predictive distribution of the regression lines.\n\n\n\n\n\n8.4.2 Results\nWe’ll now fit the model (without prior_only = TRUE).\n\nm1_post &lt;- linear_reg$sample(\n    data = list(N = nrow(hibbs),\n                y = hibbs$vote,\n                x = hibbs$growth,\n                prior_only = FALSE),\n    seed = 1227,  # for reproducibility\n    refresh = 1000\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\n\n\nm1_summ &lt;- m1_post$summary(c(\"beta0\", \"beta1\", \"sigma\"))\n# Use `knitr::kable()` for tabulation\nknitr::kable(m1_summ, digits = 2)\n\n\nTable 8.1: Posterior summary of linear regression model.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\nbeta0\n46.25\n46.26\n1.73\n1.66\n43.42\n49.06\n1\n1582.97\n1590.35\n\n\nbeta1\n3.05\n3.06\n0.75\n0.71\n1.83\n4.26\n1\n1605.18\n1745.88\n\n\nsigma\n4.03\n3.91\n0.78\n0.70\n2.97\n5.48\n1\n2047.68\n2056.33\n\n\n\n\n\n\n\n\nThe parameter estimates are shown in Table 13.1. Here’s a paragraph for the results:\n\n\n\n\n\n\nThe model predicts that when personal income growth is 0, the vote share for the incumbent party is 46%, 90% CI [43%, 49%]. A 1-unit difference in personal income growth corresponds to a difference in vote share by 3 percentage points, 90% CI [1.8, 4.3].\n\n\n\n\n8.4.3 Convergence\nWe will talk about convergence more in a future week. For now, you want to see that\n\nThe chains mix well\nthe rank histograms are close to uniform distributions\n\n\nm1_post_draws &lt;- m1_post$draws(c(\"beta0\", \"beta1\", \"sigma\"))\nmcmc_trace(m1_post_draws)\nmcmc_rank_hist(m1_post_draws)\n\n\n\n\n\n\n\n\n\n(a) Trace plot\n\n\n\n\n\n\n\n\n\n\n\n(b) Rank histogram\n\n\n\n\n\n\nFigure 8.5: Convergence diagnostics for the linear regression model.\n\n\n\n\n8.4.4 Posterior plots\nThere are many ways to visualize the results of a regression model. The most important thing is to be as familiar with what the results mean as possible. Statistics is not magic that gives you numbers that either support or do not support your theory or hypothesis. It is a way to describe your data. If you do not want to do the work to understand what your data tell you, why bother to collect the data in the first place?\n\n8.4.4.1 Posterior density\nPosterior distributions of the three parameters\n\nmcmc_dens(m1_post_draws)\n\n\n\n\n\n\nFigure 8.6: Posterior density plots for \\(\\beta_0\\), \\(\\beta_1\\), and \\(\\sigma\\) in the linear regression model.\n\n\n\n\nYou can also combine the density plot and the trace plot\n\nmcmc_combo(m1_post_draws)\n\n\n\n\n\n\nFigure 8.7: Diagnostic plots for MCMC sampling.\n\n\n\n\n\n8.4.4.2 Plot regression prediction\nFigure 13.4 shows the 50% and 90% prediction intervals based on the posterior samples and the model. For example, with the 90% intervals, one expects 90% of the data should be within those intervals. If many data points lie outside the intervals, the linear model is not a good fit.\n\nm1_post$draws(\"ytilde\", format = \"matrix\") |&gt;\n    ppc_intervals(y = hibbs$vote, x = hibbs$growth) +\n    labs(x = \"Average recent growth in personal income\",\n         y = \"Predicted incumbent party's vote share (%)\") +\n    ggrepel::geom_label_repel(\n        aes(y = hibbs$vote, label = hibbs$year)\n    )\n\n\n\n\n\n\nFigure 8.8: Posterior predictive intervals of vote share against personal income growth.",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Linear Models</span>"
    ]
  },
  {
    "objectID": "06-linear-models.html#predicting-a-new-data-point",
    "href": "06-linear-models.html#predicting-a-new-data-point",
    "title": "\n8  Linear Models\n",
    "section": "\n8.5 Predicting a New Data Point",
    "text": "8.5 Predicting a New Data Point\nIn the four years before 2016, the weighted average personal income growth was 2.0 (based on Hibbs’ calculation). So, based on the model, we can obtain a posterior distribution for the predicted vote share of the Democratic Party, which is the incumbent party prior to the 2016 presidential election.\n\nlinear_pred &lt;- cmdstan_model(\"stan_code/linear_reg_pred.stan\")\n\n\nm1_pred &lt;- linear_pred$sample(\n    data = list(N = nrow(hibbs),\n                y = hibbs$vote,\n                x = hibbs$growth,\n                prior_only = FALSE,\n                xpred = 2),\n    seed = 1227,  # for reproducibility\n    refresh = 1000\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\n\n\nm1_pred$draws(\"ypred\") |&gt;\n    mcmc_dens()\n\n\n\n\n\n\nFigure 8.9: Posterior predictive distribution of predicted vote share when growth = 2.\n\n\n\n\nThe mean of the incumbent’s predicted vote share with average income growth = 2 is 52.3006575. The actual outcome of the election was that the Democratic Party received about 51.1% of the votes among the two parties, so it was below the posterior predictive mean but within the range of possible outcomes. Of course, we know that the actual election outcome is based on the Eelectoral College, not the majority vote.",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Linear Models</span>"
    ]
  },
  {
    "objectID": "06-linear-models.html#robust-regression",
    "href": "06-linear-models.html#robust-regression",
    "title": "\n8  Linear Models\n",
    "section": "\n8.6 Robust Regression",
    "text": "8.6 Robust Regression\nThe linear model assuming normally distributed errors is not robust to outliers or influential observations. It can be robustified by assuming a more heavy-tailed distribution, such as the \\(t\\) distribution:\n\\[\n\\text{vote}_i \\sim t_\\nu(\\mu_i, \\sigma),\n\\]\nwhere \\(\\nu\\) is an additional degrees of freedom parameter controlling for the “heaviness” of the tails. When \\(\\nu\\) is close to 0 (e.g., 3 or 4), the outliers/influential cases are weighed less; when \\(\\nu\\) is close to infinity, the \\(t\\) distribution becomes a normal distribution.\nWith Bayesian methods, we can let the model learn from the data about the \\(\\nu\\) parameter. In this case, we assume a hyperprior for \\(\\nu\\); \\(\\mathrm{Gamma}(2, 0.1)\\) is something recommended in the literature.\n\ndata {\n  int&lt;lower=0&gt; N;  // number of observations\n  vector[N] y;  // outcome;\n  vector[N] x;  // predictor;\n  int&lt;lower=0,upper=1&gt; prior_only;  // whether to sample prior only\n}\nparameters {\n  real beta0;  // regression intercept\n  real beta1;  // regression coefficient\n  real&lt;lower=0&gt; sigma;  // SD of prediction error\n  real&lt;lower=1&gt; nu;  // df parameter\n}\nmodel {\n  // model\n  if (!prior_only) {\n    y ~ student_t(nu, beta0 + beta1 * x, sigma);\n  }\n  // prior\n  beta0 ~ normal(45, 10);\n  beta1 ~ normal(0, 10);\n  sigma ~ student_t(4, 0, 5);\n  nu ~ gamma(2, 0.1); // prior for df parameter\n}\ngenerated quantities {\n  vector[N] ytilde;  // place holder\n  for (i in 1:N)\n    ytilde[i] = normal_rng(beta0 + beta1 * x[i], sigma);\n}\n\n\nrobust_reg &lt;- cmdstan_model(\"stan_code/robust_reg.stan\")\n\n\nm1_robust &lt;- robust_reg$sample(\n    data = list(N = nrow(hibbs),\n                y = hibbs$vote,\n                x = hibbs$growth,\n                prior_only = FALSE),\n    seed = 1227,  # for reproducibility\n    refresh = 0\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 0.0 seconds.\nChain 2 finished in 0.0 seconds.\nChain 3 finished in 0.0 seconds.\nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\n\n\nm1r_summ &lt;- m1_robust$summary(c(\"beta0\", \"beta1\", \"sigma\", \"nu\"))\n# Use `knitr::kable()` for tabulation\nknitr::kable(m1r_summ, digits = 2)\n\n\nTable 8.2: Posterior summary of Student t regression model.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\nbeta0\n46.17\n46.18\n1.55\n1.45\n43.55\n48.64\n1\n1628.35\n1673.90\n\n\nbeta1\n3.20\n3.22\n0.69\n0.66\n2.01\n4.30\n1\n1598.75\n1914.04\n\n\nsigma\n3.56\n3.49\n0.92\n0.83\n2.20\n5.10\n1\n1044.24\n586.21\n\n\nnu\n18.26\n14.64\n13.86\n11.60\n2.97\n45.62\n1\n1234.64\n638.30\n\n\n\n\n\n\n\n\n\nm1_robust$draws(\"ytilde\", format = \"matrix\") |&gt;\n    ppc_intervals(y = hibbs$vote, x = hibbs$growth) +\n    labs(x = \"Average recent growth in personal income\",\n         y = \"Predicted incumbent party's vote share (%)\") +\n    ggrepel::geom_label_repel(\n        aes(y = hibbs$vote, label = hibbs$year)\n    )\n\n\n\n\n\n\nFigure 8.10: Posterior predictive intervals of vote share against personal income growth based on Student t regression.",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Linear Models</span>"
    ]
  },
  {
    "objectID": "06-linear-models.html#footnotes",
    "href": "06-linear-models.html#footnotes",
    "title": "\n8  Linear Models\n",
    "section": "",
    "text": "See https://douglas-hibbs.com/background-information-on-bread-and-peace-voting-in-us-presidential-elections/ for more information on the “bread and peace” model.↩︎",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Linear Models</span>"
    ]
  },
  {
    "objectID": "06b-multiple-predictors.html",
    "href": "06b-multiple-predictors.html",
    "title": "9  Multiple Predictors",
    "section": "",
    "text": "9.1 Stratified Analysis\nHere, we’ll use an example from McElreath (2020), which contains some marriage and demographic statistics for the individual states in the United States. See https://rdrr.io/github/rmcelreath/rethinking/man/WaffleDivorce.html for more details.\nLet’s consider whether the association between MedianAgeMarriage and Divorce differs between Southern and non-Southern states. Because (and only because) the groups are independent, we can fit a linear regression for each subset of states.\nggplot(waffle_divorce,\n       aes(x = MedianAgeMarriage, y = Divorce, col = South)) +\n    geom_point() +\n    geom_smooth() +\n    labs(x = \"Median age marriage (10 years)\",\n         y = \"Divorce rate (per 10 adults)\") +\n    ggrepel::geom_text_repel(aes(label = Loc), max.overlaps = 15)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\nFigure 9.1: State-level association between median age of marriage and divorce rate.",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Multiple Predictors</span>"
    ]
  },
  {
    "objectID": "06b-multiple-predictors.html#introducing-the-brms-package",
    "href": "06b-multiple-predictors.html#introducing-the-brms-package",
    "title": "9  Multiple Predictors",
    "section": "\n9.2 Introducing the brms package",
    "text": "9.2 Introducing the brms package\nWhile Stan is very flexible, because the linear model and some related models are so widely used, some authors have created packages that would further simplify the fitting of such models. One of those packages is brms, which I believe stands for “Bayesian regression models with Stan.” It allows one to do MCMC sampling using Stan, but with syntax similar to that in R functions lm(), glm(), and lme4::lmer(). brms probably supports more models than any R packages that statisticians routinely used; there are models, like factor analysis, that are not directly supported. If you came across some fancy regression models, chances are you can do something similar in brms. You can find some resources for learning brms on this page: https://paul-buerkner.github.io/brms/.\nModel formula\nbrms comes with some default prior options, but I recommend you always check what priors are used and think about whether they make sense for your data. You can use get_priors() to show the default priors used in brms.\nTo do MCMC sampling, we use the brm() function. The first argument is a formula in R. The variable before ~ is the outcome, whereas the ones after ~ are the predictors. For example,\nvote ~ 1 + growth\nmeans the model\n\\[\nE(\\text{vote}_i) = \\beta_0 (1) + \\beta_1 (\\text{growth}_i).\n\\]\nUsually, I write vote ~ 1 + growth as vote ~ growth, as the 1 + part is automatically added.\nSetting Priors\nbrms comes with some default prior options, but over the years, the package maintainers have changed those priors, so the default today may be different from the one next year. Therefore, you should always check what priors are used and think about whether they make sense for your data. You can use get_priors() to show the default priors used in brms. For example,\n\nget_prior(Divorce ~ MedianAgeMarriage,\n          data = waffle_divorce)\n\n\n  \n\n\n\n\nm_nonsouth &lt;-\n    brm(Divorce ~ MedianAgeMarriage,\n        # Filter `waffle_divorce` to only include non-southern states\n        data = filter(waffle_divorce, South == \"non-south\"),\n        # Use N(0, 2) and N(0, 10) as priors for beta1 and beta0,\n        # and use t_4(0, 3) as a prior for sigma\n        prior = prior(normal(0, 2), class = \"b\") +          \n            prior(normal(0, 10), class = \"Intercept\") +     \n            prior(student_t(4, 0, 3), class = \"sigma\"),     \n        seed = 941,\n        iter = 4000,\n        file = \"m_nonsouth\"\n    )\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 4000 [  2%]  (Warmup) \nChain 1 Iteration:  200 / 4000 [  5%]  (Warmup) \nChain 1 Iteration:  300 / 4000 [  7%]  (Warmup) \nChain 1 Iteration:  400 / 4000 [ 10%]  (Warmup) \nChain 1 Iteration:  500 / 4000 [ 12%]  (Warmup) \nChain 1 Iteration:  600 / 4000 [ 15%]  (Warmup) \nChain 1 Iteration:  700 / 4000 [ 17%]  (Warmup) \nChain 1 Iteration:  800 / 4000 [ 20%]  (Warmup) \nChain 1 Iteration:  900 / 4000 [ 22%]  (Warmup) \nChain 1 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 1 Iteration: 1100 / 4000 [ 27%]  (Warmup) \nChain 1 Iteration: 1200 / 4000 [ 30%]  (Warmup) \nChain 1 Iteration: 1300 / 4000 [ 32%]  (Warmup) \nChain 1 Iteration: 1400 / 4000 [ 35%]  (Warmup) \nChain 1 Iteration: 1500 / 4000 [ 37%]  (Warmup) \nChain 1 Iteration: 1600 / 4000 [ 40%]  (Warmup) \nChain 1 Iteration: 1700 / 4000 [ 42%]  (Warmup) \nChain 1 Iteration: 1800 / 4000 [ 45%]  (Warmup) \nChain 1 Iteration: 1900 / 4000 [ 47%]  (Warmup) \nChain 1 Iteration: 2000 / 4000 [ 50%]  (Warmup) \nChain 1 Iteration: 2001 / 4000 [ 50%]  (Sampling) \nChain 1 Iteration: 2100 / 4000 [ 52%]  (Sampling) \nChain 1 Iteration: 2200 / 4000 [ 55%]  (Sampling) \nChain 1 Iteration: 2300 / 4000 [ 57%]  (Sampling) \nChain 1 Iteration: 2400 / 4000 [ 60%]  (Sampling) \nChain 1 Iteration: 2500 / 4000 [ 62%]  (Sampling) \nChain 1 Iteration: 2600 / 4000 [ 65%]  (Sampling) \nChain 1 Iteration: 2700 / 4000 [ 67%]  (Sampling) \nChain 1 Iteration: 2800 / 4000 [ 70%]  (Sampling) \nChain 1 Iteration: 2900 / 4000 [ 72%]  (Sampling) \nChain 1 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 1 Iteration: 3100 / 4000 [ 77%]  (Sampling) \nChain 1 Iteration: 3200 / 4000 [ 80%]  (Sampling) \nChain 1 Iteration: 3300 / 4000 [ 82%]  (Sampling) \nChain 1 Iteration: 3400 / 4000 [ 85%]  (Sampling) \nChain 1 Iteration: 3500 / 4000 [ 87%]  (Sampling) \nChain 1 Iteration: 3600 / 4000 [ 90%]  (Sampling) \nChain 1 Iteration: 3700 / 4000 [ 92%]  (Sampling) \nChain 1 Iteration: 3800 / 4000 [ 95%]  (Sampling) \nChain 1 Iteration: 3900 / 4000 [ 97%]  (Sampling) \nChain 1 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 4000 [  2%]  (Warmup) \nChain 2 Iteration:  200 / 4000 [  5%]  (Warmup) \nChain 2 Iteration:  300 / 4000 [  7%]  (Warmup) \nChain 2 Iteration:  400 / 4000 [ 10%]  (Warmup) \nChain 2 Iteration:  500 / 4000 [ 12%]  (Warmup) \nChain 2 Iteration:  600 / 4000 [ 15%]  (Warmup) \nChain 2 Iteration:  700 / 4000 [ 17%]  (Warmup) \nChain 2 Iteration:  800 / 4000 [ 20%]  (Warmup) \nChain 2 Iteration:  900 / 4000 [ 22%]  (Warmup) \nChain 2 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 2 Iteration: 1100 / 4000 [ 27%]  (Warmup) \nChain 2 Iteration: 1200 / 4000 [ 30%]  (Warmup) \nChain 2 Iteration: 1300 / 4000 [ 32%]  (Warmup) \nChain 2 Iteration: 1400 / 4000 [ 35%]  (Warmup) \nChain 2 Iteration: 1500 / 4000 [ 37%]  (Warmup) \nChain 2 Iteration: 1600 / 4000 [ 40%]  (Warmup) \nChain 2 Iteration: 1700 / 4000 [ 42%]  (Warmup) \nChain 2 Iteration: 1800 / 4000 [ 45%]  (Warmup) \nChain 2 Iteration: 1900 / 4000 [ 47%]  (Warmup) \nChain 2 Iteration: 2000 / 4000 [ 50%]  (Warmup) \nChain 2 Iteration: 2001 / 4000 [ 50%]  (Sampling) \nChain 2 Iteration: 2100 / 4000 [ 52%]  (Sampling) \nChain 2 Iteration: 2200 / 4000 [ 55%]  (Sampling) \nChain 2 Iteration: 2300 / 4000 [ 57%]  (Sampling) \nChain 2 Iteration: 2400 / 4000 [ 60%]  (Sampling) \nChain 2 Iteration: 2500 / 4000 [ 62%]  (Sampling) \nChain 2 Iteration: 2600 / 4000 [ 65%]  (Sampling) \nChain 2 Iteration: 2700 / 4000 [ 67%]  (Sampling) \nChain 2 Iteration: 2800 / 4000 [ 70%]  (Sampling) \nChain 2 Iteration: 2900 / 4000 [ 72%]  (Sampling) \nChain 2 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 2 Iteration: 3100 / 4000 [ 77%]  (Sampling) \nChain 2 Iteration: 3200 / 4000 [ 80%]  (Sampling) \nChain 2 Iteration: 3300 / 4000 [ 82%]  (Sampling) \nChain 2 Iteration: 3400 / 4000 [ 85%]  (Sampling) \nChain 2 Iteration: 3500 / 4000 [ 87%]  (Sampling) \nChain 2 Iteration: 3600 / 4000 [ 90%]  (Sampling) \nChain 2 Iteration: 3700 / 4000 [ 92%]  (Sampling) \nChain 2 Iteration: 3800 / 4000 [ 95%]  (Sampling) \nChain 2 Iteration: 3900 / 4000 [ 97%]  (Sampling) \nChain 2 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 4000 [  2%]  (Warmup) \nChain 3 Iteration:  200 / 4000 [  5%]  (Warmup) \nChain 3 Iteration:  300 / 4000 [  7%]  (Warmup) \nChain 3 Iteration:  400 / 4000 [ 10%]  (Warmup) \nChain 3 Iteration:  500 / 4000 [ 12%]  (Warmup) \nChain 3 Iteration:  600 / 4000 [ 15%]  (Warmup) \nChain 3 Iteration:  700 / 4000 [ 17%]  (Warmup) \nChain 3 Iteration:  800 / 4000 [ 20%]  (Warmup) \nChain 3 Iteration:  900 / 4000 [ 22%]  (Warmup) \nChain 3 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 3 Iteration: 1100 / 4000 [ 27%]  (Warmup) \nChain 3 Iteration: 1200 / 4000 [ 30%]  (Warmup) \nChain 3 Iteration: 1300 / 4000 [ 32%]  (Warmup) \nChain 3 Iteration: 1400 / 4000 [ 35%]  (Warmup) \nChain 3 Iteration: 1500 / 4000 [ 37%]  (Warmup) \nChain 3 Iteration: 1600 / 4000 [ 40%]  (Warmup) \nChain 3 Iteration: 1700 / 4000 [ 42%]  (Warmup) \nChain 3 Iteration: 1800 / 4000 [ 45%]  (Warmup) \nChain 3 Iteration: 1900 / 4000 [ 47%]  (Warmup) \nChain 3 Iteration: 2000 / 4000 [ 50%]  (Warmup) \nChain 3 Iteration: 2001 / 4000 [ 50%]  (Sampling) \nChain 3 Iteration: 2100 / 4000 [ 52%]  (Sampling) \nChain 3 Iteration: 2200 / 4000 [ 55%]  (Sampling) \nChain 3 Iteration: 2300 / 4000 [ 57%]  (Sampling) \nChain 3 Iteration: 2400 / 4000 [ 60%]  (Sampling) \nChain 3 Iteration: 2500 / 4000 [ 62%]  (Sampling) \nChain 3 Iteration: 2600 / 4000 [ 65%]  (Sampling) \nChain 3 Iteration: 2700 / 4000 [ 67%]  (Sampling) \nChain 3 Iteration: 2800 / 4000 [ 70%]  (Sampling) \nChain 3 Iteration: 2900 / 4000 [ 72%]  (Sampling) \nChain 3 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 3 Iteration: 3100 / 4000 [ 77%]  (Sampling) \nChain 3 Iteration: 3200 / 4000 [ 80%]  (Sampling) \nChain 3 Iteration: 3300 / 4000 [ 82%]  (Sampling) \nChain 3 Iteration: 3400 / 4000 [ 85%]  (Sampling) \nChain 3 Iteration: 3500 / 4000 [ 87%]  (Sampling) \nChain 3 Iteration: 3600 / 4000 [ 90%]  (Sampling) \nChain 3 Iteration: 3700 / 4000 [ 92%]  (Sampling) \nChain 3 Iteration: 3800 / 4000 [ 95%]  (Sampling) \nChain 3 Iteration: 3900 / 4000 [ 97%]  (Sampling) \nChain 3 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 4000 [  2%]  (Warmup) \nChain 4 Iteration:  200 / 4000 [  5%]  (Warmup) \nChain 4 Iteration:  300 / 4000 [  7%]  (Warmup) \nChain 4 Iteration:  400 / 4000 [ 10%]  (Warmup) \nChain 4 Iteration:  500 / 4000 [ 12%]  (Warmup) \nChain 4 Iteration:  600 / 4000 [ 15%]  (Warmup) \nChain 4 Iteration:  700 / 4000 [ 17%]  (Warmup) \nChain 4 Iteration:  800 / 4000 [ 20%]  (Warmup) \nChain 4 Iteration:  900 / 4000 [ 22%]  (Warmup) \nChain 4 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 4 Iteration: 1100 / 4000 [ 27%]  (Warmup) \nChain 4 Iteration: 1200 / 4000 [ 30%]  (Warmup) \nChain 4 Iteration: 1300 / 4000 [ 32%]  (Warmup) \nChain 4 Iteration: 1400 / 4000 [ 35%]  (Warmup) \nChain 4 Iteration: 1500 / 4000 [ 37%]  (Warmup) \nChain 4 Iteration: 1600 / 4000 [ 40%]  (Warmup) \nChain 4 Iteration: 1700 / 4000 [ 42%]  (Warmup) \nChain 4 Iteration: 1800 / 4000 [ 45%]  (Warmup) \nChain 4 Iteration: 1900 / 4000 [ 47%]  (Warmup) \nChain 4 Iteration: 2000 / 4000 [ 50%]  (Warmup) \nChain 4 Iteration: 2001 / 4000 [ 50%]  (Sampling) \nChain 4 Iteration: 2100 / 4000 [ 52%]  (Sampling) \nChain 4 Iteration: 2200 / 4000 [ 55%]  (Sampling) \nChain 4 Iteration: 2300 / 4000 [ 57%]  (Sampling) \nChain 4 Iteration: 2400 / 4000 [ 60%]  (Sampling) \nChain 4 Iteration: 2500 / 4000 [ 62%]  (Sampling) \nChain 4 Iteration: 2600 / 4000 [ 65%]  (Sampling) \nChain 4 Iteration: 2700 / 4000 [ 67%]  (Sampling) \nChain 4 Iteration: 2800 / 4000 [ 70%]  (Sampling) \nChain 4 Iteration: 2900 / 4000 [ 72%]  (Sampling) \nChain 4 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 4 Iteration: 3100 / 4000 [ 77%]  (Sampling) \nChain 4 Iteration: 3200 / 4000 [ 80%]  (Sampling) \nChain 4 Iteration: 3300 / 4000 [ 82%]  (Sampling) \nChain 4 Iteration: 3400 / 4000 [ 85%]  (Sampling) \nChain 4 Iteration: 3500 / 4000 [ 87%]  (Sampling) \nChain 4 Iteration: 3600 / 4000 [ 90%]  (Sampling) \nChain 4 Iteration: 3700 / 4000 [ 92%]  (Sampling) \nChain 4 Iteration: 3800 / 4000 [ 95%]  (Sampling) \nChain 4 Iteration: 3900 / 4000 [ 97%]  (Sampling) \nChain 4 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.6 seconds.\n\n\n\nm_south &lt;-\n    brm(Divorce ~ MedianAgeMarriage,\n        data = filter(waffle_divorce, South == \"south\"),\n        prior = prior(normal(0, 2), class = \"b\") +\n            prior(normal(0, 10), class = \"Intercept\") +\n            prior(student_t(4, 0, 3), class = \"sigma\"),\n        seed = 2157,  # use a different seed\n        iter = 4000,\n        file = \"m_south\"\n    )\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 4000 [  2%]  (Warmup) \nChain 1 Iteration:  200 / 4000 [  5%]  (Warmup) \nChain 1 Iteration:  300 / 4000 [  7%]  (Warmup) \nChain 1 Iteration:  400 / 4000 [ 10%]  (Warmup) \nChain 1 Iteration:  500 / 4000 [ 12%]  (Warmup) \nChain 1 Iteration:  600 / 4000 [ 15%]  (Warmup) \nChain 1 Iteration:  700 / 4000 [ 17%]  (Warmup) \nChain 1 Iteration:  800 / 4000 [ 20%]  (Warmup) \nChain 1 Iteration:  900 / 4000 [ 22%]  (Warmup) \nChain 1 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 1 Iteration: 1100 / 4000 [ 27%]  (Warmup) \nChain 1 Iteration: 1200 / 4000 [ 30%]  (Warmup) \nChain 1 Iteration: 1300 / 4000 [ 32%]  (Warmup) \nChain 1 Iteration: 1400 / 4000 [ 35%]  (Warmup) \nChain 1 Iteration: 1500 / 4000 [ 37%]  (Warmup) \nChain 1 Iteration: 1600 / 4000 [ 40%]  (Warmup) \nChain 1 Iteration: 1700 / 4000 [ 42%]  (Warmup) \nChain 1 Iteration: 1800 / 4000 [ 45%]  (Warmup) \nChain 1 Iteration: 1900 / 4000 [ 47%]  (Warmup) \nChain 1 Iteration: 2000 / 4000 [ 50%]  (Warmup) \nChain 1 Iteration: 2001 / 4000 [ 50%]  (Sampling) \nChain 1 Iteration: 2100 / 4000 [ 52%]  (Sampling) \nChain 1 Iteration: 2200 / 4000 [ 55%]  (Sampling) \nChain 1 Iteration: 2300 / 4000 [ 57%]  (Sampling) \nChain 1 Iteration: 2400 / 4000 [ 60%]  (Sampling) \nChain 1 Iteration: 2500 / 4000 [ 62%]  (Sampling) \nChain 1 Iteration: 2600 / 4000 [ 65%]  (Sampling) \nChain 1 Iteration: 2700 / 4000 [ 67%]  (Sampling) \nChain 1 Iteration: 2800 / 4000 [ 70%]  (Sampling) \nChain 1 Iteration: 2900 / 4000 [ 72%]  (Sampling) \nChain 1 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 1 Iteration: 3100 / 4000 [ 77%]  (Sampling) \nChain 1 Iteration: 3200 / 4000 [ 80%]  (Sampling) \nChain 1 Iteration: 3300 / 4000 [ 82%]  (Sampling) \nChain 1 Iteration: 3400 / 4000 [ 85%]  (Sampling) \nChain 1 Iteration: 3500 / 4000 [ 87%]  (Sampling) \nChain 1 Iteration: 3600 / 4000 [ 90%]  (Sampling) \nChain 1 Iteration: 3700 / 4000 [ 92%]  (Sampling) \nChain 1 Iteration: 3800 / 4000 [ 95%]  (Sampling) \nChain 1 Iteration: 3900 / 4000 [ 97%]  (Sampling) \nChain 1 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 4000 [  2%]  (Warmup) \nChain 2 Iteration:  200 / 4000 [  5%]  (Warmup) \nChain 2 Iteration:  300 / 4000 [  7%]  (Warmup) \nChain 2 Iteration:  400 / 4000 [ 10%]  (Warmup) \nChain 2 Iteration:  500 / 4000 [ 12%]  (Warmup) \nChain 2 Iteration:  600 / 4000 [ 15%]  (Warmup) \nChain 2 Iteration:  700 / 4000 [ 17%]  (Warmup) \nChain 2 Iteration:  800 / 4000 [ 20%]  (Warmup) \nChain 2 Iteration:  900 / 4000 [ 22%]  (Warmup) \nChain 2 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 2 Iteration: 1100 / 4000 [ 27%]  (Warmup) \nChain 2 Iteration: 1200 / 4000 [ 30%]  (Warmup) \nChain 2 Iteration: 1300 / 4000 [ 32%]  (Warmup) \nChain 2 Iteration: 1400 / 4000 [ 35%]  (Warmup) \nChain 2 Iteration: 1500 / 4000 [ 37%]  (Warmup) \nChain 2 Iteration: 1600 / 4000 [ 40%]  (Warmup) \nChain 2 Iteration: 1700 / 4000 [ 42%]  (Warmup) \nChain 2 Iteration: 1800 / 4000 [ 45%]  (Warmup) \nChain 2 Iteration: 1900 / 4000 [ 47%]  (Warmup) \nChain 2 Iteration: 2000 / 4000 [ 50%]  (Warmup) \nChain 2 Iteration: 2001 / 4000 [ 50%]  (Sampling) \nChain 2 Iteration: 2100 / 4000 [ 52%]  (Sampling) \nChain 2 Iteration: 2200 / 4000 [ 55%]  (Sampling) \nChain 2 Iteration: 2300 / 4000 [ 57%]  (Sampling) \nChain 2 Iteration: 2400 / 4000 [ 60%]  (Sampling) \nChain 2 Iteration: 2500 / 4000 [ 62%]  (Sampling) \nChain 2 Iteration: 2600 / 4000 [ 65%]  (Sampling) \nChain 2 Iteration: 2700 / 4000 [ 67%]  (Sampling) \nChain 2 Iteration: 2800 / 4000 [ 70%]  (Sampling) \nChain 2 Iteration: 2900 / 4000 [ 72%]  (Sampling) \nChain 2 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 2 Iteration: 3100 / 4000 [ 77%]  (Sampling) \nChain 2 Iteration: 3200 / 4000 [ 80%]  (Sampling) \nChain 2 Iteration: 3300 / 4000 [ 82%]  (Sampling) \nChain 2 Iteration: 3400 / 4000 [ 85%]  (Sampling) \nChain 2 Iteration: 3500 / 4000 [ 87%]  (Sampling) \nChain 2 Iteration: 3600 / 4000 [ 90%]  (Sampling) \nChain 2 Iteration: 3700 / 4000 [ 92%]  (Sampling) \nChain 2 Iteration: 3800 / 4000 [ 95%]  (Sampling) \nChain 2 Iteration: 3900 / 4000 [ 97%]  (Sampling) \nChain 2 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 4000 [  2%]  (Warmup) \nChain 3 Iteration:  200 / 4000 [  5%]  (Warmup) \nChain 3 Iteration:  300 / 4000 [  7%]  (Warmup) \nChain 3 Iteration:  400 / 4000 [ 10%]  (Warmup) \nChain 3 Iteration:  500 / 4000 [ 12%]  (Warmup) \nChain 3 Iteration:  600 / 4000 [ 15%]  (Warmup) \nChain 3 Iteration:  700 / 4000 [ 17%]  (Warmup) \nChain 3 Iteration:  800 / 4000 [ 20%]  (Warmup) \nChain 3 Iteration:  900 / 4000 [ 22%]  (Warmup) \nChain 3 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 3 Iteration: 1100 / 4000 [ 27%]  (Warmup) \nChain 3 Iteration: 1200 / 4000 [ 30%]  (Warmup) \nChain 3 Iteration: 1300 / 4000 [ 32%]  (Warmup) \nChain 3 Iteration: 1400 / 4000 [ 35%]  (Warmup) \nChain 3 Iteration: 1500 / 4000 [ 37%]  (Warmup) \nChain 3 Iteration: 1600 / 4000 [ 40%]  (Warmup) \nChain 3 Iteration: 1700 / 4000 [ 42%]  (Warmup) \nChain 3 Iteration: 1800 / 4000 [ 45%]  (Warmup) \nChain 3 Iteration: 1900 / 4000 [ 47%]  (Warmup) \nChain 3 Iteration: 2000 / 4000 [ 50%]  (Warmup) \nChain 3 Iteration: 2001 / 4000 [ 50%]  (Sampling) \nChain 3 Iteration: 2100 / 4000 [ 52%]  (Sampling) \nChain 3 Iteration: 2200 / 4000 [ 55%]  (Sampling) \nChain 3 Iteration: 2300 / 4000 [ 57%]  (Sampling) \nChain 3 Iteration: 2400 / 4000 [ 60%]  (Sampling) \nChain 3 Iteration: 2500 / 4000 [ 62%]  (Sampling) \nChain 3 Iteration: 2600 / 4000 [ 65%]  (Sampling) \nChain 3 Iteration: 2700 / 4000 [ 67%]  (Sampling) \nChain 3 Iteration: 2800 / 4000 [ 70%]  (Sampling) \nChain 3 Iteration: 2900 / 4000 [ 72%]  (Sampling) \nChain 3 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 3 Iteration: 3100 / 4000 [ 77%]  (Sampling) \nChain 3 Iteration: 3200 / 4000 [ 80%]  (Sampling) \nChain 3 Iteration: 3300 / 4000 [ 82%]  (Sampling) \nChain 3 Iteration: 3400 / 4000 [ 85%]  (Sampling) \nChain 3 Iteration: 3500 / 4000 [ 87%]  (Sampling) \nChain 3 Iteration: 3600 / 4000 [ 90%]  (Sampling) \nChain 3 Iteration: 3700 / 4000 [ 92%]  (Sampling) \nChain 3 Iteration: 3800 / 4000 [ 95%]  (Sampling) \nChain 3 Iteration: 3900 / 4000 [ 97%]  (Sampling) \nChain 3 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 4000 [  2%]  (Warmup) \nChain 4 Iteration:  200 / 4000 [  5%]  (Warmup) \nChain 4 Iteration:  300 / 4000 [  7%]  (Warmup) \nChain 4 Iteration:  400 / 4000 [ 10%]  (Warmup) \nChain 4 Iteration:  500 / 4000 [ 12%]  (Warmup) \nChain 4 Iteration:  600 / 4000 [ 15%]  (Warmup) \nChain 4 Iteration:  700 / 4000 [ 17%]  (Warmup) \nChain 4 Iteration:  800 / 4000 [ 20%]  (Warmup) \nChain 4 Iteration:  900 / 4000 [ 22%]  (Warmup) \nChain 4 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 4 Iteration: 1100 / 4000 [ 27%]  (Warmup) \nChain 4 Iteration: 1200 / 4000 [ 30%]  (Warmup) \nChain 4 Iteration: 1300 / 4000 [ 32%]  (Warmup) \nChain 4 Iteration: 1400 / 4000 [ 35%]  (Warmup) \nChain 4 Iteration: 1500 / 4000 [ 37%]  (Warmup) \nChain 4 Iteration: 1600 / 4000 [ 40%]  (Warmup) \nChain 4 Iteration: 1700 / 4000 [ 42%]  (Warmup) \nChain 4 Iteration: 1800 / 4000 [ 45%]  (Warmup) \nChain 4 Iteration: 1900 / 4000 [ 47%]  (Warmup) \nChain 4 Iteration: 2000 / 4000 [ 50%]  (Warmup) \nChain 4 Iteration: 2001 / 4000 [ 50%]  (Sampling) \nChain 4 Iteration: 2100 / 4000 [ 52%]  (Sampling) \nChain 4 Iteration: 2200 / 4000 [ 55%]  (Sampling) \nChain 4 Iteration: 2300 / 4000 [ 57%]  (Sampling) \nChain 4 Iteration: 2400 / 4000 [ 60%]  (Sampling) \nChain 4 Iteration: 2500 / 4000 [ 62%]  (Sampling) \nChain 4 Iteration: 2600 / 4000 [ 65%]  (Sampling) \nChain 4 Iteration: 2700 / 4000 [ 67%]  (Sampling) \nChain 4 Iteration: 2800 / 4000 [ 70%]  (Sampling) \nChain 4 Iteration: 2900 / 4000 [ 72%]  (Sampling) \nChain 4 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 4 Iteration: 3100 / 4000 [ 77%]  (Sampling) \nChain 4 Iteration: 3200 / 4000 [ 80%]  (Sampling) \nChain 4 Iteration: 3300 / 4000 [ 82%]  (Sampling) \nChain 4 Iteration: 3400 / 4000 [ 85%]  (Sampling) \nChain 4 Iteration: 3500 / 4000 [ 87%]  (Sampling) \nChain 4 Iteration: 3600 / 4000 [ 90%]  (Sampling) \nChain 4 Iteration: 3700 / 4000 [ 92%]  (Sampling) \nChain 4 Iteration: 3800 / 4000 [ 95%]  (Sampling) \nChain 4 Iteration: 3900 / 4000 [ 97%]  (Sampling) \nChain 4 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\n\nWe can make a table like Table 9.1 for brms results using the modelsummary::msummary() function.\n\nmsummary(list(South = m_south, `Non-South` = m_nonsouth),\n         estimate = \"{estimate} [{conf.low}, {conf.high}]\",\n         statistic = NULL, fmt = 2,\n         gof_omit = \"^(?!Num)\"  # only include number of observations\n)\n\nWarning: \n`modelsummary` uses the `performance` package to extract goodness-of-fit\nstatistics from models of this class. You can specify the statistics you wish\nto compute by supplying a `metrics` argument to `modelsummary`, which will then\npush it forward to `performance`. Acceptable values are: \"all\", \"common\",\n\"none\", or a character vector of metrics names. For example: `modelsummary(mod,\nmetrics = c(\"RMSE\", \"R2\")` Note that some metrics are computationally\nexpensive. See `?performance::performance` for details.\n This warning appears once per session.\n\n\n\nTable 9.1: Intercepts and slopes for south and non-south states.\n\n\n\n\n\nSouth\nNon-South\n\n\n\nb_Intercept\n6.09 [3.60, 8.45]\n2.74 [1.75, 3.74]\n\n\nb_MedianAgeMarriage\n−1.96 [−2.89, −0.98]\n−0.69 [−1.07, −0.31]\n\n\nsigma\n0.11 [0.07, 0.17]\n0.15 [0.12, 0.20]\n\n\nNum.Obs.\n14\n36\n\n\n\n\n\n\n\n\nWe can now ask two questions:\n\nIs the intercept different across southern and non-southern states?\nIs the slope different across southern and non-southern states?\n\nThe correct way to answer the above questions is to obtain the posterior distribution of the difference in the coefficients. Repeat: obtain the posterior distribution of the difference. The incorrect way is to compare whether the CIs overlap.\nHere are the posteriors of the differences (\\(\\beta_0^\\text{south} - \\beta_0^\\text{nonsouth}\\) and \\(\\beta_1^\\text{south} - \\beta_1^\\text{nonsouth}\\)):\n\n# Extract draws\ndraws_south &lt;- as_draws_matrix(m_south,\n    variable = c(\"b_Intercept\", \"b_MedianAgeMarriage\")\n)\ndraws_nonsouth &lt;- as_draws_matrix(m_nonsouth,\n    variable = c(\"b_Intercept\", \"b_MedianAgeMarriage\")\n)\n# Difference in coefficients\ndraws_diff &lt;- draws_south - draws_nonsouth\n# Rename the columns\ncolnames(draws_diff) &lt;- paste0(\"d\", colnames(draws_diff))\n# Summarize\nsummarize_draws(draws_diff) |&gt;\n    knitr::kable(digits = 2)\n\n\nTable 9.2: Difference in intercept and slope for south and non-south states.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\ndb_Intercept\n3.32\n3.34\n1.34\n1.29\n1.14\n5.45\n1\n6115.12\n5017.01\n\n\ndb_MedianAgeMarriage\n-1.26\n-1.27\n0.52\n0.50\n-2.09\n-0.41\n1\n6112.20\n5034.56\n\n\n\n\n\n\n\n\nAs you can see, the southern states have a higher intercept and a lower slope.\nplot(\n    conditional_effects(m_nonsouth),\n    points = TRUE, plot = FALSE\n)[[1]] + ggtitle(\"Non-South\") + lims(x = c(2.3, 3), y = c(0.6, 1.4))\nplot(\n    conditional_effects(m_south),\n    points = TRUE, plot = FALSE\n)[[1]] + ggtitle(\"South\") + lims(x = c(2.3, 3), y = c(0.6, 1.4))\n\n\n\n\n\n\n\n\n\n(a) Non-southern states\n\n\n\n\n\n\n\n\n\n(b) Southern states\n\n\n\n\n\n\nFigure 9.2: Model-implied regression lines",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Multiple Predictors</span>"
    ]
  },
  {
    "objectID": "06b-multiple-predictors.html#additive-model",
    "href": "06b-multiple-predictors.html#additive-model",
    "title": "9  Multiple Predictors",
    "section": "\n9.3 Additive Model",
    "text": "9.3 Additive Model\nAn additive model assumes that the difference between predicted \\(Y\\) for two levels of \\(X_1\\) is the same regardless of the level of \\(X_2\\). In our example, we assume that the predicted difference in divorce rate associated with the median age of marriage does not depend on whether the state is southern or not. Equivalently, we assume that the predicted difference in Southern and non-Southern states does not depend on the median age of marriage.\n\\[\n\\begin{aligned}\n  D_i & \\sim N(\\mu_i, \\sigma)  \\\\\n  \\mu_i & = \\beta_0 + \\beta_1 S_i + \\beta_2 A_i \\\\\n  \\beta_0 & \\sim N(0, 10) \\\\\n  \\beta_1 & \\sim N(0, 10) \\\\\n  \\beta_2 & \\sim N(0, 1)  \\\\\n  \\sigma & \\sim t^+_4(0, 3)\n\\end{aligned}\n\\]\n\n\n\\(\\beta_1\\): Expected difference in divorce rate between southern and non-southern states with the same median age of marriage.\n\n\\(\\beta_2\\): Expected difference in divorce rate for one unit difference in median age of marriage, when both states are southern (or non-southern).\n\nIn the model, the variable S, southern state, is a dummy variable with 0 = non-southern and 1 = southern. Therefore,\n\n\n\n\n\n\nDummy Coding\n\n\n\n\nFor non-southern states, \\(\\mu = (\\beta_0) + (\\beta_2) A\\);\nFor southern states, \\(\\mu = (\\beta_0 + \\beta_1) + \\beta_2 A\\)\n\n\n\n\n\nm_additive &lt;- brm(\n    Divorce ~ South + MedianAgeMarriage,\n    data = waffle_divorce,\n    prior = prior(normal(0, 2), class = \"b\") +\n        prior(normal(0, 10), class = \"b\", coef = \"Southsouth\") +\n        prior(normal(0, 10), class = \"Intercept\") +\n        prior(student_t(4, 0, 3), class = \"sigma\"),\n    seed = 941,\n    iter = 4000,\n    file = \"m_additive\"\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 4000 [  2%]  (Warmup) \nChain 1 Iteration:  200 / 4000 [  5%]  (Warmup) \nChain 1 Iteration:  300 / 4000 [  7%]  (Warmup) \nChain 1 Iteration:  400 / 4000 [ 10%]  (Warmup) \nChain 1 Iteration:  500 / 4000 [ 12%]  (Warmup) \nChain 1 Iteration:  600 / 4000 [ 15%]  (Warmup) \nChain 1 Iteration:  700 / 4000 [ 17%]  (Warmup) \nChain 1 Iteration:  800 / 4000 [ 20%]  (Warmup) \nChain 1 Iteration:  900 / 4000 [ 22%]  (Warmup) \nChain 1 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 1 Iteration: 1100 / 4000 [ 27%]  (Warmup) \nChain 1 Iteration: 1200 / 4000 [ 30%]  (Warmup) \nChain 1 Iteration: 1300 / 4000 [ 32%]  (Warmup) \nChain 1 Iteration: 1400 / 4000 [ 35%]  (Warmup) \nChain 1 Iteration: 1500 / 4000 [ 37%]  (Warmup) \nChain 1 Iteration: 1600 / 4000 [ 40%]  (Warmup) \nChain 1 Iteration: 1700 / 4000 [ 42%]  (Warmup) \nChain 1 Iteration: 1800 / 4000 [ 45%]  (Warmup) \nChain 1 Iteration: 1900 / 4000 [ 47%]  (Warmup) \nChain 1 Iteration: 2000 / 4000 [ 50%]  (Warmup) \nChain 1 Iteration: 2001 / 4000 [ 50%]  (Sampling) \nChain 1 Iteration: 2100 / 4000 [ 52%]  (Sampling) \nChain 1 Iteration: 2200 / 4000 [ 55%]  (Sampling) \nChain 1 Iteration: 2300 / 4000 [ 57%]  (Sampling) \nChain 1 Iteration: 2400 / 4000 [ 60%]  (Sampling) \nChain 1 Iteration: 2500 / 4000 [ 62%]  (Sampling) \nChain 1 Iteration: 2600 / 4000 [ 65%]  (Sampling) \nChain 1 Iteration: 2700 / 4000 [ 67%]  (Sampling) \nChain 1 Iteration: 2800 / 4000 [ 70%]  (Sampling) \nChain 1 Iteration: 2900 / 4000 [ 72%]  (Sampling) \nChain 1 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 1 Iteration: 3100 / 4000 [ 77%]  (Sampling) \nChain 1 Iteration: 3200 / 4000 [ 80%]  (Sampling) \nChain 1 Iteration: 3300 / 4000 [ 82%]  (Sampling) \nChain 1 Iteration: 3400 / 4000 [ 85%]  (Sampling) \nChain 1 Iteration: 3500 / 4000 [ 87%]  (Sampling) \nChain 1 Iteration: 3600 / 4000 [ 90%]  (Sampling) \nChain 1 Iteration: 3700 / 4000 [ 92%]  (Sampling) \nChain 1 Iteration: 3800 / 4000 [ 95%]  (Sampling) \nChain 1 Iteration: 3900 / 4000 [ 97%]  (Sampling) \nChain 1 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 4000 [  2%]  (Warmup) \nChain 2 Iteration:  200 / 4000 [  5%]  (Warmup) \nChain 2 Iteration:  300 / 4000 [  7%]  (Warmup) \nChain 2 Iteration:  400 / 4000 [ 10%]  (Warmup) \nChain 2 Iteration:  500 / 4000 [ 12%]  (Warmup) \nChain 2 Iteration:  600 / 4000 [ 15%]  (Warmup) \nChain 2 Iteration:  700 / 4000 [ 17%]  (Warmup) \nChain 2 Iteration:  800 / 4000 [ 20%]  (Warmup) \nChain 2 Iteration:  900 / 4000 [ 22%]  (Warmup) \nChain 2 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 2 Iteration: 1100 / 4000 [ 27%]  (Warmup) \nChain 2 Iteration: 1200 / 4000 [ 30%]  (Warmup) \nChain 2 Iteration: 1300 / 4000 [ 32%]  (Warmup) \nChain 2 Iteration: 1400 / 4000 [ 35%]  (Warmup) \nChain 2 Iteration: 1500 / 4000 [ 37%]  (Warmup) \nChain 2 Iteration: 1600 / 4000 [ 40%]  (Warmup) \nChain 2 Iteration: 1700 / 4000 [ 42%]  (Warmup) \nChain 2 Iteration: 1800 / 4000 [ 45%]  (Warmup) \nChain 2 Iteration: 1900 / 4000 [ 47%]  (Warmup) \nChain 2 Iteration: 2000 / 4000 [ 50%]  (Warmup) \nChain 2 Iteration: 2001 / 4000 [ 50%]  (Sampling) \nChain 2 Iteration: 2100 / 4000 [ 52%]  (Sampling) \nChain 2 Iteration: 2200 / 4000 [ 55%]  (Sampling) \nChain 2 Iteration: 2300 / 4000 [ 57%]  (Sampling) \nChain 2 Iteration: 2400 / 4000 [ 60%]  (Sampling) \nChain 2 Iteration: 2500 / 4000 [ 62%]  (Sampling) \nChain 2 Iteration: 2600 / 4000 [ 65%]  (Sampling) \nChain 2 Iteration: 2700 / 4000 [ 67%]  (Sampling) \nChain 2 Iteration: 2800 / 4000 [ 70%]  (Sampling) \nChain 2 Iteration: 2900 / 4000 [ 72%]  (Sampling) \nChain 2 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 2 Iteration: 3100 / 4000 [ 77%]  (Sampling) \nChain 2 Iteration: 3200 / 4000 [ 80%]  (Sampling) \nChain 2 Iteration: 3300 / 4000 [ 82%]  (Sampling) \nChain 2 Iteration: 3400 / 4000 [ 85%]  (Sampling) \nChain 2 Iteration: 3500 / 4000 [ 87%]  (Sampling) \nChain 2 Iteration: 3600 / 4000 [ 90%]  (Sampling) \nChain 2 Iteration: 3700 / 4000 [ 92%]  (Sampling) \nChain 2 Iteration: 3800 / 4000 [ 95%]  (Sampling) \nChain 2 Iteration: 3900 / 4000 [ 97%]  (Sampling) \nChain 2 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 4000 [  2%]  (Warmup) \nChain 3 Iteration:  200 / 4000 [  5%]  (Warmup) \nChain 3 Iteration:  300 / 4000 [  7%]  (Warmup) \nChain 3 Iteration:  400 / 4000 [ 10%]  (Warmup) \nChain 3 Iteration:  500 / 4000 [ 12%]  (Warmup) \nChain 3 Iteration:  600 / 4000 [ 15%]  (Warmup) \nChain 3 Iteration:  700 / 4000 [ 17%]  (Warmup) \nChain 3 Iteration:  800 / 4000 [ 20%]  (Warmup) \nChain 3 Iteration:  900 / 4000 [ 22%]  (Warmup) \nChain 3 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 3 Iteration: 1100 / 4000 [ 27%]  (Warmup) \nChain 3 Iteration: 1200 / 4000 [ 30%]  (Warmup) \nChain 3 Iteration: 1300 / 4000 [ 32%]  (Warmup) \nChain 3 Iteration: 1400 / 4000 [ 35%]  (Warmup) \nChain 3 Iteration: 1500 / 4000 [ 37%]  (Warmup) \nChain 3 Iteration: 1600 / 4000 [ 40%]  (Warmup) \nChain 3 Iteration: 1700 / 4000 [ 42%]  (Warmup) \nChain 3 Iteration: 1800 / 4000 [ 45%]  (Warmup) \nChain 3 Iteration: 1900 / 4000 [ 47%]  (Warmup) \nChain 3 Iteration: 2000 / 4000 [ 50%]  (Warmup) \nChain 3 Iteration: 2001 / 4000 [ 50%]  (Sampling) \nChain 3 Iteration: 2100 / 4000 [ 52%]  (Sampling) \nChain 3 Iteration: 2200 / 4000 [ 55%]  (Sampling) \nChain 3 Iteration: 2300 / 4000 [ 57%]  (Sampling) \nChain 3 Iteration: 2400 / 4000 [ 60%]  (Sampling) \nChain 3 Iteration: 2500 / 4000 [ 62%]  (Sampling) \nChain 3 Iteration: 2600 / 4000 [ 65%]  (Sampling) \nChain 3 Iteration: 2700 / 4000 [ 67%]  (Sampling) \nChain 3 Iteration: 2800 / 4000 [ 70%]  (Sampling) \nChain 3 Iteration: 2900 / 4000 [ 72%]  (Sampling) \nChain 3 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 3 Iteration: 3100 / 4000 [ 77%]  (Sampling) \nChain 3 Iteration: 3200 / 4000 [ 80%]  (Sampling) \nChain 3 Iteration: 3300 / 4000 [ 82%]  (Sampling) \nChain 3 Iteration: 3400 / 4000 [ 85%]  (Sampling) \nChain 3 Iteration: 3500 / 4000 [ 87%]  (Sampling) \nChain 3 Iteration: 3600 / 4000 [ 90%]  (Sampling) \nChain 3 Iteration: 3700 / 4000 [ 92%]  (Sampling) \nChain 3 Iteration: 3800 / 4000 [ 95%]  (Sampling) \nChain 3 Iteration: 3900 / 4000 [ 97%]  (Sampling) \nChain 3 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 4000 [  2%]  (Warmup) \nChain 4 Iteration:  200 / 4000 [  5%]  (Warmup) \nChain 4 Iteration:  300 / 4000 [  7%]  (Warmup) \nChain 4 Iteration:  400 / 4000 [ 10%]  (Warmup) \nChain 4 Iteration:  500 / 4000 [ 12%]  (Warmup) \nChain 4 Iteration:  600 / 4000 [ 15%]  (Warmup) \nChain 4 Iteration:  700 / 4000 [ 17%]  (Warmup) \nChain 4 Iteration:  800 / 4000 [ 20%]  (Warmup) \nChain 4 Iteration:  900 / 4000 [ 22%]  (Warmup) \nChain 4 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 4 Iteration: 1100 / 4000 [ 27%]  (Warmup) \nChain 4 Iteration: 1200 / 4000 [ 30%]  (Warmup) \nChain 4 Iteration: 1300 / 4000 [ 32%]  (Warmup) \nChain 4 Iteration: 1400 / 4000 [ 35%]  (Warmup) \nChain 4 Iteration: 1500 / 4000 [ 37%]  (Warmup) \nChain 4 Iteration: 1600 / 4000 [ 40%]  (Warmup) \nChain 4 Iteration: 1700 / 4000 [ 42%]  (Warmup) \nChain 4 Iteration: 1800 / 4000 [ 45%]  (Warmup) \nChain 4 Iteration: 1900 / 4000 [ 47%]  (Warmup) \nChain 4 Iteration: 2000 / 4000 [ 50%]  (Warmup) \nChain 4 Iteration: 2001 / 4000 [ 50%]  (Sampling) \nChain 4 Iteration: 2100 / 4000 [ 52%]  (Sampling) \nChain 4 Iteration: 2200 / 4000 [ 55%]  (Sampling) \nChain 4 Iteration: 2300 / 4000 [ 57%]  (Sampling) \nChain 4 Iteration: 2400 / 4000 [ 60%]  (Sampling) \nChain 4 Iteration: 2500 / 4000 [ 62%]  (Sampling) \nChain 4 Iteration: 2600 / 4000 [ 65%]  (Sampling) \nChain 4 Iteration: 2700 / 4000 [ 67%]  (Sampling) \nChain 4 Iteration: 2800 / 4000 [ 70%]  (Sampling) \nChain 4 Iteration: 2900 / 4000 [ 72%]  (Sampling) \nChain 4 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 4 Iteration: 3100 / 4000 [ 77%]  (Sampling) \nChain 4 Iteration: 3200 / 4000 [ 80%]  (Sampling) \nChain 4 Iteration: 3300 / 4000 [ 82%]  (Sampling) \nChain 4 Iteration: 3400 / 4000 [ 85%]  (Sampling) \nChain 4 Iteration: 3500 / 4000 [ 87%]  (Sampling) \nChain 4 Iteration: 3600 / 4000 [ 90%]  (Sampling) \nChain 4 Iteration: 3700 / 4000 [ 92%]  (Sampling) \nChain 4 Iteration: 3800 / 4000 [ 95%]  (Sampling) \nChain 4 Iteration: 3900 / 4000 [ 97%]  (Sampling) \nChain 4 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.6 seconds.\n\n\n\nm_additive\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: Divorce ~ South + MedianAgeMarriage \n   Data: waffle_divorce (Number of observations: 50) \n  Draws: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;\n         total post-warmup draws = 8000\n\nRegression Coefficients:\n                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept             3.00      0.46     2.10     3.89 1.00     7435     5360\nSouthsouth            0.08      0.05    -0.01     0.18 1.00     7847     5519\nMedianAgeMarriage    -0.79      0.18    -1.13    -0.45 1.00     7406     5423\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.15      0.02     0.12     0.18 1.00     7217     5426\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Multiple Predictors</span>"
    ]
  },
  {
    "objectID": "06b-multiple-predictors.html#interaction-model-different-slopes-across-two-groups",
    "href": "06b-multiple-predictors.html#interaction-model-different-slopes-across-two-groups",
    "title": "9  Multiple Predictors",
    "section": "\n9.4 Interaction Model: Different Slopes Across Two Groups",
    "text": "9.4 Interaction Model: Different Slopes Across Two Groups\nAn alternative is to include an interaction term\n\\[\n\\begin{aligned}\n  D_i & \\sim N(\\mu_i, \\sigma)  \\\\\n  \\mu_i & = \\beta_0 + \\beta_1 S_i + \\beta_2 A_i + \\beta_3 S_i \\times A_i \\\\\n  \\beta_0 & \\sim N(0, 10) \\\\\n  \\beta_1 & \\sim N(0, 10) \\\\\n  \\beta_2 & \\sim N(0, 1) \\\\\n  \\beta_3 & \\sim N(0, 2) \\\\\n  \\sigma & \\sim t^+_4(0, 3)\n\\end{aligned}\n\\]\n\n\n\\(\\beta_1\\): Difference in intercept between southern and non-southern states.\n\n\\(\\beta_3\\): Difference in the coefficient for A → D between southern and non-southern states\n\n\n\n\n\n\n\nDummy Coding in Interaction Model\n\n\n\n\nFor non-southern states, \\(\\mu = (\\beta_0) + (\\beta_2) A\\);\nFor southern states, \\(\\mu = (\\beta_0 + \\beta_1) + (\\beta_2 + \\beta_3) A\\)\n\n\n\n\n\nm_inter &lt;- brm(\n    Divorce ~ South * MedianAgeMarriage,\n    data = waffle_divorce,\n    prior = prior(normal(0, 2), class = \"b\") +\n        prior(normal(0, 10), class = \"b\", coef = \"Southsouth\") +\n        prior(normal(0, 10), class = \"Intercept\") +\n        prior(student_t(4, 0, 3), class = \"sigma\"),\n    seed = 941,\n    iter = 4000,\n    file = \"m_inter\"\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 4000 [  2%]  (Warmup) \nChain 1 Iteration:  200 / 4000 [  5%]  (Warmup) \nChain 1 Iteration:  300 / 4000 [  7%]  (Warmup) \nChain 1 Iteration:  400 / 4000 [ 10%]  (Warmup) \nChain 1 Iteration:  500 / 4000 [ 12%]  (Warmup) \nChain 1 Iteration:  600 / 4000 [ 15%]  (Warmup) \nChain 1 Iteration:  700 / 4000 [ 17%]  (Warmup) \nChain 1 Iteration:  800 / 4000 [ 20%]  (Warmup) \nChain 1 Iteration:  900 / 4000 [ 22%]  (Warmup) \nChain 1 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 1 Iteration: 1100 / 4000 [ 27%]  (Warmup) \nChain 1 Iteration: 1200 / 4000 [ 30%]  (Warmup) \nChain 1 Iteration: 1300 / 4000 [ 32%]  (Warmup) \nChain 1 Iteration: 1400 / 4000 [ 35%]  (Warmup) \nChain 1 Iteration: 1500 / 4000 [ 37%]  (Warmup) \nChain 1 Iteration: 1600 / 4000 [ 40%]  (Warmup) \nChain 1 Iteration: 1700 / 4000 [ 42%]  (Warmup) \nChain 1 Iteration: 1800 / 4000 [ 45%]  (Warmup) \nChain 1 Iteration: 1900 / 4000 [ 47%]  (Warmup) \nChain 1 Iteration: 2000 / 4000 [ 50%]  (Warmup) \nChain 1 Iteration: 2001 / 4000 [ 50%]  (Sampling) \nChain 1 Iteration: 2100 / 4000 [ 52%]  (Sampling) \nChain 1 Iteration: 2200 / 4000 [ 55%]  (Sampling) \nChain 1 Iteration: 2300 / 4000 [ 57%]  (Sampling) \nChain 1 Iteration: 2400 / 4000 [ 60%]  (Sampling) \nChain 1 Iteration: 2500 / 4000 [ 62%]  (Sampling) \nChain 1 Iteration: 2600 / 4000 [ 65%]  (Sampling) \nChain 1 Iteration: 2700 / 4000 [ 67%]  (Sampling) \nChain 1 Iteration: 2800 / 4000 [ 70%]  (Sampling) \nChain 1 Iteration: 2900 / 4000 [ 72%]  (Sampling) \nChain 1 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 1 Iteration: 3100 / 4000 [ 77%]  (Sampling) \nChain 1 Iteration: 3200 / 4000 [ 80%]  (Sampling) \nChain 1 Iteration: 3300 / 4000 [ 82%]  (Sampling) \nChain 1 Iteration: 3400 / 4000 [ 85%]  (Sampling) \nChain 1 Iteration: 3500 / 4000 [ 87%]  (Sampling) \nChain 1 Iteration: 3600 / 4000 [ 90%]  (Sampling) \nChain 1 Iteration: 3700 / 4000 [ 92%]  (Sampling) \nChain 1 Iteration: 3800 / 4000 [ 95%]  (Sampling) \nChain 1 Iteration: 3900 / 4000 [ 97%]  (Sampling) \nChain 1 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 1 finished in 0.7 seconds.\nChain 2 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 4000 [  2%]  (Warmup) \nChain 2 Iteration:  200 / 4000 [  5%]  (Warmup) \nChain 2 Iteration:  300 / 4000 [  7%]  (Warmup) \nChain 2 Iteration:  400 / 4000 [ 10%]  (Warmup) \nChain 2 Iteration:  500 / 4000 [ 12%]  (Warmup) \nChain 2 Iteration:  600 / 4000 [ 15%]  (Warmup) \nChain 2 Iteration:  700 / 4000 [ 17%]  (Warmup) \nChain 2 Iteration:  800 / 4000 [ 20%]  (Warmup) \nChain 2 Iteration:  900 / 4000 [ 22%]  (Warmup) \nChain 2 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 2 Iteration: 1100 / 4000 [ 27%]  (Warmup) \nChain 2 Iteration: 1200 / 4000 [ 30%]  (Warmup) \nChain 2 Iteration: 1300 / 4000 [ 32%]  (Warmup) \nChain 2 Iteration: 1400 / 4000 [ 35%]  (Warmup) \nChain 2 Iteration: 1500 / 4000 [ 37%]  (Warmup) \nChain 2 Iteration: 1600 / 4000 [ 40%]  (Warmup) \nChain 2 Iteration: 1700 / 4000 [ 42%]  (Warmup) \nChain 2 Iteration: 1800 / 4000 [ 45%]  (Warmup) \nChain 2 Iteration: 1900 / 4000 [ 47%]  (Warmup) \nChain 2 Iteration: 2000 / 4000 [ 50%]  (Warmup) \nChain 2 Iteration: 2001 / 4000 [ 50%]  (Sampling) \nChain 2 Iteration: 2100 / 4000 [ 52%]  (Sampling) \nChain 2 Iteration: 2200 / 4000 [ 55%]  (Sampling) \nChain 2 Iteration: 2300 / 4000 [ 57%]  (Sampling) \nChain 2 Iteration: 2400 / 4000 [ 60%]  (Sampling) \nChain 2 Iteration: 2500 / 4000 [ 62%]  (Sampling) \nChain 2 Iteration: 2600 / 4000 [ 65%]  (Sampling) \nChain 2 Iteration: 2700 / 4000 [ 67%]  (Sampling) \nChain 2 Iteration: 2800 / 4000 [ 70%]  (Sampling) \nChain 2 Iteration: 2900 / 4000 [ 72%]  (Sampling) \nChain 2 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 2 Iteration: 3100 / 4000 [ 77%]  (Sampling) \nChain 2 Iteration: 3200 / 4000 [ 80%]  (Sampling) \nChain 2 Iteration: 3300 / 4000 [ 82%]  (Sampling) \nChain 2 Iteration: 3400 / 4000 [ 85%]  (Sampling) \nChain 2 Iteration: 3500 / 4000 [ 87%]  (Sampling) \nChain 2 Iteration: 3600 / 4000 [ 90%]  (Sampling) \nChain 2 Iteration: 3700 / 4000 [ 92%]  (Sampling) \nChain 2 Iteration: 3800 / 4000 [ 95%]  (Sampling) \nChain 2 Iteration: 3900 / 4000 [ 97%]  (Sampling) \nChain 2 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 2 finished in 0.7 seconds.\nChain 3 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 4000 [  2%]  (Warmup) \nChain 3 Iteration:  200 / 4000 [  5%]  (Warmup) \nChain 3 Iteration:  300 / 4000 [  7%]  (Warmup) \nChain 3 Iteration:  400 / 4000 [ 10%]  (Warmup) \nChain 3 Iteration:  500 / 4000 [ 12%]  (Warmup) \nChain 3 Iteration:  600 / 4000 [ 15%]  (Warmup) \nChain 3 Iteration:  700 / 4000 [ 17%]  (Warmup) \nChain 3 Iteration:  800 / 4000 [ 20%]  (Warmup) \nChain 3 Iteration:  900 / 4000 [ 22%]  (Warmup) \nChain 3 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 3 Iteration: 1100 / 4000 [ 27%]  (Warmup) \nChain 3 Iteration: 1200 / 4000 [ 30%]  (Warmup) \nChain 3 Iteration: 1300 / 4000 [ 32%]  (Warmup) \nChain 3 Iteration: 1400 / 4000 [ 35%]  (Warmup) \nChain 3 Iteration: 1500 / 4000 [ 37%]  (Warmup) \nChain 3 Iteration: 1600 / 4000 [ 40%]  (Warmup) \nChain 3 Iteration: 1700 / 4000 [ 42%]  (Warmup) \nChain 3 Iteration: 1800 / 4000 [ 45%]  (Warmup) \nChain 3 Iteration: 1900 / 4000 [ 47%]  (Warmup) \nChain 3 Iteration: 2000 / 4000 [ 50%]  (Warmup) \nChain 3 Iteration: 2001 / 4000 [ 50%]  (Sampling) \nChain 3 Iteration: 2100 / 4000 [ 52%]  (Sampling) \nChain 3 Iteration: 2200 / 4000 [ 55%]  (Sampling) \nChain 3 Iteration: 2300 / 4000 [ 57%]  (Sampling) \nChain 3 Iteration: 2400 / 4000 [ 60%]  (Sampling) \nChain 3 Iteration: 2500 / 4000 [ 62%]  (Sampling) \nChain 3 Iteration: 2600 / 4000 [ 65%]  (Sampling) \nChain 3 Iteration: 2700 / 4000 [ 67%]  (Sampling) \nChain 3 Iteration: 2800 / 4000 [ 70%]  (Sampling) \nChain 3 Iteration: 2900 / 4000 [ 72%]  (Sampling) \nChain 3 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 3 Iteration: 3100 / 4000 [ 77%]  (Sampling) \nChain 3 Iteration: 3200 / 4000 [ 80%]  (Sampling) \nChain 3 Iteration: 3300 / 4000 [ 82%]  (Sampling) \nChain 3 Iteration: 3400 / 4000 [ 85%]  (Sampling) \nChain 3 Iteration: 3500 / 4000 [ 87%]  (Sampling) \nChain 3 Iteration: 3600 / 4000 [ 90%]  (Sampling) \nChain 3 Iteration: 3700 / 4000 [ 92%]  (Sampling) \nChain 3 Iteration: 3800 / 4000 [ 95%]  (Sampling) \nChain 3 Iteration: 3900 / 4000 [ 97%]  (Sampling) \nChain 3 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 3 finished in 0.7 seconds.\nChain 4 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 4000 [  2%]  (Warmup) \nChain 4 Iteration:  200 / 4000 [  5%]  (Warmup) \nChain 4 Iteration:  300 / 4000 [  7%]  (Warmup) \nChain 4 Iteration:  400 / 4000 [ 10%]  (Warmup) \nChain 4 Iteration:  500 / 4000 [ 12%]  (Warmup) \nChain 4 Iteration:  600 / 4000 [ 15%]  (Warmup) \nChain 4 Iteration:  700 / 4000 [ 17%]  (Warmup) \nChain 4 Iteration:  800 / 4000 [ 20%]  (Warmup) \nChain 4 Iteration:  900 / 4000 [ 22%]  (Warmup) \nChain 4 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 4 Iteration: 1100 / 4000 [ 27%]  (Warmup) \nChain 4 Iteration: 1200 / 4000 [ 30%]  (Warmup) \nChain 4 Iteration: 1300 / 4000 [ 32%]  (Warmup) \nChain 4 Iteration: 1400 / 4000 [ 35%]  (Warmup) \nChain 4 Iteration: 1500 / 4000 [ 37%]  (Warmup) \nChain 4 Iteration: 1600 / 4000 [ 40%]  (Warmup) \nChain 4 Iteration: 1700 / 4000 [ 42%]  (Warmup) \nChain 4 Iteration: 1800 / 4000 [ 45%]  (Warmup) \nChain 4 Iteration: 1900 / 4000 [ 47%]  (Warmup) \nChain 4 Iteration: 2000 / 4000 [ 50%]  (Warmup) \nChain 4 Iteration: 2001 / 4000 [ 50%]  (Sampling) \nChain 4 Iteration: 2100 / 4000 [ 52%]  (Sampling) \nChain 4 Iteration: 2200 / 4000 [ 55%]  (Sampling) \nChain 4 Iteration: 2300 / 4000 [ 57%]  (Sampling) \nChain 4 Iteration: 2400 / 4000 [ 60%]  (Sampling) \nChain 4 Iteration: 2500 / 4000 [ 62%]  (Sampling) \nChain 4 Iteration: 2600 / 4000 [ 65%]  (Sampling) \nChain 4 Iteration: 2700 / 4000 [ 67%]  (Sampling) \nChain 4 Iteration: 2800 / 4000 [ 70%]  (Sampling) \nChain 4 Iteration: 2900 / 4000 [ 72%]  (Sampling) \nChain 4 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 4 Iteration: 3100 / 4000 [ 77%]  (Sampling) \nChain 4 Iteration: 3200 / 4000 [ 80%]  (Sampling) \nChain 4 Iteration: 3300 / 4000 [ 82%]  (Sampling) \nChain 4 Iteration: 3400 / 4000 [ 85%]  (Sampling) \nChain 4 Iteration: 3500 / 4000 [ 87%]  (Sampling) \nChain 4 Iteration: 3600 / 4000 [ 90%]  (Sampling) \nChain 4 Iteration: 3700 / 4000 [ 92%]  (Sampling) \nChain 4 Iteration: 3800 / 4000 [ 95%]  (Sampling) \nChain 4 Iteration: 3900 / 4000 [ 97%]  (Sampling) \nChain 4 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 4 finished in 0.6 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.7 seconds.\nTotal execution time: 3.0 seconds.\n\n\nThe formula Divorce ~ South * MedianAgeMarriage is the same as\nDivorce ~ South + MedianAgeMarriage + South:MedianAgeMarriage\nwhere : is the symbol in R for a product term.\n\n# Print summary of the model\nm_inter\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: Divorce ~ South * MedianAgeMarriage \n   Data: waffle_divorce (Number of observations: 50) \n  Draws: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;\n         total post-warmup draws = 8000\n\nRegression Coefficients:\n                             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept                        2.78      0.46     1.87     3.68 1.00     4716\nSouthsouth                       3.20      1.60     0.19     6.30 1.00     2863\nMedianAgeMarriage               -0.70      0.18    -1.05    -0.35 1.00     4714\nSouthsouth:MedianAgeMarriage    -1.22      0.62    -2.42    -0.03 1.00     2876\n                             Tail_ESS\nIntercept                        4042\nSouthsouth                       3608\nMedianAgeMarriage                4085\nSouthsouth:MedianAgeMarriage     3584\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.14      0.02     0.12     0.18 1.00     4244     4998\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\n9.4.1 Posterior predictive checks\n\n# Check density (normality)\npp_check(m_inter, type = \"dens_overlay_grouped\", group = \"South\")\n\nUsing 10 posterior draws for ppc type 'dens_overlay_grouped' by default.\n\n# Check prediction (a few outliers)\npp_check(m_inter,\n    type = \"ribbon_grouped\", x = \"MedianAgeMarriage\",\n    group = \"South\",\n    y_draw = \"points\"\n)\n\nUsing all posterior draws for ppc type 'ribbon_grouped' by default.\n\n\n\n\n\n\n\n\n\n(a) Density overlayed plots\n\n\n\n\n\n\n\n\n\n(b) Prediction intervals\n\n\n\n\n\nFigure 9.3: Posterior predictive checks for the interaction model.\n\n\n\n\n# Check errors (no clear pattern)\npp_check(m_inter,\n    type = \"error_scatter_avg_vs_x\", x = \"MedianAgeMarriage\"\n)\n\nUsing all posterior draws for ppc type 'error_scatter_avg_vs_x' by default.\n\n\n\n\n\n\n\nFigure 9.4: Average prediction error against the predictor. No clear pattern should be observed for a correctly specified model.\n\n\n\n\n\n9.4.2 Conditional effects/simple slopes\nSlope of MedianAgeMarriage when South = 0: \\(\\beta_1\\)\nSlope of MedianAgeMarriage when South = 1: \\(\\beta_1 + \\beta_3\\)\n\nas_draws(m_inter) |&gt;\n    mutate_variables(\n        b_nonsouth = b_MedianAgeMarriage,\n        b_south = b_MedianAgeMarriage + `b_Southsouth:MedianAgeMarriage`\n    ) |&gt;\n    posterior::subset_draws(\n        variable = c(\"b_nonsouth\", \"b_south\")\n    ) |&gt;\n    summarize_draws() |&gt;\n    knitr::kable(digits = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\nb_nonsouth\n-0.70\n-0.71\n0.18\n0.18\n-1.00\n-0.41\n1\n4713.61\n4085.16\n\n\nb_south\n-1.92\n-1.91\n0.60\n0.60\n-2.91\n-0.93\n1\n3168.15\n3659.43\n\n\n\n\n\n\nplot(\n    conditional_effects(m_inter,\n        effects = \"MedianAgeMarriage\",\n        conditions = data.frame(South = c(\"south\", \"non-south\"),\n                                cond__ = c(\"South\", \"Non-South\"))\n    ),\n    points = TRUE\n)\n\n\n\n\n\n\nFigure 9.5: Model-implied simple slopes based on the interaction model.",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Multiple Predictors</span>"
    ]
  },
  {
    "objectID": "06b-multiple-predictors.html#interaction-of-continuous-predictors",
    "href": "06b-multiple-predictors.html#interaction-of-continuous-predictors",
    "title": "9  Multiple Predictors",
    "section": "\n9.5 Interaction of Continuous Predictors",
    "text": "9.5 Interaction of Continuous Predictors\n\nplotly::plot_ly(waffle_divorce,\n                x = ~Marriage,\n                y = ~MedianAgeMarriage,\n                z = ~Divorce)\n\nNo trace type specified:\n  Based on info supplied, a 'scatter3d' trace seems appropriate.\n  Read more about this trace type -&gt; https://plotly.com/r/reference/#scatter3d\n\n\nNo scatter3d mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -&gt; https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\n\nFigure 9.6: 3-D plot visualizing one outcome and two predictors.\n\n\n\n\\[\n\\begin{aligned}\n  D_i & \\sim N(\\mu_i, \\sigma)  \\\\\n  \\mu_i & = \\beta_0 + \\beta_1 M_i + \\beta_2 A_i + \\beta_3 M_i \\times A_i \\\\\n\\end{aligned}\n\\]\n\n# Use default priors (just for convenience here)\nm_inter2 &lt;- brm(Divorce ~ Marriage * MedianAgeMarriage,\n    data = waffle_divorce,\n    seed = 941,\n    iter = 4000,\n    file = \"m_inter2\"\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 4000 [  2%]  (Warmup) \nChain 1 Iteration:  200 / 4000 [  5%]  (Warmup) \nChain 1 Iteration:  300 / 4000 [  7%]  (Warmup) \nChain 1 Iteration:  400 / 4000 [ 10%]  (Warmup) \nChain 1 Iteration:  500 / 4000 [ 12%]  (Warmup) \nChain 1 Iteration:  600 / 4000 [ 15%]  (Warmup) \nChain 1 Iteration:  700 / 4000 [ 17%]  (Warmup) \nChain 1 Iteration:  800 / 4000 [ 20%]  (Warmup) \nChain 1 Iteration:  900 / 4000 [ 22%]  (Warmup) \nChain 1 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 1 Iteration: 1100 / 4000 [ 27%]  (Warmup) \nChain 1 Iteration: 1200 / 4000 [ 30%]  (Warmup) \nChain 1 Iteration: 1300 / 4000 [ 32%]  (Warmup) \nChain 1 Iteration: 1400 / 4000 [ 35%]  (Warmup) \nChain 1 Iteration: 1500 / 4000 [ 37%]  (Warmup) \nChain 1 Iteration: 1600 / 4000 [ 40%]  (Warmup) \nChain 1 Iteration: 1700 / 4000 [ 42%]  (Warmup) \nChain 1 Iteration: 1800 / 4000 [ 45%]  (Warmup) \nChain 1 Iteration: 1900 / 4000 [ 47%]  (Warmup) \nChain 1 Iteration: 2000 / 4000 [ 50%]  (Warmup) \nChain 1 Iteration: 2001 / 4000 [ 50%]  (Sampling) \nChain 1 Iteration: 2100 / 4000 [ 52%]  (Sampling) \nChain 1 Iteration: 2200 / 4000 [ 55%]  (Sampling) \nChain 1 Iteration: 2300 / 4000 [ 57%]  (Sampling) \nChain 1 Iteration: 2400 / 4000 [ 60%]  (Sampling) \nChain 1 Iteration: 2500 / 4000 [ 62%]  (Sampling) \nChain 1 Iteration: 2600 / 4000 [ 65%]  (Sampling) \nChain 1 Iteration: 2700 / 4000 [ 67%]  (Sampling) \nChain 1 Iteration: 2800 / 4000 [ 70%]  (Sampling) \nChain 1 Iteration: 2900 / 4000 [ 72%]  (Sampling) \nChain 1 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 1 Iteration: 3100 / 4000 [ 77%]  (Sampling) \nChain 1 Iteration: 3200 / 4000 [ 80%]  (Sampling) \nChain 1 Iteration: 3300 / 4000 [ 82%]  (Sampling) \nChain 1 Iteration: 3400 / 4000 [ 85%]  (Sampling) \nChain 1 Iteration: 3500 / 4000 [ 87%]  (Sampling) \nChain 1 Iteration: 3600 / 4000 [ 90%]  (Sampling) \nChain 1 Iteration: 3700 / 4000 [ 92%]  (Sampling) \nChain 1 Iteration: 3800 / 4000 [ 95%]  (Sampling) \nChain 1 Iteration: 3900 / 4000 [ 97%]  (Sampling) \nChain 1 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 1 finished in 0.3 seconds.\nChain 2 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 4000 [  2%]  (Warmup) \nChain 2 Iteration:  200 / 4000 [  5%]  (Warmup) \nChain 2 Iteration:  300 / 4000 [  7%]  (Warmup) \nChain 2 Iteration:  400 / 4000 [ 10%]  (Warmup) \nChain 2 Iteration:  500 / 4000 [ 12%]  (Warmup) \nChain 2 Iteration:  600 / 4000 [ 15%]  (Warmup) \nChain 2 Iteration:  700 / 4000 [ 17%]  (Warmup) \nChain 2 Iteration:  800 / 4000 [ 20%]  (Warmup) \nChain 2 Iteration:  900 / 4000 [ 22%]  (Warmup) \nChain 2 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 2 Iteration: 1100 / 4000 [ 27%]  (Warmup) \nChain 2 Iteration: 1200 / 4000 [ 30%]  (Warmup) \nChain 2 Iteration: 1300 / 4000 [ 32%]  (Warmup) \nChain 2 Iteration: 1400 / 4000 [ 35%]  (Warmup) \nChain 2 Iteration: 1500 / 4000 [ 37%]  (Warmup) \nChain 2 Iteration: 1600 / 4000 [ 40%]  (Warmup) \nChain 2 Iteration: 1700 / 4000 [ 42%]  (Warmup) \nChain 2 Iteration: 1800 / 4000 [ 45%]  (Warmup) \nChain 2 Iteration: 1900 / 4000 [ 47%]  (Warmup) \nChain 2 Iteration: 2000 / 4000 [ 50%]  (Warmup) \nChain 2 Iteration: 2001 / 4000 [ 50%]  (Sampling) \nChain 2 Iteration: 2100 / 4000 [ 52%]  (Sampling) \nChain 2 Iteration: 2200 / 4000 [ 55%]  (Sampling) \nChain 2 Iteration: 2300 / 4000 [ 57%]  (Sampling) \nChain 2 Iteration: 2400 / 4000 [ 60%]  (Sampling) \nChain 2 Iteration: 2500 / 4000 [ 62%]  (Sampling) \nChain 2 Iteration: 2600 / 4000 [ 65%]  (Sampling) \nChain 2 Iteration: 2700 / 4000 [ 67%]  (Sampling) \nChain 2 Iteration: 2800 / 4000 [ 70%]  (Sampling) \nChain 2 Iteration: 2900 / 4000 [ 72%]  (Sampling) \nChain 2 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 2 Iteration: 3100 / 4000 [ 77%]  (Sampling) \nChain 2 Iteration: 3200 / 4000 [ 80%]  (Sampling) \nChain 2 Iteration: 3300 / 4000 [ 82%]  (Sampling) \nChain 2 Iteration: 3400 / 4000 [ 85%]  (Sampling) \nChain 2 Iteration: 3500 / 4000 [ 87%]  (Sampling) \nChain 2 Iteration: 3600 / 4000 [ 90%]  (Sampling) \nChain 2 Iteration: 3700 / 4000 [ 92%]  (Sampling) \nChain 2 Iteration: 3800 / 4000 [ 95%]  (Sampling) \nChain 2 Iteration: 3900 / 4000 [ 97%]  (Sampling) \nChain 2 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 2 finished in 0.3 seconds.\nChain 3 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 4000 [  2%]  (Warmup) \nChain 3 Iteration:  200 / 4000 [  5%]  (Warmup) \nChain 3 Iteration:  300 / 4000 [  7%]  (Warmup) \nChain 3 Iteration:  400 / 4000 [ 10%]  (Warmup) \nChain 3 Iteration:  500 / 4000 [ 12%]  (Warmup) \nChain 3 Iteration:  600 / 4000 [ 15%]  (Warmup) \nChain 3 Iteration:  700 / 4000 [ 17%]  (Warmup) \nChain 3 Iteration:  800 / 4000 [ 20%]  (Warmup) \nChain 3 Iteration:  900 / 4000 [ 22%]  (Warmup) \nChain 3 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 3 Iteration: 1100 / 4000 [ 27%]  (Warmup) \nChain 3 Iteration: 1200 / 4000 [ 30%]  (Warmup) \nChain 3 Iteration: 1300 / 4000 [ 32%]  (Warmup) \nChain 3 Iteration: 1400 / 4000 [ 35%]  (Warmup) \nChain 3 Iteration: 1500 / 4000 [ 37%]  (Warmup) \nChain 3 Iteration: 1600 / 4000 [ 40%]  (Warmup) \nChain 3 Iteration: 1700 / 4000 [ 42%]  (Warmup) \nChain 3 Iteration: 1800 / 4000 [ 45%]  (Warmup) \nChain 3 Iteration: 1900 / 4000 [ 47%]  (Warmup) \nChain 3 Iteration: 2000 / 4000 [ 50%]  (Warmup) \nChain 3 Iteration: 2001 / 4000 [ 50%]  (Sampling) \nChain 3 Iteration: 2100 / 4000 [ 52%]  (Sampling) \nChain 3 Iteration: 2200 / 4000 [ 55%]  (Sampling) \nChain 3 Iteration: 2300 / 4000 [ 57%]  (Sampling) \nChain 3 Iteration: 2400 / 4000 [ 60%]  (Sampling) \nChain 3 Iteration: 2500 / 4000 [ 62%]  (Sampling) \nChain 3 Iteration: 2600 / 4000 [ 65%]  (Sampling) \nChain 3 Iteration: 2700 / 4000 [ 67%]  (Sampling) \nChain 3 Iteration: 2800 / 4000 [ 70%]  (Sampling) \nChain 3 Iteration: 2900 / 4000 [ 72%]  (Sampling) \nChain 3 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 3 Iteration: 3100 / 4000 [ 77%]  (Sampling) \nChain 3 Iteration: 3200 / 4000 [ 80%]  (Sampling) \nChain 3 Iteration: 3300 / 4000 [ 82%]  (Sampling) \nChain 3 Iteration: 3400 / 4000 [ 85%]  (Sampling) \nChain 3 Iteration: 3500 / 4000 [ 87%]  (Sampling) \nChain 3 Iteration: 3600 / 4000 [ 90%]  (Sampling) \nChain 3 Iteration: 3700 / 4000 [ 92%]  (Sampling) \nChain 3 Iteration: 3800 / 4000 [ 95%]  (Sampling) \nChain 3 Iteration: 3900 / 4000 [ 97%]  (Sampling) \nChain 3 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 3 finished in 0.3 seconds.\nChain 4 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 4000 [  2%]  (Warmup) \nChain 4 Iteration:  200 / 4000 [  5%]  (Warmup) \nChain 4 Iteration:  300 / 4000 [  7%]  (Warmup) \nChain 4 Iteration:  400 / 4000 [ 10%]  (Warmup) \nChain 4 Iteration:  500 / 4000 [ 12%]  (Warmup) \nChain 4 Iteration:  600 / 4000 [ 15%]  (Warmup) \nChain 4 Iteration:  700 / 4000 [ 17%]  (Warmup) \nChain 4 Iteration:  800 / 4000 [ 20%]  (Warmup) \nChain 4 Iteration:  900 / 4000 [ 22%]  (Warmup) \nChain 4 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 4 Iteration: 1100 / 4000 [ 27%]  (Warmup) \nChain 4 Iteration: 1200 / 4000 [ 30%]  (Warmup) \nChain 4 Iteration: 1300 / 4000 [ 32%]  (Warmup) \nChain 4 Iteration: 1400 / 4000 [ 35%]  (Warmup) \nChain 4 Iteration: 1500 / 4000 [ 37%]  (Warmup) \nChain 4 Iteration: 1600 / 4000 [ 40%]  (Warmup) \nChain 4 Iteration: 1700 / 4000 [ 42%]  (Warmup) \nChain 4 Iteration: 1800 / 4000 [ 45%]  (Warmup) \nChain 4 Iteration: 1900 / 4000 [ 47%]  (Warmup) \nChain 4 Iteration: 2000 / 4000 [ 50%]  (Warmup) \nChain 4 Iteration: 2001 / 4000 [ 50%]  (Sampling) \nChain 4 Iteration: 2100 / 4000 [ 52%]  (Sampling) \nChain 4 Iteration: 2200 / 4000 [ 55%]  (Sampling) \nChain 4 Iteration: 2300 / 4000 [ 57%]  (Sampling) \nChain 4 Iteration: 2400 / 4000 [ 60%]  (Sampling) \nChain 4 Iteration: 2500 / 4000 [ 62%]  (Sampling) \nChain 4 Iteration: 2600 / 4000 [ 65%]  (Sampling) \nChain 4 Iteration: 2700 / 4000 [ 67%]  (Sampling) \nChain 4 Iteration: 2800 / 4000 [ 70%]  (Sampling) \nChain 4 Iteration: 2900 / 4000 [ 72%]  (Sampling) \nChain 4 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 4 Iteration: 3100 / 4000 [ 77%]  (Sampling) \nChain 4 Iteration: 3200 / 4000 [ 80%]  (Sampling) \nChain 4 Iteration: 3300 / 4000 [ 82%]  (Sampling) \nChain 4 Iteration: 3400 / 4000 [ 85%]  (Sampling) \nChain 4 Iteration: 3500 / 4000 [ 87%]  (Sampling) \nChain 4 Iteration: 3600 / 4000 [ 90%]  (Sampling) \nChain 4 Iteration: 3700 / 4000 [ 92%]  (Sampling) \nChain 4 Iteration: 3800 / 4000 [ 95%]  (Sampling) \nChain 4 Iteration: 3900 / 4000 [ 97%]  (Sampling) \nChain 4 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 4 finished in 0.3 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.3 seconds.\nTotal execution time: 1.4 seconds.",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Multiple Predictors</span>"
    ]
  },
  {
    "objectID": "06b-multiple-predictors.html#centering",
    "href": "06b-multiple-predictors.html#centering",
    "title": "9  Multiple Predictors",
    "section": "\n9.6 Centering",
    "text": "9.6 Centering\nIn the previous model, \\(\\beta_1\\) is the slope of M → D when A is 0 (i.e., median marriage age = 0), and \\(\\beta_2\\) is the slope of A → D when M is 0 (i.e., marriage rate is 0). These two are not very meaningful. Therefore, it is common to make the zero values more meaningful by doing centering.\nHere, I use M - 2 as the predictor, so the zero point means a marriage rate of 2 per 10 adults; I use A - 2.5 as the other predictor, so the zero point means a median marriage rate of 25 years old.\n\\[\n\\mu_i = \\beta_0 + \\beta_1 (M_i - 2) + \\beta_2 (A_i - 2.5) + \\beta_3 (M_i - 2) \\times (A_i - 2.5)\n\\]\n\n# Use default priors (just for convenience here)\nm_inter2c &lt;- brm(Divorce ~ I(Marriage - 2) * I(MedianAgeMarriage - 2.5),\n    data = waffle_divorce,\n    seed = 941,\n    iter = 4000,\n    file = \"m_inter2c\"\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 4000 [  2%]  (Warmup) \nChain 1 Iteration:  200 / 4000 [  5%]  (Warmup) \nChain 1 Iteration:  300 / 4000 [  7%]  (Warmup) \nChain 1 Iteration:  400 / 4000 [ 10%]  (Warmup) \nChain 1 Iteration:  500 / 4000 [ 12%]  (Warmup) \nChain 1 Iteration:  600 / 4000 [ 15%]  (Warmup) \nChain 1 Iteration:  700 / 4000 [ 17%]  (Warmup) \nChain 1 Iteration:  800 / 4000 [ 20%]  (Warmup) \nChain 1 Iteration:  900 / 4000 [ 22%]  (Warmup) \nChain 1 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 1 Iteration: 1100 / 4000 [ 27%]  (Warmup) \nChain 1 Iteration: 1200 / 4000 [ 30%]  (Warmup) \nChain 1 Iteration: 1300 / 4000 [ 32%]  (Warmup) \nChain 1 Iteration: 1400 / 4000 [ 35%]  (Warmup) \nChain 1 Iteration: 1500 / 4000 [ 37%]  (Warmup) \nChain 1 Iteration: 1600 / 4000 [ 40%]  (Warmup) \nChain 1 Iteration: 1700 / 4000 [ 42%]  (Warmup) \nChain 1 Iteration: 1800 / 4000 [ 45%]  (Warmup) \nChain 1 Iteration: 1900 / 4000 [ 47%]  (Warmup) \nChain 1 Iteration: 2000 / 4000 [ 50%]  (Warmup) \nChain 1 Iteration: 2001 / 4000 [ 50%]  (Sampling) \nChain 1 Iteration: 2100 / 4000 [ 52%]  (Sampling) \nChain 1 Iteration: 2200 / 4000 [ 55%]  (Sampling) \nChain 1 Iteration: 2300 / 4000 [ 57%]  (Sampling) \nChain 1 Iteration: 2400 / 4000 [ 60%]  (Sampling) \nChain 1 Iteration: 2500 / 4000 [ 62%]  (Sampling) \nChain 1 Iteration: 2600 / 4000 [ 65%]  (Sampling) \nChain 1 Iteration: 2700 / 4000 [ 67%]  (Sampling) \nChain 1 Iteration: 2800 / 4000 [ 70%]  (Sampling) \nChain 1 Iteration: 2900 / 4000 [ 72%]  (Sampling) \nChain 1 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 1 Iteration: 3100 / 4000 [ 77%]  (Sampling) \nChain 1 Iteration: 3200 / 4000 [ 80%]  (Sampling) \nChain 1 Iteration: 3300 / 4000 [ 82%]  (Sampling) \nChain 1 Iteration: 3400 / 4000 [ 85%]  (Sampling) \nChain 1 Iteration: 3500 / 4000 [ 87%]  (Sampling) \nChain 1 Iteration: 3600 / 4000 [ 90%]  (Sampling) \nChain 1 Iteration: 3700 / 4000 [ 92%]  (Sampling) \nChain 1 Iteration: 3800 / 4000 [ 95%]  (Sampling) \nChain 1 Iteration: 3900 / 4000 [ 97%]  (Sampling) \nChain 1 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 4000 [  2%]  (Warmup) \nChain 2 Iteration:  200 / 4000 [  5%]  (Warmup) \nChain 2 Iteration:  300 / 4000 [  7%]  (Warmup) \nChain 2 Iteration:  400 / 4000 [ 10%]  (Warmup) \nChain 2 Iteration:  500 / 4000 [ 12%]  (Warmup) \nChain 2 Iteration:  600 / 4000 [ 15%]  (Warmup) \nChain 2 Iteration:  700 / 4000 [ 17%]  (Warmup) \nChain 2 Iteration:  800 / 4000 [ 20%]  (Warmup) \nChain 2 Iteration:  900 / 4000 [ 22%]  (Warmup) \nChain 2 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 2 Iteration: 1100 / 4000 [ 27%]  (Warmup) \nChain 2 Iteration: 1200 / 4000 [ 30%]  (Warmup) \nChain 2 Iteration: 1300 / 4000 [ 32%]  (Warmup) \nChain 2 Iteration: 1400 / 4000 [ 35%]  (Warmup) \nChain 2 Iteration: 1500 / 4000 [ 37%]  (Warmup) \nChain 2 Iteration: 1600 / 4000 [ 40%]  (Warmup) \nChain 2 Iteration: 1700 / 4000 [ 42%]  (Warmup) \nChain 2 Iteration: 1800 / 4000 [ 45%]  (Warmup) \nChain 2 Iteration: 1900 / 4000 [ 47%]  (Warmup) \nChain 2 Iteration: 2000 / 4000 [ 50%]  (Warmup) \nChain 2 Iteration: 2001 / 4000 [ 50%]  (Sampling) \nChain 2 Iteration: 2100 / 4000 [ 52%]  (Sampling) \nChain 2 Iteration: 2200 / 4000 [ 55%]  (Sampling) \nChain 2 Iteration: 2300 / 4000 [ 57%]  (Sampling) \nChain 2 Iteration: 2400 / 4000 [ 60%]  (Sampling) \nChain 2 Iteration: 2500 / 4000 [ 62%]  (Sampling) \nChain 2 Iteration: 2600 / 4000 [ 65%]  (Sampling) \nChain 2 Iteration: 2700 / 4000 [ 67%]  (Sampling) \nChain 2 Iteration: 2800 / 4000 [ 70%]  (Sampling) \nChain 2 Iteration: 2900 / 4000 [ 72%]  (Sampling) \nChain 2 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 2 Iteration: 3100 / 4000 [ 77%]  (Sampling) \nChain 2 Iteration: 3200 / 4000 [ 80%]  (Sampling) \nChain 2 Iteration: 3300 / 4000 [ 82%]  (Sampling) \nChain 2 Iteration: 3400 / 4000 [ 85%]  (Sampling) \nChain 2 Iteration: 3500 / 4000 [ 87%]  (Sampling) \nChain 2 Iteration: 3600 / 4000 [ 90%]  (Sampling) \nChain 2 Iteration: 3700 / 4000 [ 92%]  (Sampling) \nChain 2 Iteration: 3800 / 4000 [ 95%]  (Sampling) \nChain 2 Iteration: 3900 / 4000 [ 97%]  (Sampling) \nChain 2 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 4000 [  2%]  (Warmup) \nChain 3 Iteration:  200 / 4000 [  5%]  (Warmup) \nChain 3 Iteration:  300 / 4000 [  7%]  (Warmup) \nChain 3 Iteration:  400 / 4000 [ 10%]  (Warmup) \nChain 3 Iteration:  500 / 4000 [ 12%]  (Warmup) \nChain 3 Iteration:  600 / 4000 [ 15%]  (Warmup) \nChain 3 Iteration:  700 / 4000 [ 17%]  (Warmup) \nChain 3 Iteration:  800 / 4000 [ 20%]  (Warmup) \nChain 3 Iteration:  900 / 4000 [ 22%]  (Warmup) \nChain 3 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 3 Iteration: 1100 / 4000 [ 27%]  (Warmup) \nChain 3 Iteration: 1200 / 4000 [ 30%]  (Warmup) \nChain 3 Iteration: 1300 / 4000 [ 32%]  (Warmup) \nChain 3 Iteration: 1400 / 4000 [ 35%]  (Warmup) \nChain 3 Iteration: 1500 / 4000 [ 37%]  (Warmup) \nChain 3 Iteration: 1600 / 4000 [ 40%]  (Warmup) \nChain 3 Iteration: 1700 / 4000 [ 42%]  (Warmup) \nChain 3 Iteration: 1800 / 4000 [ 45%]  (Warmup) \nChain 3 Iteration: 1900 / 4000 [ 47%]  (Warmup) \nChain 3 Iteration: 2000 / 4000 [ 50%]  (Warmup) \nChain 3 Iteration: 2001 / 4000 [ 50%]  (Sampling) \nChain 3 Iteration: 2100 / 4000 [ 52%]  (Sampling) \nChain 3 Iteration: 2200 / 4000 [ 55%]  (Sampling) \nChain 3 Iteration: 2300 / 4000 [ 57%]  (Sampling) \nChain 3 Iteration: 2400 / 4000 [ 60%]  (Sampling) \nChain 3 Iteration: 2500 / 4000 [ 62%]  (Sampling) \nChain 3 Iteration: 2600 / 4000 [ 65%]  (Sampling) \nChain 3 Iteration: 2700 / 4000 [ 67%]  (Sampling) \nChain 3 Iteration: 2800 / 4000 [ 70%]  (Sampling) \nChain 3 Iteration: 2900 / 4000 [ 72%]  (Sampling) \nChain 3 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 3 Iteration: 3100 / 4000 [ 77%]  (Sampling) \nChain 3 Iteration: 3200 / 4000 [ 80%]  (Sampling) \nChain 3 Iteration: 3300 / 4000 [ 82%]  (Sampling) \nChain 3 Iteration: 3400 / 4000 [ 85%]  (Sampling) \nChain 3 Iteration: 3500 / 4000 [ 87%]  (Sampling) \nChain 3 Iteration: 3600 / 4000 [ 90%]  (Sampling) \nChain 3 Iteration: 3700 / 4000 [ 92%]  (Sampling) \nChain 3 Iteration: 3800 / 4000 [ 95%]  (Sampling) \nChain 3 Iteration: 3900 / 4000 [ 97%]  (Sampling) \nChain 3 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 3 finished in 0.1 seconds.\nChain 4 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 4000 [  2%]  (Warmup) \nChain 4 Iteration:  200 / 4000 [  5%]  (Warmup) \nChain 4 Iteration:  300 / 4000 [  7%]  (Warmup) \nChain 4 Iteration:  400 / 4000 [ 10%]  (Warmup) \nChain 4 Iteration:  500 / 4000 [ 12%]  (Warmup) \nChain 4 Iteration:  600 / 4000 [ 15%]  (Warmup) \nChain 4 Iteration:  700 / 4000 [ 17%]  (Warmup) \nChain 4 Iteration:  800 / 4000 [ 20%]  (Warmup) \nChain 4 Iteration:  900 / 4000 [ 22%]  (Warmup) \nChain 4 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 4 Iteration: 1100 / 4000 [ 27%]  (Warmup) \nChain 4 Iteration: 1200 / 4000 [ 30%]  (Warmup) \nChain 4 Iteration: 1300 / 4000 [ 32%]  (Warmup) \nChain 4 Iteration: 1400 / 4000 [ 35%]  (Warmup) \nChain 4 Iteration: 1500 / 4000 [ 37%]  (Warmup) \nChain 4 Iteration: 1600 / 4000 [ 40%]  (Warmup) \nChain 4 Iteration: 1700 / 4000 [ 42%]  (Warmup) \nChain 4 Iteration: 1800 / 4000 [ 45%]  (Warmup) \nChain 4 Iteration: 1900 / 4000 [ 47%]  (Warmup) \nChain 4 Iteration: 2000 / 4000 [ 50%]  (Warmup) \nChain 4 Iteration: 2001 / 4000 [ 50%]  (Sampling) \nChain 4 Iteration: 2100 / 4000 [ 52%]  (Sampling) \nChain 4 Iteration: 2200 / 4000 [ 55%]  (Sampling) \nChain 4 Iteration: 2300 / 4000 [ 57%]  (Sampling) \nChain 4 Iteration: 2400 / 4000 [ 60%]  (Sampling) \nChain 4 Iteration: 2500 / 4000 [ 62%]  (Sampling) \nChain 4 Iteration: 2600 / 4000 [ 65%]  (Sampling) \nChain 4 Iteration: 2700 / 4000 [ 67%]  (Sampling) \nChain 4 Iteration: 2800 / 4000 [ 70%]  (Sampling) \nChain 4 Iteration: 2900 / 4000 [ 72%]  (Sampling) \nChain 4 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 4 Iteration: 3100 / 4000 [ 77%]  (Sampling) \nChain 4 Iteration: 3200 / 4000 [ 80%]  (Sampling) \nChain 4 Iteration: 3300 / 4000 [ 82%]  (Sampling) \nChain 4 Iteration: 3400 / 4000 [ 85%]  (Sampling) \nChain 4 Iteration: 3500 / 4000 [ 87%]  (Sampling) \nChain 4 Iteration: 3600 / 4000 [ 90%]  (Sampling) \nChain 4 Iteration: 3700 / 4000 [ 92%]  (Sampling) \nChain 4 Iteration: 3800 / 4000 [ 95%]  (Sampling) \nChain 4 Iteration: 3900 / 4000 [ 97%]  (Sampling) \nChain 4 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 4 finished in 0.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.6 seconds.\n\n\n\nmsummary(list(`No centering` = m_inter2, `centered` = m_inter2c),\n         estimate = \"{estimate} [{conf.low}, {conf.high}]\",\n         statistic = NULL, fmt = 2)\n\n\n\n\nNo centering\ncentered\n\n\n\nb_Intercept\n7.38 [3.02, 11.58]\n1.09 [1.02, 1.16]\n\n\nb_Marriage\n−1.93 [−4.00, 0.16]\n\n\n\nb_MedianAgeMarriage\n−2.45 [−4.07, −0.78]\n\n\n\nb_Marriage × MedianAgeMarriage\n0.74 [−0.07, 1.56]\n\n\n\nsigma\n0.15 [0.12, 0.18]\n0.15 [0.12, 0.18]\n\n\nb_IMarriageM2\n\n−0.08 [−0.24, 0.09]\n\n\nb_IMedianAgeMarriageM2.5\n\n−0.94 [−1.44, −0.44]\n\n\nb_IMarriageM2 × IMedianAgeMarriageM2.5\n\n0.75 [−0.08, 1.59]\n\n\nNum.Obs.\n50\n50\n\n\nR2\n0.414\n0.413\n\n\nR2 Adj.\n0.280\n0.267\n\n\nELPD\n21.5\n21.2\n\n\nELPD s.e.\n6.1\n6.2\n\n\nLOOIC\n−42.9\n−42.5\n\n\nLOOIC s.e.\n12.2\n12.5\n\n\nWAIC\n−43.5\n−43.1\n\n\nRMSE\n0.14\n0.14\n\n\n\n\n\nAs shown in the table above, while the two models are equivalent in fit and give the same posterior distribution for \\(\\beta_3\\), they differ in \\(\\beta_0\\), \\(\\beta_1\\), and \\(\\beta_2\\).\n\nplot(\n    conditional_effects(m_inter2c,\n        effects = \"Marriage:MedianAgeMarriage\",\n        int_conditions = list(MedianAgeMarriage = c(2.3, 2.5, 2.7)),\n    ),\n    points = TRUE\n)\n\n\n\n\n\n\nFigure 9.7: Model-implied simple slopes of marriage for different levels of median age of marriage.\n\n\n\n\n\n\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: a Bayesian course with examples in R and Stan (Second edition). CRC Press.",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Multiple Predictors</span>"
    ]
  },
  {
    "objectID": "06c-regression-diagnostics.html",
    "href": "06c-regression-diagnostics.html",
    "title": "\n10  Model Diagnostics\n",
    "section": "",
    "text": "10.1 Assumptions of Linear Models\nAll statistical models are sets of assumptions about the data-generating process, and estimation will be meaningless or misleading if these assumptions do not hold for the data. As we have discussed, choosing a good model is generally more important than choosing a good prior. In this note, we will learn some tools to check the validity of linear models. Most of them are similar to what you have learned in frequentist regression.\nThe assumptions of the linear model is encoded in the model. The model is\n\\[\n\\begin{aligned}\n  Y_i & \\sim N(\\mu_i, \\sigma)  \\\\\n  \\mu_i & = \\beta_0 + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\ldots\n\\end{aligned}\n\\]\nFrom the model, we have the following assumptions, in the order of the most important one to the least important one:",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Model Diagnostics</span>"
    ]
  },
  {
    "objectID": "06c-regression-diagnostics.html#assumptions-of-linear-models",
    "href": "06c-regression-diagnostics.html#assumptions-of-linear-models",
    "title": "\n10  Model Diagnostics\n",
    "section": "",
    "text": "Correct specification of the model. This means that all relevant predictors for \\(Y\\) have been included in the model. This is probably an assumption that is never satisfied in real data analysis, as one can never include all relevant factors that can have an impact on \\(Y\\), be it small or large. However, it is important to be thoughtful to include major predictors that have been shown to relate to \\(Y\\). Leaving out key predictors can bias the coefficients \\(\\beta\\).\n\nLinearity. This is about the conditional mean, \\(\\mu = E(Y | X_1, X_2, \\ldots)\\), being a linear function. If you have a function like \\(\\mu = \\exp[\\beta_1 X_1 \\sin (\\beta_2 X_2)]\\), the conditional mean is not a linear function. Note that linearity does not require \\(\\mu\\) to be a linear function of predictors; quadratic and exponential relationships, interaction, and polynomials can all be handled by linear models. (And technically, linearity requires \\(\\mu\\) to be a linear function of the coefficients.)\n\nIndependent observations. This assumption is not directly encoded in the model equation above, mainly because I omit that part when writing out the model. This assumption requires that the value of one observation is independent of the value of another observation after taking into account the conditional mean, \\(\\mu\\). This will be discussed more in multilevel models.\n\nEqual variance of errors. This means that \\(\\sigma^2\\) has to be constant for each observation. In general, Violating this assumption is generally a minor issue, although it can affect the posterior standard deviation (analogous to standard errors).\n\nNormality. This requires that the conditional distribution of \\(Y\\) is normal. Violating of the normality assumption generally does not affect the estimation of the coefficients, and will be a minor issue when the sample size is large enough (&gt; 30) and when the degree of nonnormality is small to moderate.",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Model Diagnostics</span>"
    ]
  },
  {
    "objectID": "06c-regression-diagnostics.html#diagnostic-tools",
    "href": "06c-regression-diagnostics.html#diagnostic-tools",
    "title": "\n10  Model Diagnostics\n",
    "section": "\n10.2 Diagnostic Tools",
    "text": "10.2 Diagnostic Tools\nNow let’s review some tools for regression diagnostics for Bayesian regression. There are hundreds of plots available that I will not cover here, and you can treat what is discussed in this note as a minimal requirement for regression diagnostics. The first one is about a correct specification of the model, which can be partly assessed with posterior predictive check.\n\n10.2.1 Posterior Predictive Check\nWe’ve already seen a few examples of posterior predictive checks in the previous chapters. Continuing with the example of predicting the divorce rate, here are a few more plots.\nBelow is the posterior predictive graphical check for the interaction model we fit for the state-level divorce rate data:\n\n\n\n\n\n\n\n\n\n\n(a) Density overlayed plots\n\n\n\n\n\n\n\n\n\n(b) Prediction intervals\n\n\n\n\n\nFigure 10.1: Posterior predictive checks for the interaction model.\n\n\n\n\nBased on the graphical check, we do not see any major systematic discrepancies between the distribution of our data and what can be predicted from our model. The ribbon plot shows that some points are outside the 90% predictive intervals but not too far off.\nWe should do the posterior predictive check with test statistics too. The following functions show the mean, maximum value, and minimum value of the outcome.\n\n# PPC for the mean (it should always fit)\npp_check(m_inter, type = \"stat_grouped\", stat = \"mean\", group = \"South\")\n\nUsing all posterior draws for ppc type 'stat_grouped' by default.\n\n\nLoading required package: rstan\n\n\nLoading required package: StanHeaders\n\n\n\nrstan version 2.32.5 (Stan version 2.32.2)\n\n\nFor execution on a local, multicore CPU with excess RAM we recommend calling\noptions(mc.cores = parallel::detectCores()).\nTo avoid recompilation of unchanged Stan programs, we recommend calling\nrstan_options(auto_write = TRUE)\nFor within-chain threading using `reduce_sum()` or `map_rect()` Stan functions,\nchange `threads_per_chain` option:\nrstan_options(threads_per_chain = 1)\n\n\n\nAttaching package: 'rstan'\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nFigure 10.2: Posterior predictive check for the sample mean.\n\n\n\n\n\n# PPC for the mean (it should always fit)\n# PPC for the maximum and minimum values\npp_check(m_inter, type = \"stat_2d\", stat = c(\"max\", \"min\"))\n\nUsing all posterior draws for ppc type 'stat_2d' by default.\n\n\n\n\n\n\n\nFigure 10.3: Posterior predictive check for the sample maximum and minimum.\n\n\n\n\n\n10.2.2 Marginal model plots\nTo check the linearity assumption, we need to ensure that the conditional mean of \\(Y\\) fits according to the model. A marginal model plot compares the model predicted relationship between the outcome and each predictor, and the relationship obtained using nonparametric methods with smoothing.\n\npp_check(m_inter, type = \"intervals_grouped\",\n         x = \"MedianAgeMarriage\", group = \"South\") +\n    geom_smooth(se = FALSE, col = \"blue\") +\n    geom_smooth(aes(y = y_obs), se = FALSE, col = \"red\", linetype = \"dashed\")\n\nUsing all posterior draws for ppc type 'intervals_grouped' by default.\n\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: The following aesthetics were dropped during statistical transformation: ymin,\nymax\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\nThe following aesthetics were dropped during statistical transformation: ymin,\nymax\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: The following aesthetics were dropped during statistical transformation: ymin,\nymax\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\nThe following aesthetics were dropped during statistical transformation: ymin,\nymax\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n# Alternative code\n# plot(\n#     conditional_effects(m_inter,\n#         effects = \"MedianAgeMarriage\",\n#         conditions = data.frame(South = c(\"south\", \"non-south\"),\n#                                 cond__ = c(\"South\", \"Non-South\"))\n#     ),\n#     plot = FALSE\n# )[[1]] +\n#     # Add data points\n#     geom_point(\n#         data = m_inter$data,\n#         aes(x = MedianAgeMarriage, y = Divorce),\n#         inherit.aes = FALSE\n#     ) +\n#     # Add smoother\n#     geom_smooth(\n#         data = m_inter$data,\n#         aes(x = MedianAgeMarriage, y = Divorce),\n#         col = \"red\", linetype = \"dashed\",\n#         inherit.aes = FALSE,\n#         se = FALSE) +\n#     facet_wrap(~ South)\n\n\n\n\n\n\nFigure 10.4: Marginal model plots with the model-implied (blue solid) and the nonparametric (red dashed) smoother.\n\n\n\n\nMarginal model plots are more appropriate for ordinal or continuous predictors. As you can see above, the red line (for nonparametric fit) and the blue line (from the linear model) fit the data well, but not for the left tail area, where some of the non-Southern states have lower divorce rates than predicted. If the linearity assumption holds, these two lines should be very similar. Generally speaking, deviations in the middle indicate a strong misspecification that needs to be fixed.\nAlso, we want to check outliers that lie way outside the predictive interval. With a 95% predictive interval, we generally expect 5% to lie outside of the predictive interval band. In this example, we don’t see a great problem with outliers.\n\n10.2.2.1 LOO PIT plots\nHere’s a check using probability integral transform. Roughly speaking, you can think of it as a flattened version of the marginal model plots, where you’d like to see the darkened line be relatively flat and within the range of the model prediction.\n\npp_check(m_inter, type = \"loo_pit_overlay\")\n\nUsing all posterior draws for ppc type 'loo_pit_overlay' by default.\n\n\nNOTE: The kernel density estimate assumes continuous observations and is not optimal for discrete observations.\n\n\n\n\n\n\n\n\n\n10.2.3 Residual plots\nFor regression analyses, one can learn a lot about model fit from the residuals, which is \\(y_i - \\tilde{y}_i | \\theta\\), i.e., subtracting the observed \\(y_i\\) values by the posterior predictions. Because in Bayesian, there is not just one predicted value, but a whole predictive distribution, one also has an entire posterior distribution for each residual. Figure 10.5 is a check of the average residual \\(Y\\) (i.e., \\(Y\\) - \\(\\hat Y\\)) and the true value of \\(Y\\). If the model fit the data well, the points should be scattered with no specific pattern, like in Figure 10.5.\n\n\n\n\n\n\n\n\nFigure 10.5: Average prediction error against the predictor. No clear pattern should be observed for a correctly specified model.\n\n\n\n\n\nNo big problem was found in the residuals. If you see that the SD of the residuals is not uniform, or the residuals have some non-linear relationships with the predictor, there can be some problems.\n\n10.2.4 Multicollinearity\nStrictly speaking, multicollinearity is not an assumption of regression. However, especially in frequentist analysis, having predictors that are strongly correlated can increase the uncertainty of the posterior distributions of the regression coefficients. On the other hand, the use of the prior distribution in Bayesian analyses can somewhat come to the rescue, as it makes it less likely for the posteriors to have extremely large posterior mean and standard deviation    \nYou can look at the posterior density of the coefficients to see how correlated they are:\n\npairs(m_inter,\n    variable = \"^b\",  # for all variables starting with b\n    regex = TRUE,\n    off_diag_args = # arguments of the scatterplots\n        list(\n            size = 0.5, # point size\n            alpha = 0.25 # transparency\n        )\n)\n\n\n\n\n\n\n\nIf some coefficients are particularly strongly correlated, you may need to think about using a stronger prior or combining some predictors. In this case, the collinearity is a result of the interactions. Principal component and factor analysis are some approaches for that.",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Model Diagnostics</span>"
    ]
  },
  {
    "objectID": "06c-regression-diagnostics.html#other-topics",
    "href": "06c-regression-diagnostics.html#other-topics",
    "title": "\n10  Model Diagnostics\n",
    "section": "\n10.3 Other Topics",
    "text": "10.3 Other Topics\nThere are other topics we have yet to discuss here for diagnostics of multiple regression, but are just as important, including:\n\nTransformation (e.g., logarithm transformation with skewed outcomes and predictors, like income);\nLeverage points and influential observations (e.g., hat values, Cook’s \\(D\\))\nMeasurement error of predictors",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Model Diagnostics</span>"
    ]
  },
  {
    "objectID": "07-model-comparison.html",
    "href": "07-model-comparison.html",
    "title": "\n11  Model Comparison\n",
    "section": "",
    "text": "11.1 Overfitting and Underfitting\nIn statistical modeling, a more complex model almost always results in a better fit to the data. Roughly speaking, a more complex model means a model with more parameters. However, as you will see later, determining the number of parameters in Bayesian analyses is not straightforward. On the extreme side, if one has 10 observations, a model with 10 parameters will perfectly predict every single data point (by just having a parameter to predict each data point). However, there are two problems with too complex a model. First, an increasingly complex model makes it increasingly hard to extract useful information from the data. Instead of describing the relationship between two variables, like Marriage and Divorce, by a straight line, one ends up with a crazy model that is difficult to make sense of. Second, as you will also see, the more complex a model, the more is the risk that it overfits the current data, such that it does not work for future observations.\nFor example, let’s randomly sample 10 states in the waffle_divorce data set and build some models.\nwaffle_divorce &lt;- read_delim(  # read delimited files\n    \"data/WaffleDivorce.csv\",\n    delim = \";\"\n)\n\nRows: 50 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr  (2): Location, Loc\ndbl (11): Population, MedianAgeMarriage, Marriage, Marriage SE, Divorce, Div...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Rescale Marriage and Divorce by dividing by 10\nwaffle_divorce$Marriage &lt;- waffle_divorce$Marriage / 10\nwaffle_divorce$Divorce &lt;- waffle_divorce$Divorce / 10\nwaffle_divorce$MedianAgeMarriage &lt;- waffle_divorce$MedianAgeMarriage / 10\n# Recode `South` to a factor variable\nwaffle_divorce$South &lt;- factor(waffle_divorce$South,\n    levels = c(0, 1),\n    labels = c(\"non-south\", \"south\")\n)\nset.seed(1547)  # set the seed for reproducibility\n# Sample 10 observations\ntrain &lt;- sample.int(nrow(waffle_divorce), 10L)\nwd_sub &lt;- waffle_divorce[train, ]\nbase &lt;- ggplot(aes(x = Marriage, y = Divorce),\n               data = wd_sub) +\n    geom_point() +\n    coord_cartesian(ylim = c(0.6, 1.4)) +\n    xlim(range(waffle_divorce$Marriage))\nggplot(waffle_divorce,\n       aes(x = Marriage, y = Divorce)) + \n    geom_point(col = \"lightblue\") +\n    geom_point(size = 1.5, data = wd_sub, col = \"red\") +\n    coord_cartesian(ylim = c(0.6, 1.4)) +\n    xlim(range(waffle_divorce$Marriage))\nWhen using Marriage to predict Divorce, we can use beyond a linear regression line by using higher-order polynomials. For example, a second-order polynomial represents a quadratic effect (with one turning point); it goes to cubic, quartic, and more. The figure below shows the fit from a linear effect of Marriage, a quadratic effect, and increasingly complex models up to a sixth-degree polynomial. As you can see, as the model gets more complex, the fitted line tries to capture all the 10 points really well, with an increasing \\(R^2\\). However, the standard error around the fitted line also gets larger and bizarre, meaning more uncertainty in the model parameters.\nCoder2 &lt;- function(object, newresp, newdata) {\n    # Function for computing R^2\n    ypred &lt;- predict(object, newdata = newdata)\n    cor(ypred, newresp)^2\n}\nrmse &lt;- function(object, newresp, newdata) {\n    # Function for RMSE\n    ypred &lt;- predict(object, newdata = newdata)\n    sqrt(mean((ypred - newresp)^2))\n}\n# Create six plots through a loop\np_list &lt;- map(1:6, function(i) {\n    # Use frequentist analyses for speed\n    mod &lt;- lm(Divorce ~ poly(Marriage, degree = i), data = wd_sub)\n    base +\n        geom_smooth(method = \"lm\", formula = y ~ poly(x, i), level = .80,\n                    fullrange = TRUE) +\n        annotate(\"text\", x = 1.7, y = 1.4,\n                 label = paste0(\"italic(R)^2 == \",\n                                round(r2(mod, wd_sub$Divorce), 2)),\n                 parse = TRUE) +\n        annotate(\"text\", x = 1.7, y = 1.2,\n                 label = paste0(\"RMSE == \",\n                                round(rmse(mod, wd_sub$Divorce), 2)),\n                 parse = TRUE)\n})\ndo.call(grid.arrange, c(p_list, nrow = 2))\n\n\n\n\n\n\nFigure 11.1: Fit of models on the 10 random cases. Top panel: linear, quadratic, and cubic; bottom panel: 4th, 5th, and 6th degree polynomials\nAnother way to look at model accuracy is the Root Mean Squared Error (RMSE), defined as the square root of the average squared prediction error. RMSE is a measure of prediction error. The smaller the RMSE, the better the prediction is. As you can see in the above figure, more complex models always reduce the RMSE in the data we use to fit the model (also called training data).\nHowever, if I take the estimated regression line/curve based on the subsample of 10 observations, and predict the remaining cases in the data set, things will be different. As you can see in the figure below, whereas prediction error is comparable for the linear and the quadratic model, polynomials of higher degrees predict the data really badly. When you use a complex model in a data set, it tailors the coefficients to any sampling errors and noise in the data such that it will not generalize to new observations. Therefore, our goal in model comparison is to choose a model complex enough to capture the essence of the data generation process (and thus avoid underfitting), but not too complex such that it suffers from overfitting.\nCodebase2 &lt;- ggplot(aes(x = Marriage, y = Divorce),\n               data = waffle_divorce[-train, ]) +\n    geom_point() +\n    coord_cartesian(ylim = c(0.6, 1.4)) +\n    xlim(range(waffle_divorce$Marriage))\n# Create six plots through a loop\np_list2 &lt;- map(1:6, function(i) {\n    # Use frequentist analyses for speed\n    mod &lt;- lm(Divorce ~ poly(Marriage, degree = i), data = wd_sub)\n    # New data and response\n    test_dat &lt;- waffle_divorce[-train, ]\n    ynew &lt;- test_dat$Divorce\n    base2 +\n        geom_smooth(data = wd_sub, method = \"lm\", formula = y ~ poly(x, i),\n                    level = .80, fullrange = TRUE) +\n        annotate(\"text\", x = 1.7, y = 1.4,\n                 label = paste0(\"italic(R)^2 == \",\n                                round(r2(mod, ynew, test_dat), 2)),\n                 parse = TRUE) +\n        annotate(\"text\", x = 1.7, y = 1.2,\n                 label = paste0(\"RMSE == \",\n                                round(rmse(mod, ynew, test_dat), 2)),\n                 parse = TRUE)\n})\ndo.call(grid.arrange, c(p_list2, nrow = 2))\n\n\n\n\n\n\nFigure 11.2: Using the regression lines based on 10 random cases to predict the remaining 40 cases. Top panel: linear, quadratic, and cubic; bottom panel: 4th, 5th, and 6th degree polynomials\nThe goal of statistical modeling is to choose an optimal model between the overfitting/underfitting dichotomy. In machine learning, this is also commonly referred to as the bias-variance trade-off, as a model that is too simple tends to produce biased predictions because it does not capture the essence of the data generating process. In contrast, a overly complex model is unbiased but results in a lot of uncertainty in the prediction because there are too many unnecessary components that can affect predictions, as indicated in the confidence bands around the 6th-degree polynomial line.\nPolynomials of varying degrees are merely one example of comparing simple to complex models. You can think about:\nWhereas one can always avoid underfitting by fitting a more and more complex model, we need tools to keep us from overfitting. This lecture is about finding an optimal model that avoids overfitting and avoids underfitting. You will learn to perform model comparisons with information criteria to find a model that has a better balance between overfitting and underfitting.",
    "crumbs": [
      "Week 7",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Model Comparison</span>"
    ]
  },
  {
    "objectID": "07-model-comparison.html#overfitting-and-underfitting",
    "href": "07-model-comparison.html#overfitting-and-underfitting",
    "title": "\n11  Model Comparison\n",
    "section": "",
    "text": "models with and without interactions,\nmodels with a few predictors versus hundreds of predictors,\nregression analyses versus multilevel models, etc.",
    "crumbs": [
      "Week 7",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Model Comparison</span>"
    ]
  },
  {
    "objectID": "07-model-comparison.html#kullback-leibler-divergence",
    "href": "07-model-comparison.html#kullback-leibler-divergence",
    "title": "\n11  Model Comparison\n",
    "section": "\n11.2 Kullback-Leibler Divergence",
    "text": "11.2 Kullback-Leibler Divergence\nWhen comparing models (e.g., linear vs. quadratic), we prefer models closer to the “true” data-generating process. To do so, we need some ways to quantify the degree of “closeness” to the true model. In this context, models comprise both the distributional family and the parameter values. For example, the model \\(y_i \\sim N(5, 2)\\) is a different model than \\(y_i \\sim N(3, 2)\\), which is a different model than \\(y_i \\sim \\mathrm{Gamma}(2, 2)\\). The first two have the same family but different parameter values (different means, same \\(\\mathit{SD}\\)). In contrast, the last two have different distributional families (Normal vs. Gamma).\nTo measure the degree of “closeness” between two models, \\(M_0\\) and \\(M_1\\), by far the most popular metric in statistics is the Kullback-Liebler Divergence (or Kullback-Liebler discrepancy; \\(D_\\textrm{KL}\\)). By definition,\n\\[\n\\begin{aligned}\nD_\\textrm{KL}(M_0 \\mid M_1) & = \\int_{-\\infty}^\\infty p_{M_0} (\\boldsymbol{\\mathbf{y}})\n                    \\log \\frac{p_{M_0}(\\boldsymbol{\\mathbf{y}})}{p_{M_1}(\\boldsymbol{\\mathbf{y}})} \\; \\mathrm{d}\\boldsymbol{\\mathbf{y}} \\\\\n                & = \\int_{-\\infty}^\\infty p_{M_0} (\\boldsymbol{\\mathbf{y}})\n                          \\log p_{M_0}(\\boldsymbol{\\mathbf{y}}) \\; \\mathrm{d}\\boldsymbol{\\mathbf{y}} -\n                    \\int_{-\\infty}^\\infty p_{M_0} (\\boldsymbol{\\mathbf{y}})\n                          \\log p_{M_1}(\\boldsymbol{\\mathbf{y}}) \\; \\mathrm{d}\\boldsymbol{\\mathbf{y}}.\n\\end{aligned}\n\\]\nNote that strictly speaking, \\(D_\\textrm{KL}\\) cannot be called a “distance” between two models because in general, \\(D_\\textrm{KL}(M_0 \\mid M_1) \\neq D_\\textrm{KL}(M_1 \\mid M_0)\\). As an example, assume that the data are generated by a true model \\(M_0\\), and we have two candidate models \\(M_1\\) and \\(M_2\\), where\n\n\\(M_0: y \\sim N(3, 2)\\)\n\\(M_1: y \\sim N(3.5, 2.5)\\)\n\\(M_2: y \\sim \\mathrm{Cauchy}(3, 2)\\)\n\n\nCodeggplot(data.frame(x = c(-3, 9)), aes(x = x)) +\n    stat_function(fun = dnorm, args = list(mean = 3, sd = 2),\n                  aes(col = \"M0\"), linewidth = 1) +\n    stat_function(fun = dnorm, args = list(mean = 3.5, sd = 2.5),\n                  aes(col = \"M1\"), linewidth = 2) +\n    stat_function(fun = dcauchy, args = list(location = 3, scale = 2),\n                  aes(col = \"M2\"), linewidth = 2) +\n    scale_color_manual(values = c(\"black\", \"red\", \"blue\"),\n                       labels = c(\"M0\", \"M1\", \"M2\")) +\n    labs(x = \"y\", y = \"density\", col = NULL)\n\n\n\n\n\n\nFigure 11.3: Density for \\(M_0\\), \\(M_1\\), and \\(M_2\\)\n\n\n\n\n\nf1 &lt;- function(x) {\n    dnorm(x, 3, 2) * (dnorm(x, 3, 2, log = TRUE) -\n        dnorm(x, 3.5, 2.5, log = TRUE))\n}\nf2 &lt;- function(x) {\n    dnorm(x, 3, 2) * (dnorm(x, 3, 2, log = TRUE) -\n        dcauchy(x, 3, 2, log = TRUE))\n}\n\nOne can compute that \\(D_\\textrm{KL}(M_0 \\mid M_1) = 0.0631436\\) and \\(D_\\textrm{KL}(M_0 \\mid M_1) = 0.2592445\\), and so \\(M_1\\) is a better model than \\(M_2\\).\nNote that in the expression of \\(D_\\textrm{KL}\\), when talking about the same target model, the first term is always the same and describes the “true” model, \\(M_0\\). Therefore, it is sufficient to compare models on the second term, \\(\\int_{-\\infty}^\\infty p_{M_0} (\\boldsymbol{\\mathbf{y}}) \\log p_{M_1}(\\boldsymbol{\\mathbf{y}}) \\; \\mathrm{d}\\boldsymbol{\\mathbf{y}}\\), which can also be written as \\(\\mathrm{E}=[\\log p_{M_1} (\\boldsymbol{\\mathbf{y}})]\\), i.e., the expected log predictive density (elpd). In other words, a model with a larger elpd is preferred over a model with a smaller elpd.\nHowever, we don’t know what \\(M_0\\) is in real data analysis. If we knew, then we would just need to choose \\(M_0\\) as our model, and there will be no need for model comparisons. In addition, even if we know that the true model is, e.g., a normal model (which never happens in real data analysis), we still need to estimate the parameter values, and the estimates will not be exactly the same as the true parameter values. However, elpd is defined as the expected value over the true predictive distribution, \\(p_{M_0}(y)\\), which cannot be obtained without knowing what \\(M_0\\) is.\nSo instead, we need to estimate the elpd. A naive way to estimate it is to use the data distribution in place of the true model, but that will lead to an overly optimistic estimate as the sample data are noisy. Computing elpd this way will always favor a more complex model. The ideal way is to collect data on a new, independent sample that share the same data generating process as the current sample, and estimate elpd on the new sample. This is called out-of-sample validation. The problem, of course, is that we usually do not have the resources to collect a new sample.\nTherefore, statisticians have worked hard to find ways to estimate elpd from the current sample, and there are two broad approaches:\n\nInformation criteria: AIC, DIC, and WAIC, which estimate the elpd in the current sample, minus a correction factor\nCross-validation, which splits the current sample into \\(K\\) parts, estimates the parameters in \\(K - 1\\) parts, and estimates the elpd in the remaining part. A special case is when \\(K\\) = \\(N\\), each time one uses \\(N\\) - 1 data points to estimate the model parameters, and estimate the elpd for the observation that was left out. This is called leave-one-out cross-validation (LOO-CV).",
    "crumbs": [
      "Week 7",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Model Comparison</span>"
    ]
  },
  {
    "objectID": "07-model-comparison.html#deviance",
    "href": "07-model-comparison.html#deviance",
    "title": "\n11  Model Comparison\n",
    "section": "\n11.3 Deviance",
    "text": "11.3 Deviance\nWithout going too deep into the underlying math, it can be shown that a good estimate of elpd is\n\\[\n\\sum_{i = 1}^n \\log p_{M_1}(y_i) - p,\n\\]\nwhere \\(p\\) is some measure of the number of parameters in \\(M_1\\). The first term is the likelihood of the model in the current sample. The second term is an adjustment factor so that the quantity above represents the average likelihood of the model in a new sample. It is more common to work with deviance by multiplying the log-likelihood by \\(-2\\), i.e.,\n\\[\nD = -2 \\sum_{i = 1}^n \\log p_{M_1}(y_i).\n\\]\n\n11.3.1 Experiment on Deviance\nNow, let’s check the in-sample deviance and out-of-sample deviance of our waffle_divorce data with different polynomial functions. Here is a sample function for computing elpd (with frequentist, just for speed) for polynomials of different degrees:\n\nCode# Function for computing deviance with different polynomial\ndeviance_divorce &lt;- function(degree = 1,\n                             train = 10,\n                             y = waffle_divorce$Divorce,\n                             x = waffle_divorce$Marriage) {\n    N &lt;- length(y)\n    # get training sample\n    if (length(train) == 1) {\n        train &lt;- sample.int(N, train)\n    }\n    ntrain &lt;- length(train)\n    # Obtain design matrix\n    X &lt;- cbind(1, poly(x, degree, simple = TRUE))\n    # Get elpd for training sample\n    Xtrain &lt;- X[train, ]\n    ytrain &lt;- y[train]\n    betahat &lt;- qr.solve(Xtrain, ytrain)  # estimated betas\n    res_train &lt;- ytrain - Xtrain %*% betahat\n    sigmahat &lt;- sqrt(sum(res_train^2) /\n        (ntrain - 1 - degree)) # estimated sigma\n    deviance_train &lt;- -2 * sum(dnorm(res_train, sd = sigmahat, log = TRUE))\n    res_test &lt;- y[-train] - X[-train, ] %*% betahat\n    deviance_test &lt;- -2 * sum(dnorm(res_test, sd = sigmahat, log = TRUE))\n    data.frame(\n        degree = degree,\n        sample = c(\"in-sample\", \"out-of-sample\"),\n        deviance = c(deviance_train / ntrain,\n                     deviance_test / (N - ntrain))\n    )\n}\n\n\nBelow shows the in-sample and out-of-sample elpd for the linear model:\n\ndeviance_divorce(degree = 1, train = train)\n\n\n  \n\n\n\nAnd for quadratic:\n\ndeviance_divorce(degree = 2, train = train)\n\n\n  \n\n\n\nIn general, as you can see, the deviance is smaller for the current data than for the hold-out data. Note that because the training and testing data sets have different sizes, I divided the deviance by the sample size so that they can be compared.\nNow let’s run an experiment to check the elpd with different degrees polynomial, with a training sample size of 25:\n\nset.seed(1733)\n# Use the `map` function to run different polynomials, and use the `rerun`\n# function run the deviance 100 times. The code below runs `deviance_divorce` by\n# randomly sampling 25 training samples 100 times, and compute the in-sample\n# and out-of-sample deviance for each.\n# rerun(100, deviance_divorce(degree = 1, train = 25L)) |&gt;\n#     bind_rows()\n# Now run 1 to 4 degree polynomial, each 1000 times:\ndev_list &lt;- lapply(1:4, FUN = function(p) {\n    results &lt;- replicate(1000, deviance_divorce(degree = p, train = 25L), simplify = FALSE)\n    do.call(rbind, results)\n})\ndev_df &lt;- do.call(rbind, dev_list)\n# Plot the results\ndev_df |&gt;\n    ggplot(aes(x = degree, y = deviance, col = sample)) +\n    stat_summary() +\n    stat_summary(geom = \"line\") +\n    labs(col = NULL)\n\nNo summary function supplied, defaulting to `mean_se()`\nNo summary function supplied, defaulting to `mean_se()`\n\n\n\n\n\n\n\n\nAs you can see, the in-sample deviance (red line) keeps decreasing, indicating that a more complex model fits the data better, which is always the case. So if one were to use deviance to determine what model is optimal, one would always choose the most complex model, just like using \\(R^2\\) (indeed, for linear models, deviance is basically the same as \\(R^2\\)).\nNow, look at the blue line, which represents the deviance computed using the coefficients obtained from the training set but applied to the remaining data. As you can see, the deviance achieves its minimum around the linear and the quadratic model, and starts to increase, meaning that the more complex models do not fit the hold-out data.\nA statistical model is used to learn something from a data set that can generalize to other observations. Therefore, we should care about the blue line, instead of the red one. The indices you will see in the remaining of this note are all attempts to approximate the blue line.\n\nMore complex models always fit the current data better, but may not generalize to other data. In other words, models that are too complex are not generalizable.",
    "crumbs": [
      "Week 7",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Model Comparison</span>"
    ]
  },
  {
    "objectID": "07-model-comparison.html#information-criteria",
    "href": "07-model-comparison.html#information-criteria",
    "title": "\n11  Model Comparison\n",
    "section": "\n11.4 Information Criteria",
    "text": "11.4 Information Criteria\nWe will illustrate the computation of information criteria with Marriage predicting Divorce:\n\nm1 &lt;- brm(Divorce ~ Marriage, data = waffle_divorce,\n          prior = c(prior(student_t(4, 0, 5), class = \"Intercept\"),\n                    prior(normal(0, 2), class = \"b\"),\n                    prior(student_t(4, 0, 1), class = \"sigma\")),\n          iter = 4000,\n          seed = 2302,\n          file = \"07_m1\"\n)\n\nStart sampling\n\n\nLoading required package: rstan\n\n\nLoading required package: StanHeaders\n\n\n\nrstan version 2.32.5 (Stan version 2.32.2)\n\n\nFor execution on a local, multicore CPU with excess RAM we recommend calling\noptions(mc.cores = parallel::detectCores()).\nTo avoid recompilation of unchanged Stan programs, we recommend calling\nrstan_options(auto_write = TRUE)\nFor within-chain threading using `reduce_sum()` or `map_rect()` Stan functions,\nchange `threads_per_chain` option:\nrstan_options(threads_per_chain = 1)\n\n\n\nAttaching package: 'rstan'\n\n\nThe following objects are masked from 'package:posterior':\n\n    ess_bulk, ess_tail\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\n\n\n11.4.1 Akaike Information Criteria (AIC)\nMultiplying the quantity of elpd - \\(p\\) by \\(-2\\), or deviance + 2\\(p\\), with the deviance obtained using the maximum likelihood estimates (MLEs) for the parameters, gives you the formula for AIC:\n\\[\n\\textrm{AIC} = D(\\hat \\theta) + 2p,\n\\]\nand \\(p\\) in AIC is just the number of parameters. As we have multiplied by a negative number, maximizing the estimate of elpd is equivalent to minimizing the AIC, so one would prefer a model with the smallest AIC.\nThe AIC is not Bayesian because it only uses point estimates (MLEs) of parameters rather than their posterior distributions. Also, it does not take into account any prior information.\n\n# Frequentist model\nm1_freq &lt;- lm(m1$formula, data = m1$data)\nAIC(m1_freq)\n\n[1] -30.96869\n\n\n\n11.4.2 Deviance Information Criteria (DIC)\nThe definition of AIC assumes that the parameter estimates are known or are maximum likelihood estimates. The DIC, instead, replaces those with the posterior distribution of the parameters. The general formula for DIC is\n\\[\n\\textrm{DIC} = \\mathrm{E}(D \\mid \\boldsymbol{\\mathbf{y}}) + 2 p_D,\n\\]\nwhere \\(p_D\\) is the effective number of parameters estimated in the Markov chain. Although DIC does take into account the prior distributions, it does not consider the full posterior distributions of the parameters.\n\n# Function to compute DIC\ndic_brmsfit &lt;- function(object) {\n    Dbar &lt;- -2 * mean(rowSums(log_lik(object)))\n    res &lt;- residuals(object)[ , \"Estimate\"]\n    sigma &lt;- posterior_summary(object, variable = \"sigma\")[ , \"Estimate\"]\n    Dhat &lt;- -2 * sum(dnorm(res, sd = sigma, log = TRUE))\n    p &lt;- Dbar - Dhat\n    elpd &lt;- Dhat / -2 - p\n    data.frame(elpd_dic = elpd, p_dic = p, dic = Dhat + 2 * p,\n               row.names = \"Estimate\")\n}\ndic_brmsfit(m1)\n\n\n  \n\n\n\n\n11.4.3 Watanabe-Akaike Information Criteria (WAIC)\nA further modification is to use the log pointwise posterior predictive density, with the effective number of parameters computed using the posterior variance of the likelihood.\n\\[\n\\textrm{WAIC} = -2 \\sum_{i = 1}^n \\log \\mathrm{E}[p(y_i \\mid \\boldsymbol{\\mathbf{\\theta}}, \\boldsymbol{\\mathbf{y}})] +\n                  2 p_\\textrm{WAIC},\n\\]\nwhere \\(\\mathrm{E}[p(y_i \\mid \\boldsymbol{\\mathbf{\\theta}}, \\boldsymbol{\\mathbf{y}})]\\) is the posterior mean of the likelihood of the \\(i\\)th observation. The WAIC incorporates prior information, and the use of pointwise likelihood makes it more robust when the posterior distributions deviate from normality. In general, WAIC is a better estimate of the out-of-sample deviance than AIC and DIC.\n\nwaic(m1)  # built-in function in brms\n\nWarning: \n1 (2.0%) p_waic estimates greater than 0.4. We recommend trying loo instead.\n\n\n\nComputed from 8000 by 50 log-likelihood matrix.\n\n          Estimate  SE\nelpd_waic     15.2 4.9\np_waic         3.2 0.9\nwaic         -30.3 9.9\n\n1 (2.0%) p_waic estimates greater than 0.4. We recommend trying loo instead. \n\n\n\n11.4.4 Leave-One-Out Cross-Validation\nThe idea of cross-validation is to split the sample so that it imitates the scenario of estimating the parameters in part of the data and predicting the remaining part. The part used for estimation is called the training set, and the part used for prediction is called the validation set. Leave-one-out information criteria (LOO-IC) means that one uses \\(N - 1\\) observations as the training set and 1 observation as the validation sample and repeat the process \\(N\\) times so that a different observation is being predicted each time. Adding up the prediction results will give an estimate of elpd that closely approximates the results that would be obtained by collecting new data and doing the validation. To make it more concrete, we can go back to the waffle_divorce data with Marriage predicting Divorce. We can do this for case #1 (Alabama), as an example:\n\n# Estimate the model without case #1\nm1_no1 &lt;- update(m1, newdata = waffle_divorce[-1, ])\n\n\n# The log predictive density for case #1\nmean(log_lik(m1_no1, newdata = waffle_divorce[1, ]))\n\n[1] -0.8111212\n\n\nBecause LOO-IC requires fitting the model \\(N\\) times, it is generally very computationally intensive. There are, however, shortcuts for some models to make the computation faster. WAIC can also be treated as a fast approximation of LOO-IC, although LOO-IC is more robust and will be a better estimate of out-of-sample deviance. The loo package uses the so-called Pareto smoothed importance sampling (PSIS) to approximate LOO-IC without repeating the process \\(N\\) times.\nHere is the LOO-IC for the model:\n\nloo(m1)\n\n\nComputed from 8000 by 50 log-likelihood matrix.\n\n         Estimate  SE\nelpd_loo     15.1 5.0\np_loo         3.3 1.0\nlooic       -30.2 9.9\n------\nMCSE of elpd_loo is 0.0.\nMCSE and ESS estimates assume MCMC draws (r_eff in [0.7, 1.0]).\n\nAll Pareto k estimates are good (k &lt; 0.7).\nSee help('pareto-k-diagnostic') for details.\n\n\nYou can save the WAIC and the LOO-IC information to the fitted result:\n\nm1 &lt;- add_criterion(m1, criterion = c(\"loo\", \"waic\"))\n\nWarning: \n1 (2.0%) p_waic estimates greater than 0.4. We recommend trying loo instead.\n\n\nAutomatically saving the model object in '07_m1.rds'\n\n\nSee Vehtari et al. (2017) for more discussions on WAIC and LOO-IC.\n\n11.4.5 Example\nConsider four potential models in predicting Divorce:\n\\[\n\\texttt{Divorce}_i \\sim N(\\mu_i, \\sigma)\n\\]\n\nM1: Marriage\n\nM2: Marriage, South, Marriage \\(\\times\\) South\n\nM3: South, smoothing spline of Marriage by South\n\nM4: Marriage, South, MedianAgeMarriage, Marriage \\(\\times\\) South, Marriage \\(\\times\\) MedianAgeMarriage, South \\(\\times\\) MedianAgeMarriage, Marriage \\(\\times\\) South \\(\\times\\) MedianAgeMarriage\n\n\n\n# Note, m1 has been fit before; the `update()` function\n# can be used to simply change the formula, and brms will\n# determine whether it needs re-compiling.\n# M2: Add South and interaction\nm2 &lt;- update(m1, formula = Divorce ~ Marriage * South,\n             newdata = waffle_divorce)\nm2 &lt;- add_criterion(m2, c(\"loo\", \"waic\"))\n\nWarning: \n1 (2.0%) p_waic estimates greater than 0.4. We recommend trying loo instead.\n\n# M3: Spline function for Marriage\nm3 &lt;- update(m1, formula = Divorce ~ South + s(Marriage, by = South),\n             newdata = waffle_divorce,\n             control = list(adapt_delta = .999))\nm3 &lt;- add_criterion(m3, c(\"loo\", \"waic\"))\n\nWarning: Found 2 observations with a pareto_k &gt; 0.7 in model 'm3'. We recommend\nto set 'moment_match = TRUE' in order to perform moment matching for\nproblematic observations.\n\n\nWarning: \n4 (8.0%) p_waic estimates greater than 0.4. We recommend trying loo instead.\n\n# M4: Three-way interactions\nm4 &lt;- update(m1, formula = Divorce ~ Marriage * MedianAgeMarriage * South,\n             newdata = waffle_divorce,\n             control = list(max_treedepth = 12))  # increase due to warning\nm4 &lt;- add_criterion(m4, c(\"loo\", \"waic\"))\n\nWarning: Found 1 observations with a pareto_k &gt; 0.7 in model 'm4'. We recommend\nto set 'moment_match = TRUE' in order to perform moment matching for\nproblematic observations.\n\n\nWarning: \n3 (6.0%) p_waic estimates greater than 0.4. We recommend trying loo instead.\n\n\nThe first model only has Marriage as a predictor, which means that the coefficients for South and MedianAgeMarriage are assumed to be zero. The second model added South and its interaction with Marriage as a predictor. The third model includes a smoothing spline term (a flexible non-linear function, within the class of linear models), whereas the fourth model also includes MedianAgeMarriage and all two-way and three-way interactions. Now, we can compare the four models:\n\nloo_compare(m1, m2, m3, m4)\n\n   elpd_diff se_diff\nm4  0.0       0.0   \nm2 -5.3       4.1   \nm3 -6.1       4.1   \nm1 -8.5       4.3   \n\n# m4 is the best\n\n\nmsummary(list(M1 = m1, M2 = m2, M3 = m3, M4 = m4),\n         estimate = \"{estimate} [{conf.low}, {conf.high}]\",\n         statistic = NULL, fmt = 2)\n\nWarning: \n`modelsummary` uses the `performance` package to extract goodness-of-fit\nstatistics from models of this class. You can specify the statistics you wish\nto compute by supplying a `metrics` argument to `modelsummary`, which will then\npush it forward to `performance`. Acceptable values are: \"all\", \"common\",\n\"none\", or a character vector of metrics names. For example: `modelsummary(mod,\nmetrics = c(\"RMSE\", \"R2\")` Note that some metrics are computationally\nexpensive. See `?performance::performance` for details.\n This warning appears once per session.\n\n\n\n\n\nM1\n M2\n M3\n M4\n\n\n\nb_Intercept\n0.61 [0.35, 0.87]\n0.67 [0.41, 0.92]\n0.94 [0.89, 0.99]\n5.50 [1.86, 9.13]\n\n\nb_Marriage\n0.18 [0.05, 0.31]\n0.13 [0.01, 0.26]\n\n−1.20 [−2.88, 0.50]\n\n\nsigma\n0.17 [0.14, 0.21]\n0.16 [0.13, 0.20]\n0.15 [0.12, 0.19]\n0.14 [0.11, 0.18]\n\n\nb_Southsouth\n\n−0.62 [−1.44, 0.19]\n0.10 [−0.03, 0.22]\n0.34 [−3.00, 3.88]\n\n\nb_Marriage × Southsouth\n\n0.36 [−0.03, 0.76]\n\n0.49 [−1.62, 2.81]\n\n\nbs_sMarriage × SouthnonMsouth_1\n\n\n−0.46 [−3.34, 1.51]\n\n\n\nbs_sMarriage × Southsouth_1\n\n\n1.27 [−2.02, 3.54]\n\n\n\nsds_sMarriageSouthnonMsouth_1\n\n\n0.87 [0.05, 2.60]\n\n\n\nsds_sMarriageSouthsouth_1\n\n\n0.48 [0.02, 2.48]\n\n\n\nb_MedianAgeMarriage\n\n\n\n−1.72 [−3.10, −0.32]\n\n\nb_Marriage × MedianAgeMarriage\n\n\n\n0.45 [−0.22, 1.10]\n\n\nb_MedianAgeMarriage × Southsouth\n\n\n\n−0.37 [−1.72, 0.96]\n\n\nb_Marriage × MedianAgeMarriage × Southsouth\n\n\n\n−0.07 [−1.08, 0.88]\n\n\nNum.Obs.\n50\n50\n50\n50\n\n\nR2\n0.139\n0.305\n0.388\n0.490\n\n\nR2 Adj.\n0.072\n0.209\n0.164\n0.367\n\n\nELPD\n15.1\n18.3\n17.5\n23.7\n\n\nELPD s.e.\n5.0\n5.5\n5.9\n6.1\n\n\nLOOIC\n−30.2\n−36.7\n−35.1\n−47.3\n\n\nLOOIC s.e.\n9.9\n11.0\n11.9\n12.3\n\n\nWAIC\n−30.3\n−36.8\n−36.7\n−48.1\n\n\nRMSE\n0.17\n0.15\n0.14\n0.13\n\n\n\n\n\nModel 4 has the lowest LOO-IC, so one may conclude that Model 4 is the best model among the four, for prediction purposes.\n\n\n\n\n\n\n\nVehtari, A., Gelman, A., & Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC. Statistics and Computing, 27(5), 1413–1432. https://doi.org/10.1007/s11222-016-9696-4",
    "crumbs": [
      "Week 7",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Model Comparison</span>"
    ]
  },
  {
    "objectID": "07b-stacking-and-regularization.html",
    "href": "07b-stacking-and-regularization.html",
    "title": "\n12  Stacking, Regularization, and Variable Selection\n",
    "section": "",
    "text": "12.1 Stacking/Model Averaging\nSometimes it may not be a good practice to only choose one model with low WAIC or LOO-IC, especially when several models have very imilar WAIC/LOO-IC, but they make somewhat different predictions. Instead, we can perform stacking or model averaging by weighting the predictions from multiple models, using weights that are based on their information criteria performance. Stacking approaches this by optimizing the leave-one-out mean squared error in the resulting prediction, whereas model averaging preserves the uncertainty and was not optimized for that task. The technical details can be found in Yao et al. (2018).\nNote that the conventional Bayesian model averaging used the posterior model probability (Hoeting et al., 1999), which are approximated by the BIC. The discussion in this note is based on more recent discussion in, e.g., Yao et al. (2018).\nWe’ll use a data set kidiq that is used in the textbook by Gelman et al. (2021), which can be downloaded and imported with the direct link:\nkidiq &lt;- haven::read_dta(\"http://www.stat.columbia.edu/~gelman/arm/examples/child.iq/kidiq.dta\")\nhead(kidiq)\nLet’s run four models. First rescale some of the variables:\nkidiq100 &lt;- kidiq |&gt;\n  mutate(mom_iq = mom_iq / 100,  # divid mom_iq by 100\n         kid_score = kid_score / 100,   # divide kid_score by 100\n         mom_iq_c = mom_iq - 1,\n         mom_hs = factor(mom_hs, labels = c(\"no\", \"yes\")),\n         mom_age_c = (mom_age - 18) / 10)\nI will run four models, which is from the last note\n\\[\n\\texttt{kidscore}_i \\sim N(\\mu_i, \\sigma)\n\\]\n\\[\n\\begin{aligned}\n  \\mu_i & = \\beta_0 + \\beta_1 (\\texttt{mom\\_iq}_i)  \\\\\n  \\mu_i & = \\beta_0 + \\beta_1 (\\texttt{mom\\_iq}_i) +\n            \\beta_2 (\\texttt{mom\\_hs}_i) \\\\\n  \\mu_i & = \\beta_0 + \\beta_1 (\\texttt{mom\\_iq}_i) +\n            \\beta_2 (\\texttt{mom\\_hs}_i) + \\beta_3 (\\texttt{mom\\_iq}_i \\times\n                                                    \\texttt{mom\\_hs}_i)  \\\\\n  \\mu_i & = \\beta_0 + \\beta_1 (\\texttt{mom\\_iq}_i) +\n            \\beta_2 (\\texttt{mom\\_hs}_i) +\n            \\beta_3 (\\texttt{mom\\_iq}_i \\times \\texttt{mom\\_hs}_i) +\n            \\beta_4 (\\texttt{mom\\_age}_i)\n\\end{aligned}\n\\]\nm1 &lt;- brm(kid_score ~ mom_iq_c,\n    data = kidiq100,\n    prior = c(\n        prior(normal(0, 1), class = \"Intercept\"),\n        prior(normal(0, 1), class = \"b\"),\n        prior(student_t(4, 0, 1), class = \"sigma\")\n    ),\n    seed = 2302,\n    file = \"07b_m1\"\n)\n\nStart sampling\n\n\nLoading required package: rstan\n\n\nLoading required package: StanHeaders\n\n\n\nrstan version 2.32.5 (Stan version 2.32.2)\n\n\nFor execution on a local, multicore CPU with excess RAM we recommend calling\noptions(mc.cores = parallel::detectCores()).\nTo avoid recompilation of unchanged Stan programs, we recommend calling\nrstan_options(auto_write = TRUE)\nFor within-chain threading using `reduce_sum()` or `map_rect()` Stan functions,\nchange `threads_per_chain` option:\nrstan_options(threads_per_chain = 1)\n\n\n\nAttaching package: 'rstan'\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\nm1 &lt;- add_criterion(m1, c(\"loo\", \"waic\"))\n\nAutomatically saving the model object in '07b_m1.rds'\n\n# Use `update` will sometimes avoid recompiling\nm2 &lt;- update(m1, kid_score ~ mom_iq_c + mom_hs,\n    newdata = kidiq100,\n    file = \"07b_m2\"\n)\n\nStart sampling\n\nm2 &lt;- add_criterion(m2, c(\"loo\", \"waic\"))\n\nAutomatically saving the model object in '07b_m2.rds'\n\nm3 &lt;- update(m2, kid_score ~ mom_iq_c * mom_hs,\n    prior = c(prior(normal(0, 0.5),\n        class = \"b\",\n        coef = \"mom_iq_c:mom_hsyes\"\n    )),\n    file = \"07b_m3\"\n)\n\nThe desired updates require recompiling the model\n\n\nStart sampling\n\nm3 &lt;- add_criterion(m3, c(\"loo\", \"waic\"))\n\nAutomatically saving the model object in '07b_m3.rds'\n\nm4 &lt;- update(m3, kid_score ~ mom_iq_c * mom_hs + mom_age_c,\n    newdata = kidiq100,\n    file = \"07b_m4\"\n)\n\nThe desired updates require recompiling the model\nStart sampling\n\nm4 &lt;- add_criterion(m4, c(\"loo\", \"waic\"))\n\nWarning: \n1 (0.2%) p_waic estimates greater than 0.4. We recommend trying loo instead.\n\n\nAutomatically saving the model object in '07b_m4.rds'",
    "crumbs": [
      "Week 7",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Stacking, Regularization, and Variable Selection</span>"
    ]
  },
  {
    "objectID": "07b-stacking-and-regularization.html#stackingmodel-averaging",
    "href": "07b-stacking-and-regularization.html#stackingmodel-averaging",
    "title": "\n12  Stacking, Regularization, and Variable Selection\n",
    "section": "",
    "text": "12.1.1 Model Weights\nWe can see that m3 and m4 gave the best LOO-IC and WAIC:\n\nloo_compare(m1, m2, m3, m4)\n\n   elpd_diff se_diff\nm3  0.0       0.0   \nm4 -0.6       1.1   \nm2 -3.5       2.5   \nm1 -6.0       3.9   \n\n\nSo it makes sense that if we’re to assign weights, m4 should get most weights. Let’s check the following:\n\n# Weights based on WAIC\nwaic_wts &lt;- model_weights(m1, m2, m3, m4, weights = \"waic\")\n# Weights based on Stacking (based on the posterior predictive distribution)\nstack_wts &lt;- loo_model_weights(m1, m2, m3, m4)\n# Print out the weights\nround(cbind(waic_wts, stack_wts), 3)\n\n   waic_wts stack_wts\nm1    0.002     0.100\nm2    0.019     0.000\nm3    0.635     0.882\nm4    0.344     0.018\n\n\nYou can see m3 would get the highest weight, but it’s only 0.6352557 and thus less than half of the weights when all four models are considered together.\nIn Bayesian, we want to preserve all the uncertainty in our analyses. Therefore, if we’re not certain which models to use and have tried multiple ones, it would make sense to use all of them to get the best information. So unlike what is commonly done in practice where a researcher would test multiple models and present the best model as if they intended only to test this model, Bayesian analysts should do the honest thing and use all models. The reward is usually better prediction!\n\n12.1.2 Stacking\nStacking is one way to combine the predictions of different models. The technical details can be found in Yao et al. (2018), but you can obtain the predictions using the pp_average function:\n\n# Prediction from stacking by Yao et al. (2018)\npred_stacking &lt;- pp_average(m1, m2, m3, m4)\n# Compare the weights\nplot(pred_stacking)\n\n\n\n\n\n\n\n\n12.1.3 Prediction example\nConsider a kid whose mother’s IQ is 120 (mom_iq = .2), mother’s age is 40, (mom_age_c = 2.2), mother does not have a high school degree, and mother did not work in first three years of child’s life (mom_work = 1). Then the prediction based on the various models are:\n\nnewkid &lt;- data.frame(mom_iq_c = .2,\n                     mom_age_c = 2.2,\n                     mom_work = 1,\n                     mom_hs = \"no\")\n# Visualize the prediction by different models\ndata.frame(stacking = pp_average(m1, m2, m3, m4, newdata = newkid,\n                                 summary = FALSE),\n           m4 = posterior_predict(m4, newdata = newkid),\n           m3 = posterior_predict(m3, newdata = newkid),\n           m2 = posterior_predict(m2, newdata = newkid),\n           m1 = posterior_predict(m1, newdata = newkid)) |&gt;\n    mcmc_intervals()\n\n\n\n\n\n\n\nCheck out this blog post https://mc-stan.org/loo/articles/loo2-weights.html for more information on stacking and Averaging.",
    "crumbs": [
      "Week 7",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Stacking, Regularization, and Variable Selection</span>"
    ]
  },
  {
    "objectID": "07b-stacking-and-regularization.html#shrinkage-priors",
    "href": "07b-stacking-and-regularization.html#shrinkage-priors",
    "title": "\n12  Stacking, Regularization, and Variable Selection\n",
    "section": "\n12.2 Shrinkage Priors",
    "text": "12.2 Shrinkage Priors\nWhen the number of parameters to be estimated is large relative to the amount of data available, ordinary least square (in frequentist) and estimation using non-informative or weakly informative priors tend to overfit. For example, fitting a 6th degree polynomial (with 8 parameters) on a data set with only 10 observations will severely overfit the data, making the results not generalizable. One way to avoid overfitting is to perform regularization, that is, to shrink some of the parameters to closer to zero. This makes the model fit less well to the existing data, but will be much more generalizable to an independent data set.\n\n12.2.1 Number of parameters\nIn Bayesian analyses, the concept of number of parameters is a little vague. This is because the posterior distribution is a function of both the prior and the data. For non-informative priors, it would make sense to simply count the number of parameters. However, say one put a very strong prior on one of the regression coefficients, which has about 9 times the weights of the information contributed by the data:\n\nCodeggplot(data.frame(th = c(-3, 3)), aes(x = th)) +\n    stat_function(\n        fun = dnorm, args = list(mean = 0, sd = 1 / 9),\n        aes(col = \"prior\"), n = 501\n    ) +\n    stat_function(\n        fun = dnorm, args = list(mean = 0.3, sd = 1),\n        aes(col = \"likelihood\"), n = 501\n    ) +\n    labs(y = \"Density\", x = expression(theta), col = \"\")\n\n\n\n\n\n\n\nThen the posterior for the parameter only uses 1/10 of the information from the data! Therefore, it would make more sense to count this as 0.1 parameter, instead of 1 full parameter.\nThe concept of regularization is essentially to introduce a stronger prior so that the posterior is less likely to overfit the data, and the resulting model will have lower effective number of parameters, which, when done appropriately, would find a model that is more likely to generalize to external data sets.\nIn Bayesian methods, regularization can be done by choosing a prior on the coefficient that has a sharp peak at 0, but also has a heavy tail. One such prior is what is called the horseshoe prior. The discussion here is based on the blog pot by Michael Betancourt: https://betanalpha.github.io/assets/case_studies/bayes_sparse_regression.html\nIt should first be pointed out that these priors were based on the assumption that the predictors and the outcome has been scaled to have a standard deviation of one. So we will do this here:\n\n# For variable selection, scale the predictor and outcome to have unit variance\nkidiq_std &lt;- scale(kidiq)\nhead(kidiq_std)\n\n       kid_score    mom_hs     mom_iq    mom_work    mom_age\n[1,] -1.06793237  0.521631  1.4078352  0.93422435  1.5602285\n[2,]  0.54886757  0.521631 -0.7092079  0.93422435  0.8197811\n[3,] -0.08805362  0.521631  1.0295443  0.93422435  1.5602285\n[4,] -0.18604150  0.521631 -0.0366907  0.08776638  0.8197811\n[5,]  1.38176451  0.521631 -0.4836193  0.93422435  1.5602285\n[6,]  0.54886757 -1.912647  0.5267892 -1.60514956 -1.7717849\n\n\n\n12.2.2 Sparsity-Inducing Priors\nThe horseshoe prior (Carvalho et al., 2010) is a type of hierarchical prior for regression models by introducing a global scale, \\(\\tau\\), and local scale,\\(\\lambda_m\\), parameters on the priors for the regression coefficients (Piironen & Vehtari, 2017). Specifically, with \\(p\\) predictors,\n\\[\n\\begin{aligned}\n  Y_i & \\sim N(\\mu_i, \\sigma^2) \\\\\n  \\mu_i & = \\beta_0 + \\sum_{m = 1}^p \\beta_m X_m \\\\\n  \\beta_0 & \\sim N(0, 1) \\\\\n  \\beta_m & \\sim N(0, \\tau \\lambda_m) \\\\\n  \\lambda_m & \\sim \\textrm{Cauchy}^+(0, 1)  \\\\\n  \\tau & \\sim \\textrm{Cauchy}^+(0, \\tau_0)\n\\end{aligned}\n\\]\nThe local scale, \\(\\lambda_m\\), can flexibly shrink the coefficient to close to zero. Below is the implication of the prior on the shrinkage of \\(\\beta\\):\n\nggplot(data.frame(shrinkage = c(0, 1)), aes(x = shrinkage)) +\n    stat_function(fun = function(x) {\n        dcauchy(sqrt(1 / x - 1)) * 2 * (1 / x - 1)^(-1 / 2) * x^(-2) / 2\n    }, n = 501) +\n    theme(\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank()\n    ) +\n    labs(y = \"\")\n\nWarning: Removed 1 row containing missing values (`geom_function()`).\n\n\n\n\n\n\n\n\nThe U-shape here means that, for coefficients that are weakly supported by the data, the horseshoe will shrink it to very close to zero, whereas for coefficients that are more strongly supported by the data, the horseshoe will not shrink it much.\nThe red curve in the following is one example for the resulting prior distribution on \\(\\beta\\):\n\ndhs &lt;- Vectorize(\n    function(y, df = 1) {\n        ff &lt;- function(lam) dnorm(y, 0, sd = lam) * dt(lam, df) * 2\n        if (y != 0) {\n            integrate(ff, lower = 0, upper = Inf)$value\n        } else {\n            Inf\n        }\n    }\n)\nggplot(data.frame(x = c(-6, 6)), aes(x = x)) +\n    stat_function(\n        fun = dhs, args = list(df = 3), n = 501,\n        aes(col = \"HS\"), linetype = 1\n    ) +\n    stat_function(\n        fun = dnorm, n = 501,\n        aes(col = \"norm\"), linetype = 2\n    ) +\n    scale_color_manual(\"\",\n        values = c(\"red\", \"black\"),\n        labels = c(\"horseshoe(3)\", \"N(0, 1)\")\n    ) +\n    xlab(\"y\") +\n    ylab(\"density\") +\n    ylim(0, 0.75)\n\n\n\nDensity for the regularized horseshoe prior with 3 degrees of freedom\n\n\n\nSuch a prior has more density at 0, but also more density for extreme values, as compared to a normal distribution. Thus, for coefficients with very weak evidence, the regularizing prior will shrink it to zero, whereas for coefficients with strong evidence, the shrinkage will be very small. This is called a horseshoe prior. In brms, one can specify it with horseshoe(), which is a stabilized version of the original horseshoe prior (Carvalho et al., 2010).\n\n12.2.3 Regularized Horseshoe/Hierarchical Shrinkage\nThe regularized horseshoe (https://projecteuclid.org/euclid.ejs/1513306866) prior is\n\\[\n\\begin{aligned}\n  \\beta_m & \\sim N(0, \\tau \\tilde \\lambda_m) \\\\\n  \\tilde \\lambda_m & = \\frac{c \\lambda_m}{\\sqrt{c^2 + \\tau^2 \\lambda^2_m}} \\\\\n  \\lambda_m & \\sim \\textrm{Cauchy}^+(0, 1)  \\\\\n  c^2 & \\sim \\textrm{Inv-Gamma}(\\nu / 2, nu / 2 s^2) \\\\\n  \\tau & \\sim \\textrm{Cauchy}^+(0, \\tau_0)\n\\end{aligned}\n\\]\nThe additional parameters are chosen in the code below. First, fit a model without shrinkage:\n\n# A model with all main and interaction effects\nm5 &lt;- brm(kid_score ~ (.)^2,\n    data = kidiq_std,\n    prior = c(\n        prior(normal(0, 1), class = \"Intercept\"),\n        prior(normal(0, 1), class = \"b\"),\n        prior(student_t(4, 0, 1), class = \"sigma\")\n    ),\n    seed = 2217,\n    file = \"07b_m5\"\n)\n\nStart sampling\n\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.1 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.1 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.1 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.6 seconds.\n\n\n\n# A model with all main and interaction effects, and regularization\nm_hs &lt;- brm(kid_score ~ (.)^2,\n    data = kidiq_std,\n    prior = c(\n        prior(normal(0, 1), class = \"Intercept\"),\n        # Prior guess of 20% of the terms are non-zero\n        prior(horseshoe(par_ratio = 2 / 8), class = \"b\"),\n        prior(student_t(4, 0, 1), class = \"sigma\")\n    ),\n    # Need higher adapt_delta\n    control = list(adapt_delta = .995, max_treedepth = 12),\n    seed = 2217,\n    file = \"07b_m_hs\"\n)\n\nStart sampling\n\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 2.7 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 1.8 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 2.4 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 3.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 2.5 seconds.\nTotal execution time: 10.2 seconds.\n\n\nWe can plot the coefficients:\n\nmcmc_plot(m_hs, variable = \"^b_\",\n          regex = TRUE) +\n    # Show the shrinkage as orange, transparent dots\n    geom_point(\n        data = posterior_summary(m5) |&gt;\n            as_tibble(rownames = \"parameter\") |&gt;\n            filter(parameter != \"lp__\"),\n        aes(x = Estimate, y = parameter), alpha = 0.8,\n        col = \"orange\"\n    ) +\n    geom_vline(xintercept = c(-.05, .05), col = \"red\")\n\nWarning: Removed 3 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\nAn arbitrary cutoff is to select only coefficients with posterior means larger than .05, in which case only mom_iq and mom_hs and their interaction were supported by the data.\nYou can also double check that the regularized version has better LOO-IC:\n\nloo(m5, m_hs)\n\nOutput of model 'm5':\n\nComputed from 4000 by 434 log-likelihood matrix.\n\n         Estimate   SE\nelpd_loo   -567.3 14.4\np_loo        12.8  1.4\nlooic      1134.6 28.8\n------\nMCSE of elpd_loo is 0.1.\nMCSE and ESS estimates assume MCMC draws (r_eff in [0.6, 2.0]).\n\nAll Pareto k estimates are good (k &lt; 0.7).\nSee help('pareto-k-diagnostic') for details.\n\nOutput of model 'm_hs':\n\nComputed from 4000 by 434 log-likelihood matrix.\n\n         Estimate   SE\nelpd_loo   -565.2 14.4\np_loo         8.5  0.9\nlooic      1130.5 28.9\n------\nMCSE of elpd_loo is 0.1.\nMCSE and ESS estimates assume MCMC draws (r_eff in [0.5, 1.3]).\n\nAll Pareto k estimates are good (k &lt; 0.7).\nSee help('pareto-k-diagnostic') for details.\n\nModel comparisons:\n     elpd_diff se_diff\nm_hs  0.0       0.0   \nm5   -2.1       2.3   \n\n\nAnd also that the effective number of parameters was smaller in m_hs.",
    "crumbs": [
      "Week 7",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Stacking, Regularization, and Variable Selection</span>"
    ]
  },
  {
    "objectID": "07b-stacking-and-regularization.html#variable-selection",
    "href": "07b-stacking-and-regularization.html#variable-selection",
    "title": "\n12  Stacking, Regularization, and Variable Selection\n",
    "section": "\n12.3 Variable Selection",
    "text": "12.3 Variable Selection\nOne way to identify variables that are relevant to predict a certain outcome is to use the projection-based method, as discussed in https://mc-stan.org/projpred/articles/projpred.html and in Piironen et al. (2020).\nBuilding from the full model with shrinkage priors, we first do a trial run to identify the importance of various variables in terms of their importance for prediction:\n\n# Get reference model\nrefm_obj &lt;- get_refmodel(m_hs)\n# Preliminary run to find `nterms_max`\ncvvs_fast &lt;- cv_varsel(\n    refm_obj,\n    validate_search = FALSE\n)\n\n-----\nRunning the search ...\n10% of terms selected\n20% of terms selected\n30% of terms selected\n40% of terms selected\n50% of terms selected\n60% of terms selected\n70% of terms selected\n80% of terms selected\n90% of terms selected\n100% of terms selected\n-----\n-----\nRunning the performance evaluation with `refit_prj = TRUE` ...\n-----\n\n# mlpd = mean log predictive density\nplot(cvvs_fast, stats = \"mlpd\", ranking_nterms_max = NA)\n\n\n\n\n\n\n\nFrom the plot, we find when the predictive performance starts to level off when we keep adding more terms to the model. In this case, it seems to be 4. Given that this is a trial run, we’ll set nterms_max to 5, which is slightly higher.\nWe then set validate_search = FALSE for a final run. For computational feasibility, we’ll use 10-fold validation.\n\n# With 10-fold cross-validation\ncvvs &lt;- cv_varsel(\n    refm_obj,\n    validate_search = TRUE,\n    cv_method = \"kfold\",\n    K = 10,\n    nterms_max = 5\n)\n\n-----\nRunning the search using the full dataset ...\n20% of terms selected\n40% of terms selected\n60% of terms selected\n80% of terms selected\n100% of terms selected\n-----\n-----\nRefitting the reference model K = 10 times (using the fold-wise training data) ...\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 2.2 seconds.\nChain 2 finished in 1.9 seconds.\nChain 3 finished in 2.2 seconds.\nChain 4 finished in 2.3 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 2.1 seconds.\nTotal execution time: 8.9 seconds.\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 2.7 seconds.\nChain 2 finished in 2.5 seconds.\nChain 3 finished in 1.6 seconds.\nChain 4 finished in 2.4 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 2.3 seconds.\nTotal execution time: 9.7 seconds.\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 1.4 seconds.\nChain 2 finished in 1.4 seconds.\nChain 3 finished in 3.4 seconds.\nChain 4 finished in 2.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 2.1 seconds.\nTotal execution time: 8.7 seconds.\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 2.2 seconds.\nChain 2 finished in 1.6 seconds.\nChain 3 finished in 2.4 seconds.\nChain 4 finished in 1.7 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 2.0 seconds.\nTotal execution time: 8.4 seconds.\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 1.7 seconds.\nChain 2 finished in 2.1 seconds.\nChain 3 finished in 3.3 seconds.\nChain 4 finished in 2.3 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 2.4 seconds.\nTotal execution time: 9.8 seconds.\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 1.9 seconds.\nChain 2 finished in 2.0 seconds.\nChain 3 finished in 2.3 seconds.\nChain 4 finished in 2.4 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 2.2 seconds.\nTotal execution time: 9.1 seconds.\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 2.0 seconds.\nChain 2 finished in 1.6 seconds.\nChain 3 finished in 2.2 seconds.\nChain 4 finished in 1.7 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 1.9 seconds.\nTotal execution time: 7.9 seconds.\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 1.6 seconds.\nChain 2 finished in 1.5 seconds.\nChain 3 finished in 2.1 seconds.\nChain 4 finished in 2.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 1.8 seconds.\nTotal execution time: 7.5 seconds.\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 1.7 seconds.\nChain 2 finished in 1.5 seconds.\nChain 3 finished in 2.2 seconds.\nChain 4 finished in 2.2 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 1.9 seconds.\nTotal execution time: 7.9 seconds.\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 2.0 seconds.\nChain 2 finished in 2.0 seconds.\nChain 3 finished in 1.7 seconds.\nChain 4 finished in 2.3 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 2.0 seconds.\nTotal execution time: 8.6 seconds.\n\n-----\n-----\nRunning the search and the performance evaluation with `refit_prj = TRUE` for each of the K = 10 CV folds separately ...\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |======================================================================| 100%\n-----\n\nplot(cvvs, stats = \"mlpd\", deltas = TRUE)\n\n\n\n\n\n\n\n\n# model size suggested by the program\nsuggest_size(cvvs, stat = \"mlpd\")\n\n[1] 2\n\n# Same with RMSE\nsuggest_size(cvvs, stat = \"rmse\")\n\n[1] 2\n\n# Summary of the variable selection results\nsummary(cvvs,\n    stats = \"mlpd\", type = c(\"mean\", \"lower\", \"upper\"),\n    deltas = TRUE\n)\n\n\nFamily: gaussian \nLink function: identity \n\nFormula: kid_score ~ mom_hs + mom_iq + mom_work + mom_age + mom_hs:mom_iq + \n    mom_hs:mom_work + mom_hs:mom_age + mom_iq:mom_work + mom_iq:mom_age + \n    mom_work:mom_age\nObservations: 434\nProjection method: traditional\nCV method: K-fold CV with K = 10 and search included (i.e., fold-wise searches)\nSearch method: forward\nMaximum submodel size for the search: 5\nNumber of projected draws in the search: 20 (from clustered projection)\nNumber of projected draws in the performance evaluation: 400\nArgument `refit_prj`: TRUE\n\nSubmodel performance evaluation summary with `deltas = TRUE` and `cumulate = FALSE`:\n size ranking_fulldata cv_proportions_diag    mlpd mlpd.lower mlpd.upper\n    0      (Intercept)                  NA -0.1219   -0.14332    -0.1004\n    1           mom_iq                 1.0 -0.0106   -0.01811    -0.0032\n    2           mom_hs                 1.0 -0.0037   -0.00966     0.0023\n    3    mom_hs:mom_iq                 1.0  0.0034    0.00062     0.0063\n    4          mom_age                 0.9  0.0024   -0.00024     0.0050\n    5   mom_hs:mom_age                 0.9  0.0030    0.00094     0.0051\n\nReference model performance evaluation summary with `deltas = TRUE`:\n      mlpd mlpd.lower mlpd.upper \n         0          0          0 \n\n# Predictor ranking(s)\nrk &lt;- ranking(cvvs)\nplot(cv_proportions(rk, cumulate = TRUE))\n\n\n\n\n\n\n\nHere it suggests to either include only mom_iq and mom_hs, or to also include their interactions.\n\n12.3.1 Projection-Based Method\nThe projection-based method will obtain the posterior distributions based on a projection from the full model on the simplified model. In other words, we’re asking the question:\n\nIf we want a model with only mom_iq and mom_hs, what coefficients should be obtained so that the resulting prediction accuracy is as closed to the full model as possible?\n\nNote that the coefficients will be different from if you were to directly estimate the model using the two predictors (i.e., m2). In this case, simulation results showed that the projection-based method will yield a model with better predictive performance.\n\n# Fit m2 with the standardized data\nm2_std &lt;- brm(kid_score ~ mom_hs + mom_iq,\n    data = kidiq_std,\n    prior = c(\n        prior(normal(0, 1), class = \"Intercept\"),\n        prior(normal(0, 1), class = \"b\"),\n        prior(student_t(4, 0, 1), class = \"sigma\")\n    ),\n    seed = 2302,\n    file = \"07b_m2_std\"\n)\n\nStart sampling\n\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.6 seconds.\n\n\n\n# Visualise the projected three most relevant variables\nprj &lt;- project(refm_obj,\n    predictor_terms = c(\"mom_iq\", \"mom_hs\"),\n    verbose = FALSE\n)\nmcmc_intervals(as.matrix(prj)) +\n    # Show the non-projection version as black, transparent dots\n    geom_point(\n        data =\n            posterior_summary(m2_std) |&gt;\n                as_tibble(rownames = \"parameter\"),\n        aes(x = Estimate, y = parameter), alpha = 0.8,\n        col = \"orange\"\n    )\n\nWarning: Removed 3 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCarvalho, C. M., Polson, N. G., & Scott, J. G. (2010). The horseshoe estimator for sparse signals. Biometrika, 97(2), 465–480. https://doi.org/10.1093/biomet/asq017\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nHoeting, J. A., Madigan, D., Raftery, A. E., & Volinsky, C. T. (1999). Bayesian model averaging: A tutorial. Statistical Science, 14(4). https://doi.org/10.1214/ss/1009212519\n\n\nPiironen, J., Paasiniemi, M., & Vehtari, A. (2020). Projective inference in high-dimensional problems: Prediction and feature selection. Electronic Journal of Statistics, 14(1). https://doi.org/10.1214/20-EJS1711\n\n\nPiironen, J., & Vehtari, A. (2017). Sparsity information and regularization in the horseshoe and other shrinkage priors. Electronic Journal of Statistics, 11(2). https://doi.org/10.1214/17-EJS1337SI\n\n\nYao, Y., Vehtari, A., Simpson, D., & Gelman, A. (2018). Using stacking to average Bayesian predictive distributions (with discussion). Bayesian Analysis, 13(3). https://doi.org/10.1214/17-BA1091",
    "crumbs": [
      "Week 7",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Stacking, Regularization, and Variable Selection</span>"
    ]
  },
  {
    "objectID": "08-causal-inference.html",
    "href": "08-causal-inference.html",
    "title": "\n13  Causal Inference\n",
    "section": "",
    "text": "13.1 Potential Outcomes\nCausal inference is an important topic in statistics, but it also has a complicated history with statistics. Early-day statisticians saw causality as a taboo such that researchers were discouraged from drawing any causal conclusions in nonexperimental research. In the past few decades, much progress has been made on causal inference in epidemiology, computer science, and statistics, with several frameworks proposed and many tools developed for experimental and nonexperimental data.1 This note will introduce the causal diagram framework for encoding causal assumptions, which can be used to guide analysis for drawing causal conclusions. The goal is to give you some basic ideas so that you can learn more from other sources, such as the book Causality by Pearl and the book Causal Inference for Statistics, Social, and Biomedical Sciences: An Introduction by Imbens and Rubin.\nIn this note, we will draw on both frameworks.\nConsider a binary treatment variable. For each individual, there are two potential outcomes: one if they receive the treatment (T = 1) and one if they do not (T = 0). Here is a hypothetical data set of a new drug for improving statistics knowledge, with the treatment condition receiving the drug and the control condition receiving a placebo:\nCodepo_dat &lt;- data.frame(\n    person = c(1, 2, 3, 4, 5, 6, 7, 8),\n    attitude = c(4, 7, 3, 9, 5, 6, 8, 2),\n    treat = c(75, 80, 70, 90, 85, 82, 95, 78),\n    control = c(70, 88, 75, 92, 82, 85, 90, 78)\n)\nknitr::kable(po_dat,\n    col.names = c(\"Person\", \"Math Attitude\", \"Y (if T = 1)\", \"Y (if T = 0)\"))\n\n\n\nPerson\nMath Attitude\nY (if T = 1)\nY (if T = 0)\n\n\n\n1\n4\n75\n70\n\n\n2\n7\n80\n88\n\n\n3\n3\n70\n75\n\n\n4\n9\n90\n92\n\n\n5\n5\n85\n82\n\n\n6\n6\n82\n85\n\n\n7\n8\n95\n90\n\n\n8\n2\n78\n78\nIf one could observe the two potential outcomes for each person (which is impossible in the real world), one could compute the treatment effect for each person:\n(te &lt;- po_dat$treat - po_dat$control)\n\n[1]  5 -8 -5 -2  3 -3  5  0\nand the average treatment effect (ATE) (here we just compute it on the sample, so the sample ATE):\n(ate &lt;- mean(te))\n\n[1] -0.625\nHowever, in practice, we can only observe one of the two potential outcomes. For example, if persons 2, 4, 6, 7 are in the treatment condition, we have\nCodepo_dat$t &lt;- ifelse(po_dat$person %in% c(2, 4, 6, 7), 1, 0)\npo_dat$y &lt;- ifelse(po_dat$t, po_dat$treat, po_dat$control)\npo_dat[c(\"t\", \"y\")] |&gt;\n    knitr::kable(col.names = c(\"Treatment\", \"Observed Y\"))\n\n\n\nTreatment\nObserved Y\n\n\n\n0\n70\n\n\n1\n80\n\n\n0\n75\n\n\n1\n90\n\n\n0\n82\n\n\n1\n82\n\n\n1\n95\n\n\n0\n78\nand the naive comparison of those in the treatment condition and those in the control condition will have a mean difference of\nmean(po_dat$y[po_dat$t == 1]) - mean(po_dat$y[po_dat$t == 0])\n\n[1] 10.5\nwhich gives a misleading estimate of the ATE.",
    "crumbs": [
      "Week 9",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Causal Inference</span>"
    ]
  },
  {
    "objectID": "08-causal-inference.html#directed-acyclic-graph-dag",
    "href": "08-causal-inference.html#directed-acyclic-graph-dag",
    "title": "\n13  Causal Inference\n",
    "section": "\n13.2 Directed Acyclic Graph (DAG)",
    "text": "13.2 Directed Acyclic Graph (DAG)\nDAG is a tool for encoding causal assumptions. It contains nodes and paths. A node is usually a variable that can be measured in the data or unmeasured. Generally, paths in a DAG are directional (as implied by directed), which indicates the directions of causal relations. Acyclic means the causal chain does not close in a loop.\nWe will use an example described in McElreath (2020), chapter 5, about data from 50 U.S. states from the 2009 American Community Survey (ACS), which we have already seen in Chapter 9 and Figure 9.1.\n\nwaffle_divorce &lt;- read_delim(  # read delimited files\n    \"https://raw.githubusercontent.com/rmcelreath/rethinking/master/data/WaffleDivorce.csv\",\n    delim = \";\"\n)\n\nRows: 50 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr  (2): Location, Loc\ndbl (11): Population, MedianAgeMarriage, Marriage, Marriage SE, Divorce, Div...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Rescale Marriage and Divorce by dividing by 10\nwaffle_divorce$Marriage &lt;- waffle_divorce$Marriage / 10\nwaffle_divorce$Divorce &lt;- waffle_divorce$Divorce / 10\nwaffle_divorce$MedianAgeMarriage &lt;- waffle_divorce$MedianAgeMarriage / 10\n# See data description at https://rdrr.io/github/rmcelreath/rethinking/man/WaffleDivorce.html\n\nThe outcome of interest is the divorce rate. Remember the plot shows how marriage rate is related to divorce rate at the state level. It looks like marriage rate can predict divorce rate. A causal interpretation would be a stronger assertion, such that we expect a higher divorce rate if policymakers encourage more people to get married. In order to make a causal claim, we need to remove potential confounders.\nA potential confounder is when people get married. Suppose people are forced to get married later in life. In that case, fewer people in the population will be married, and people may have less time, opportunity, and motivation to get divorced (as it may be harder to find a new partner). Therefore, we can use the following DAG:\n\ndag1 &lt;- dagitty(\"dag{ A -&gt; D; A -&gt; M; M -&gt; D }\")\ncoordinates(dag1) &lt;- list(x = c(M = 0, A = 1, D = 2),\n                          y = c(M = 0, A = 1, D = 0))\n# Plot\nggdag(dag1) + theme_dag()\n\n\n\n\n\n\nFigure 13.1: DAG for the relationship between marriage rate (M) and divorce rate (D) example, with median age of marriage (A) as a potential confounder.\n\n\n\n\nWe can look at how the median age people get married in different states relates to the divorce rate:\n\nggplot(waffle_divorce,\n       aes(x = MedianAgeMarriage, y = Divorce)) +\n    geom_point() +\n    geom_smooth() +\n    labs(x = \"Median age marriage (10 years)\",\n         y = \"Divorce rate (per 10 adults)\") +\n    ggrepel::geom_text_repel(aes(label = Loc))\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\nFigure 13.2: Scatter plot of divorce rate (y) vs median age of marriage (x).\n\n\n\n\n\n13.2.1 Assumptions in a DAG\nIn a graphical model, there are usually two kinds of assumptions conveyed. Perhaps counterintuitively, the weaker assumptions are the ones you can see, whereas the stronger assumptions are ones you do not see.\nFor example, a weak assumption is:\n\nMarriage age may directly influence the number of people who are married\n\nOn the other hand, examples of a strong assumption are:\n\nMarriage rate does not directly influence the age people get married\nthere is no other variable in the causal pathway M → D\n\nThe last assumption will not hold if there is a common cause of M and D other than A.\n\n13.2.2 Basic Types of Junctions\n\nFork: A ← B → C\n\nA and C are correlated due to a common cause B\n\n\nChain/Pipe: A → B → C\n\nB is on the causal pathway of A to C\n\n\nCollider: A → B ← C\n\nB is a descendant of both A and C\n\n\n\nGoing back to our example, there is a fork relation: M → A → D. In this case, A is a confounder when estimating the causal relation between M and D. In this case, the causal effect of M to D can be obtained by adjusting for A, which means looking at the subsets of data where A is constant. In regression, adjustment is obtained by including both M and A as predictors of D.",
    "crumbs": [
      "Week 9",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Causal Inference</span>"
    ]
  },
  {
    "objectID": "08-causal-inference.html#the-back-door-criterion-estimating-causal-effect-in-nonexperimental-data",
    "href": "08-causal-inference.html#the-back-door-criterion-estimating-causal-effect-in-nonexperimental-data",
    "title": "\n13  Causal Inference\n",
    "section": "\n13.3 The Back-Door Criterion: Estimating Causal Effect in Nonexperimental Data",
    "text": "13.3 The Back-Door Criterion: Estimating Causal Effect in Nonexperimental Data\nRandomization is one—but not the only—way to rule out confounding variables. Much progress has been made in clarifying that causal effects can be estimated in nonexperimental data. After all, researchers have not randomly assigned individuals to smoke \\(x\\) cigarettes per day, but we are confident that smoking causes cancer; we never manipulated the moon’s gravitational force, but we are pretty sure that the moon is a cause of high and low tides.\nIn a DAG, the back-door criterion can be used to identify variables that we should adjust for to obtain a causal effect. The set of variables to be adjusted should (a) blocks every path between X and Y that contains an arrow entering X and (b) does not contain variables that are descendant of X.\n\ndag4 &lt;- dagitty(\n    \"dag{\n      X -&gt; Y; W1 -&gt; X; U -&gt; W2; W2 -&gt; X; W1 -&gt; Y; U -&gt; Y\n    }\"\n)\nlatents(dag4) &lt;- \"U\"\ncoordinates(dag4) &lt;- list(x = c(X = 0, W1 = 0.66, U = 1.32, W2 = 0.66, Y = 2),\n                          y = c(X = 0, W1 = 1, U = 1, W2 = 0.5, Y = 0))\nggdag(dag4) + theme_dag()\n\n\n\n\n\n\nFigure 13.3: DAG for a hypothetical model with two measured and one unobserved confounder.\n\n\n\n\nWe can use a function in the daggity package to identify the set of variables that satisfy the back-door criterion. In this case, we say that X and Y are \\(d\\)-separated by this set of adjusted variables:\n\nadjustmentSets(dag4, exposure = \"X\", outcome = \"Y\",\n               effect = \"direct\")\n\n{ W1, W2 }",
    "crumbs": [
      "Week 9",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Causal Inference</span>"
    ]
  },
  {
    "objectID": "08-causal-inference.html#using-multiple-regression-model",
    "href": "08-causal-inference.html#using-multiple-regression-model",
    "title": "\n13  Causal Inference\n",
    "section": "\n13.4 Using Multiple Regression Model",
    "text": "13.4 Using Multiple Regression Model\n\\[\n  \\begin{aligned}\n    D_i & \\sim N(\\mu_i, \\sigma)  \\\\\n    \\mu_i & = \\beta_0 + \\beta_1 A_i + \\beta_2 M_i \\\\\n    \\beta_0 & \\sim N(0, 1) \\\\\n    \\beta_1 & \\sim N(0, 1) \\\\\n    \\beta_2 & \\sim N(0, 1) \\\\\n  \\end{aligned}\n\\]\nAssuming a correctly specified DAG, all all assumptions of a linear model are met, \\(\\beta_2\\) is the causal effect of M on D. Here is the brms code:\n\nm1 &lt;- brm(Divorce ~ MedianAgeMarriage + Marriage,\n          data = waffle_divorce,\n          prior = prior(std_normal(), class = \"b\") +\n              prior(normal(0, 5), class = \"Intercept\") +\n              prior(student_t(4, 0, 3), class = \"sigma\"),\n          seed = 941,\n          iter = 4000,\n          file = \"08_m1\"\n)\n\nStart sampling\n\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 4000 [  2%]  (Warmup) \nChain 1 Iteration:  200 / 4000 [  5%]  (Warmup) \nChain 1 Iteration:  300 / 4000 [  7%]  (Warmup) \nChain 1 Iteration:  400 / 4000 [ 10%]  (Warmup) \nChain 1 Iteration:  500 / 4000 [ 12%]  (Warmup) \nChain 1 Iteration:  600 / 4000 [ 15%]  (Warmup) \nChain 1 Iteration:  700 / 4000 [ 17%]  (Warmup) \nChain 1 Iteration:  800 / 4000 [ 20%]  (Warmup) \nChain 1 Iteration:  900 / 4000 [ 22%]  (Warmup) \nChain 1 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 1 Iteration: 1100 / 4000 [ 27%]  (Warmup) \nChain 1 Iteration: 1200 / 4000 [ 30%]  (Warmup) \nChain 1 Iteration: 1300 / 4000 [ 32%]  (Warmup) \nChain 1 Iteration: 1400 / 4000 [ 35%]  (Warmup) \nChain 1 Iteration: 1500 / 4000 [ 37%]  (Warmup) \nChain 1 Iteration: 1600 / 4000 [ 40%]  (Warmup) \nChain 1 Iteration: 1700 / 4000 [ 42%]  (Warmup) \nChain 1 Iteration: 1800 / 4000 [ 45%]  (Warmup) \nChain 1 Iteration: 1900 / 4000 [ 47%]  (Warmup) \nChain 1 Iteration: 2000 / 4000 [ 50%]  (Warmup) \nChain 1 Iteration: 2001 / 4000 [ 50%]  (Sampling) \nChain 1 Iteration: 2100 / 4000 [ 52%]  (Sampling) \nChain 1 Iteration: 2200 / 4000 [ 55%]  (Sampling) \nChain 1 Iteration: 2300 / 4000 [ 57%]  (Sampling) \nChain 1 Iteration: 2400 / 4000 [ 60%]  (Sampling) \nChain 1 Iteration: 2500 / 4000 [ 62%]  (Sampling) \nChain 1 Iteration: 2600 / 4000 [ 65%]  (Sampling) \nChain 1 Iteration: 2700 / 4000 [ 67%]  (Sampling) \nChain 1 Iteration: 2800 / 4000 [ 70%]  (Sampling) \nChain 1 Iteration: 2900 / 4000 [ 72%]  (Sampling) \nChain 1 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 1 Iteration: 3100 / 4000 [ 77%]  (Sampling) \nChain 1 Iteration: 3200 / 4000 [ 80%]  (Sampling) \nChain 1 Iteration: 3300 / 4000 [ 82%]  (Sampling) \nChain 1 Iteration: 3400 / 4000 [ 85%]  (Sampling) \nChain 1 Iteration: 3500 / 4000 [ 87%]  (Sampling) \nChain 1 Iteration: 3600 / 4000 [ 90%]  (Sampling) \nChain 1 Iteration: 3700 / 4000 [ 92%]  (Sampling) \nChain 1 Iteration: 3800 / 4000 [ 95%]  (Sampling) \nChain 1 Iteration: 3900 / 4000 [ 97%]  (Sampling) \nChain 1 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 4000 [  2%]  (Warmup) \nChain 2 Iteration:  200 / 4000 [  5%]  (Warmup) \nChain 2 Iteration:  300 / 4000 [  7%]  (Warmup) \nChain 2 Iteration:  400 / 4000 [ 10%]  (Warmup) \nChain 2 Iteration:  500 / 4000 [ 12%]  (Warmup) \nChain 2 Iteration:  600 / 4000 [ 15%]  (Warmup) \nChain 2 Iteration:  700 / 4000 [ 17%]  (Warmup) \nChain 2 Iteration:  800 / 4000 [ 20%]  (Warmup) \nChain 2 Iteration:  900 / 4000 [ 22%]  (Warmup) \nChain 2 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 2 Iteration: 1100 / 4000 [ 27%]  (Warmup) \nChain 2 Iteration: 1200 / 4000 [ 30%]  (Warmup) \nChain 2 Iteration: 1300 / 4000 [ 32%]  (Warmup) \nChain 2 Iteration: 1400 / 4000 [ 35%]  (Warmup) \nChain 2 Iteration: 1500 / 4000 [ 37%]  (Warmup) \nChain 2 Iteration: 1600 / 4000 [ 40%]  (Warmup) \nChain 2 Iteration: 1700 / 4000 [ 42%]  (Warmup) \nChain 2 Iteration: 1800 / 4000 [ 45%]  (Warmup) \nChain 2 Iteration: 1900 / 4000 [ 47%]  (Warmup) \nChain 2 Iteration: 2000 / 4000 [ 50%]  (Warmup) \nChain 2 Iteration: 2001 / 4000 [ 50%]  (Sampling) \nChain 2 Iteration: 2100 / 4000 [ 52%]  (Sampling) \nChain 2 Iteration: 2200 / 4000 [ 55%]  (Sampling) \nChain 2 Iteration: 2300 / 4000 [ 57%]  (Sampling) \nChain 2 Iteration: 2400 / 4000 [ 60%]  (Sampling) \nChain 2 Iteration: 2500 / 4000 [ 62%]  (Sampling) \nChain 2 Iteration: 2600 / 4000 [ 65%]  (Sampling) \nChain 2 Iteration: 2700 / 4000 [ 67%]  (Sampling) \nChain 2 Iteration: 2800 / 4000 [ 70%]  (Sampling) \nChain 2 Iteration: 2900 / 4000 [ 72%]  (Sampling) \nChain 2 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 2 Iteration: 3100 / 4000 [ 77%]  (Sampling) \nChain 2 Iteration: 3200 / 4000 [ 80%]  (Sampling) \nChain 2 Iteration: 3300 / 4000 [ 82%]  (Sampling) \nChain 2 Iteration: 3400 / 4000 [ 85%]  (Sampling) \nChain 2 Iteration: 3500 / 4000 [ 87%]  (Sampling) \nChain 2 Iteration: 3600 / 4000 [ 90%]  (Sampling) \nChain 2 Iteration: 3700 / 4000 [ 92%]  (Sampling) \nChain 2 Iteration: 3800 / 4000 [ 95%]  (Sampling) \nChain 2 Iteration: 3900 / 4000 [ 97%]  (Sampling) \nChain 2 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 4000 [  2%]  (Warmup) \nChain 3 Iteration:  200 / 4000 [  5%]  (Warmup) \nChain 3 Iteration:  300 / 4000 [  7%]  (Warmup) \nChain 3 Iteration:  400 / 4000 [ 10%]  (Warmup) \nChain 3 Iteration:  500 / 4000 [ 12%]  (Warmup) \nChain 3 Iteration:  600 / 4000 [ 15%]  (Warmup) \nChain 3 Iteration:  700 / 4000 [ 17%]  (Warmup) \nChain 3 Iteration:  800 / 4000 [ 20%]  (Warmup) \nChain 3 Iteration:  900 / 4000 [ 22%]  (Warmup) \nChain 3 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 3 Iteration: 1100 / 4000 [ 27%]  (Warmup) \nChain 3 Iteration: 1200 / 4000 [ 30%]  (Warmup) \nChain 3 Iteration: 1300 / 4000 [ 32%]  (Warmup) \nChain 3 Iteration: 1400 / 4000 [ 35%]  (Warmup) \nChain 3 Iteration: 1500 / 4000 [ 37%]  (Warmup) \nChain 3 Iteration: 1600 / 4000 [ 40%]  (Warmup) \nChain 3 Iteration: 1700 / 4000 [ 42%]  (Warmup) \nChain 3 Iteration: 1800 / 4000 [ 45%]  (Warmup) \nChain 3 Iteration: 1900 / 4000 [ 47%]  (Warmup) \nChain 3 Iteration: 2000 / 4000 [ 50%]  (Warmup) \nChain 3 Iteration: 2001 / 4000 [ 50%]  (Sampling) \nChain 3 Iteration: 2100 / 4000 [ 52%]  (Sampling) \nChain 3 Iteration: 2200 / 4000 [ 55%]  (Sampling) \nChain 3 Iteration: 2300 / 4000 [ 57%]  (Sampling) \nChain 3 Iteration: 2400 / 4000 [ 60%]  (Sampling) \nChain 3 Iteration: 2500 / 4000 [ 62%]  (Sampling) \nChain 3 Iteration: 2600 / 4000 [ 65%]  (Sampling) \nChain 3 Iteration: 2700 / 4000 [ 67%]  (Sampling) \nChain 3 Iteration: 2800 / 4000 [ 70%]  (Sampling) \nChain 3 Iteration: 2900 / 4000 [ 72%]  (Sampling) \nChain 3 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 3 Iteration: 3100 / 4000 [ 77%]  (Sampling) \nChain 3 Iteration: 3200 / 4000 [ 80%]  (Sampling) \nChain 3 Iteration: 3300 / 4000 [ 82%]  (Sampling) \nChain 3 Iteration: 3400 / 4000 [ 85%]  (Sampling) \nChain 3 Iteration: 3500 / 4000 [ 87%]  (Sampling) \nChain 3 Iteration: 3600 / 4000 [ 90%]  (Sampling) \nChain 3 Iteration: 3700 / 4000 [ 92%]  (Sampling) \nChain 3 Iteration: 3800 / 4000 [ 95%]  (Sampling) \nChain 3 Iteration: 3900 / 4000 [ 97%]  (Sampling) \nChain 3 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 3 finished in 0.1 seconds.\nChain 4 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 4000 [  2%]  (Warmup) \nChain 4 Iteration:  200 / 4000 [  5%]  (Warmup) \nChain 4 Iteration:  300 / 4000 [  7%]  (Warmup) \nChain 4 Iteration:  400 / 4000 [ 10%]  (Warmup) \nChain 4 Iteration:  500 / 4000 [ 12%]  (Warmup) \nChain 4 Iteration:  600 / 4000 [ 15%]  (Warmup) \nChain 4 Iteration:  700 / 4000 [ 17%]  (Warmup) \nChain 4 Iteration:  800 / 4000 [ 20%]  (Warmup) \nChain 4 Iteration:  900 / 4000 [ 22%]  (Warmup) \nChain 4 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 4 Iteration: 1100 / 4000 [ 27%]  (Warmup) \nChain 4 Iteration: 1200 / 4000 [ 30%]  (Warmup) \nChain 4 Iteration: 1300 / 4000 [ 32%]  (Warmup) \nChain 4 Iteration: 1400 / 4000 [ 35%]  (Warmup) \nChain 4 Iteration: 1500 / 4000 [ 37%]  (Warmup) \nChain 4 Iteration: 1600 / 4000 [ 40%]  (Warmup) \nChain 4 Iteration: 1700 / 4000 [ 42%]  (Warmup) \nChain 4 Iteration: 1800 / 4000 [ 45%]  (Warmup) \nChain 4 Iteration: 1900 / 4000 [ 47%]  (Warmup) \nChain 4 Iteration: 2000 / 4000 [ 50%]  (Warmup) \nChain 4 Iteration: 2001 / 4000 [ 50%]  (Sampling) \nChain 4 Iteration: 2100 / 4000 [ 52%]  (Sampling) \nChain 4 Iteration: 2200 / 4000 [ 55%]  (Sampling) \nChain 4 Iteration: 2300 / 4000 [ 57%]  (Sampling) \nChain 4 Iteration: 2400 / 4000 [ 60%]  (Sampling) \nChain 4 Iteration: 2500 / 4000 [ 62%]  (Sampling) \nChain 4 Iteration: 2600 / 4000 [ 65%]  (Sampling) \nChain 4 Iteration: 2700 / 4000 [ 67%]  (Sampling) \nChain 4 Iteration: 2800 / 4000 [ 70%]  (Sampling) \nChain 4 Iteration: 2900 / 4000 [ 72%]  (Sampling) \nChain 4 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 4 Iteration: 3100 / 4000 [ 77%]  (Sampling) \nChain 4 Iteration: 3200 / 4000 [ 80%]  (Sampling) \nChain 4 Iteration: 3300 / 4000 [ 82%]  (Sampling) \nChain 4 Iteration: 3400 / 4000 [ 85%]  (Sampling) \nChain 4 Iteration: 3500 / 4000 [ 87%]  (Sampling) \nChain 4 Iteration: 3600 / 4000 [ 90%]  (Sampling) \nChain 4 Iteration: 3700 / 4000 [ 92%]  (Sampling) \nChain 4 Iteration: 3800 / 4000 [ 95%]  (Sampling) \nChain 4 Iteration: 3900 / 4000 [ 97%]  (Sampling) \nChain 4 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.6 seconds.\n\n\nLoading required package: rstan\n\n\nLoading required package: StanHeaders\n\n\n\nrstan version 2.32.5 (Stan version 2.32.2)\n\n\nFor execution on a local, multicore CPU with excess RAM we recommend calling\noptions(mc.cores = parallel::detectCores()).\nTo avoid recompilation of unchanged Stan programs, we recommend calling\nrstan_options(auto_write = TRUE)\nFor within-chain threading using `reduce_sum()` or `map_rect()` Stan functions,\nchange `threads_per_chain` option:\nrstan_options(threads_per_chain = 1)\n\n\n\nAttaching package: 'rstan'\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\n\n\n13.4.1 Table\n\nmsummary(m1,\n         estimate = \"{estimate} [{conf.low}, {conf.high}]\",\n         statistic = NULL, fmt = 2\n)\n\nWarning: \n`modelsummary` uses the `performance` package to extract goodness-of-fit\nstatistics from models of this class. You can specify the statistics you wish\nto compute by supplying a `metrics` argument to `modelsummary`, which will then\npush it forward to `performance`. Acceptable values are: \"all\", \"common\",\n\"none\", or a character vector of metrics names. For example: `modelsummary(mod,\nmetrics = c(\"RMSE\", \"R2\")` Note that some metrics are computationally\nexpensive. See `?performance::performance` for details.\n This warning appears once per session.\n\n\n\nTable 13.1: Model results for the divorce rate example.\n\n\n\n\n\n (1)\n\n\n\nb_Intercept\n3.49 [1.98, 5.02]\n\n\nb_MedianAgeMarriage\n−0.93 [−1.43, −0.45]\n\n\nb_Marriage\n−0.04 [−0.20, 0.12]\n\n\nsigma\n0.15 [0.12, 0.19]\n\n\nNum.Obs.\n50\n\n\nR2\n0.349\n\n\nR2 Adj.\n0.283\n\n\nELPD\n21.0\n\n\nELPD s.e.\n6.4\n\n\nLOOIC\n−42.0\n\n\nLOOIC s.e.\n12.9\n\n\nWAIC\n−42.2\n\n\nRMSE\n0.14\n\n\n\n\n\n\n\n\nAs shown in the table, when holding constant the median marriage age of states, marriage rate has only a small effect on divorce rate.\n\n13.4.2 Posterior predictive checks\npp_check(m1, ndraws = 100) # density\npp_check(m1, type = \"intervals\", x = \"Marriage\") +\n    labs(x = \"Marriage\", y = \"Divorce\")\n\nUsing all posterior draws for ppc type 'intervals' by default.\n\npp_check(m1, type = \"intervals\", x = \"MedianAgeMarriage\") +\n    labs(x = \"MedianAgeMarriage\", y = \"Divorce\")\n\nUsing all posterior draws for ppc type 'intervals' by default.\n\n\n\n\n\n\n\n\n\n\n(a) Posterior predictive density of divorce rate.\n\n\n\n\n\n\n\n\n\n(b) Posterior predictive intervals of marriage rate predicting divorce rate.\n\n\n\n\n\n\n\n\n\n\n\n(c) Posterior predictive intervals of median marriage age predicting marriage rate.\n\n\n\n\n\n\nFigure 13.4: Posterior predictive checks for the multiple regression model.\n\n\nThe model does not fit every state (e.g., UT, ME, ID).",
    "crumbs": [
      "Week 9",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Causal Inference</span>"
    ]
  },
  {
    "objectID": "08-causal-inference.html#predicting-an-intervention",
    "href": "08-causal-inference.html#predicting-an-intervention",
    "title": "\n13  Causal Inference\n",
    "section": "\n13.5 Predicting an Intervention",
    "text": "13.5 Predicting an Intervention\nIf the causal assumption in our DAG is reasonable, we have obtained an estimate of the causal effect of marriage rate on divorce rate at the state level. This allows us to answer questions like\n\nWhat would happen to the divorce rate if we encouraged more people to get married (so the marriage rate would increase by 10 percentage points)?\n\nWe can use the Bayesian model, which is generative, to make such predictions. Consider a state with a marriage rate of 2 (per 10 adults). The predicted divorce rate is\n\\[\n\\beta_0 + \\beta_1 A + \\beta_2 (2)\n\\]\nConsider an intervention that increases the marriage rate from 2 to 3. The predicted divorce rate will be\n\\[\n\\beta_0 + \\beta_1 A + \\beta_2 (3)\n\\]\nThe change in divorce rate is\n\\[\n\\beta_0 + \\beta_1 A + \\beta_2 (3) - \\beta_0 + \\beta_1 A + \\beta_2 (2) = \\beta_2\n\\]\nHere is what the model would predict in terms of the change in the divorce rate (holding median marriage age to 25 years old), using R:\n\npred_df &lt;- data.frame(\n    Marriage = c(2, 3),\n    MedianAgeMarriage = c(2.5, 2.5)\n)\ncbind(pred_df, fitted(m1, newdata = pred_df)) %&gt;%\n    knitr::kable(digits = 3)\n\n\n\nMarriage\nMedianAgeMarriage\nEstimate\nEst.Error\nQ2.5\nQ97.5\n\n\n\n2\n2.5\n1.068\n0.035\n1.002\n1.138\n\n\n3\n2.5\n1.026\n0.067\n0.894\n1.160\n\n\n\n\n\nThe difference should be just the estimate of \\(\\beta_2\\), which has the following posterior distribution:\n\nmcmc_dens(m1, pars = \"b_Marriage\")\n\n\n\n\n\n\nFigure 13.5: Estimated “causal” effect of marriage rate on divorce rate, based on the specified DAG and a linear model.",
    "crumbs": [
      "Week 9",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Causal Inference</span>"
    ]
  },
  {
    "objectID": "08-causal-inference.html#collider",
    "href": "08-causal-inference.html#collider",
    "title": "\n13  Causal Inference\n",
    "section": "\n13.6 Collider",
    "text": "13.6 Collider\nA collider is a descendant of two parent nodes. When one holds the collider constant, it induces a spurious association between the parents. This leads to many unexpected results in data analysis and daily life. For example, consider people who are nice and who are good-looking. Is there an association between a person being nice and a person being good-looking? Maybe. But this association can be induced when we condition on a collider. Let’s say a friend of yours only dates people who are either nice or good-looking. So we have this colliding relation:\nNice → Dating ← Good looking\nSuppose you look at just the people that your friend dated. In that case, they are either nice or good-looking, but the fact that you select to look at (condition on) only the people that your friend dated would automatically eliminate people who are neither nice nor good-looking. This induces a spurious negative association between nice and good-looking, so your friend may believe that nice people would be less likely to have appearances that fit their taste, and vice versa.\nAs another example, is research that is newsworthy less trustworthy? There could be a negative association due to collider bias, because people who select research to be reported, funded, or published, consider both newsworthiness and trustworthiness. Assume that trustworthiness has no causal relation with newsworthiness, below shows what happens when we only focus on papers that are either high on newsworthiness or trustworthiness:\n\nCodeset.seed(2221) # different seed from the text\nnum_proposals &lt;- 200 # number of grant proposals\nprop_selected &lt;- 0.1 # proportion to select\n# Simulate independent newsworthiness and trustworthiness\nplot_dat &lt;- data.frame(\n    nw = rnorm(num_proposals),\n    tw = rnorm(num_proposals)\n)\nplot_dat &lt;- plot_dat |&gt;\n    mutate(total = nw + tw)\nsel_dat &lt;- plot_dat |&gt;\n    # select top 10% of combined scores\n    slice_max(order_by = total, prop = prop_selected)\nplot_dat |&gt;\n    ggplot(aes(x = nw, y = tw)) +\n    geom_point() +\n    geom_point(data = sel_dat, shape = 1, size = 3,\n               color = \"red\") +\n    geom_smooth(method = \"lm\", se = FALSE) +\n    geom_smooth(data = sel_dat, method = \"lm\", se = FALSE,\n                col = \"purple\") +\n    labs(x = \"newsworthiness\", y = \"trustworthiness\")\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\nFigure 13.6: Simulation of newsworthiness and trustworthiness.\n\n\n\n\nAs you can see, a negative correlation happens. This is collider bias: spurious correlation due to conditioning on the common descendant. This also goes by the name Berkson’s Paradox.\nIn the DAG below, X and Y have no causal association. Conditioning on S, however, induces a negative correlation between X and Y. With the DAG below,\n\n\n\n\n\n\nGenerally speaking, do not condition on a collider, unless you’re going to de-confound the spurious association using other variables.\n\n\n\n\nCodedag7 &lt;- dagitty(\n    \"dag{\n      X -&gt; Y; X -&gt; S; Y -&gt; S\n    }\"\n)\ncoordinates(dag7) &lt;- list(x = c(X = 0, S = 1, Y = 2),\n                          y = c(X = 0, S = -1, Y = 0))\nggdag(dag7) + theme_dag()\n\n\n\n\n\n\nFigure 13.7: DAG with collider bias.\n\n\n\n\n\n\n\n\n\n\nAge and Happiness, conditioned on Marital Status (Example from text)\n\n\n\nIn this example, we assume that age and happiness are not related, but as people age, they are more likely to get married.\n\nCode# Code adapted from the rethinking package (https://github.com/rmcelreath/rethinking/blob/master/R/sim_happiness.R)\nsim_happiness &lt;- function(seed = 1977, N_years = 100,\n                          max_age = 65, N_births = 50,\n                          aom = 18) {\n    set.seed(seed)\n    H &lt;- M &lt;- A &lt;- c()\n    for (t in seq_len(N_years)) {\n        A &lt;- A + 1 # age existing individuals\n        A &lt;- c(A, rep(1, N_births)) # newborns\n        H &lt;- c(H, seq(from = 1, to = 5, length.out = N_births)) # sim happiness trait - never changes\n        M &lt;- c(M, rep(0, N_births)) # not yet married\n        # for each person over 17, chance get married\n        M[A &gt;= aom & M == 0] &lt;- \n            rbinom(A[A &gt;= aom & M == 0], size = 1,\n                   prob = plogis(H[A &gt;= aom & M == 0] - 7.9))\n        # mortality\n        deaths &lt;- which(A &gt; max_age)\n        if (length(deaths) &gt; 0) {\n            A &lt;- A[-deaths]\n            H &lt;- H[-deaths]\n            M &lt;- M[-deaths]\n        }\n    }\n    d &lt;- data.frame(age = A, married = M, happiness = H)\n    return(d)\n}\ndd &lt;- sim_happiness(2024, N_years = 100)\n\n\n\nggplot(dd, aes(x = age, y = happiness)) +\n    geom_point(alpha = .1, size = .5)\n\n\n\n\n\n\nFigure 13.8: Age and happiness.\n\n\n\n\n\nggplot(dd[dd$married == 1, ], aes(x = age, y = happiness)) +\n    geom_point(alpha = .5, size = .5)\n\n\n\n\n\n\nFigure 13.9: Age and happiness, conditioned on married couples.\n\n\n\n\n\n\nSome other collider examples:\n\nimpulsivity → high-risk youth ← delinquency\nhealthcare worker → COVID-19 testing ← COVID-19 severity\nstandardized test → admission ← research skills\nmaternal smoking → birth weight → birth defect ← mortality",
    "crumbs": [
      "Week 9",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Causal Inference</span>"
    ]
  },
  {
    "objectID": "08-causal-inference.html#some-additional-references",
    "href": "08-causal-inference.html#some-additional-references",
    "title": "\n13  Causal Inference\n",
    "section": "\n13.7 Some Additional References",
    "text": "13.7 Some Additional References\n\nhttps://doi.org/10.1177/25152459221095823\nhttps://doi.org/10.1038/s41562-024-01939-z\n\n\n\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: a Bayesian course with examples in R and Stan (Second edition). CRC Press.",
    "crumbs": [
      "Week 9",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Causal Inference</span>"
    ]
  },
  {
    "objectID": "08-causal-inference.html#footnotes",
    "href": "08-causal-inference.html#footnotes",
    "title": "\n13  Causal Inference\n",
    "section": "",
    "text": "See this paper: https://doi.org/10.1177/1745691620921521 for an argument of how the taboo against causal inference has impeded the progress of psychology research.↩︎",
    "crumbs": [
      "Week 9",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Causal Inference</span>"
    ]
  },
  {
    "objectID": "08b-mediation.html",
    "href": "08b-mediation.html",
    "title": "\n14  Mediation\n",
    "section": "",
    "text": "14.1 Summary Statistics Tables\nWe’ll use the framing data set from the mediation package, so you’ll need to have the package installed first. The data were analyzed in a report in the American Journal of Political Science. The study examined whether “news about the costs of immigration boosts white opposition” (p. 959).\nI’ll take a quick detour to introduce you to some useful functions for tabulating your data. The functions will be from the modelsummary package.\ndata(framing, package = \"mediation\")\n# Subtract the `emo` variable by 3 so that it starts from 0-9\nframing$emo &lt;- framing$emo - 3\n# Quick summary of selected variables\ndatasummary_skim(framing)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnique (#)\nMissing (%)\nMean\nSD\nMin\nMedian\nMax\n\n\n\n\nage\n63\n0\n47.8\n16.0\n18.0\n47.0\n85.0\n\n\n\nincome\n19\n0\n10.8\n3.9\n1.0\n11.0\n19.0\n\n\n\nemo\n10\n0\n4.0\n2.8\n0.0\n4.0\n9.0\n\n\n\np_harm\n7\n0\n5.9\n1.8\n2.0\n6.0\n8.0\n\n\n\ntone\n2\n0\n0.5\n0.5\n0.0\n1.0\n1.0\n\n\n\neth\n2\n0\n0.5\n0.5\n0.0\n1.0\n1.0\n\n\n\ntreat\n2\n0\n0.3\n0.4\n0.0\n0.0\n1.0\n\n\n\nimmigr\n4\n0\n3.0\n1.0\n1.0\n3.0\n4.0\n\n\n\nanti_info\n2\n0\n0.1\n0.3\n0.0\n0.0\n1.0\n\n\n\ncong_mesg\n2\n0\n0.3\n0.5\n0.0\n0.0\n1.0\n\n\n\n\n\n# Summary by treatment condition (`tone`)\ndatasummary_balance(~ tone, data = framing)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n\n\n1\n\n\n\n\n\n\nMean\nStd. Dev.\nMean\nStd. Dev.\nDiff. in Means\nStd. Error\n\n\n\n\nage\n\n48.4\n16.0\n47.1\n16.0\n-1.3\n2.0\n\n\nincome\n\n11.0\n3.9\n10.6\n3.9\n-0.4\n0.5\n\n\nemo\n\n3.4\n2.6\n4.5\n2.8\n1.1\n0.3\n\n\np_harm\n\n5.5\n1.8\n6.2\n1.7\n0.7\n0.2\n\n\neth\n\n0.5\n0.5\n0.5\n0.5\n0.0\n0.1\n\n\ntreat\n\n0.0\n0.0\n0.5\n0.5\n0.5\n0.0\n\n\nimmigr\n\n2.8\n1.0\n3.2\n0.9\n0.4\n0.1\n\n\nanti_info\n\n0.1\n0.3\n0.1\n0.3\n0.0\n0.0\n\n\ncong_mesg\n\n0.3\n0.5\n0.4\n0.5\n0.0\n0.1\n\n\n\n\nN\nPct.\nN\nPct.\n\n\n\n\ncond\nnot asked\n0\n0.0\n0\n0.0\n\n\n\n\n\nrefused\n0\n0.0\n0\n0.0\n\n\n\n\n\ncontrol\n0\n0.0\n0\n0.0\n\n\n\n\n\n1\n0\n0.0\n68\n50.4\n\n\n\n\n\n2\n0\n0.0\n67\n49.6\n\n\n\n\n\n3\n67\n51.5\n0\n0.0\n\n\n\n\n\n4\n63\n48.5\n0\n0.0\n\n\n\n\nanx\nnot asked\n0\n0.0\n0\n0.0\n\n\n\n\n\nrefused\n0\n0.0\n0\n0.0\n\n\n\n\n\nvery anxious\n34\n26.2\n26\n19.3\n\n\n\n\n\nsomewhat anxious\n48\n36.9\n38\n28.1\n\n\n\n\n\na little anxious\n31\n23.8\n43\n31.9\n\n\n\n\n\nnot anxious at all\n17\n13.1\n28\n20.7\n\n\n\n\neduc\nnot asked\n0\n0.0\n0\n0.0\n\n\n\n\n\nrefused\n0\n0.0\n0\n0.0\n\n\n\n\n\nless than high school\n6\n4.6\n14\n10.4\n\n\n\n\n\nhigh school\n48\n36.9\n44\n32.6\n\n\n\n\n\nsome college\n31\n23.8\n39\n28.9\n\n\n\n\n\nbachelor's degree or higher\n45\n34.6\n38\n28.1\n\n\n\n\ngender\nnot asked\n0\n0.0\n0\n0.0\n\n\n\n\n\nrefused\n0\n0.0\n0\n0.0\n\n\n\n\n\nmale\n64\n49.2\n62\n45.9\n\n\n\n\n\nfemale\n66\n50.8\n73\n54.1\n\n\n\n\nenglish\nStrongly Favor\n1\n0.8\n6\n4.4\n\n\n\n\n\nFavor\n15\n11.5\n10\n7.4\n\n\n\n\n\nOppose\n44\n33.8\n38\n28.1\n\n\n\n\n\nStrongly Oppose\n70\n53.8\n81\n60.0\n\n\n\n\n\n\n# More tailor-made table with selected variables by treatment condition\ndatasummary(emo + p_harm + cong_mesg ~ Factor(tone) * (Mean + SD + Histogram),\n            data = framing)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n\n\n1\n\n\n\n\nMean\nSD\nHistogram\nMean\nSD\nHistogram\n\n\n\n\nemo\n3.39\n2.63\n▇▅▇▆▆▃▃▂▂▂\n4.53\n2.81\n▆▄▆▅▇▇▅▆▄▆\n\n\np_harm\n5.53\n1.77\n▁▃▅▄▇▂▆\n6.23\n1.69\n▁▃▂▅▄▇\n\n\ncong_mesg\n0.31\n0.46\n▇▃\n0.36\n0.48\n▇▄\n\n\n\n\n# Correlation table\nframing |&gt;\n    select(tone, emo, cong_mesg) |&gt;\n    datasummary_correlation(method = \"pearson\")\n\n\n\n\ntone\nemo\ncong_mesg\n\n\n\ntone\n1\n.\n.\n\n\nemo\n.21\n1\n.\n\n\ncong_mesg\n.05\n.37\n1",
    "crumbs": [
      "Week 9",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Mediation</span>"
    ]
  },
  {
    "objectID": "08b-mediation.html#randomization-removes-incoming-paths-for-treatment",
    "href": "08b-mediation.html#randomization-removes-incoming-paths-for-treatment",
    "title": "\n14  Mediation\n",
    "section": "\n14.2 Randomization Removes Incoming Paths for Treatment",
    "text": "14.2 Randomization Removes Incoming Paths for Treatment\nLet’s consider a DAG without randomization, for the following two variables:\n\nX: Exposure to a negatively framed news story about immigrants\nY: Anti-immigration political action\n\nThere are many possible confounders when we observe these two variables in data (e.g., an individual’s political affiliation and the state in which a person resides). We can represent these unobserved confounders as U, so the DAG will be something like\n\ndag2 &lt;- dagitty(\n    \"dag{\n      X -&gt; Y; U -&gt; X; U -&gt; Y\n      U [unobserved]\n    }\"\n)\ncoordinates(dag2) &lt;- list(x = c(X = 0, U = 1, Y = 2),\n                          y = c(X = 0, U = 1, Y = 0))\n# Plot\nggdag(dag2) + theme_dag()\n\n\n\n\n\n\nFigure 14.1: DAG with an unobserved confounder\n\n\n\n\nThe magic of randomization—randomly assigning individuals to a manipulated level of X—is that it blocks the path U → X. Therefore, with randomization, the reason a person sees a negatively-framed news story about immigrants is not related to reasons that the person may have intentions for anti-immigration actions. The DAG becomes\n\ndag3 &lt;- dagitty(\n    \"dag{\n      X -&gt; Y; U -&gt; Y\n      U [unobserved]\n    }\"\n)\ncoordinates(dag3) &lt;- list(x = c(X = 0, U = 1, Y = 2),\n                          y = c(X = 0, U = 1, Y = 0))\n# Plot\nggdag(dag3) + theme_dag()\n\n\n\n\n\n\nFigure 14.2: DAG with randomization\n\n\n\n\nTherefore, when randomization is successful, the path coefficient of X → Y is the causal effect of X on Y. However, randomized experiments do not always rule out all confounding. For example, suppose participants are randomly assigned to different experimental conditions, but those who disagree with the presented news story drop out. In that case, such attrition can induce a non-zero correlation between X and Y in the remaining sample.",
    "crumbs": [
      "Week 9",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Mediation</span>"
    ]
  },
  {
    "objectID": "08b-mediation.html#causal-chains",
    "href": "08b-mediation.html#causal-chains",
    "title": "\n14  Mediation\n",
    "section": "\n14.3 Causal Chains",
    "text": "14.3 Causal Chains\n\n14.3.1 Post-Treatment Bias\nHere are some key variables from the framing data set:\n\n\ncong_mesg: binary variable indicating whether or not the participant agreed to send a letter about immigration policy to his or her member of Congress\n\nemo: posttest anxiety about increased immigration (0-9)\n\ntone: framing of news story (0 = positive, 1 = negative)\n\nWe can compare the results of two models:\n\n\ntone → cong_mesg\n\n\ntone → cong_mesg, adjusting for emo\n\n\nWhich model gives us the causal effect estimate for tone? Let’s run the two models.\n\nm_no_adjust &lt;- brm(cong_mesg ~ tone,\n                   data = framing,\n                   family = bernoulli(link = \"logit\"),\n                   file = \"08b_m_no_adjust\")\n\nStart sampling\n\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.1 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.1 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.1 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.6 seconds.\n\n\nLoading required package: rstan\n\n\nLoading required package: StanHeaders\n\n\n\nrstan version 2.32.5 (Stan version 2.32.2)\n\n\nFor execution on a local, multicore CPU with excess RAM we recommend calling\noptions(mc.cores = parallel::detectCores()).\nTo avoid recompilation of unchanged Stan programs, we recommend calling\nrstan_options(auto_write = TRUE)\nFor within-chain threading using `reduce_sum()` or `map_rect()` Stan functions,\nchange `threads_per_chain` option:\nrstan_options(threads_per_chain = 1)\n\n\n\nAttaching package: 'rstan'\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\nm_adjust &lt;- brm(cong_mesg ~ tone + emo,\n                data = framing,\n                family = bernoulli(link = \"logit\"),\n                file = \"08b_m_adjust\")\n\nStart sampling\n\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.1 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.1 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.1 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.5 seconds.\n\n\nWe can combine the results in a table:\n\nmsummary(list(`No adjustment` = m_no_adjust,\n              `Adjusting for feeling` = m_adjust),\n         estimate = \"{estimate} [{conf.low}, {conf.high}]\",\n         statistic = NULL, fmt = 2\n)\n\nWarning: \n`modelsummary` uses the `performance` package to extract goodness-of-fit\nstatistics from models of this class. You can specify the statistics you wish\nto compute by supplying a `metrics` argument to `modelsummary`, which will then\npush it forward to `performance`. Acceptable values are: \"all\", \"common\",\n\"none\", or a character vector of metrics names. For example: `modelsummary(mod,\nmetrics = c(\"RMSE\", \"R2\")` Note that some metrics are computationally\nexpensive. See `?performance::performance` for details.\n This warning appears once per session.\n\n\n\n\n\nNo adjustment\nAdjusting for feeling\n\n\n\nb_Intercept\n−0.81 [−1.19, −0.46]\n−2.00 [−2.63, −1.44]\n\n\nb_tone\n0.21 [−0.28, 0.71]\n−0.13 [−0.71, 0.43]\n\n\nb_emo\n\n0.32 [0.21, 0.43]\n\n\nNum.Obs.\n265\n265\n\n\nR2\n0.003\n0.142\n\n\nELPD\n−170.1\n−152.6\n\n\nELPD s.e.\n5.5\n7.4\n\n\nLOOIC\n340.2\n305.2\n\n\nLOOIC s.e.\n11.0\n14.8\n\n\nWAIC\n340.2\n305.2\n\n\nRMSE\n0.47\n0.44\n\n\n\n\n\nWe can see that the Bayes estimate of the coefficient for tone was positive without emo, but was negative with emo. Which one should we believe? The information criteria (LOOIC and WAIC) suggested that the model with emo was better for prediction, but just because something helps predict the outcome does not make it a causal variable. To repeat,\n\nCoefficients in a predictive model are not causal effects.\n\nAnd to emphasize again,\n\nCausal inference requires causal assumptions, and these assumptions are not in the data.\n\nSo instead, we need a DAG. Given that we know emo is measured after the intervention, it seems reasonable to think that a negatively framed story about immigrants would elicit some negative emotions about increased immigration, and that emotion may prompt people to take anti-immigrant actions. Therefore, we have the following DAG:\n\nCodedag5 &lt;- dagitty(\n    \"dag{\n      T -&gt; C; T -&gt; E; E -&gt; C\n    }\"\n)\ncoordinates(dag5) &lt;- list(x = c(T = 0, E = 1, C = 2),\n                          y = c(T = 0, E = 1, C = 0))\n# Plot\nggdag(dag5) + theme_dag()\n\n\nTable 14.1: DAG for a mediation model with emotion as a mediator.\n\n\n\n\n\n\n\n\n\n\n\nThis is an example of a pipe/chain. It is a causal chain going from T(one) → E(motion) → C(ongress message). If we are interested in the causal effect of T, we should not condition on E; conditioning on E would mean comparing those who saw the negatively-framed story and those who saw the positively-framed story but had the same negative emotion towards immigrants. In other words, adjusting for E would mean taking out part of the effect of T on C through E.\nAs another example, think about a drug that is supposed to lower the risk of a heart attack. Imagine someone conducting a study comparing drug/no drug conditions on their probability of getting heart attacks. Should we adjust for participants’ blood pressure after the intervention? If we want to know the drug’s effect, and that the drug works by lowering blood pressure, we should not adjust for posttest blood pressure. Otherwise, we would be asking the question: Does the drug help prevent heart attacks through something other than lowering one’s blood pressure?\nThe latter question can be answered in mediation analysis.",
    "crumbs": [
      "Week 9",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Mediation</span>"
    ]
  },
  {
    "objectID": "08b-mediation.html#causal-mediation",
    "href": "08b-mediation.html#causal-mediation",
    "title": "\n14  Mediation\n",
    "section": "\n14.4 Causal Mediation",
    "text": "14.4 Causal Mediation\nIn the DAG above, E is a post-treatment variable potentially influenced by T, which we call a mediator. Mediator is an important topic in causal inference, as it informs the mechanism of how a variable has a causal effect on an outcome.\nOne thing to be careful of is that, statistically speaking, a mediator behaves very much like a confounder, and their difference is based on causal assumptions.\nLet’s analyze the mediation model in Figure X. There are two variables that are on the receiving end of some causal effects: emo and cong_mesg. Whereas the generalized linear model handles one outcome, with brms, we can have a system of equations—one for each outcome—estimated simultaneously, as shown in the code below.\n\n14.4.1 Using brms\n\n\nm_med &lt;- brm(\n    # Two equations for two outcomes\n    bf(cong_mesg ~ tone + emo) +\n        bf(emo ~ tone) +\n        set_rescor(FALSE),\n    # A list of two family arguments for two outcomes\n    family = list(bernoulli(\"logit\"), gaussian(\"identity\")),\n    data = framing,\n    prior = prior(normal(0, 2), class = \"b\", resp = \"emo\") +\n        prior(student_t(4, 0, 5), class = \"sigma\", resp = \"emo\") +\n        prior(student_t(4, 0, 2.5), class = \"b\", resp = \"congmesg\"),\n    seed = 1338,\n    file = \"08b_m_med\"\n)\n\nStart sampling\n\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.1 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.1 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.1 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.6 seconds.\n\n\n\n14.4.2 Using Stan\nHere’s some Stan code for running the same mediation model\n\ndata {\n    int&lt;lower=0&gt; N0;  // number of observations (control)\n    int&lt;lower=0&gt; N1;  // number of observations (treatment)\n    array[N0] int y0; // outcome (control);\n    array[N1] int y1; // outcome (treatment);\n    vector[N0] m0;    // mediator (control);\n    vector[N1] m1;    // mediator (treatment);\n}\nparameters {\n    real alpham;  // regression intercept for M\n    real alphay;  // regression intercept for M\n    real beta1;   // X -&gt; M\n    real beta2;   // X -&gt; Y\n    real beta3;   // M -&gt; Y\n    real&lt;lower=0&gt; sigmam;  // SD of prediction error for M\n}\nmodel {\n    // model\n    m0 ~ normal(alpham, sigmam);\n    m1 ~ normal(alpham + beta1, sigmam);\n    y0 ~ bernoulli_logit(alphay + beta3 * m0);\n    y1 ~ bernoulli_logit(alphay + beta2 + beta3 * m1);\n    // prior\n    alpham ~ normal(4.5, 4.5);\n    alphay ~ normal(0, 5);\n    beta1 ~ std_normal();\n    beta2 ~ std_normal();\n    beta3 ~ std_normal();\n    sigmam ~ student_t(4, 0, 5);\n}\n\n\nmed_mod &lt;- cmdstan_model(\"stan_code/mediation_logit_normal.stan\")\n\n\n# 1. Form the data list for Stan\nstan_dat &lt;- with(\n    framing,\n    list(\n        N0 = sum(tone == 0),\n        N1 = sum(tone == 1),\n        m0 = emo[which(tone == 0)],\n        m1 = emo[which(tone == 1)],\n        y0 = cong_mesg[which(tone == 0)],\n        y1 = cong_mesg[which(tone == 1)]\n    )\n)\n# 2. Run Stan\nm_med_stan &lt;- med_mod$sample(\n    data = stan_dat,\n    seed = 1338,\n    refresh = 1000\n)\n\n\n14.4.3 Direct and Indirect Effects\nIn a mediation model, the effect of X on Y has two mechanisms: - Indirect effect: X causes Y because X causes M, and M causes Y - Direct effect: X causes Y without involving M\nMore specifically, the direct effect is the change in Y for one unit change in X, holding M constant. In our example, it means comparing subsets of the treatment and the control groups, under the condition that both subsets have the same level of negative emotion about increased immigration. The indirect effect takes more effort to understand: it is the change in Y for the control group (or the treatment group) if their mediator value is set to the same level as the treatment group. In our example, it would mean comparing the control group and the counterfactual where the control group had their negative emotion changed to the same level as the treatment group.\nThe causal mediation literature has more distinctions on the different types of direct and indirect effects. Below, I give codes for obtaining these effects without going into detail.1\n\n14.4.4 Controlled direct effect (CDE)\nCDE is the direct effect when the mediator is set to a specific level. Below is the CDE for emo = 0 and emo = 9, respectively.\n\ncond_df &lt;- data.frame(tone = c(0, 1, 0, 1),\n                      emo = c(0, 0, 9, 9))\ncond_df |&gt;\n    bind_cols(\n        fitted(m_med, newdata = cond_df)[ , , \"congmesg\"]\n    ) |&gt;\n    knitr::kable()\n\n\nTable 14.2: Estimated direct effect of tone on cong_mesg at two different levels of emo.\n\n\n\n\ntone\nemo\nEstimate\nEst.Error\nQ2.5\nQ97.5\n\n\n\n0\n0\n0.1212844\n0.0320367\n0.0662354\n0.1907005\n\n\n1\n0\n0.1084567\n0.0330696\n0.0538386\n0.1830547\n\n\n0\n9\n0.6982051\n0.0698306\n0.5559154\n0.8234034\n\n\n1\n9\n0.6702609\n0.0631406\n0.5418592\n0.7855347\n\n\n\n\n\n\n\n\n\n14.4.5 Natural direct effect (NDE)\nThe “natural” effects are quantities for some kind of population averages. NDE is the direct effect when the mediator is held constant at the level of the control group. As a first step, we need to obtain the potential outcome of emo when tone = 0. We call this potential outcome variable \\(M_0\\) (potential outcome of \\(M\\) if \\(X\\) = 0). This has already been observed for the control group but will be a counterfactual for the treatment group.\nWe will use a general approach by Imai et al. (2010) to simulate potential outcomes for each observation, before computing NDE (and NIE). For each observation, we will first simulate the potential outcome of emo when tone = 0 (\\(M_0\\)), and then simulate the potential outcome of emo when tone = 1 (\\(M_1\\)).\n\n# Simulate potential outcomes for mediator when T = 0\ndat0 &lt;- m_med$data\ndat0$tone &lt;- 0\n# Predicted emo when T = 0\npo_m0 &lt;- posterior_predict(m_med, newdata = dat0, resp = \"emo\")\n# Simulate potential outcomes for mediator when T = 1\ndat1 &lt;- m_med$data\ndat1$tone &lt;- 1\n# Predicted emo when T = 1\npo_m1 &lt;- posterior_predict(m_med, newdata = dat1, resp = \"emo\")\n\nNext, we will simulate four potential outcomes for cong_mesg (Y):\n\nY(T = 0, M = \\(M_0\\))\nY(T = 1, M = \\(M_0\\))\nY(T = 0, M = \\(M_1\\))\nY(T = 1, M = \\(M_1\\))\n\n\nm_med_draws &lt;- as_draws_df(m_med)\n# Predicted logit of congmesg when T = 0 and emo = po_m0\npo_y0_m0 &lt;- m_med_draws$b_congmesg_Intercept + m_med_draws$b_congmesg_emo * po_m0\n# Predicted logit of congmesg when T = 1 and emo = po_m0\npo_y1_m0 &lt;- m_med_draws$b_congmesg_Intercept +\n    m_med_draws$b_congmesg_tone +\n    m_med_draws$b_congmesg_emo * po_m0\n# Predicted logit of congmesg when T = 0 and emo = po_m1\npo_y0_m1 &lt;- m_med_draws$b_congmesg_Intercept + m_med_draws$b_congmesg_emo * po_m1\n# Predicted logit of congmesg when T = 1 and emo = po_m1\npo_y1_m1 &lt;- m_med_draws$b_congmesg_Intercept +\n    m_med_draws$b_congmesg_tone +\n    m_med_draws$b_congmesg_emo * po_m1\n\nThe NDE is defined as Y(T = 1, M = \\(M_0\\)) - Y(T = 0, M = \\(M_0\\)).\n\n# NDE = Y(1, M(0)) - Y(0, M(0))\nnde &lt;- rowMeans(plogis(po_y1_m0)) - rowMeans(plogis(po_y0_m0))\n\n\n14.4.5.1 Natural indirect effect (NIE)\nNIE is the difference in the outcome between the actual control group and a counterfactual control group. The counterfactual here is a control group that did not receive the treatment, but had their emo value set to be equal to the treatment group. The NIE is defined as Y(T = 0, M = \\(M_1\\)) - Y(T = 0, M = \\(M_0\\)).\n\n# NIE = Y(0, M(1)) - Y(0, M(0))\nnie &lt;- rowMeans(plogis(po_y0_m1)) - rowMeans(plogis(po_y0_m0))\n\n\ndraws_nde_nie &lt;- as_draws(list(NDE = nde, NIE = nie))\nposterior::summarise_draws(draws_nde_nie)\n\n\nTable 14.3: Estimated natural direct and indirect effects for the control group.\n\n\n\n  \n\n\n\n\n\n\n\nmcmc_areas(draws_nde_nie, bw = \"SJ\")\n\n\n\n\n\n\nFigure 14.3: Estimated natural direct and indirect effects for the control group.\n\n\n\n\n\n14.4.6 Sensitivity analysis\n\nCodedag6 &lt;- dagitty(\n    \"dag{\n      T -&gt; C; T -&gt; E; E -&gt; C; U -&gt; E; U -&gt; C\n    }\"\n)\ncoordinates(dag6) &lt;- list(x = c(T = 0, E = 1, C = 2, U = 2),\n                          y = c(T = 0, E = 1, C = 0, U = 1))\nggdag(dag6) + theme_dag()\n\n\n\n\n\n\nFigure 14.4: DAG for a mediation model with an unobserved mediator-outcome confounder.\n\n\n\n\n\n\n\n\n\n\nAssumptions of Causal Mediation\n\n\n\nMediation effects can be estimated properly when the causal diagram and the corresponding model are specified correctly. In our model, we assume\n\nNo unmeasured treatment-outcome confounding\nNo unmeasured mediator-outcome confounding\nNo unmeasured treatment-mediator confounding\nThe mediator-outcome path is not moderated by the treatment\n\nNote that randomization of the treatment does not rule out confounding for the mediator-outcome path.\n\n\nOne important assumption in mediation is that there is no unobserved confounding variable between the mediator and the outcome. This assumption requires researchers’ input, as usually we don’t have studies that randomly assign both the treatment variable and the mediator. An additional technique is to ask: what would the effect be if there were unobserved confounding variables of a certain magnitude? With Bayesian, we can represent the strength of the confounding effect by a prior distribution (see McCandless & Somers, 2019, p. 10.1177/0962280217729844). The following shows the mediation estimates assuming the effect of the confounding variable to the mediator is 1, and to the outcome has a prior of N(0.5, 0.2).\n\ndata {\n    int&lt;lower=0&gt; N0;  // number of observations (control)\n    int&lt;lower=0&gt; N1;  // number of observations (treatment)\n    array[N0] int y0; // outcome (control);\n    array[N1] int y1; // outcome (treatment);\n    vector[N0] m0;    // mediator (control);\n    vector[N1] m1;    // mediator (treatment);\n}\nparameters {\n    real alpham;  // regression intercept for M\n    real alphay;  // regression intercept for M\n    real beta1;   // X -&gt; M\n    real beta2;   // X -&gt; Y\n    real beta3;   // M -&gt; Y\n    vector[N0] u0;  // confounding variable\n    vector[N1] u1;  // confounding variable\n    real beta4;   // U -&gt; Y\n    real&lt;lower=0&gt; sigmam;  // SD of prediction error for M\n}\nmodel {\n    // model\n    u0 ~ std_normal();\n    u1 ~ std_normal();\n    m0 ~ normal(alpham + u0, sigmam);\n    m1 ~ normal(alpham + beta1 + u1, sigmam);\n    y0 ~ bernoulli_logit(alphay + beta3 * m0 + beta4 * u0);\n    y1 ~ bernoulli_logit(alphay + beta2 + beta3 * m1 + beta4 * u1);\n    // prior\n    alpham ~ normal(4.5, 4.5);\n    alphay ~ normal(0, 5);\n    beta1 ~ std_normal();\n    beta2 ~ std_normal();\n    beta3 ~ std_normal();\n    beta4 ~ normal(0.5, 0.2);\n    sigmam ~ student_t(4, 0, 5);\n}\n\n\nmed_mod_sens &lt;- cmdstan_model(\"stan_code/mediation_logit_normal_sensitivity.stan\")\n\n\n# 1. form the data list for Stan\nstan_dat &lt;- with(\n    framing,\n    list(\n        N0 = sum(tone == 0),\n        N1 = sum(tone == 1),\n        m0 = emo[which(tone == 0)],\n        m1 = emo[which(tone == 1)],\n        y0 = cong_mesg[which(tone == 0)],\n        y1 = cong_mesg[which(tone == 1)]\n    )\n)\n# 2. Run Stan\nm_med_sens &lt;- med_mod_sens$sample(\n    data = stan_dat,\n    seed = 1338,\n    refresh = 1000\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 1.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 1.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 1.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 1.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 1.0 seconds.\nTotal execution time: 4.4 seconds.\n\n\nbeta1 = tone -&gt; emo; beta2 = tone -&gt; cong_mesg; beta3 = emo -&gt; cong_mesg\n\nm_med_sens$draws(\n    c(\"alpham\", \"alphay\",\n      \"beta1\", \"beta2\", \"beta3\")\n) |&gt;\n    mcmc_intervals()\n\n\n\n\n\n\nFigure 14.5: Estimated coefficients for the mediation model with the sensitivity analysis.\n\n\n\n\nAs you can see, the prior of the confounding effect attenuates the coefficients from the mediator to the outcome, but the path from the mediator to the outcome remains pretty much above zero.\nYou may also check out the BayesGmed package, which is also based on Stan. More descriptions are in the paper Yimer et al. (2023).\n\n\n\n\n\n\nImai, K., Keele, L., & Tingley, D. (2010). A general approach to causal mediation analysis. Psychological Methods, 15(4), 309–334. https://doi.org/10.1037/a0020761\n\n\nMcCandless, L. C., & Somers, J. M. (2019). Bayesian sensitivity analysis for unmeasured confounding in causal mediation analysis. Statistical Methods in Medical Research, 28(2), 515–531. https://doi.org/10.1177/0962280217729844\n\n\nYimer, B. B., Lunt, M., Beasley, M., Macfarlane, G. J., & McBeth, J. (2023). BayesGmed: An R-package for Bayesian causal mediation analysis. PLOS ONE, 18(6), e0287037. https://doi.org/10.1371/journal.pone.0287037",
    "crumbs": [
      "Week 9",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Mediation</span>"
    ]
  },
  {
    "objectID": "08b-mediation.html#footnotes",
    "href": "08b-mediation.html#footnotes",
    "title": "\n14  Mediation\n",
    "section": "",
    "text": "You can find more information about causal mediation in this paper: https://ftp.cs.ucla.edu/pub/stat_ser/r389.pdf↩︎",
    "crumbs": [
      "Week 9",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Mediation</span>"
    ]
  },
  {
    "objectID": "09-mcmc.html",
    "href": "09-mcmc.html",
    "title": "\n15  Markov Chain Monte Carlo\n",
    "section": "",
    "text": "15.1 Monte Carlo Simulation\nPreviously, we have seen a few examples with Bayesian inferences where the posterior distribution concerns only one parameter, like the Bernoulli and the Poisson model. We have also discussed the grid approximation and the conjugate prior approaches to obtain/approximate the posterior. In this note, we will discuss the simulation method and explain why we need a special class of methods called Markov Chain Monte Carlo. This note will consider mainly the Metropolis algorithm, which subsumes many other commonly used MCMC algorithms. Therefore, it is beneficial to build a solid foundation on what the basic version of the Metropolis algorithm is. You will also write your own Metropolis sampler to understand how it works.\nBut first, let’s talk about the Monte Carlo method.\nIn a previous example, we see that with a conjugate prior (e.g., Beta), the posterior distribution is from the same distributional family (Beta). Thus, we can easily draw simulation samples from the posterior distribution using R. The more samples we draw, the better we can approximate the posterior distribution based on the simulation samples. It is the same logic to get a large sample to describe our population precisely; here, the posterior distribution, determined using mathematics, is considered the population, and the simulation draws are, well, a sample from that population. With 10,000 or 100,000 samples (draws), we can accurately describe our population (posterior).\nFor example, if we know that the posterior is a \\(\\mathrm{Beta}(15, 10)\\) distribution, consider drawing 10, 100, 10,00, and 10,000 samples from it using the R function rbeta, and contrast the density estimated from the samples (in the histogram) with that of the actual Beta distribution (in red).\n# Set the `seed` (initial point) for pseudo-random number generation algorithm\nset.seed(2)\nnum_draws &lt;- c(10, 100, 1000, 10000)\nbeta_draws &lt;- data.frame(\n    th = rbeta(sum(num_draws), shape1 = 15, shape2 = 10),\n    sam = rep(paste(num_draws, \"samples\"), num_draws)\n)\nggplot(beta_draws, aes(x = th)) +\n    geom_histogram(aes(y = after_stat(density))) +\n    stat_function(\n        fun = dbeta, args = list(shape1 = 15, shape2 = 10),\n        col = \"red\"\n    ) +\n    labs(x = expression(theta)) +\n    facet_wrap(~sam)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nFigure 15.1: Monte Carlo simulation samples from the Beta(15, 10) distribution\nThe figure below shows the values when drawing 100 samples in time order:\nbeta_draws |&gt;\n    filter(sam == \"100 samples\") |&gt;\n    rowid_to_column(\"iter\") |&gt;\n    ggplot(aes(y = th, x = iter)) +\n    geom_line() +\n    labs(y = expression(theta))\n\n\n\n\n\n\nFigure 15.2: Trace plots of Monte Carlo samples.\nSo we can say that, when the number of posterior samples is very large, the sample distribution converges to the population density. The Monte Carlo method will work for many situations. Note, of course, the number of simulation samples, \\(S\\), is controlled by the analysts; it is different from the sample size of the data, which is fixed and is a property of the observed data.\nIn addition, most descriptive statistics (e.g., mean, SD) of the simulation draws will converge to the corresponding values of the true posterior distribution. The graphs below show how the mean, median, SD, and skewness converge to the true values (red dashed lines) when the number of simulation samples increases.\nCodebeta_draws |&gt;\n    filter(sam == \"1000 samples\") |&gt;\n    rowid_to_column(\"iter\") |&gt;\n    mutate(\n        mean = cumsum(th) / row_number(),\n        median = map_dbl(row_number(), ~ median(th[1:.x])),\n        SD = map_dbl(row_number(), ~ sd(th[1:.x])),\n        skewness = map_dbl(row_number(), ~ e1071::skewness(th[1:.x]))\n    ) |&gt;\n    ungroup() |&gt;\n    gather(\"stat\", \"val\", mean:skewness) |&gt;\n    ggplot(aes(x = iter, y = val)) +\n    geom_line() +\n    geom_hline(\n        data = data.frame(\n            stat = c(\"mean\", \"median\", \"SD\", \"skewness\"),\n            val = c(\n                15 / 25,\n                qbeta(.50, 15, 10),\n                sqrt(15 * 10 / (15 + 10)^2 / (15 + 10 + 1)),\n                2 * (10 - 15) * sqrt(15 + 10 + 1) /\n                    (15 + 10 + 2) / sqrt(15 * 10)\n            )\n        ),\n        aes(yintercept = val), col = \"red\", linetype = \"dashed\"\n    ) +\n    facet_wrap(~stat, scales = \"free\") +\n    labs(y = \"\")\n\n\n\n\n\n\nFigure 15.3: Sample statistics of the Monte Carlo samples.",
    "crumbs": [
      "Week 10--11",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Markov Chain Monte Carlo</span>"
    ]
  },
  {
    "objectID": "09-mcmc.html#markov-chain-monte-carlo-mcmc-drawing-dependent-samples",
    "href": "09-mcmc.html#markov-chain-monte-carlo-mcmc-drawing-dependent-samples",
    "title": "\n15  Markov Chain Monte Carlo\n",
    "section": "\n15.2 Markov Chain Monte Carlo (MCMC): Drawing Dependent Samples",
    "text": "15.2 Markov Chain Monte Carlo (MCMC): Drawing Dependent Samples\nThe above Monte Carlo simulation requires that (a) we know that the posterior distribution is exactly a beta distribution, and (b) R knows how to draw simulation samples from a beta distribution (with rbeta). As we progress through the class, it is more of an exception that we can use conjugate prior distribution, so in general, neither (a) nor (b) would hold. For example, if we instead use a normal distribution for the prior of \\(\\theta\\), we may get something like \\[\nP(\\theta \\mid y) = \\frac{\\mathrm{e}^{-(\\theta - 1 / 2)^2}\n                                     \\theta^y (1 - \\theta)^{n - y}}\n                       {\\int_0^1 \\mathrm{e}^{-(\\theta^* - 1 / 2)^2}\n                        {\\theta^*}^y (1 - {\\theta^*})^{n - y} d\\theta^*}\n\\] and it would be very hard, if possible, to draw simulation samples directly from the posterior. Luckily, MCMC provides a way to draw samples from the posterior distribution without the need to know everything about the posterior distribution. For example, the basic version of the Metropolis algorithm only requires that we know the density ratio of every two possible values \\(\\theta_1\\) and \\(\\theta_2\\). Thus, we don’t need to deal with the integral in the denominator, as the integral does not depend on \\(\\theta\\) and will get canceled out when taking the ratio.",
    "crumbs": [
      "Week 10--11",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Markov Chain Monte Carlo</span>"
    ]
  },
  {
    "objectID": "09-mcmc.html#the-metropolis-algorithm",
    "href": "09-mcmc.html#the-metropolis-algorithm",
    "title": "\n15  Markov Chain Monte Carlo\n",
    "section": "\n15.3 The Metropolis algorithm",
    "text": "15.3 The Metropolis algorithm\nThe Metropolis algorithm can generally be used to draw samples from a distribution as long as the density ratio of any two points can be computed. Remember, in Bayesian inference, for two values in the posterior distribution, the ratio of the posterior densities at \\(\\theta_1\\) and \\(\\theta_2\\) is \\[\n\\begin{aligned}\n  \\frac{P(\\theta = \\theta_2 \\mid y)}{P(\\theta = \\theta_1 \\mid y)}\n  & = \\frac{P(y \\mid \\theta = \\theta_2) P(\\theta = \\theta_2) / P(y)}\n         {P(y \\mid \\theta = \\theta_1) P(\\theta = \\theta_1) / P(y)} \\\\\n  & = \\frac{P(y \\mid \\theta = \\theta_2) P(\\theta = \\theta_2)}\n         {P(y \\mid \\theta = \\theta_1) P(\\theta = \\theta_1)}.\n\\end{aligned}\n\\] Therefore, even though we may not know \\(P(\\theta = \\theta_1 \\mid y)\\) as it involves \\(P(y)\\) as the denominator, we can still compute the density ratio.\nIn addition, the Metropolis algorithm requires the use of a proposal distribution, which can be any symmetric distribution. Common choices are normal distribution or uniform distribution. For example, let’s assume we will use a \\(N(0, 0.1)\\) proposal distribution, with 0.1 being the standard deviation.\nThe steps of a Metropolis algorithm are:\n\nRandomly start from a certain point in the parameter space, and call that point \\(\\theta_0\\)\n\nRandomly generate a sampled value from a \\(N(\\theta_0, 0.11)\\) distribution. Call this proposed value \\(\\theta^\\text{prop}\\)\n\nCompute the density ratio \\([P(\\theta = \\theta^\\text{prop} \\mid y)] / [P(\\theta = \\theta_0 \\mid y)]\\)\n\nIf the ratio is larger than 1, accept \\(\\theta^\\text{prop}\\) and include this value in the sample\nIf the ratio is smaller than 1, accept \\(\\theta^\\text{prop}\\) with probability equal to the density ratio. For example, if the ratio is 0.7, one first generates a simulated value, \\(u\\), from a uniform distribution between 0 and 1 (i.e., \\(U(0, 1)\\)). If \\(u\\) is smaller than the ratio, accept \\(\\theta^\\text{prop}\\) and include it in the sample. Otherwise, reject the proposed value, and include \\(\\theta_0\\) (again) in the sample\nAfter accepting \\(\\theta^\\text{prop}\\) or \\(\\theta_0\\) in the sample, denote the accepted value as \\(\\theta_0\\), and repeat steps 2 to 6.\n\nCompared to the Monte Carlo method, which directly samples from a Beta distribution, the Metropolis algorithm does not require an R function to draw samples from the target distribution. The cost, however, is that the sampling process is not as efficient because the sampled values are dependent. We’ll discuss this point later after seeing an example of the algorithm.",
    "crumbs": [
      "Week 10--11",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Markov Chain Monte Carlo</span>"
    ]
  },
  {
    "objectID": "09-mcmc.html#shiny-app",
    "href": "09-mcmc.html#shiny-app",
    "title": "\n15  Markov Chain Monte Carlo\n",
    "section": "\n15.4 Shiny App",
    "text": "15.4 Shiny App\nTo see a visual demonstration, you may run the shiny app I created by typing in R\n\nshiny::runGitHub(\"metropolis_demo\", \"marklhc\")",
    "crumbs": [
      "Week 10--11",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Markov Chain Monte Carlo</span>"
    ]
  },
  {
    "objectID": "09-mcmc.html#example-1-estimating-the-number-of-people-taking-the-metro",
    "href": "09-mcmc.html#example-1-estimating-the-number-of-people-taking-the-metro",
    "title": "\n15  Markov Chain Monte Carlo\n",
    "section": "\n15.5 Example 1: Estimating the Number of People Taking the Metro",
    "text": "15.5 Example 1: Estimating the Number of People Taking the Metro\nThis example uses data from the LA Barometer survey conducted by the USC Dornsife Center for Economic and Social Research. Specifically, I’m interested in the proportion of participants who took the Metro in the previous year among first-generation immigrants in LA county. You can see a press release on the data at https://dornsife.usc.edu/news/stories/3164/labarometer-mobility-in-los-angeles-survey/\n\nuas_dat &lt;- read_dta(here(\"data\", \"uas219_psyc573.dta\"))\nuas_dat |&gt;\n    filter(immigrant_status == 0) |&gt;\n    count(tr002s2)\n\n\n  \n\n\n\nSo in 338 participants who are first-generation immigrants, 86 said they had used the Metro.\nLet’s use a weakly informative prior of Beta(1.5, 2), which has a weight of 1.5 prior data points, with a weak belief that less than half of the people had used the Metro.\nModel: \\[\n\\text{usemetro}_i \\sim \\mathrm{Bern}(\\theta)\n\\] Prior: \\[\n\\theta \\sim \\mathrm{Beta}(1.5, 2)\n\\]\n\nprior_a &lt;- 1.5\nprior_b &lt;- 2\n\nBased on conjugacy, we know the posterior is Beta(87.5, 254). For pedagogical purposes, we will instead use a Metropolis sampler, which only requires the ratio of prior \\(\\times\\) likelihood for any two \\(\\theta\\) values.\n\n15.5.1 MCMC sampling\n\nnum_yes &lt;- 86\nnum_obs &lt;- 86 + 252\n# Define a function to compute values proportional to p(y | th) * p(th)\nprior_times_lik &lt;- function(th) {\n    # Return 0 if th is out of range\n    if (th &lt; 0 || th &gt; 1) return(0)\n    pth &lt;- dbeta(th, shape1 = prior_a, shape2 = prior_b)\n    py_given_th &lt;- th ^ num_yes * (1 - th) ^ (num_obs - num_yes)\n    pth * py_given_th\n}\n# Define a function for generating data from the proposal distribution\ngenerate_proposal &lt;- function(th, sd = 0.1) {\n    rnorm(1, mean = th, sd = sd)\n}\n# Initialize the Metropolis algorithm\nset.seed(2037)  # set the seed for reproducibility\nnum_draws &lt;- 1000\nnum_warmup &lt;- num_draws / 2\nth_all_draws &lt;- rep(NA, num_draws)\n# Step 1: starting value\nth_all_draws[1] &lt;- 0.1\n# counter for tracking acceptance rate\nnum_accepted &lt;- 0\nfor (s in seq_len(num_draws - 1)) {\n    current_th &lt;- th_all_draws[s]\n    # Step 2: Generate proposal\n    proposed_th &lt;- generate_proposal(current_th)\n    # Step 3: Compute acceptance probability\n    prob_accept &lt;- min(\n        1,\n        prior_times_lik(proposed_th) /\n            prior_times_lik(current_th)\n    )\n    # Steps 4 & 5: etermine whether to make the jump\n    if (runif(1) &lt; prob_accept) {\n        th_all_draws[s + 1] &lt;- proposed_th\n        if (s + 1 &gt;= num_warmup) {\n            num_accepted &lt;- num_accepted + 1\n        }\n    } else {\n        th_all_draws[s + 1] &lt;- current_th\n    }\n}\n\nWe can visualize the MCMC chain by plotting the iteration index on the x-axis and the sampled value on the y-axis:\n\nggplot(\n    data.frame(th = th_all_draws, iter = seq_along(th_all_draws)),\n    aes(x = iter, y = th)\n) +\n    geom_line()\n\n\n\n\n\n\nFigure 15.4: Trace plots of MCMC samples for the Metro example.\n\n\n\n\nEach step in MCMC is called an iteration. The sampled values are dependent, meaning that the value at iteration \\(s\\) depends on the value at iteration \\(s - 1\\). This is a major difference from functions that simulate independent random samples, like rbeta() or rnorm(). The resulting sampled values will form a Markov chain, meaning that each sampled value is correlated with the previous value (e.g., if \\(\\theta^{(s)}\\) is large, \\(\\theta^{(s + 1)}\\) is also large).\nAs shown above, the chain starts at 0.10 then quickly moves to the region around 0.25, the area with high posterior density. It then oscillates around that for the remaining iterations.\n\n15.5.2 More on Markov Chain\nA Markov chain describes how a variable transitions from one “state” to another. The current state depends on the previous state. A well-behaved Markov Chain is said to be ergodic, which means that it is (see Hoff, 2009, chapter 10):\n\n\nirreducible: at any state \\(\\theta^{(s)}\\), it can go to any value \\(\\theta^*\\) eventually. A reducible chain is one where some states cannot get to some other states; an example is when, at some point, the chain stays as a positive value forever and never gets back to the negative side.\n\naperiodic: the chain does not have any periodic states. If it is a periodic chain, some values can only be visited every \\(k\\)th iteration.\n\nrecurrent: after the chain visits a certain state \\(\\theta^*\\), if the chain runs long enough, it eventually returns to the same state \\(\\theta^*\\).\n\nUnder the above conditions, a Markov chain will converge to a stationary distribution. Thus, after a certain large amount of iterations, the draws from the chain can be considered a random (but correlated) sample of the stationary distribution. Moreover, one can prove that, with the Metropolis algorithm, the converging stationary distribution is the posterior distribution (see the discussion in Kruschke, 2015, chapter 7).\n\n15.5.3 Warm-up/Burn-in\nA Markov chain needs some iterations to get to the stationary distribution. Those iterations are usually called warm-up or burn-in (depending on the algorithm and the software) iterations and are usually discarded. In many software programs, the first half of the iterations are considered warm-ups, so even though we got 1,000 iterations, only 500 will be used:\n\nnum_warmup &lt;- num_draws / 2\nth_draws &lt;- th_all_draws[- (1:num_warmup)]\n\n\n15.5.4 Autocorrelation\nThe degree to which the value at iteration \\(s\\) is correlated with the value at \\(s - 1\\) (and at \\(s - 2\\), etc) can be measured by the autocorrelation. For example, below shows the lag-1 correlation:\n\nggplot(data.frame(current = th_draws,\n                  previous = lag(th_draws)),\n       aes(x = previous, y = current)) +\n    geom_point() +\n    geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: Removed 1 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 1 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\nFigure 15.5: Scatterplot of observations at iteration s against observations at iteration s - 1, with MCMC samples.\n\n\n\n\nCompared to samples from rbeta()\n\nrbeta_draws &lt;- rbeta(num_draws, shape1 = 87.5, shape2 = 254)\nggplot(data.frame(current = rbeta_draws,\n              previous = lag(rbeta_draws)),\n       aes(x = previous, y = current)) +\n    geom_point() +\n    geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\nWarning: Removed 1 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 1 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\nFigure 15.6: Scatterplot of observations at iteration s against observations at iteration s - 1, with independent Monte Carlo samples.\n\n\n\n\nYou can get the autocorrelation function plot (autocorrelation plot on the right):\n\nmcmc_combo(data.frame(theta = th_draws),\n    combo = c(\"trace\", \"acf\")\n)\n\n\n\n\n\n\nFigure 15.7: Trace plots and autocorrelation plots with MCMC samples.\n\n\n\n\nwhich shows substantial autocorrelations until about nine iterations apart.\n\n15.5.5 Acceptance Rate\nWhen using the Metropolis algorithm, you want to monitor the acceptance rate and ensure it is within the optimal range. If you accept almost every time, it likely means that, in each iteration, the chain only jumps a tiny step (so that the acceptance ratio is close to 1 every time). As such, the chain will take many iterations to reach other regions of the stationary distribution, and consecutive draws are very strongly correlated. On the other hand, if the acceptance rate is very low, the chain gets stuck in the same location for many iterations before moving to a different state. For the basic Metropolis algorithm with one parameter, an optimal acceptance rate would be something between 40% to 50%.\n\n\n\n\n\n\nFor Hamiltonian Monte Carlo to be discussed later, the optimal acceptance rate would be much higher, from 80% to 99%, or even higher.\n\n\n\n\n# Acceptance rate\nsum(num_accepted) / length(th_draws)\n\n[1] 0.306\n\n\n\n15.5.6 Effective sample size (ESS)\nWhen iterations are dependent, each iteration contains overlapping information with the previous iterations. In other words, when one gets 500 dependent draws from the posterior, it only contains information equivalent to &lt; 500 independent draws. The ESS quantifies the actual amount of information, so a chain with ESS = \\(n\\) will contain roughly the same information as in \\(n\\) independent draws. In general, we want ESS to be at least 400 for the general purpose of summarizing the posterior. You can obtain ESS using the posterior::ess_basic() function:\n\ness_basic(th_draws)\n\n[1] 84.42518\n\n\nwhich is not sufficient for summarizing the posterior.\n\n15.5.7 Multiple Chains\nBecause each state in a Markov chain depends on the previous states, the starting value(s) can influence the sampled values. Remember, in complex problems, one does not know how the posterior distributions would look. One solution to check the sensitivity to the starting value(s) is to use multiple chains, each with different starting values.\n\nIf multiple chains sample the same target distribution, they should be mixing well, meaning they cross each other in a trace plot.\n\nBelow are examples of two chains with good/poor mixing.\n\n\nPoor Mixing\nBetter Mixing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n15.5.8 Full R Code With More Iterations\n\nCodenum_yes &lt;- 86\nnum_obs &lt;- 86 + 252\n# Define a function to compute values proportional to p(y | th) * p(th)\nprior_times_lik &lt;- function(th) {\n    # Return 0 if th is out of range\n    if (th &lt; 0 || th &gt; 1) return(0)\n    pth &lt;- dbeta(th, shape1 = prior_a, shape2 = prior_b)\n    py_given_th &lt;- th ^ num_yes * (1 - th) ^ (num_obs - num_yes)\n    pth * py_given_th\n}\n# Define a function for generating data from the proposal distribution\ngenerate_proposal &lt;- function(th, sd = 0.1) {\n    rnorm(1, mean = th, sd = sd)\n}\n# Initialize the Metropolis algorithm\nset.seed(2037)  # set the seed for reproducibility\nnum_chains &lt;- 2\nnum_draws &lt;- 10000\nnum_warmup &lt;- num_draws / 2\nth_all_draws &lt;- matrix(NA, nrow = num_draws, ncol = num_chains)\nth_all_draws[1, ] &lt;- c(0.1, 0.9)  # starting value\n# counter for tracking acceptance rate\nnum_accepted &lt;- rep(0, num_chains)\nfor (s in seq_len(num_draws - 1)) {\n    for (j in seq_len(num_chains)) {\n        current_th &lt;- th_all_draws[s, j]\n        # Generate proposal\n        proposed_th &lt;- generate_proposal(current_th, sd = 0.05)\n        # Compute acceptance probability\n        prob_accept &lt;- min(\n            1,\n            prior_times_lik(proposed_th) /\n                prior_times_lik(current_th)\n        )\n        # Determine whether to make the jump\n        if (runif(1) &lt; prob_accept) {\n            th_all_draws[s + 1, j] &lt;- proposed_th\n            if (s + 1 &gt;= num_warmup) {\n                num_accepted[j] &lt;- num_accepted[j] + 1\n            }\n        } else {\n            th_all_draws[s + 1, j] &lt;- current_th\n        }\n    }\n}\n# Save the draws after warm-up\nth_draws &lt;- th_all_draws[- (1:num_warmup), ]\n\n\nAs shown below, the MCMC draws approximate the posterior distribution reasonably well.\n\nggplot(data.frame(th = c(th_draws)), aes(x = th)) +\n    # Plot histogram, with density on y axis\n    geom_histogram(binwidth = 0.0025, aes(y = after_stat(density))) +\n    # Overlay the theoretical Beta distribution\n    stat_function(\n        fun = dbeta,\n        args = list(\n            shape1 = 86 + prior_a,\n            shape2 = 252 + prior_b\n        ),\n        col = \"red\"\n    ) +\n    labs(x = expression(theta))\n# Acceptance rate\nsum(num_accepted) / length(th_draws)\n\n[1] 0.4889\n\n\n\n\n\n\n\nFigure 15.8: Comparing MCMC samples to the theoretical posterior distribution for the Metro example.\n\n\n\n\n\n15.5.9 Convergence Check\nThe goal of checking for convergence of MCMC samples is to ensure that the draws are representative samples of the posterior distribution, and that they contain sufficient information to describe it. Convergence can be considered in two aspects:\n\nMixing\nStationarity\n\nWe’ll see some tools in R for diagnosing convergence.\n\n15.5.9.1 Trace Plot\nMultiple chains have good mixing if they frequently cross each other. If two chains iterate in different regions of the posterior distribution and never cross each other, they don’t mix well. You can check mixing using the trace plot. The below graph shows the two chains mixing well.\n\n# Convert to `draws_array` object to use the following functions\nth_draws_array &lt;- draws_array(\n    theta = th_draws,\n    .nchains = num_chains\n)\n# Trace plot\nmcmc_trace(th_draws_array)\n\n\n\n\n\n\nFigure 15.9: Trace plots of multiple chains.\n\n\n\n\n\n15.5.9.2 Rank Histograms\nAnother useful tool is the rank histogram, recently proposed by Vehtari et al. (2021). The idea is first to convert the posterior values into ranks and then look at the distributions of the ranks across iterations. If the chains mix well and all explore the same target distribution, the average rank in an interval of iterations should be similar for every chain. Therefore, the rank histogram should show something close to a uniform distribution, as shown below:\n\n# Rank plot\nmcmc_rank_hist(th_draws_array)\n\n\n\n\n\n\nFigure 15.10: Rank histograms of two chains.\n\n\n\n\n\n15.5.9.3 \\(\\hat{R}\\)\n\nA commonly used index in diagnosing convergence is \\(\\hat{R}\\), also called the potential scale reduction factor, proposed by Gelman & Rubin (1992) and later extended for multivariate distributions by Brooks & Gelman (1998). Vehtari et al. (2021) further improved it to account for unequal variances across chains using rank normalization and folding. \\(\\hat R\\) measures the ratio of the total variability combining multiple chains to the within-chain variability. When the Markov chains converge, each chain is based on the same posterior distribution, and they should have the same variance. Therefore, if the chains converge, there should be no between-chain variability, so \\(\\hat R\\) should be very close to 1.0.1\nWhile in older literature, the cutoff of \\(\\hat R\\) &lt; 1.1 was usually used, Vehtari et al. (2021) recommended a safer criterion of \\(\\hat R\\) &lt; 1.01.\nYou can use the summarize_draws() function from the posterior package, which provides summary statistics of the posterior and some convergence diagnostics.\n\nsummarize_draws(th_draws_array)\n\n\n  \n\n\n\nThe numbers ess_bulk and ess_tail are two ways to compute ESS. ess_bulk says more about the center region of the posterior and is useful when assessing how accurate the mean of the posterior draws approximates the true posterior mean (or the posterior median). ess_tail is most useful for assessing how accurate the sample quantiles in the tail areas (e.g., 1st, 95th) approximate the true posterior quantiles. For example, the accuracy of the credible intervals would require a large ess_tail.\nAs recommended by Vehtari et al. (2021),\n\nESS should be at least 400 for \\(\\hat R\\) to be useful in diagnosing convergence.\n\n\n\n\n\n\n\nBrooks, S. P., & Gelman, A. (1998). General methods for monitoring convergence of iterative simulations. Journal of Computational and Graphical Statistics, 7(4), 434–455. https://doi.org/10.1080/10618600.1998.10474787\n\n\nGelman, A., & Rubin, D. B. (1992). Inference from iterative simulation using multiple sequences. Statistical Science, 7(4). https://doi.org/10.1214/ss/1177011136\n\n\nVehtari, A., Gelman, A., Simpson, D., Carpenter, B., & Bürkner, P.-C. (2021). Rank-normalization, folding, and localization: An improved Rˆ for assessing convergence of MCMC (with discussion). Bayesian Analysis, 16(2). https://doi.org/10.1214/20-BA1221",
    "crumbs": [
      "Week 10--11",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Markov Chain Monte Carlo</span>"
    ]
  },
  {
    "objectID": "09-mcmc.html#footnotes",
    "href": "09-mcmc.html#footnotes",
    "title": "\n15  Markov Chain Monte Carlo\n",
    "section": "",
    "text": "Note that in Stan, \\(\\hat{R}\\) is computed by splitting each chain into half. So if you have two chains, \\(\\hat{R}\\) will be based on four groups.↩︎",
    "crumbs": [
      "Week 10--11",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Markov Chain Monte Carlo</span>"
    ]
  },
  {
    "objectID": "09b-gibbs.html",
    "href": "09b-gibbs.html",
    "title": "\n16  Gibbs Sampling\n",
    "section": "",
    "text": "16.1 Data\nIn the previous note, we learn about the Metropolis algorithm. While the algorithm is very general and easy to implement, it is inefficient because the effective sample size is only about 1/4 of the actual number of draws for a one-parameter model. The Metropolis algorithm usually gets stuck when there are multiple parameters. Therefore, until about 2010, many Bayesian analyses relied on a more efficient algorithm—the Gibbs sampler. The Gibbs sampler uses conjugate priors on the conditional posterior distributions to get proposal values with high acceptance probability (it’s 100%). We’ll also see the normal model with two parameters: mean and variance.\nThe data set was from one of the studies reported in a paper published in Psychological Science in 2014. The authors compared participants’ performance on conceptual questions after taking notes either using laptops or notebooks (“longhand”). Let’s import the data directly from the Open Science Framework (https://osf.io/qrs5y/):\n# Use haven::read_sav() to import SPSS data\nnt_dat &lt;- read_sav(\"https://osf.io/qrs5y/download\")\nOne outcome variable the authors studied is the number of words in participants’ notes. Here are the distributions of the variable wordcount for the two conditions (0 = laptop, 1 = longhand).\nggplot(nt_dat, aes(x = wordcount)) +\n    geom_histogram(bins = 10) +\n    facet_wrap(~ condition)\n\n\n\n\n\n\nFigure 16.1: Number of words by experimental conditions.\nThe variable is somewhat skewed. We’ll focus on the control group (laptop) first, so let’s create a variable for that data. We’ll also divide the count by 100.\n(wc_laptop &lt;- nt_dat$wordcount[nt_dat$condition == 0] / 100)\n\n [1] 4.20 4.61 5.72 4.47 3.34 1.27 2.65 3.40 2.43 2.55 2.73 2.26 3.16 2.47 3.25\n[16] 1.67 4.49 4.77 1.67 5.19 3.00 2.98 1.59 2.23 4.39 2.29 1.52 2.13 3.11 3.82\n[31] 2.62",
    "crumbs": [
      "Week 10--11",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Gibbs Sampling</span>"
    ]
  },
  {
    "objectID": "09b-gibbs.html#data",
    "href": "09b-gibbs.html#data",
    "title": "\n16  Gibbs Sampling\n",
    "section": "",
    "text": "Often, in Bayesian analyses (and in frequentist ones as well), computer algorithms work best when the variables do not contain too many digits. In my experience, scaling variables to a range of -10 to 10 usually helps the computation.",
    "crumbs": [
      "Week 10--11",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Gibbs Sampling</span>"
    ]
  },
  {
    "objectID": "09b-gibbs.html#the-normal-model",
    "href": "09b-gibbs.html#the-normal-model",
    "title": "\n16  Gibbs Sampling\n",
    "section": "\n16.2 The Normal Model",
    "text": "16.2 The Normal Model\nWhile only an approximation, the normal distribution is a popular choice for modeling variables that are relatively symmetric and have more than a few discrete values. The normal distribution has two parameters; in some situations, there are advantages to choosing a specific parameterization. With the Gibbs sampler, we will parameterize it using the mean parameter, \\(\\mu\\), and the variance parameter, \\(\\sigma^2\\). The model is \\[\n\\text{wc\\_laptop}_i \\sim N(\\mu, \\sigma^2)\n\\] Note again that there are no subscripts to \\(\\mu\\) and \\(\\sigma^2\\), indicating exchangeability assumption.",
    "crumbs": [
      "Week 10--11",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Gibbs Sampling</span>"
    ]
  },
  {
    "objectID": "09b-gibbs.html#conjugate-actually-semiconjugate-priors",
    "href": "09b-gibbs.html#conjugate-actually-semiconjugate-priors",
    "title": "\n16  Gibbs Sampling\n",
    "section": "\n16.3 Conjugate (Actually “Semiconjugate”) Priors",
    "text": "16.3 Conjugate (Actually “Semiconjugate”) Priors\nIt can be shown that when \\(\\sigma^2\\) is known, a conjugate prior to \\(\\mu\\) is a normal prior, meaning that the posterior is also normal. However, when \\(\\sigma^2\\) is unknown, the prior distribution needs to be a joint distribution of two parameters.\nWhat we can do is consider the conditional distribution of a parameter. So instead of drawing a posterior sample from the joint posterior, \\(P(\\mu, \\sigma^2 \\mid y)\\), we consider each parameter separately, by drawing from the conditional of \\(P(\\sigma^2 \\mid \\mu^{(s - 1)}, y)\\) first, and then from \\(P(\\mu \\mid \\sigma^2 = {\\sigma^2}^{(s)}, y)\\) with \\({\\sigma^2}^{(s)}\\) being the previous draw, and then continuing with \\(P(\\sigma^2 \\mid \\mu^{(s)}, y)\\). The advantage of doing so is that we can use a conjugate normal prior for \\(\\mu\\) when conditioning on \\(\\sigma^2\\). We also have a conjugate prior for \\(\\sigma^2\\) when conditioning on \\(\\mu\\), which will be discussed later. Here is how the algorithm works:\n\nSet an initial value for \\({\\sigma^2}{(1)}\\)\n\nAt iteration \\(s\\), given sample \\({\\sigma^2}^{(s - 1)}\\), sample \\(\\mu^{(s)}\\) from the conditional posterior, \\(P(\\mu \\mid {\\sigma^2}^{(s)}, y)\\)\n\nGiven \\(\\mu^{(s)}\\), sample \\({\\sigma^2}^{(s)}\\) from the conditional posterior, \\(P(\\sigma^2 \\mid \\mu^{(s - 1)}, y)\\)\n\nRepeat steps 2 and 3\n\nIt can be shown that with this Gibbs algorithm, the posterior draws will be from the joint posterior of \\(P(\\mu, \\sigma^2 \\mid y)\\).\nBelow I provide more details on conjugacy. The actual detail is not the most important for this class because, in practice, the software will likely handle the computation. You may want to, however, pay attention to the suggested meanings of the hyperparameters:\n\n\n\\(\\mu_0\\): Prior mean\n\n\\(\\tau_0^2\\): Prior variance (i.e., uncertainty) of the mean\n\n\\(\\nu_0\\): Prior sample size for the variance\n\n\\(\\sigma^2_0\\): Prior expectation of the variance\n\n\n16.3.1 For \\(\\mu \\mid \\sigma^2\\)\n\nA conjugate prior for \\(\\mu \\mid \\sigma^2\\) is \\(\\mu \\sim N(\\mu_0, \\tau_0^2)\\), which gives the posterior conditional \\[\\mu \\mid \\sigma^2, y \\sim N(\\mu_n, \\tau_n^2),\\] where \\[\n  \\begin{aligned}\n    \\tau_n^2 & = \\left(\\frac{1}{\\tau_0^2} + \\frac{n}{\\sigma^2}\\right)^{-1} \\\\\n    \\mu_n & = \\tau_n^2 \\left(\\frac{\\mu_0}{\\tau_0^2} + \\frac{n \\bar y}{\\sigma^2}\\right)\n  \\end{aligned},\n\\] with \\(n\\) being the number of observations in the data and \\(\\bar y\\) being the sample mean of the data. The hyperparameters, \\(\\mu_0\\) and \\(\\tau_0^2\\), can be considered the prior mean and the prior variance of the mean, with a smaller prior variance indicating a stronger prior.\n\n\n\n\n\n\nNote that \\(n\\) (instead of \\(N\\)) is used here for the sample size to avoid confusion with the normal distribution.\n\n\n\n\n16.3.2 For \\(\\sigma^2 \\mid \\mu\\)\n\nA conjugate prior for \\(\\mu \\mid \\sigma^2\\) is from the Inverse-Gamma family: \\(\\sigma^2 \\sim \\text{Inv-Gamma}(\\nu_0 / 2, \\nu_0 \\sigma^2_0 / 2)\\). You usually only hear about the Inverse-Gamma distribution in Gibbs sampling, mainly because of conjugacy. As the name suggested, the Inverse-Gamma distribution is the distribution of the inverse of a variable that follows a Gamma distribution. So we also write \\(1 / \\sigma^2 \\sim \\mathrm{Gamma}(\\nu_0 / 2, \\nu_0 \\sigma^2_0 / 2)\\).\n\n\n\n\n\n\nThe Gamma distribution used here is also called a scaled \\(\\chi^2\\) distribution by some authors, with \\(\\mathrm{Gamma}(\\nu_0 / 2, \\nu_0 \\sigma^2_0 / 2)\\) being the same as \\(\\chi^2(\\nu_0, \\sigma^2_0)\\).\n\n\n\nThe posterior is also Inverse-Gamma, with \\[\n1 / \\sigma^2 \\mid \\mu^2, y \\sim \\mathrm{Gamma}(\\nu_n / 2, \\nu_n \\sigma^2_n [\\mu] / 2),\n\\] where \\[\n\\begin{aligned}\n  \\nu_n & = \\nu_0 + n \\\\\n  \\sigma^2_n (\\mu) & = \\frac{1}{\\nu_n} \\left[\\nu_0 \\sigma^2_0 + (n - 1) s^2_y + \\sum (\\bar y - \\mu)^2\\right]\n\\end{aligned},\n\\] with \\(s^2_y = \\sum (y_i - \\bar y)^2 / (n - 1)\\) being the sample variance of \\(y\\). The hyperparameters, \\(\\nu_0\\) and \\(\\sigma^2_0\\), can be considered the prior degrees of freedom and prior expected value of variance; \\(\\nu_0\\) can be roughly considered as the prior sample size.",
    "crumbs": [
      "Week 10--11",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Gibbs Sampling</span>"
    ]
  },
  {
    "objectID": "09b-gibbs.html#prior-model-and-posterior",
    "href": "09b-gibbs.html#prior-model-and-posterior",
    "title": "\n16  Gibbs Sampling\n",
    "section": "\n16.4 Prior, Model, and Posterior",
    "text": "16.4 Prior, Model, and Posterior\nWe will use some weakly informative priors, written in the following equations:\nModel: \\[\\text{wc\\_laptop}_i \\sim N(\\mu, \\sigma^2)\\] Prior: \\[\n  \\begin{aligned}\n    \\mu & \\sim N(5, 10^2) \\\\\n    1 / \\sigma^2 & \\sim \\mathrm{Gamma}(1 / 2, [1] [1] / 2)\n  \\end{aligned}\n\\]\nThe priors are very weak. We also assume that the priors are independent, which is commonly the case. Here are some simulated data from these priors:\n\nset.seed(2259)\nnum_draws &lt;- 100\nmu &lt;- rnorm(num_draws, mean = 5, sd = 10)\ninv_sigma2 &lt;- rgamma(num_draws,\n                     shape = 1 / 2, rate = 1 / 2)\nnum_obs &lt;- length(wc_laptop)\n# Initialize an S by N matrix to store the simulated data\ny_tilde &lt;- matrix(NA,\n                  nrow = num_draws,\n                  ncol = num_obs)\nfor (s in seq_len(num_draws)) {\n    mu_s &lt;- mu[s]\n    sigma2_s &lt;- 1 / inv_sigma2[s]\n    y_tilde[s, ] &lt;- rnorm(num_obs, mean = mu_s, sd = sqrt(sigma2_s))\n}\n# Plot the simulated data based on priors\nppd_dens_overlay(y_tilde)\n\n\n\n\n\n\nFigure 16.2: Prior predictive distributions.\n\n\n\n\nThe plot shows the types of data one can get. One can do better by avoiding the negative values if desired.",
    "crumbs": [
      "Week 10--11",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Gibbs Sampling</span>"
    ]
  },
  {
    "objectID": "09b-gibbs.html#the-gibbs-sampler",
    "href": "09b-gibbs.html#the-gibbs-sampler",
    "title": "\n16  Gibbs Sampling\n",
    "section": "\n16.5 The Gibbs Sampler",
    "text": "16.5 The Gibbs Sampler\nThe following is the full Gibbs sampler for the above normal model.\n\n# Sufficient statistics from data\nybar &lt;- mean(wc_laptop)  # sample mean\ns2y &lt;- var(wc_laptop)  # sample variance\nn &lt;- length(wc_laptop)  # sample size\n# Hyperparameters\nmu_0 &lt;- 5\nsigma2_0 &lt;- 1\ntau2_0 &lt;- 10^2\nnu_0 &lt;- 1\n# Initialize the Gibbs sampler\nset.seed(2120)\nnum_draws &lt;- 10000\nnum_warmup &lt;- num_draws / 2\nnum_chains &lt;- 2\n# Initialize a 3-D array (S x # chains x 2 parameters)\npost_all_draws &lt;- array(\n    dim = c(num_draws, num_chains, 2),\n    dimnames = list(NULL, NULL, c(\"mu\", \"sigma2\"))\n)\n# Step 1: starting values for sigma2\npost_all_draws[1, 1, \"sigma2\"] &lt;- 1  # for chain 1\npost_all_draws[1, 2, \"sigma2\"] &lt;- 3  # for chain 2\nfor (s in seq_len(num_draws - 1)) {\n    for (j in seq_len(num_chains)) {\n        sigma2_s &lt;- post_all_draws[s, j, \"sigma2\"]\n        # Step 2: Sample mu from the conditional posterior\n        tau2_n &lt;- 1 / (1 / tau2_0 + n / sigma2_s)\n        mu_n &lt;- tau2_n * (mu_0 / tau2_0 + n * ybar / sigma2_s)\n        mu_new &lt;- rnorm(1, mean = mu_n, sd = sqrt(tau2_n))\n        post_all_draws[s + 1, j, \"mu\"] &lt;- mu_new\n        # Step 3: Sample sigma2 from the conditional posterior\n        nu_n &lt;- nu_0 + n  # you could put this line outside the loop\n        sigma2_n &lt;- 1 / nu_n *\n            (nu_0 * sigma2_0 + (n - 1) * s2y + (ybar - mu_new)^2)\n        sigma2_new &lt;- 1 / rgamma(1,\n            shape = nu_n / 2,\n            rate = nu_n * sigma2_n / 2\n        )\n        post_all_draws[s + 1, j, \"sigma2\"] &lt;- sigma2_new\n    }\n}\n# Draws after warm-up\npost_draws &lt;- post_all_draws[- (1:num_warmup), , ]",
    "crumbs": [
      "Week 10--11",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Gibbs Sampling</span>"
    ]
  },
  {
    "objectID": "09b-gibbs.html#visualizing-the-jumps",
    "href": "09b-gibbs.html#visualizing-the-jumps",
    "title": "\n16  Gibbs Sampling\n",
    "section": "\n16.6 Visualizing the Jumps",
    "text": "16.6 Visualizing the Jumps\nThe plot below shows the jumps for 20 iterations in one chain, with the intermediate steps.\n\nCodedata.frame(\n    mu = post_draws[c(1, rep(2:20, each = 2)), 1, \"mu\"],\n    sigma2 = post_draws[c(rep(1:19, each = 2), 20), 1, \"sigma2\"]\n) |&gt;\n    ggplot(aes(x = mu, y = sigma2)) +\n    geom_path() +\n    geom_point() +\n    labs(x = expression(mu), y = expression(sigma^2))\n\n\n\n\n\n\nFigure 16.3: Jumps in the Gibbs sampler across iterations.\n\n\n\n\n\n16.6.1 Convergence Check\n\n# Convert to `draws_array` object to use the following functions\npost_draws_array &lt;- as_draws_array(post_draws)\n# Trace plots\nmcmc_trace(post_draws_array)  # good mixing\n# Rank histograms\nmcmc_rank_hist(post_draws_array)  # good mixing\n\n\n\n\n\n\n\n\n\n(a) Trace plots.\n\n\n\n\n\n\n\n\n\n\n\n(b) Rank histograms.\n\n\n\n\n\n\nFigure 16.4: Diagnostic plots for the Gibbs sampler.\n\n\n\n\n# Summary (with rhat and ESS)\nsummarize_draws(post_draws_array) |&gt;\n    knitr::kable(digits = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\nmu\n3.1\n3.10\n0.21\n0.21\n2.75\n3.45\n1\n9928.49\n9935.87\n\n\nsigma2\n1.4\n1.33\n0.38\n0.34\n0.90\n2.11\n1\n10188.76\n10135.62\n\n\n\n\n\nAs can be seen, the ESS is very high, indeed much higher than that obtained with the Metropolis algorithm.\n\n16.6.2 Visualizing the Marginal and Joint Posterior\n\nmcmc_areas(post_draws_array)  # marginal\n\n\n\n\n\n\nFigure 16.5: Marginal posterior distributions of model parameters.\n\n\n\n\n\nmcmc_scatter(post_draws_array,  # joint\n             size = 1, alpha = 0.3)  # make points smaller\n\n\n\n\n\n\nFigure 16.6: Joint posterior distributions of model parameters.\n\n\n\n\n\n16.6.3 Posterior Predictive Check\nWe can check whether the simulated data based on the posterior look like the observed data.\n\nnum_draws &lt;- 100\nnum_obs &lt;- length(wc_laptop)\n# Initialize an S by N matrix to store the simulated data\ny_tilde &lt;- matrix(NA,\n                  nrow = num_draws,\n                  ncol = num_obs)\nfor (s in seq_len(num_draws)) {\n    mu_s &lt;- post_draws[s, 1, \"mu\"]\n    sigma2_s &lt;- post_draws[s, 1, \"sigma2\"]\n    y_tilde[s, ] &lt;- rnorm(num_obs, mean = mu_s, sd = sqrt(sigma2_s))\n}\n# Plot the simulated data (in lighter lines)\n# and the current data (in the darker line)\nppc_dens_overlay(wc_laptop, yrep = y_tilde)\n\n\n\n\n\n\nFigure 16.7: Posterior predictive check.\n\n\n\n\nThe simulated data are not too far off from the observed data. Just that the simulated data can also get negative values.\n\n16.6.4 Limitations of Gibbs Sampler\nThe Gibbs sampler has been popular due to its computational efficiency for many problems. However, there are situations in which it works less well, such as when some parameters are highly correlated in the posterior, in which case a Gibbs sampler may get stuck. Another limitation is that Gibbs samplers require the use of conjugate priors. On the one hand, sometimes researcher beliefs may be better expressed in distributions other than the conjugate family. On the other hand, some conjugate families, such as the inverse Gamma distribution, are hard to work with and may yield suboptimal results in small sample situations.",
    "crumbs": [
      "Week 10--11",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Gibbs Sampling</span>"
    ]
  },
  {
    "objectID": "09b-gibbs.html#the-metropolis-hastings-algorithm",
    "href": "09b-gibbs.html#the-metropolis-hastings-algorithm",
    "title": "\n16  Gibbs Sampling\n",
    "section": "\n16.7 The Metropolis-Hastings Algorithm",
    "text": "16.7 The Metropolis-Hastings Algorithm\nThe Metropolis-Hastings (MH) algorithm is a generalization of the Metropolis algorithm, where it allows for more than one parameter and can use a proposal distribution that is not symmetric. It is less efficient than the Gibbs sampler but can accommodate non-conjugate prior distributions. Note that the proposal distribution needs to have the same dimension as the posterior so that the proposal is a vector in the parameter space. For example, we need a bivariate proposal density with \\(\\mu\\) and \\(\\sigma\\).\nBelow is an example using a bivariate normal distribution for the proposal. While we can choose how correlated the variables are in the proposal, for simplicity, I just consider zero correlation and equal SD for both dimensions. I also parameterize the normal distribution by the mean, \\(\\mu\\), and the standard deviation (instead of the variance), \\(\\sigma\\). The priors are: \\[\n  \\begin{aligned}\n    \\mu & \\sim N(5, 10^2) \\\\\n    \\sigma & \\sim N^+(0, 3)\n  \\end{aligned},\n\\] where \\(N^+\\) is a half-normal distribution because \\(\\sigma\\) is non-negative. We’ll revisit this for some later models.\nHere is the code for the MH algorithm:\n\n# Define a function to compute values proportional to p(y | th) * p(th)\nprior_times_lik &lt;- function(mu_sigma, y = wc_laptop) {\n    mu &lt;- mu_sigma[1]\n    sigma &lt;- mu_sigma[2]\n    # Return 0 if sigma is out of range\n    if (sigma &lt; 0) return(0)\n    # Joint prior = product of marginal priors\n    pth &lt;- dnorm(mu, mean = 5, sd = 10) *\n        # half-normal is proportional to normal in [0, infinity)\n        dnorm(sigma, sd = 3)\n    # Likelihood\n    py_given_th &lt;- prod(dnorm(y, mean = mu, sd = sigma))\n    pth * py_given_th\n}\n# Define a function for generating data from the proposal distribution\ngenerate_proposal &lt;- function(mu_sigma, sd = 0.1) {\n    rnorm(length(mu_sigma), mean = mu_sigma, sd = sd)\n}\n# Initialize the Metropolis algorithm\nset.seed(1051)  # set the seed for reproducibility\nnum_draws &lt;- 10000\nnum_warmup &lt;- num_draws / 2\nnum_chains &lt;- 2\n# Initialize a 3-D array (S x # chains x 2 parameters)\npost_all_draws &lt;- array(\n    dim = c(num_draws, num_chains, 2),\n    dimnames = list(NULL, NULL, c(\"mu\", \"sigma\"))\n)\n# Step 1: starting value\npost_all_draws[1, 1, ] &lt;- c(1, 1)  # for chain 1\npost_all_draws[1, 2, ] &lt;- c(8, 3)  # for chain 2\n# counter for tracking acceptance rate\nnum_accepted &lt;- rep(0, num_chains)\nfor (s in seq_len(num_draws - 1)) {\n    for (j in seq_len(num_chains)) {\n        current_par &lt;- post_all_draws[s, j, ]\n        # Generate proposal vector\n        proposed_par &lt;- generate_proposal(current_par, sd = 0.1)\n        # Compute acceptance probability\n        prob_accept &lt;- min(\n            1,\n            prior_times_lik(proposed_par) /\n                prior_times_lik(current_par)\n        )\n        # Determine whether to make the jump\n        if (runif(1) &lt; prob_accept) {\n            post_all_draws[s + 1, j, ] &lt;- proposed_par\n            if (s + 1 &gt;= num_warmup) {\n                num_accepted[j] &lt;- num_accepted[j] + 1\n            }\n        } else {\n            post_all_draws[s + 1, j, ] &lt;- current_par\n        }\n    }\n}\n# Draws after warm-up\npost_draws &lt;- post_all_draws[- (1:num_warmup), , ]\n# Acceptance rate\nsum(num_accepted) / length(post_draws)\n\n[1] 0.3638\n\n\n\n16.7.1 Convergence\n\n# Convert to `draws_array` object to use the following functions\npost_draws_array &lt;- as_draws_array(post_draws)\n# Trace plots\nmcmc_trace(post_draws_array)  # good mixing\n# Rank histograms\nmcmc_rank_hist(post_draws_array)  # good mixing\n\n\n\n\n\n\n\n\n\n(a) Trace plots.\n\n\n\n\n\n\n\n\n\n\n\n(b) Rank histograms.\n\n\n\n\n\n\nFigure 16.8: Diagnostic plots for the MH sampler.\n\n\n\n\n# Summary (with rhat and ESS)\nsummarize_draws(post_draws_array) |&gt;\n    knitr::kable(digits = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\nmu\n3.11\n3.11\n0.23\n0.23\n2.72\n3.49\n1.01\n304.66\n426.00\n\n\nsigma\n1.20\n1.19\n0.15\n0.15\n0.98\n1.48\n1.00\n694.50\n733.81\n\n\n\n\n\nAs can be seen, ESS is much lower, so more iterations will be needed with MH.",
    "crumbs": [
      "Week 10--11",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Gibbs Sampling</span>"
    ]
  },
  {
    "objectID": "09c-hmc.html",
    "href": "09c-hmc.html",
    "title": "\n17  Hamiltonian Monte Carlo\n",
    "section": "",
    "text": "17.1 Leapfrog Integrator\nA more recent development in MCMC is the development of algorithms under the umbrella of Hamiltonian Monte Carlo or hybrid Monte Carlo (HMC). The algorithm is a bit complex, and my goal is to help you develop some intuition of the algorithm, hopefully, enough to help you diagnose the Markov chains.\nSo now, how does HMC work? First, consider a two-dimensional posterior below, which is the posterior of \\((\\mu, \\sigma^2)\\) from a normal model.\nThe HMC algorithm improves from the Metropolis algorithm by simulating smart proposal values. It does so by using the gradient of the logarithm of the posterior density. Let’s first take the log of the joint density:\nNow, flip it upside-down.\nImagine placing a marble on the above surface. With gravity, it is natural that the marble will have a tendency to move to the bottom of the surface. If you place the marble in a higher location, it will have a higher potential energy and tends to move faster towards the bottom, because that energy converts to a larger kinetic energy. If you place it close to the bottom, it will tend to move slower.\nFor simplicity, let’s consider just one dimension with the following picture:\nFor the graph on the left, the marble (represented as a dot) has high potential energy and should quickly go down to the bottom; on the right, the marble has low potential energy and should move less fast.\nBut we don’t want the marble to stay at the bottom without moving; otherwise, all our posterior draws will be just the posterior mode. In HMC, it moves the marble with a push, called momentum. The direction and the magnitude of the momentum will be randomly simulated, usually from a normal distribution. If the momentum is large, it should travel farther away; however, it also depends on the gradient, which is the slope in a one-dimension case.\nAt the beginning of a trajectory, the marble has a certain amount of kinetic and potential energy, and the sum is the total amount of energy, called the Hamiltonian. Based on the conservation of energy, at any point in the motion, the Hamiltonian should remain constant.\nThe following shows the trajectory of a point starting at 2, with a random momentum of 0.5 in the positive direction.\nThis one has the same starting value, with a random momentum of 0.5 in the negative direction.\nTo simulate the marble’s motion, one needs to solve a system of differential equations, which is not an easy task. A standard method is the so-called leapfrog integrator, which discretizes a unit of time into \\(L\\) steps. The following shows how it approximates the motion using \\(L\\) = 3 and \\(L\\) = 10 steps. The red dot is the target. As can be seen, larger \\(L\\) simulates the motion more accurately.\nSuppose the simulated trajectory differs from the true trajectory by a certain threshold, like the one on the left. In that case, it is called a divergent transition, in which case the proposed value should not be trusted. In software like STAN, it will print out a warning about that. When the number of divergent transitions is large, one thing to do is increase \\(L\\). If that does not help, it may indicate difficulty in a high-dimensional model, and reparameterization may be needed.\nFor more information on HMC, go to https://mc-stan.org/docs/reference-manual/mcmc.html. You can also find some sample R code at http://www.stat.columbia.edu/~gelman/book/software.pdf.",
    "crumbs": [
      "Week 10--11",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Hamiltonian Monte Carlo</span>"
    ]
  },
  {
    "objectID": "09c-hmc.html#leapfrog-integrator",
    "href": "09c-hmc.html#leapfrog-integrator",
    "title": "\n17  Hamiltonian Monte Carlo\n",
    "section": "",
    "text": "Codenum_steps &lt;- 3\nleapfrog_df &lt;- cbind(\n    leapfrog_step(3, rho = -0.5, num_steps = num_steps),\n    step = 0:num_steps\n)\nfinal_x &lt;- leapfrog_step(3, rho = -0.5, num_steps = 1000)[1001, 1]\np2 + geom_point(\n    data = leapfrog_df,\n    aes(x = x, y = -lp_sigma(x)), col = \"green\"\n) +\n    geom_point(\n        x = final_x, y = -lp_sigma(final_x),\n        col = \"red\", size = 2, shape = 21\n    ) +\n    geom_path(\n        data = leapfrog_df,\n        aes(x = x, y = -lp_sigma(x)), col = \"green\"\n    )\nnum_steps &lt;- 10\nleapfrog_df &lt;- cbind(\n    leapfrog_step(3, rho = -0.5, num_steps = num_steps),\n    step = 0:num_steps\n)\np2 + geom_point(\n    data = leapfrog_df,\n    aes(x = x, y = -lp_sigma(x)), col = \"green\"\n) +\n    geom_point(\n        x = final_x, y = -lp_sigma(final_x),\n        col = \"red\", size = 2, shape = 21\n    ) +\n    geom_path(\n        data = leapfrog_df,\n        aes(x = x, y = -lp_sigma(x)), col = \"green\"\n    )\n\n\n\n\n\n\n\n\n\n(a) 3 steps\n\n\n\n\n\n\n\n\n\n(b) 10 steps\n\n\n\n\n\n\nFigure 17.7: Simulated motion using the leapfrog integrator.",
    "crumbs": [
      "Week 10--11",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Hamiltonian Monte Carlo</span>"
    ]
  },
  {
    "objectID": "09c-hmc.html#the-no-u-turn-sampler-nuts",
    "href": "09c-hmc.html#the-no-u-turn-sampler-nuts",
    "title": "\n17  Hamiltonian Monte Carlo\n",
    "section": "\n17.2 The No-U-Turn Sampler (NUTS)",
    "text": "17.2 The No-U-Turn Sampler (NUTS)\nAlthough HMC is more efficient by generating smarter proposal values, one performance bottleneck is that the motion sometimes takes a U-turn, like in some graphs above, in which the marble goes up (right) and then goes down (left), and eventually may stay in a similar location. The improvement of NUTS is that it uses a binary search tree that simulates both the forward and backward trajectory. The algorithm is complex, but to my understanding, it achieves two purposes: (a) finding the path that avoids a U-turn and (b) selecting an appropriate number of leapfrog steps, \\(L\\). When each leapfrog step moves slowly, the search process may take a long time. With NUTS, one can control the maximum depth of the search tree.\nSee https://mc-stan.org/docs/reference-manual/mcmc.html#hmc-algorithm-parameters for more information on NUTS.",
    "crumbs": [
      "Week 10--11",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Hamiltonian Monte Carlo</span>"
    ]
  },
  {
    "objectID": "10-glm.html",
    "href": "10-glm.html",
    "title": "\n18  Generalized Linear Model\n",
    "section": "",
    "text": "18.1 Overview of GLM\nGLM (generalized linear model) is a general class of statistical models for predicting an outcome variable, \\(Y\\). It accommodates \\(Y\\) in different types of measurement, such as continuous, counts, ordinal, or categorical. GLM is a generalization of the usual regression model that assumes linear associations and normally distributed errors.\nUnder the GLM framework, with one predictor, we have models in the form\n\\[\n  \\begin{aligned}\n    Y_i & \\sim \\mathrm{Dist}(\\mu_i, \\tau)  \\\\\n    g(\\mu_i) & = \\eta_i \\\\\n    \\eta_i & = \\beta_0 + \\beta_1 X_i\n  \\end{aligned}\n\\]\nA GLM model has three components:\nIn a GLM, one selects distributions like Dist = Normal, Poisson, Binomial, Bernoulli, etc. The distribution has a mean parameter \\(\\mu_i\\) and may have a dispersion parameter, \\(\\tau\\). An intermediate step in GLM is transforming \\(\\mu_i\\) to \\(\\eta_i\\). \\(\\eta_i\\) is called the linear predictor, which is the linear function of the predictors. In linear models, we directly model the conditional mean, \\(\\mu_i\\), as the same as \\(\\eta_i\\). However, to allow for the possibility of \\(\\mu_i\\) being a nonlinear function of the predictors, in GLM we transform \\(\\mu_i\\) by applying a link function, \\(g(\\cdot)\\), so that, even though we \\(\\eta_i\\) to be linear in the coefficients, \\(\\mu_i = g^{-1}(\\eta_i)\\) will be a nonlinear function of the coefficients as long as the link function is not linear. This step is needed to ensure the predicted values are not out of range.\nTable 18.1 includes some commonly used GLMs.",
    "crumbs": [
      "Week 12",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Generalized Linear Model</span>"
    ]
  },
  {
    "objectID": "10-glm.html#overview-of-glm",
    "href": "10-glm.html#overview-of-glm",
    "title": "\n18  Generalized Linear Model\n",
    "section": "",
    "text": "Conditional distribution of \\(Y\\) (e.g., Dist = Normal, Poisson, Binomial, Bernoulli)1\n\nLinear predictor \\(\\eta\\), which is a linear combination of the predictor\nLink function \\(g(\\cdot)\\), which maps \\(\\mu\\) to \\(\\eta\\)\n\n\n\n\n\n\nTable 18.1: Commonly used GLMs\n\n\n\n\n\n\n\n\n\noutcome type\nSupport\nDistributions\nLink\n\n\n\ncontinuous\n[\\(-\\infty\\), \\(\\infty\\)]\nNormal\nIdentity\n\n\ncount (fixed duration)\n{0, 1, \\(\\ldots\\)}\nPoisson\nLog\n\n\ncount (known # of trials)\n{0, 1, \\(\\ldots\\), \\(N\\)}\nBinomial\nLogit\n\n\nbinary\n{0, 1}\nBernoulli\nLogit\n\n\nordinal\n{0, 1, \\(\\ldots\\), K}\ncategorical\nLogit\n\n\nnominal\n\n\\(K\\)-vector of {0, 1}\ncategorical\nLogit\n\n\nmultinomial\n\n\\(K\\)-vector of {0, 1, \\(\\ldots\\), \\(K\\)}\ncategorical\nLogit",
    "crumbs": [
      "Week 12",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Generalized Linear Model</span>"
    ]
  },
  {
    "objectID": "10-glm.html#poisson-regression",
    "href": "10-glm.html#poisson-regression",
    "title": "\n18  Generalized Linear Model\n",
    "section": "\n18.2 Poisson Regression",
    "text": "18.2 Poisson Regression\nThe Poisson GLM is used to model count outcomes. Count outcomes are non-negative discrete integers. Remember, with GLM, we are modeling the mean of the outcome, \\(\\mu\\). Therefore, we need to make sure \\(\\mu\\) is non-negative, so we need a link function that can map \\(\\eta\\) from the whole real line to non-negative numbers; by far, the most commonly used link function is the logarithmic transformation, \\(g(\\mu) = \\log(\\mu)\\).\nHere’s an example data set recording the effect of anticonvulsant therapy in epilepsy. The outcome variable is the number of seizures in the two-week window prior to the last of the four visits.\nFirst check the distribution of the counts in Figure 18.1.\nepilepsy4 &lt;- dplyr::filter(epilepsy, visit == 4)\nepilepsy4$Trt &lt;- factor(epilepsy4$Trt)\nggplot(epilepsy4, aes(x = count)) +\n    geom_bar(width = 0.5)\nggplot(epilepsy4, aes(x = Trt, y = count)) +\n    geom_boxplot() +\n    geom_jitter(width = 0.05)\n\n\n\n\n\n\n\n\n\n(a) Overall counts\n\n\n\n\n\n\n\n\n\n(b) By treatment conditions\n\n\n\n\n\n\nFigure 18.1: Distribution of the number of seizures in the epilepsy data set",
    "crumbs": [
      "Week 12",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Generalized Linear Model</span>"
    ]
  },
  {
    "objectID": "10-glm.html#model-and-priors",
    "href": "10-glm.html#model-and-priors",
    "title": "\n18  Generalized Linear Model\n",
    "section": "\n18.3 Model and Priors",
    "text": "18.3 Model and Priors\nModel:\n\\[\n\\begin{aligned}\n  \\text{count}_i & \\sim \\mathrm{Pois}(\\mu_i)  \\\\\n  \\log(\\mu_i) & = \\eta_i \\\\\n  \\eta_i & = \\beta_0 + \\beta_1 \\text{Trt}_{i}\n\\end{aligned}\n\\]\nPriors:\n\\[\n\\begin{aligned}\n  \\beta_0 & \\sim N(3, 2.5)  \\\\\n  \\beta_1 & \\sim N(0, 1)\n\\end{aligned}\n\\]\nPredicted seizure rate = \\(\\exp(\\beta_0 + \\beta_1) = \\exp(\\beta_0) \\exp(\\beta_1)\\) for Trt = 1; \\(\\exp(\\beta_0)\\) for Trt = 0\n\\(\\beta_1\\) = mean difference in log rate of seizure; \\(\\exp(\\beta_1)\\) = ratio in rate of seizure\n\n18.3.1 MCMC Sampling With brms\n\n\nm2 &lt;- brm(count ~ Trt,\n    data = epilepsy4,\n    family = poisson(link = \"log\"),\n    prior = c(\n        prior(normal(1, 3), class = \"Intercept\"),\n        prior(normal(0, 1), class = \"b\")\n    ),\n    seed = 31143,\n    file = \"10_m2\"\n)\n\nStart sampling\n\n\nRunning MCMC with 4 chains, at most 2 in parallel...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.7 seconds.\n\n\nLoading required package: rstan\n\n\nLoading required package: StanHeaders\n\n\n\nrstan version 2.32.5 (Stan version 2.32.2)\n\n\nFor execution on a local, multicore CPU with excess RAM we recommend calling\noptions(mc.cores = parallel::detectCores()).\nTo avoid recompilation of unchanged Stan programs, we recommend calling\nrstan_options(auto_write = TRUE)\nFor within-chain threading using `reduce_sum()` or `map_rect()` Stan functions,\nchange `threads_per_chain` option:\nrstan_options(threads_per_chain = 1)\n\n\n\nAttaching package: 'rstan'\n\n\nThe following objects are masked from 'package:posterior':\n\n    ess_bulk, ess_tail\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\n\n\n18.3.2 Interpretations\nBecause of the nonlinear link function, one needs to be careful in interpreting the coefficients. With the log link, it is common to obtain the exponentiated coefficient. With the exponentiated coefficient, for every unit difference in \\(X\\), the predicted rate of seizure occurrence is multiplied by \\(\\exp(\\beta_1)\\) times. Here is the usual step for obtaining the posterior distributions of the transformed parameters:\n\nm2_summary &lt;- as_draws(m2) |&gt;\n    mutate_variables(\n        exp_beta0 = exp(b_Intercept),\n        exp_beta1 = exp(b_Trt1)\n    ) |&gt;\n    summarize_draws()\nknitr::kable(m2_summary, digits = 2)\n\n\nTable 18.2: Posterior summary of the Poisson regression model\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\nb_Intercept\n2.07\n2.07\n0.07\n0.07\n1.96\n2.18\n1\n3472.02\n2643.16\n\n\nb_Trt1\n-0.17\n-0.17\n0.10\n0.10\n-0.33\n-0.01\n1\n3139.53\n2637.42\n\n\nIntercept\n1.98\n1.98\n0.05\n0.05\n1.91\n2.06\n1\n2930.65\n2699.11\n\n\nlprior\n-3.01\n-3.00\n0.02\n0.01\n-3.04\n-2.99\n1\n3326.32\n2899.07\n\n\nlp__\n-334.41\n-334.12\n0.99\n0.70\n-336.27\n-333.48\n1\n1838.59\n2379.17\n\n\nexp_beta0\n7.95\n7.93\n0.52\n0.53\n7.13\n8.84\n1\n3472.02\n2643.16\n\n\nexp_beta1\n0.85\n0.85\n0.08\n0.08\n0.72\n0.99\n1\n3139.53\n2637.42\n\n\n\n\n\n\n\n\nSo here is a paragraph for the example:\n\n\n\n\n\n\nThe model predicts that the mean seizure rate in two weeks for the control condition is 8, 90% CI [7.1, 8.8]; the exponentiated coefficient for the treatment indicator is 0.85, 90% CI [0.72, 0.99], meaning that on average, the treatment reduces seizure rate by 0.94% to 27.83%.\n\n\n\n\n18.3.3 Rootogram\nThere is also a useful graphical tool, the rootogram (Figure 18.2), for diagnosing count models.\n\npp_check(m2, type = \"rootogram\", style = \"hanging\")\n\nUsing all posterior draws for ppc type 'rootogram' by default.\n\n\n\n\n\n\n\nFigure 18.2: Rootogram for the Poisson regression model\n\n\n\n\nIf the fit is good, the bars should be close to touching the horizontal x-axis. Thus, the fit was not good in the above figure. Models that accommodate overdispersion and excessive zeros may be needed.",
    "crumbs": [
      "Week 12",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Generalized Linear Model</span>"
    ]
  },
  {
    "objectID": "10-glm.html#negative-binomial-model",
    "href": "10-glm.html#negative-binomial-model",
    "title": "\n18  Generalized Linear Model\n",
    "section": "\n18.4 Negative Binomial Model",
    "text": "18.4 Negative Binomial Model\nThe negative binomial distribution is usually used to handle overdispersion in count data. The idea is that even with the same predictor value, each individual has a different rate of occurrence for an event, which is highly plausible for the epilepsy data. This class will not get into the details of the negative binomial, but you can check out this paper or this book.\n\nm2_nb &lt;- brm(count ~ Trt,\n    data = epilepsy4,\n    family = negbinomial(link = \"log\"),\n    prior = c(\n        prior(normal(1, 3), class = \"Intercept\"),\n        prior(normal(0, 1), class = \"b\")\n    ),\n    seed = 31143,\n    file = \"10_m2_nb\"\n)\n\nStart sampling\n\n\nRunning MCMC with 4 chains, at most 2 in parallel...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 finished in 0.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.3 seconds.\n\n\n\npp_check(m2_nb, type = \"rootogram\", style = \"hanging\")\n\nUsing all posterior draws for ppc type 'rootogram' by default.\n\n\n\n\n\n\n\nFigure 18.3: Rootogram for the Negative binomial model",
    "crumbs": [
      "Week 12",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Generalized Linear Model</span>"
    ]
  },
  {
    "objectID": "10-glm.html#binary-logistic-regression",
    "href": "10-glm.html#binary-logistic-regression",
    "title": "\n18  Generalized Linear Model\n",
    "section": "\n18.5 Binary Logistic Regression",
    "text": "18.5 Binary Logistic Regression\nWe will use an example from this paper: https://journals.sagepub.com/doi/abs/10.1177/0956797616645672, which examines how common it was for researchers to report marginal \\(p\\) values (i.e., .05 &lt; \\(p\\) \\(\\leq\\) .10). The outcome is whether a study reported one or more marginal \\(p\\) values (1 = Yes, 0 = No). The researchers also categorized the studies into three subfields (Cognitive Psychology, Developmental Psychology, Social Psychology), and there were a total of 1,535 studies examined from 1970 to 2010.\n\n# readxl package can be used to import excel files\ndatfile &lt;- here(\"data\", \"marginalp.xlsx\")\nif (!file.exists(datfile)) {\n    dir.create(here(\"data\"), showWarnings = FALSE)\n    download.file(\"https://osf.io/r4njf/download\",\n        destfile = datfile\n    )\n}\nmarginalp &lt;- readxl::read_excel(datfile)\n# Recode `Field` into a factor\nmarginalp &lt;- marginalp |&gt;\n    # Filter out studies without any experiments\n    filter(`Number of Experiments` &gt;= 1) |&gt;\n    mutate(Field = factor(Field,\n        labels = c(\n            \"Cognitive Psychology\",\n            \"Developmental Psychology\",\n            \"Social Psychology\"\n        )\n    )) |&gt;\n    # Rename the outcome\n    rename(marginal_p = `Marginals Yes/No`)\n# Proportion of marginal p in each subfield across Years\nmarginalp |&gt;\n    ggplot(aes(x = Year, y = marginal_p)) +\n    stat_summary(aes(fill = Field), geom = \"ribbon\", alpha = 0.3) +\n    stat_summary(aes(col = Field), geom = \"line\") +\n    stat_summary(aes(col = Field), geom = \"point\") +\n    coord_cartesian(ylim = c(0, 0.7)) +\n    facet_wrap(~ Field) +\n    theme(legend.position = \"top\")\n\nNo summary function supplied, defaulting to `mean_se()`\nNo summary function supplied, defaulting to `mean_se()`\nNo summary function supplied, defaulting to `mean_se()`\nNo summary function supplied, defaulting to `mean_se()`\nNo summary function supplied, defaulting to `mean_se()`\nNo summary function supplied, defaulting to `mean_se()`\nNo summary function supplied, defaulting to `mean_se()`\nNo summary function supplied, defaulting to `mean_se()`\nNo summary function supplied, defaulting to `mean_se()`\n\n\n\n\n\n\n\n\n\n18.5.1 Centering\nThe issue of centering applies to most regression models, including GLMs. Because the predictor Year has values 1970, 1980, etc, if we use this variable as a predictor, the intercept \\(\\beta_0\\) will be the predicted value of \\(\\eta\\) when Year = 0, which is like 2,000 years before the data were collected. So instead, we usually want the value 0 to be something meaningful and/or a possible value in the data. So we will center the variable year by making 0 the year 1970. In addition, we will divide the values by 10 so that one unit in the new predictor means 10 years.\nIn other words, we will use a transformed predictor, Year10 = (Year - 1970) / 10. So when Year = 1970, Year10 = 0; when Year = 1990, Year10 = 2.\n\nmarginalp &lt;- marginalp |&gt;\n  mutate(Year10 = (Year - 1970) / 10)\n# Check the recode\ndistinct(marginalp, Year, Year10)\n\n\n  \n\n\n\nFor this example, I’ll look at the subset of developmental psychology. You may want to try using the other subsets of the data for practice.\n\nmarginalp_dev &lt;- filter(marginalp,\n                        Field == \"Developmental Psychology\")\nhead(marginalp_dev)\n\n\n  \n\n\n\n\n18.5.2 Model and Priors\nAs the name “logistic regression” suggested, the logistic function is used somewhere in the model. The logistic function, or the inverse logit function, is \\[\n\\mu = g^{-1}(\\eta) = \\frac{\\exp(\\eta)}{1 + \\exp(\\eta)},\n\\] which is a transformation from \\(\\eta\\) to \\(\\mu\\). The link function, which is a transformation from \\(\\mu\\) to \\(\\eta\\), is the logit function, \\[\n\\eta = g(\\mu) = \\log\\frac{\\mu}{1 - \\mu},\n\\] which converts \\(\\mu\\), which is in probability metric, to \\(\\eta\\), which is in log odds metric (odds = probability / [1 - probability]).\nModel:\n\\[\n\\begin{aligned}\n  \\text{marginal\\_p}_i & \\sim \\mathrm{Bern}(\\mu_i)  \\\\\n  \\mathrm{logit}(\\mu_i) & = \\eta_i \\\\\n  \\eta_i & = \\beta_0 + \\beta_1 \\text{Year10}_{i}\n\\end{aligned}\n\\]\nPriors:\n\\[\n\\begin{aligned}\n  \\beta_0 & \\sim t_4(0, 2.5)  \\\\\n  \\beta_1 & \\sim t_4(0, 1)\n\\end{aligned}\n\\]\nThere has been previous literature on what choices of prior on the \\(\\beta\\) coefficients for logistic regressions would be appropriate (see this paper). \\(\\beta\\) coefficients in logistic regression can be relatively large, unlike in normal regression. Therefore, it’s pointed out that a heavy tail distribution, like Cauchy and \\(t\\), would be more appropriate. Recent discussions have settled on priors such as \\(t\\) distributions with small degrees of freedom as a good balance between heavy tails and efficiency for MCMC sampling. I use \\(t_4(4, 0, 2.5)\\) for \\(\\beta_0\\), which puts more density in [-2.5, 2.5] on the log odds unit. This means, in the year 1970, our belief is that the probability of marginally significant results would be somewhere between 0.08 to 0.92, which seems to cover a reasonable range. For \\(\\beta_1\\), I use \\(t_4(4, 0, 1)\\), which suggests that a 10-year difference like corresponds to a difference in log odds between -1 and 1. While it’s hard to interpret the difference in log odds, a quick rule of thumb is to divide \\(\\beta_1\\) by 4, which roughly corresponds to the maximum difference in probability for a unit difference in the predictor. So if \\(\\beta_1\\) = 1, the maximum difference in probability will be no more than 25 percentage points. So my prior says that it’s unlikely that the probability of reporting marginal \\(p\\) values would increase or decrease by 25 percentage points every 10 years, which again is a weak prior. If you’re uncertain, you can consider something weaker.\nThe priors are chosen to be weakly informative.\n\nm4 &lt;- brm(marginal_p ~ Year10,\n    data = marginalp_dev,\n    family = bernoulli(link = \"logit\"),\n    prior = c(\n        prior(student_t(4, 0, 1), class = \"b\"),\n        prior(student_t(4, 0, 2.5), class = \"Intercept\")\n    ),\n    # Note: no sigma\n    seed = 1340,\n    file = \"10_m4\"\n)\n\nStart sampling\n\n\nRunning MCMC with 4 chains, at most 2 in parallel...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.1 seconds.\nChain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 2 finished in 0.1 seconds.\nChain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 3 finished in 0.1 seconds.\nChain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.5 seconds.\n\n\n\n\n\n\n\n\nIn brms we used family = bernoulli(). In other R functions, such as glm, they do not distinguish between bernoulli and Binomial and only recognize family = binomial(), as a Bernoulli variable is a binomial variable with \\(n = 1\\).\n\n\n\n\n18.5.3 Interpreting the results\nAny nonlinear relationships will involve more work in interpretations, and the coefficients in logistic regressions are no exception.\n\n18.5.3.1 Posterior predictions\nA good way to start is to plot the model-implied association on the original unit of the data. The conditional_effects() function in brms comes in very handy, and I recommend you always start with this:\n\nplot(\n    conditional_effects(m4, prob = .90),\n    points = TRUE,\n    point_args = list(height = 0.01, width = 0.05, alpha = 0.05),\n    plot = FALSE\n)[[1]] +\n    scale_x_continuous(\n        breaks = 0:4,\n        labels = c(\"1970\", \"1980\", \"1990\", \"2000\", \"2010\")\n    ) +\n    xlab(\"Year\")\n\n\n\n\n\n\nFigure 18.4: Predicted probabilities of marginal significant results over time.\n\n\n\n\nAs you can see, the logistic model implies a somewhat nonlinear association between Year10 and the outcome. From the graph, when Year10 = 2, which is the Year 1990, the predicted probability of marginal significant results is about 25%, with a 90% credible interval of about 21 to 28%. We can get that using\n\nposterior_epred(m4, newdata = list(Year10 = 2)) |&gt;\n    summarise_draws()\n\n\n  \n\n\n\n\n18.5.3.2 Intercept\nFrom the equation, when all predictors are zero, we have \\[\n\\mathrm{logit}(\\mu_i) = \\beta_0.\n\\] Therefore, the intercept is the log odds that a study reported a marginally significant \\(p\\) value when Year10 = 0 (i.e, in 1970), which was estimated to be -1.8, 90% CI [-2.1, -1.5]. As log odds are not as intuitive as probability, it is common to interpret instead \\(\\hat{\\mu} = \\mathrm{logistic}(\\beta_0)\\), which is the conditional probability of being marginal_p = 1 in 1970. For Bayesian, that means obtaining the posterior distribution of \\(\\mathrm{logistic}(\\beta_0)\\), which can be done by\n\nm4_draws &lt;- as_draws(m4)\nm4_draws &lt;- m4_draws |&gt;\n    mutate_variables(logistic_beta0 = plogis(b_Intercept))\nm4_draws |&gt;\n    subset(variable = \"logistic_beta0\") |&gt;\n    summary()\n\n\n  \n\n\n\nThe bayesplot package allows you to plot transformed parameters quickly:\n\nmcmc_areas(m4, pars = \"b_Intercept\",\n           transformations = list(\"b_Intercept\" = \"plogis\"),\n           bw = \"SJ\")\n\n\n\n\n\n\n\n\n18.5.3.3 Interpreting \\(\\exp(\\beta_1)\\) as odds ratio\nThe slope, \\(\\beta_1\\), represents the difference in the predicted log odds between two observations with a unit difference in the predictor. For example, for two individuals with a unit difference in Year10 (i.e., 10 years), we have \\[\n\\mathrm{logit}(\\mu_{\\text{marginal\\_p} = 1}) -\n  \\mathrm{logit}(\\mu_{\\text{marginal\\_p} = 0}) = \\beta_1.\n\\]\nAgain, the difference in log odds are hard to interpret, so we will exponentiate to get \\[\n\\frac{\\mathrm{odds}_{\\text{marginal\\_p} = 1}}\n       {\\mathrm{odds}_{\\text{marginal\\_p} = 0}} = \\exp(\\beta_1).\n\\]\nThe fraction on the left-hand side is the odds ratio of reporting a marginal \\(p\\) value associated with a unit difference in Year10 (i.e., 10 years). An odds of 1.0 means that the probability of success and failure is equal; an odds &gt; 1 means success is more likely than failures; and an odds &lt; 1 means success is less likely than failures. Again, for Bayesian, we can obtain the posterior distribution of \\(\\exp(\\beta_1)\\) by\n\nm4_draws &lt;- m4_draws |&gt;\n    mutate_variables(exp_beta1 = exp(b_Year10))\nm4_draws |&gt;\n    subset(variable = \"exp_beta1\") |&gt;\n    summary()\n\n\n  \n\n\n\nUsing the posterior mean, we predict that the odds of reporting a marginal \\(p\\) value for a study that is 10 years later is multiplied by 1.4 times, 90% CI [1.3, 1.6]; in other words, every 10 years, the odds increased by 41.5852521%. Here’s the posterior density plot for the odds ratio:\n\nmcmc_areas(m4, pars = \"b_Year10\",\n           transformations = list(\"b_Year10\" = \"exp\"),\n           bw = \"SJ\")\n\n\n\n\n\n\n\nOdds ratio (OR) is popular as the multiplicative effect is constant, thus making interpretations easier. Also, in medical research and some other research areas, OR can be an excellent approximation of the relative risk, which is the probability ratio of two groups, of some rare diseases or events. However, odds and odds ratios are never intuitive metrics for people, and in many situations, a large odds ratio may be misleading as it may represent a very small effect. Therefore, in general, I would recommend you to interpret coefficients in probability units, even though that means more work.\n\n18.5.3.4 Interpreting Coefficients in Probability Units\nAnother way to interpret the results of the logistic regression coefficient is to examine the change in probability. Because the predicted probability is a nonlinear function of the predictors, a unit difference in the predictor has different meanings depending on the values of \\(X\\) you chose for interpretations. You can see that in the conditional_effects() plot earlier.\nConsider the change in the predicted probability of reporting a marginal \\(p\\) value with Year10 = 0 (1970), Year10 = 1 (1980), to Year10 = 4, respectively:\n\nm4_pred &lt;- posterior_epred(m4, list(Year10 = 0:4))\ncolnames(m4_pred) &lt;- paste0(\"Year10=\", 0:4)\nsummarise_draws(m4_pred)\n\n\n  \n\n\n\nAs you can see, the predicted difference in probability is smaller when comparing Year10 = 0 and 1, but is larger when comparing Year10 = 3 and 4.\n\n\n\n\n\n\nThe “divide by 4 rule”\n\n\n\nA quick approximation is to divide the coefficient by 4 to get an upper bound on the change in probability associated with a unit change in the predictor. In our example, this corresponds to 0.3454722 / 4 = 0.086368, which is very close to the predicted difference in probability from Year10 = 3 to Year10 = 4.\n\n\n\n18.5.4 Posterior Predictive Check\n\npp_check(\n    m4,\n    type = \"error_binned\"\n)\n\nUsing 10 posterior draws for ppc type 'error_binned' by default.\n\n\n\n\n\n\n\nFigure 18.5: Posterior Predictive Check for the binary logistic model.\n\n\n\n\nThe linear model is not the best fit.\n\n18.5.5 Linear Spline\nUse bs() to specify a linear spline (degree = 1) with one turning point (knots = 3).\n\nlibrary(splines)\nm5 &lt;- brm(marginal_p ~ bs(Year10, degree = 1, knots = 3),\n    data = marginalp_dev,\n    family = bernoulli(link = \"logit\"),\n    prior = prior(student_t(4, 0, .875), class = \"b\"),\n    # Note: no sigma\n    seed = 1340,\n    file = \"10_m5\"\n)\n\nStart sampling\n\n\nRunning MCMC with 4 chains, at most 2 in parallel...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.2 seconds.\nChain 2 finished in 0.1 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.1 seconds.\nChain 4 finished in 0.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.5 seconds.\n\n\n\n18.5.6 Posterior Prediction\n\nplot(\n    conditional_effects(m5),\n    points = TRUE,\n    point_args = list(height = 0.01, width = 0.05, alpha = 0.05)\n)\n\n\n\n\n\n\nFigure 18.6: Predicted probabilities of marginal significant results over time with the spline model.\n\n\n\n\n\npp_check(\n    m5,\n    type = \"error_binned\",\n    x = \"Year10\"\n)\n\nUsing 10 posterior draws for ppc type 'error_binned' by default.\n\n\nWarning: The following arguments were unrecognized and ignored: x\n\n\n\n\n\n\n\nFigure 18.7: Posterior Predictive Check for the binary logistic model with a linear spline.\n\n\n\n\n\n18.5.7 Model Comparison\n\nmsummary(list(linear = m4, `linear spline` = m5),\n         estimate = \"{estimate} [{conf.low}, {conf.high}]\",\n         statistic = NULL, fmt = 2)\n\nWarning: \n`modelsummary` uses the `performance` package to extract goodness-of-fit\nstatistics from models of this class. You can specify the statistics you wish\nto compute by supplying a `metrics` argument to `modelsummary`, which will then\npush it forward to `performance`. Acceptable values are: \"all\", \"common\",\n\"none\", or a character vector of metrics names. For example: `modelsummary(mod,\nmetrics = c(\"RMSE\", \"R2\")` Note that some metrics are computationally\nexpensive. See `?performance::performance` for details.\n This warning appears once per session.\n\n\n\n\n\nlinear\nlinear spline\n\n\n\nb_Intercept\n−1.82 [−2.20, −1.46]\n−1.95 [−2.37, −1.55]\n\n\nb_Year10\n0.35 [0.22, 0.48]\n\n\n\nb_bsYear10degreeEQ1knotsEQ31\n\n1.57 [0.93, 2.27]\n\n\nb_bsYear10degreeEQ1knotsEQ32\n\n1.22 [0.69, 1.77]\n\n\nNum.Obs.\n535\n535\n\n\nR2\n0.049\n0.050\n\n\nELPD\n−292.9\n−290.1\n\n\nELPD s.e.\n11.2\n11.1\n\n\nLOOIC\n585.8\n580.2\n\n\nLOOIC s.e.\n22.5\n22.2\n\n\nWAIC\n585.8\n580.2\n\n\nRMSE\n0.43\n0.42\n\n\n\n\n\nThe linear spline is better according to the information criteria.",
    "crumbs": [
      "Week 12",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Generalized Linear Model</span>"
    ]
  },
  {
    "objectID": "10-glm.html#footnotes",
    "href": "10-glm.html#footnotes",
    "title": "\n18  Generalized Linear Model\n",
    "section": "",
    "text": "Strictly speaking, GLM requires distributions that are in the exponential family, which will not include distributions like the \\(t\\) distribution, but here, we also include models that use distributions similar to those in the exponential family, like the Student’s \\(t\\) distribution.↩︎",
    "crumbs": [
      "Week 12",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Generalized Linear Model</span>"
    ]
  },
  {
    "objectID": "10b-glm2.html",
    "href": "10b-glm2.html",
    "title": "\n19  Generalized Linear Model (II)\n",
    "section": "",
    "text": "19.1 Flexible Non-Linear Models\nThe brms package has a special syntax for non-linear models for more complex relationships. More information can be found in https://cran.r-project.org/web/packages/brms/vignettes/brms_nonlinear.html.\nAs an example, in the marginalp data, some studies have more than one experiment:\nCodeggplot(marginalp, aes(x = `Number of Experiments`)) +\n    geom_bar() +\n    scale_x_discrete(limits = as.character(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)))\nIt seems sensible that the probability of reporting at least one marginally significant result would be higher when there are more experiments. And if the number of experiments increases over time, this variable is a potential confound for the relationship between time and the probability of marginally significant results.\nOne can instead explicitly incorporate the number of experiments in the model. Assuming that the probability of reporting marginal significant result in one experiment is \\(p\\), and assume that, within a study, the chance of reporting marginal significant results in different experiments is constant and independent, then the probability of reporting at least one marginal \\(p\\) value in a study with \\(n\\) experiments is\n\\[\n1 - (1 - p_m)^n\n\\tag{19.1}\\]\nWe will see how to incorporate this into brms using the non-linear syntax. But first, let’s use the non-linear syntax to refit our binary logistic model.",
    "crumbs": [
      "Week 12",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Generalized Linear Model (II)</span>"
    ]
  },
  {
    "objectID": "10b-glm2.html#flexible-non-linear-models",
    "href": "10b-glm2.html#flexible-non-linear-models",
    "title": "\n19  Generalized Linear Model (II)\n",
    "section": "",
    "text": "19.1.1 Binary Logistic Using the Non-Linear Syntax\nRecall that our model can be written as\n\\[\n\\begin{aligned}\n  \\text{marginal\\_p}_i & \\sim \\mathrm{Bern}(\\mu_i)  \\\\\n  \\mu_i & = \\mathrm{logit}^{-1}(\\beta_0 + \\beta_1 \\text{Year10}_{i})\n\\end{aligned}\n\\]\nWe can translate the above model into the non-linear syntax:\n\nf1 &lt;- bf(\n    # mu = logit^{-1}(beta0 + beta1 * Year10)\n    marginal_p ~ inv_logit(b0 + b1 * Year10),\n    # b0 and b1 are constant numbers\n    b0 + b1 ~ 1,\n    # nl = TRUE means we are using the non-linear syntax\n    nl = TRUE\n)\n\n\n\n\n\n\n\nBecause we already incorporate the inverse link function (inverse logit) in the syntax, we should use family = bernoulli(link = \"identity\").\n\n\n\n\n# Reft m4 using the non-linear syntax\nm4b &lt;- brm(f1,\n    data = marginalp_dev,\n    family = bernoulli(link = \"identity\"),\n    prior = c(\n        prior(student_t(4, 0, 1), nlpar = \"b1\"),\n        prior(student_t(4, 0, 2.5), nlpar = \"b0\")\n    ),\n    file = \"10_m4b\"\n)\nm4b\n\n Family: bernoulli \n  Links: mu = identity \nFormula: marginal_p ~ inv_logit(b0 + b1 * Year10) \n         b0 ~ 1\n         b1 ~ 1\n   Data: marginalp_dev (Number of observations: 535) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nb0_Intercept    -1.81      0.19    -2.18    -1.45 1.00     1248     1451\nb1_Intercept     0.34      0.07     0.21     0.47 1.00     1281     1562\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nThe results are basically the same as m4 in the previous note, as they are the same model.\n\n19.1.2 Custom Model Incorporating Number of Experiments\nNow, we can modify the above model by incorporating Equation 19.1. Just substite \\(p_m\\) = inv_logit(b0 + b1 * Year10):\n\nf2 &lt;- bf(\n    marginal_p ~ 1 - (1 - inv_logit(b0 + b1 * Year10))^nexp,\n    b0 + b1 ~ 1,\n    nl = TRUE\n)\n\n\n# Rename `Number of Experiments`\nmarginalp_dev$nexp &lt;- marginalp_dev$`Number of Experiments`\nm4c &lt;- brm(f2,\n    data = marginalp_dev,\n    family = bernoulli(link = \"identity\"),\n    prior = c(\n        prior(student_t(4, 0, 1), nlpar = \"b1\"),\n        prior(student_t(4, 0, 2.5), nlpar = \"b0\")\n    ),\n    file = \"10_m4c\"\n)\n\nWe can now plot the model-implied probabilities of marginal significant results over time, for one experiment.\n\nconditional_effects(\n    m4c,\n    effects = \"Year10\",\n    conditions = data.frame(\n        nexp = 1\n    )\n)\n\n\n\n\n\n\nFigure 19.1: Predicted probabilities of marginal significant results over time for one experiment.",
    "crumbs": [
      "Week 12",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Generalized Linear Model (II)</span>"
    ]
  },
  {
    "objectID": "10b-glm2.html#binomial-logistic-regression",
    "href": "10b-glm2.html#binomial-logistic-regression",
    "title": "\n19  Generalized Linear Model (II)\n",
    "section": "\n19.2 Binomial Logistic Regression",
    "text": "19.2 Binomial Logistic Regression\n\n\n\n\n\n\nTwo Equivalent Models\n\n\n\nWhen the probability is assumed equal across trials, the following are equivalent:\n\nIndividual data: Bernoulli\nGrouped data: Binomial\n\n\n\n\n19.2.1 Model\n\\[\n\\begin{aligned}\n  \\text{marginal\\_p}_j & \\sim \\mathrm{Bin}(N_j, \\mu_j)  \\\\\n  \\mathrm{logit}(\\mu_j) & = \\eta_j \\\\\n  \\eta_j & = \\beta_0 + \\beta_1 \\text{Year10}_{j}\n\\end{aligned}\n\\]\nPriors:\n\\[\n\\begin{aligned}\n  \\beta_0 & \\sim t_3(0, 2.5)  \\\\\n  \\beta_1 & \\sim t_4(0, 1)\n\\end{aligned}\n\\]\n\n# Grouping data should only be done for observations with\n# the same predicted probabilities\nmarginalp_dev_grouped &lt;-\n    marginalp_dev |&gt;\n    group_by(Year10) |&gt;\n    summarize(\n        marginal_p = sum(marginal_p),  # number of \"successes\"\n        n = n()  # number of trials\n    )\n\n\nm5_bin &lt;- brm(\n    marginal_p | trials(n) ~ bs(Year10, degree = 1, knots = 3),\n    data = marginalp_dev_grouped,\n    family = binomial(link = \"logit\"),\n    prior = prior(student_t(4, 0, 1), class = \"b\"),\n    # Note: no sigma\n    seed = 1340,\n    file = \"10_m5_bin\"\n)\n\n\npp_check(m5_bin, type = \"intervals\", x = \"Year10\")\n\nUsing all posterior draws for ppc type 'intervals' by default.\n\n\n\n\n\n\n\nFigure 19.2: Posterior predictive check using the predicted and observed counts.",
    "crumbs": [
      "Week 12",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Generalized Linear Model (II)</span>"
    ]
  },
  {
    "objectID": "10b-glm2.html#ordinal-regression",
    "href": "10b-glm2.html#ordinal-regression",
    "title": "\n19  Generalized Linear Model (II)\n",
    "section": "\n19.3 Ordinal Regression",
    "text": "19.3 Ordinal Regression\nThe example here is based on this paper: https://journals.sagepub.com/doi/full/10.1177/2515245918823199. The data come from the 2006 U.S. General Social Survey (GSS), where the codebook can be found at https://www.thearda.com/data-archive?tab=2&fid=GSS2006. The data can be imported from OSF:\n\nstemcell &lt;- read.csv(\"https://osf.io/vxw73/download\")\nstemcell &lt;- stemcell |&gt;\n    mutate(\n        belief = factor(belief,\n            levels = c(\"moderate\", \"fundamentalist\", \"liberal\")\n        )\n    )\n\nThe predictor is religious belief, and the outcome is the attitude toward stem cell research:\n\nRecently, there has been controversy over whether the government should provide any funds at all for scientific research that uses stem cells taken from human embryos. Would you say the government . . .\n\n\n1 = Definitely, should fund such research\n2 = Probably should fund such research\n3 = Probably should not fund such research\n4 = Definitely should not fund such research\n\n\nstemcell |&gt;\n    ggplot(aes(x = rating)) +\n    geom_bar() +\n    facet_wrap(~ belief)\n\n\n\n\n\n\nFigure 19.3: Distribution of opinion ratings on whether the government should fund stem-cell research by religious belief.",
    "crumbs": [
      "Week 12",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Generalized Linear Model (II)</span>"
    ]
  },
  {
    "objectID": "10b-glm2.html#model-1",
    "href": "10b-glm2.html#model-1",
    "title": "\n19  Generalized Linear Model (II)\n",
    "section": "\n19.4 Model",
    "text": "19.4 Model\n\\[\n\\begin{aligned}\n  \\text{rating}_i & \\sim \\mathrm{Categorical}(\\pi^1_i, \\pi^2_i, \\pi^3_i, \\pi^4_i)  \\\\\n  \\pi^1_{i} & = \\mathrm{logit}^{-1}(\\tau^1 - \\eta_i)  \\\\\n  \\pi^2_{i} & = \\mathrm{logit}^{-1}(\\tau^2 - \\eta_i) - \\mathrm{logit}^{-1}(\\tau^1 - \\eta_i)  \\\\\n  \\pi^3_{i} & = \\mathrm{logit}^{-1}(\\tau^3 - \\eta_i) - \\mathrm{logit}^{-1}(\\tau^2 - \\eta_i)  \\\\\n  \\pi^4_{i} & = 1 - \\mathrm{logit}^{-1}(\\tau^3 - \\eta_i)  \\\\\n  \\eta_i & = \\beta_1 \\text{fundamentalist}_{i} + \\beta_2 \\text{liberal}_{i}\n\\end{aligned}\n\\]\nPriors:\n\\[\n\\begin{aligned}\n  \\tau^1, \\tau^2, \\tau^3 & \\sim t_3(0, 2.5)  \\\\\n  \\beta_1 & \\sim N(0, 1)\n\\end{aligned}\n\\]\n\nm6 &lt;- brm(\n    rating ~ belief,\n    data = stemcell,\n    family = cumulative(link = \"logit\"),\n    prior = prior(std_normal(), class = \"b\"),\n    seed = 1340,\n    file = \"10_m6\"\n)\n\n\n19.4.1 Posterior Predictive Check\n\npp_check(m6, type = \"bars_grouped\", group = \"belief\",\n         ndraws = 100)\n\n\n\n\n\n\nFigure 19.4: Posterior Predictive Check for the ordinal regression model.\n\n\n\n\nThe fit was reasonable.\n\n19.4.2 Plot\n\nconditional_effects(m6, categorical = TRUE)\n\n\n\n\n\n\nFigure 19.5: Model-predicted probabilities based on the ordinal regression model.",
    "crumbs": [
      "Week 12",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Generalized Linear Model (II)</span>"
    ]
  },
  {
    "objectID": "10b-glm2.html#nominal-logistic-regression",
    "href": "10b-glm2.html#nominal-logistic-regression",
    "title": "\n19  Generalized Linear Model (II)\n",
    "section": "\n19.5 Nominal Logistic Regression",
    "text": "19.5 Nominal Logistic Regression\nOrdinal regression is a special case of nominal regression with the proportional odds assumption.\n\n19.5.1 Model\n\\[\n\\begin{aligned}\n  \\text{rating}_i & \\sim \\mathrm{Categorical}(\\pi^1_{i}, \\pi^2_{i}, \\pi^3_{i}, \\pi^4_{i})  \\\\\n  \\pi^1_{i} & = \\frac{1}{\\exp(\\eta^2_{i}) + \\exp(\\eta^3_{i}) + \\exp(\\eta^4_{i}) + 1}  \\\\\n  \\pi^2_{i} & = \\frac{\\exp(\\eta^2_{i})}{\\exp(\\eta^2_{i}) + \\exp(\\eta^3_{i}) + \\exp(\\eta^4_{i}) + 1}  \\\\\n  \\pi^3_{i} & = \\frac{\\exp(\\eta^3_{i})}{\\exp(\\eta^2_{i}) + \\exp(\\eta^3_{i}) + \\exp(\\eta^4_{i}) + 1}  \\\\\n  \\pi^4_{i} & = \\frac{\\exp(\\eta^4_{i})}{\\exp(\\eta^2_{i}) + \\exp(\\eta^3_{i}) + \\exp(\\eta^4_{i}) + 1}  \\\\\n  \\eta^2_{i} & = \\beta^2_{0} + \\beta^2_{1} \\text{fundamentalist}_{i} + \\beta^2_{2} \\text{liberal}_{i}  \\\\\n  \\eta^3_{i} & = \\beta^3_{0} + \\beta^3_{1} \\text{belief}_{i} + \\beta^3_{2} \\text{liberal}_{i} \\\\\n  \\eta^4_{i} & = \\beta^4_{0} + \\beta^4_{1} \\text{belief}_{i} + \\beta^4_{2} \\text{liberal}_{i} \\\\\n\\end{aligned}\n\\]\nAs you can see, it has two additional parameters for each predictor column.\n\nm7 &lt;- brm(\n    rating ~ belief,\n    data = stemcell,\n    family = categorical(link = \"logit\"),\n    prior = prior(std_normal(), class = \"b\", dpar = \"mu2\") +\n        prior(std_normal(), class = \"b\", dpar = \"mu3\") +\n        prior(std_normal(), class = \"b\", dpar = \"mu4\"),\n    seed = 1340,\n    file = \"10_m7\"\n)\n\n\n19.5.2 Model Comparison\n\nmsummary(list(`ordinal (proportional odds)` = m6, norminal = m7),\n         estimate = \"{estimate} [{conf.low}, {conf.high}]\",\n         statistic = NULL, fmt = 2)\n\nWarning: \n`modelsummary` uses the `performance` package to extract goodness-of-fit\nstatistics from models of this class. You can specify the statistics you wish\nto compute by supplying a `metrics` argument to `modelsummary`, which will then\npush it forward to `performance`. Acceptable values are: \"all\", \"common\",\n\"none\", or a character vector of metrics names. For example: `modelsummary(mod,\nmetrics = c(\"RMSE\", \"R2\")` Note that some metrics are computationally\nexpensive. See `?performance::performance` for details.\n This warning appears once per session.\n\n\n\nTable 19.1: Comparison of the ordinal and nominal regression models.\n\n\n\n\n\nordinal (proportional odds)\nnorminal\n\n\n\nb_Intercept[1]\n−0.94 [−1.18, −0.72]\n\n\n\nb_Intercept[2]\n1.04 [0.81, 1.28]\n\n\n\nb_Intercept[3]\n2.14 [1.86, 2.44]\n\n\n\nb_belieffundamentalist\n0.41 [0.12, 0.72]\n\n\n\nb_beliefliberal\n−0.55 [−0.85, −0.25]\n\n\n\nb_mu2_Intercept\n\n0.63 [0.38, 0.90]\n\n\nb_mu3_Intercept\n\n−0.57 [−0.94, −0.20]\n\n\nb_mu4_Intercept\n\n−1.05 [−1.48, −0.65]\n\n\nb_mu2_belieffundamentalist\n\n0.12 [−0.29, 0.54]\n\n\nb_mu2_beliefliberal\n\n−0.69 [−1.06, −0.33]\n\n\nb_mu3_belieffundamentalist\n\n0.52 [0.00, 1.04]\n\n\nb_mu3_beliefliberal\n\n−0.77 [−1.32, −0.24]\n\n\nb_mu4_belieffundamentalist\n\n0.70 [0.13, 1.26]\n\n\nb_mu4_beliefliberal\n\n−0.58 [−1.18, 0.01]\n\n\nNum.Obs.\n829\n829\n\n\nR2\n0.043\n\n\n\nELPD\n−1019.2\n−1020.9\n\n\nELPD s.e.\n15.5\n15.6\n\n\nLOOIC\n2038.5\n2041.8\n\n\nLOOIC s.e.\n31.1\n31.2\n\n\nWAIC\n2038.5\n2041.8",
    "crumbs": [
      "Week 12",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Generalized Linear Model (II)</span>"
    ]
  },
  {
    "objectID": "11-multilevel.html",
    "href": "11-multilevel.html",
    "title": "\n20  Multilevel Models\n",
    "section": "",
    "text": "20.1 Examples of Clustering\nIn this note, we’ll talk about multilevel models. To start, we have already seen a basic version of a multilevel—when discussing hierarchical models with partial pooling. There, we consider a binomial model with a parameter \\(\\theta_j\\) for each person, and consider a common distribution for all the \\(\\theta\\) parameters. A multilevel model is a model where we can have one or more cluster-specific parameters for each cluster (e.g., person, group, etc.), and these parameters are assumed to come from some common distributions.\nWe will use a within-subject example in this note, starting with a few data points to fit a model equivalent to a repeated-measure ANOVA, and then generalize to a multilevel regression model with varying intercepts and slopes. The latter is also called a growth curve model.\nThere are many different forms of clustering in data across different disciplines, including\nThey can be represented in network graphs like Figure 20.1 (students within schools):\nSometimes, there is more than one level of clustering, like students clustered by middle and high schools. This is called a crossed structure, as shown in Figure 20.2, where we say that students are cross-classified by both middle and high schools. Another typical example in psychological experiments is when participants see multiple stimuli, each as an item, so the observations are cross-classified by both persons and items.\nThe scenario of repeated measures nested within persons is particularly relevant, as essentially all longitudinal data are multilevel and should be modelled accordingly. It allows one to build individualized models to look at within-person changes, as well as between-person differences of those changes. Techniques such as dependent-sample \\(t\\)-test, repeated-measures ANOVA, growth curve modeling, and time-series analyses, can all be represented in the multilevel modeling framework. Therefore, some authors, such as @ mcelreath2020, suggest that MLM should be the default model we use for analyses rather than regression.",
    "crumbs": [
      "Week 13",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Multilevel Models</span>"
    ]
  },
  {
    "objectID": "11-multilevel.html#examples-of-clustering",
    "href": "11-multilevel.html#examples-of-clustering",
    "title": "\n20  Multilevel Models\n",
    "section": "",
    "text": "Students in schools\nClients nested within therapists within clinics\nEmployees nested within organizations\nCitizens nested within employees\nRepeated measures nested within persons\n\n\n\n\n\n\n\nFigure 20.1\n\n\n\n\n\n\n\n\nFigure 20.2",
    "crumbs": [
      "Week 13",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Multilevel Models</span>"
    ]
  },
  {
    "objectID": "11-multilevel.html#data",
    "href": "11-multilevel.html#data",
    "title": "\n20  Multilevel Models\n",
    "section": "\n20.2 Data",
    "text": "20.2 Data\nWe will use the data set sleepstudy from the lme4 package, a popular package for frequentist multilevel modeling. The data set contains 18 participants, each with 10 observations. It examines the change in average reaction time daily with increasing sleep deprivation. See ?lme4::sleepstudy for more of the description. Here is a plot of the the Reaction variable:\n\ndata(sleepstudy, package = \"lme4\")\nhist(sleepstudy$Reaction)\n\n\n\n\n\n\nFigure 20.3: Distribution of reaction times (ms)\n\n\n\n\nThis data set has clustering because it is repeated measures nested within persons. For the initial example, we will only take the first three time points (Days 1-3).\n\nsleep3 &lt;- sleepstudy |&gt;\n    filter(Days %in% 1:3)\nhead(sleep3)  # first two people\n\n\n  \n\n\n\n\n\n\n\n\n\nLong-Format Data\n\n\n\nNote that the data above is in long format, which is typically required for multilevel analysis. Here, each row of the data represents one observation, so there are multiple rows for each person. This is in contrast to wide format, where each row represents one person and has multiple columns for each observation.\n\n\nHere is a spaghetti plot of each individual over the three days:\n\nggplot(sleep3, aes(x = Days, y = Reaction)) +\n    geom_point(size = 0.5) +\n    geom_line(aes(group = Subject)) +\n    scale_x_continuous(breaks = 1:3) +\n    ylab(\"Reaction Time (ms)\")\n\n\n\n\n\n\nFigure 20.4: Reaction time change over three days.\n\n\n\n\nThe plot shows a general increasing trend of reaction time.",
    "crumbs": [
      "Week 13",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Multilevel Models</span>"
    ]
  },
  {
    "objectID": "11-multilevel.html#analysis-1-time-as-nominal",
    "href": "11-multilevel.html#analysis-1-time-as-nominal",
    "title": "\n20  Multilevel Models\n",
    "section": "\n20.3 Analysis 1: Time as Nominal",
    "text": "20.3 Analysis 1: Time as Nominal\nThis analysis is analogous to a repeated-measure ANOVA. Here, our interest is simply whether there are any differences across time, without any assumption on any linear or nonlinear trends. In other words, we treat time as a nominal variable.\n\n20.3.1 Model\nWe use \\(\\text{Reaction}_{ij}\\) to represent the reaction time for the \\(j\\)th person on the \\(i\\)th day.\n\\[\n\\begin{aligned}\n  \\text{Reaction}_{ij} & \\sim N(\\mu_{ij}, \\sigma)  \\\\\n  \\mu_{ij} \\sim N(\\gamma_i, \\tau)\n\\end{aligned}\n\\]\n\n\n\\(\\mu_{ij}\\): the expected reaction time for person \\(j\\) on day \\(i\\).\n\n\\(\\sigma\\): the within-person error.\n\n\\(\\gamma_i\\): the mean reaction time across participants on day \\(i\\).\n\n\\(\\tau\\): the between-person variance on a particular day.\n\n\n\n\n\n\n\nAssumptions\n\n\n\nThe above model assumes:\n\nNormality\nHomogeneity of error variance across observations\nHomogeneity of variance across persons\n\n\n\n\n# Treat Days as a nominal variable\nsleep3$Days_cat &lt;- factor(sleep3$Days)\nm1 &lt;- brm(Reaction ~ 0 + Days_cat + (1 | Subject),\n    data = sleep3,\n    seed = 2225,\n    file = \"11_m1\")\nm1\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: Reaction ~ 0 + Days_cat + (1 | Subject) \n   Data: sleep3 (Number of observations: 54) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~Subject (Number of levels: 18) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)    31.56      6.16    21.58    45.07 1.00      869     1371\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nDays_cat1   264.32      8.43   248.27   281.08 1.00      600      719\nDays_cat2   265.21      8.37   248.87   282.11 1.00      632      640\nDays_cat3   282.98      8.37   266.77   299.18 1.00      615      702\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma    16.70      2.17    13.28    21.77 1.00     2120     2344\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nThe model estimates the mean reaction time on each day, as well as the between-person and within-person variances. One can visualize the means:\n\nconditional_effects(m1)\n\n\n\n\n\n\nFigure 20.5: Model predicted mean reaction times over three days.\n\n\n\n\nOne can compare this model to one where the mean reaction time is assumed equal across days:\n\nm0 &lt;- brm(Reaction ~ 1 + (1 | Subject),\n    data = sleep3,\n    seed = 2225,\n    file = \"11_m0\")\nloo(m0, m1)\n\nWarning: Found 2 observations with a pareto_k &gt; 0.7 in model 'm1'. We recommend\nto set 'moment_match = TRUE' in order to perform moment matching for\nproblematic observations.\n\n\nOutput of model 'm0':\n\nComputed from 4000 by 54 log-likelihood matrix.\n\n         Estimate   SE\nelpd_loo   -245.9  5.9\np_loo        15.4  2.8\nlooic       491.7 11.9\n------\nMCSE of elpd_loo is 0.2.\nMCSE and ESS estimates assume MCMC draws (r_eff in [0.4, 1.6]).\n\nAll Pareto k estimates are good (k &lt; 0.7).\nSee help('pareto-k-diagnostic') for details.\n\nOutput of model 'm1':\n\nComputed from 4000 by 54 log-likelihood matrix.\n\n         Estimate  SE\nelpd_loo   -239.2 4.6\np_loo        17.4 2.4\nlooic       478.3 9.2\n------\nMCSE of elpd_loo is NA.\nMCSE and ESS estimates assume MCMC draws (r_eff in [0.4, 1.6]).\n\nPareto k diagnostic values:\n                         Count Pct.    Min. ESS\n(-Inf, 0.7]   (good)     52    96.3%   115     \n   (0.7, 1]   (bad)       2     3.7%   &lt;NA&gt;    \n   (1, Inf)   (very bad)  0     0.0%   &lt;NA&gt;    \nSee help('pareto-k-diagnostic') for details.\n\nModel comparisons:\n   elpd_diff se_diff\nm1  0.0       0.0   \nm0 -6.7       3.4   \n\n\nLOO indicates that allowing a different mean reaction time for each day fits the data better.",
    "crumbs": [
      "Week 13",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Multilevel Models</span>"
    ]
  },
  {
    "objectID": "11-multilevel.html#analysis-2-growth-curve",
    "href": "11-multilevel.html#analysis-2-growth-curve",
    "title": "\n20  Multilevel Models\n",
    "section": "\n20.4 Analysis 2: Growth Curve",
    "text": "20.4 Analysis 2: Growth Curve\nWe will now use all 10 time points, and try to fit a line/curve to the time trend. Figure 20.6 shows the changes across participants.\n\nggplot(sleepstudy, aes(x = Days, y = Reaction)) +\n    geom_point(size = 0.5) +\n    geom_smooth() +\n    # presented by person\n    facet_wrap(~Subject, ncol = 6)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\nFigure 20.6: Individual trajectories across days.\n\n\n\n\nAs you can see, most people experience increases in reaction time, although there are certainly differences across individuals, such that each person has a different trajectory.\n\n20.4.1 Intraclass correlation\nWith multilevel data, the first question is how much variation in the outcome is at each level. This is quantified by the intraclass correlation, which, for a two-level model, is defined by \\[\n\\rho = \\frac{\\tau^2}{\\tau^2 + \\sigma^2}\n\\] where \\(\\tau\\) is the between-level SD, which is the SD of the cluster means (i.e., the variability of mean response time across persons in this example), and \\(\\sigma\\) is the within-level SD (i.e., variability within a person, which is assumed constant across persons).\n\n\n\n\n\n\nHow Things Look With Different ICCs\n\n\n\n\nThe ICC represents the proportion of variance of the outcome that is due to between-level (e.g., between-group, between-person) differences\n\nCodeset.seed(1)\nfake_dat1 &lt;- data.frame(\n    person = as.character(rep(1:8, 25)),\n    y = rnorm(200,\n        mean = rnorm(8, mean = 50, sd = 0.1),\n        sd = 10\n    )\n)\n\npbase &lt;- ggplot(fake_dat1, aes(x = person, y = y)) +\n    geom_jitter(width = 0.1, col = \"darkgrey\") +\n    stat_summary(\n        geom = \"point\", fun = mean,\n        size = 4, shape = 24, fill = \"red\"\n    ) +\n    ylim(20, 80) +\n    theme(axis.text.y = element_blank())\npbase\n\nfake_dat2 &lt;- data.frame(\n    person = as.character(rep(1:8, 25)),\n    y = rnorm(200,\n        mean = rnorm(8, mean = 50, sd = sqrt(20)),\n        sd = sqrt(80)\n    )\n)\npbase %+% fake_dat2\n\nfake_dat3 &lt;- data.frame(\n    person = as.character(rep(1:8, 25)),\n    y = rnorm(200,\n        mean = rnorm(8, mean = 50, sd = sqrt(95)),\n        sd = sqrt(5)\n    )\n)\npbase %+% fake_dat3\n\n\n\n\n\n\n\n\n\n(a) ICC close to 0\n\n\n\n\n\n\n\n\n\n(b) ICC = .2\n\n\n\n\n\n\n\n\n\n(c) ICC = .95\n\n\n\n\n\n\nFigure 20.7: ICC examples.\n\n\nAs you can see, the higher the ICC, the higher the variations in the cluster means, relative to the within-cluster variations.\n\n\nFigure 20.8 shows substantial between-person variation for the sleepstudy data.\n\nggplot(sleepstudy, aes(x = Subject, y = Reaction)) +\n    geom_jitter(width = 0.1, col = \"darkgrey\") +\n    stat_summary(\n        geom = \"point\", fun = mean,\n        size = 4, shape = 24, fill = \"red\"\n    )\n\n\n\n\n\n\nFigure 20.8: ICC for the sleepstudy data.\n\n\n\n\n\n20.4.1.1 Computing ICC: Varying-intercept model\nTo compute the ICC, we need first to fit a multilevel model, which in this case is the varying intercept model:\n\\[\n\\begin{aligned}\n  \\text{Reaction}_{ij} & \\sim N(\\mu_j, \\sigma)  \\\\\n  \\mu_j & \\sim N(\\gamma, \\tau)\n\\end{aligned}\n\\] where \\(\\mu_j\\) is the mean reaction for the \\(j\\)th person.\nWe’ll rescale Reaction by 10:\n\nsleepstudy &lt;- sleepstudy |&gt;\n    mutate(Reaction10 = Reaction / 10)\n\nTo use weakly informative priors, we will set\n\\[\n\\begin{aligned}\n  \\gamma & \\sim N(0, 50)  \\\\\n  \\sigma & \\sim t^+(4, 0, 5)  \\\\\n  \\tau & \\sim \\mathrm{Gamma}(2, 1 / 5)\n\\end{aligned}\n\\]\n\nm2 &lt;- brm(Reaction10 ~ (1 | Subject), data = sleepstudy,\n          prior = c(# for intercept\n            prior(normal(0, 50), class = \"Intercept\"),\n            # for tau\n            prior(gamma(2, 0.2), class = \"sd\"),\n            # for sigma\n            prior(student_t(4, 0, 5), class = \"sigma\")),\n          # Higher adapt_delta is usually needed for MLM\n          control = list(adapt_delta = .95),\n          seed = 2107,\n          file = \"11_m2\")\nm2\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: Reaction10 ~ (1 | Subject) \n   Data: sleepstudy (Number of observations: 180) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~Subject (Number of levels: 18) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     3.94      0.87     2.61     6.05 1.01      959     1207\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept    29.81      1.00    27.78    31.82 1.01      662     1199\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     4.45      0.25     3.98     4.96 1.00     3691     2506\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nNow use the posterior draws of \\(\\tau\\) and \\(\\sigma\\) to compute the posterior for the ICC:\n\nicc_draws &lt;- as_draws(m2, variable = c(\"sd_Subject__Intercept\", \"sigma\")) |&gt;\n    mutate_variables(\n        icc = sd_Subject__Intercept^2 / (sd_Subject__Intercept^2 + sigma^2)\n    )\nsummary(icc_draws)\n\n\n  \n\n\n\n\nmcmc_dens(icc_draws, pars = \"icc\")\n\n\n\n\n\n\nFigure 20.9: Posterior distribution of the ICC for reaction time.\n\n\n\n\n\n\n\n\n\n\nInterpretations\n\n\n\nThe model suggested that the average reaction time across individuals and measurement occasions was 298ms, 90% CI [281ms, 314ms]. It was estimated that 43.22%, 90% CI [27.12%, 61.31%] of the variations in reaction time was attributed to between-person differences.\n\n\n\n\n\n\n\n\nIs MLM Needed?\n\n\n\nThis is a commonly asked question. Based on Lai & Kwok (2015), you can compute the design effect index, which shows the inflation in the variability of the estimates due to clustering. It is recommended to account for clustering if the design effect is larger than 1.1. It is defined as: \\[\n\\mathrm{Deff} = 1 + (n - 1) \\rho\n\\] where \\(n\\) is the (average) number of observations in each cluster, and in our case it is 10. Therefore, the design effect in sleepstudy for Reaction is \\[\n\\mathrm{Deff} = 1 + (10 - 1) (0.432219)\n\\] which is 4.889971, so we do need to account for the clustering.",
    "crumbs": [
      "Week 13",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Multilevel Models</span>"
    ]
  },
  {
    "objectID": "11-multilevel.html#varying-coefficients",
    "href": "11-multilevel.html#varying-coefficients",
    "title": "\n20  Multilevel Models\n",
    "section": "\n20.5 Varying Coefficients",
    "text": "20.5 Varying Coefficients\nThe strength of a multilevel model is that it can allow researchers to build models that allow for cluster-specific coefficients. In our example data, this is analogous to fitting separate models for each person, but instead of only using 10 data points for each model, MLM pools information from other people as it believes that we can learn something about one person by looking at data from other people.\nFor example, for each person, we’ll fit a regression model using Days to predict Reaction10. Using our previous notations,\n\\[\n\\begin{aligned}\n  \\text{Reaction10}_i & \\sim N(\\mu_i, \\sigma)  \\\\\n  \\mu_i & = \\beta_0 + \\beta_1 \\text{Days}_i\n\\end{aligned}\n\\] However, because we have more than one person, we’ll use the subscript \\(j\\) to denote the person, so that the model becomes \\[\n\\begin{aligned}\n  \\text{Reaction10}_{ij} & \\sim N(\\mu_{ij}, \\sigma_j)  \\\\\n  \\mu_{ij} & = \\beta_{0j} + \\beta_{1j} \\text{Days}_{ij}\n\\end{aligned}\n\\] which suggests that all three of \\(\\beta_0\\), \\(\\beta_1\\), and \\(\\sigma\\) can be different across persons. We’ll first start with varying \\(\\beta_0\\), or varying intercepts.\n\n20.5.1 Varying Intercepts\nWith varying intercepts model, we assumed that only \\(\\beta_0\\) is different across persons, but \\(\\beta_1\\) and \\(\\sigma\\) are common parameters that do not change across persons. This is called a random intercept model in (frequentist) MLM literature. Specifically, the model and priors are:\n\\[\n\\begin{aligned}\n\\text{Repeated-measure level:}  \\\\\n  \\text{Reaction10}_{ij} & \\sim N(\\mu_{ij}, \\sigma)  \\\\\n  \\mu_{ij} & = \\beta_{0j} + \\beta_{1} \\text{Days}_{ij}  \\\\\n\\text{Person level:}  \\\\\n  \\beta_{0j} & \\sim N(\\mu^{[\\beta_0]}, \\tau^{[\\beta_0]})  \\\\\n\\text{Priors:}  \\\\\n  \\mu^{[\\beta_0]} & \\sim N(0, 50) \\\\\n  \\tau^{[\\beta_0]} & \\sim \\mathrm{Gamma}(2, 0.2) \\\\\n  \\beta_1 & \\sim N(0, 10) \\\\\n  \\sigma & \\sim t^+(4, 0, 5)\n\\end{aligned}\n\\] where the \\(\\beta_{0j}\\)s follow a common normal distribution with hyperparameters \\(\\mu^{[\\beta_0]}\\) and \\(\\tau^{[\\beta_0]}\\). Thus, \\(\\mu^{[\\beta_0]}\\) is the grand intercept, or the average intercept across persons, and \\(\\tau^{[\\beta_0]}\\) is the SD of those intercepts.\nThe model can be fitted in brms:\n\nm3 &lt;- brm(Reaction10 ~ Days + (1 | Subject),\n    data = sleepstudy,\n    prior = c( # for intercept\n        prior(normal(0, 50), class = \"Intercept\"),\n        # for slope\n        prior(normal(0, 10), class = \"b\"),\n        # for tau\n        prior(gamma(2, 0.2), class = \"sd\"),\n        # for sigma\n        prior(student_t(4, 0, 5), class = \"sigma\")\n    ),\n    control = list(adapt_delta = .95),\n    seed = 2107,\n    file = \"11_m3\"\n)\n\n\nm3\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: Reaction10 ~ Days + (1 | Subject) \n   Data: sleepstudy (Number of observations: 180) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~Subject (Number of levels: 18) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     4.11      0.82     2.85     6.04 1.00      765     1360\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept    25.23      1.07    23.16    27.27 1.00      589      929\nDays          1.05      0.08     0.89     1.21 1.00     2906     2862\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     3.12      0.17     2.81     3.49 1.00     2370     2541\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nLet’s check the fit of the model to the data, first to the overall data and then to each individual.\n\n20.5.1.1 Fit of Overall data\n\npp_check(m3, type = \"intervals\", x = \"Days\",\n         re_formula = NA) +\n    geom_smooth(se = FALSE, col = \"blue\") +\n    geom_smooth(aes(y = y_obs), se = FALSE, col = \"red\", linetype = \"dashed\")\n\nUsing all posterior draws for ppc type 'intervals' by default.\n\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: The following aesthetics were dropped during statistical transformation: ymin,\nymax\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: The following aesthetics were dropped during statistical transformation: ymin,\nymax\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\n\n\nFigure 20.10: Marginal model plot of the overall data.\n\n\n\n\nAs can be seen, the estimated coefficient for Days, which was assumed constant for everyone, fit the overall data. However, does it fit each individual?\n\n20.5.1.2 Fit of Individuals\n\nce_m3 &lt;- conditional_effects(m3,\n    re_formula = NULL,\n    conditions = data.frame(Subject = unique(sleepstudy$Subject))\n)\n# Add original outcome variable\nplot(ce_m3, points = TRUE, ncol = 6, plot = FALSE)[[1]] +\n    geom_smooth(\n        data = attr(ce_m3[[1]], \"points\"),\n        aes(x = Days, y = resp__),\n        se = FALSE, col = \"red\",\n        linewidth = 0.8, alpha = 0.5,\n        inherit.aes = FALSE\n    )\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\nFigure 20.11: Marginal model plot by individuals, with only varying intercepts.\n\n\n\n\nObviously, it only fits a few individuals, but not all. So let’s also allow \\(\\beta_1\\) to vary.\n\n20.5.2 Varying Slopes\nWe’ll now also allow \\(\\beta_1\\) to vary across clusters, with the following model:\n\\[\n\\begin{aligned}\n\\text{Repeated-measure level:}  \\\\\n  \\text{Reaction10}_{ij} & \\sim N(\\mu_{ij}, \\sigma)  \\\\\n  \\mu_{ij} & = \\beta_{0j} + \\beta_{1j} \\text{Days}_{ij}  \\\\\n\\text{Person level:}  \\\\\n  \\begin{bmatrix}\n    \\beta_{0j} \\\\\n    \\beta_{1j} \\\\\n  \\end{bmatrix} & \\sim N_2\\left(\n    \\begin{bmatrix}\n      \\mu^{[\\beta_0]} \\\\\n      \\mu^{[\\beta_1]} \\\\\n    \\end{bmatrix}, \\mathbf T\n    \\right)\n\\end{aligned}\n\\] where \\[\n\\mathbf T = \\begin{bmatrix}\n      {\\tau^{[\\beta_0]}}^2 & \\\\\n      \\tau^{\\beta{10}} & {\\tau^{[\\beta_1]}}^2 \\\\\n    \\end{bmatrix}\n\\]\nNote that \\(N_2\\) denotes a bivariate normal (i.e., 2-dimensional multivariate normal) distribution, because now we can talk about how \\(\\beta_0\\) and \\(\\beta_1\\) are associated at the person level. Generally, I don’t interpret the covariance between them because it largely depends on how the variables were centered, but we should allow them to be correlated. The parameter \\(\\tau^{\\beta{10}}\\) thus denotes their covariance.\n\n\n\n\n\n\nPrograms using Gibbs sampling, such as MCMCglmm, use an inverse-Wishart distribution as a prior for the covariance matrix \\(\\mathbf T\\), but it has been shown to usually lead to biased and inefficient estimates.\n\n\n\nTo estimate \\(\\mathbf T\\), recent recommendations, as implemented in brms, suggest decomposing \\(\\mathbf T\\) into a correlation matrix and the scaling matrices, and using an LKJ prior to the correlation matrix. We explain the LKJ prior in Important 20.1. Let’s first do the decomposition:\n\\[\n\\mathbf T = \\mathrm{diag}(\\boldsymbol{\\tau}) \\boldsymbol{\\Omega} \\mathrm{diag}(\\boldsymbol{\\tau}),\n\\] where \\(\\mathbf T\\) = \\([\\tau_1, \\tau_2, \\ldots]\\) is a vector containing the scale parameters (i.e., SD) of the varying coefficients, and \\(\\boldsymbol{\\Omega}\\) is the correlation matrix of the varying coefficients.\n\n\n\n\n\n\nImportant 20.1: LKJ Prior\n\n\n\nThe LKJ Prior is a probability distribution for correlation matrices. A correlation matrix has 1 on all the diagonal elements. For example, a 2 \\(\\times\\) 2 correlation matrix is \\[\n\\begin{bmatrix}\n    1 & \\\\\n    0.35 & 1\n\\end{bmatrix}\n\\] where the correlation is 0.35. Therefore, with two variables, there is one correlation; with three or more variables, the number of correlations will be \\(q (q - 1) / 2\\), where \\(q\\) is the number of variables.\nFor a correlation matrix of a given size, the LKJ prior has one shape parameter, \\(\\eta\\), where \\(\\eta = 1\\) corresponds to a uniform distribution of the correlations such that any correlations are equally likely, \\(\\eta \\geq 1\\) favors a matrix closer to an identity matrix so that the correlations are closer to zero, and \\(\\eta \\leq 1\\) favors a matrix with larger correlations. For a 2 \\(\\times\\) 2 matrix, the distribution of the correlation, \\(\\rho\\), with different \\(\\eta\\) values are shown in the graph below:\n\nCodedlkjcorr2 &lt;- function(rho, eta = 1, log = FALSE) {\n    # Function to compute the LKJ density given a correlation\n    out &lt;- (eta - 1) * log(1 - rho^2) -\n        1 / 2 * log(pi) - lgamma(eta) + lgamma(eta + 1 / 2)\n    if (!log) out &lt;- exp(out)\n    out\n}\nggplot(data.frame(rho = c(-1, 1)), aes(x = rho)) +\n    stat_function(\n        fun = dlkjcorr2, args = list(eta = 0.1),\n        aes(col = \"0.1\"), n = 501\n    ) +\n    stat_function(\n        fun = dlkjcorr2, args = list(eta = 0.5),\n        aes(col = \"0.5\"), n = 501\n    ) +\n    stat_function(\n        fun = dlkjcorr2, args = list(eta = 1),\n        aes(col = \"1\"), n = 501\n    ) +\n    stat_function(\n        fun = dlkjcorr2, args = list(eta = 2),\n        aes(col = \"2\"), n = 501\n    ) +\n    stat_function(\n        fun = dlkjcorr2, args = list(eta = 10),\n        aes(col = \"10\"), n = 501\n    ) +\n    stat_function(\n        fun = dlkjcorr2, args = list(eta = 100),\n        aes(col = \"100\"), n = 501\n    ) +\n    labs(col = expression(eta), x = expression(rho), y = \"Density\")\n\nWarning: Removed 2 rows containing missing values (`geom_function()`).\n\n\n\n\nLKJ prior on a correlation with different different \\(\\eta\\) values.\n\n\n\nAs you can see, when \\(\\eta\\) increases, the correlation is more concentrated to zero.\nThe default of brms is to use \\(\\eta\\) = 1, which is non-informative. If you have a weak but informative belief that the correlations shouldn’t be very large, using \\(\\eta\\) = 2 is reasonable.\n\n\nThe resulting model and priors are:\n\\[\n\\begin{aligned}\n\\text{Repeated-measure level:}  \\\\\n  \\text{Reaction10}_{ij} & \\sim N(\\mu_{ij}, \\sigma)  \\\\\n  \\mu_{ij} & = \\beta_{0j} + \\beta_{1j} \\text{Days}_{ij}  \\\\\n\\text{Person level:}  \\\\\n  \\begin{bmatrix}\n    \\beta_{0j} \\\\\n    \\beta_{1j} \\\\\n  \\end{bmatrix} & \\sim N_2\\left(\n    \\begin{bmatrix}\n      \\mu^{[\\beta_0]} \\\\\n      \\mu^{[\\beta_1]} \\\\\n    \\end{bmatrix}, \\mathbf T\n    \\right)  \\\\\n  \\mathbf T & = \\mathrm{diag}(\\boldsymbol{\\tau}) \\boldsymbol{\\Omega} \\mathrm{diag}(\\boldsymbol{\\tau}) \\\\\n\\text{Priors:}  \\\\\n  \\mu^{[\\beta_0]} & \\sim N(0, 50) \\\\\n  \\mu^{[\\beta_1]} & \\sim N(0, 10) \\\\\n  \\tau^{[\\beta_m]} & \\sim \\mathrm{Gamma}(2, 0.2), \\; m = 0, 1 \\\\\n  \\boldsymbol{\\Omega} & \\sim \\mathrm{LKJ}(1) \\\\\n  \\sigma & \\sim t^+(4, 0, 5)\n\\end{aligned}\n\\]\n\nm4 &lt;- brm(Reaction10 ~ Days + (Days | Subject),\n    data = sleepstudy,\n    prior = c( # for intercept\n        prior(normal(0, 50), class = \"Intercept\"),\n        # for slope\n        prior(normal(0, 10), class = \"b\"),\n        # for tau_beta0 and tau_beta1\n        prior(gamma(2, 0.2), class = \"sd\", group = \"Subject\"),\n        # for correlation\n        prior(lkj(1), class = \"cor\"),\n        # for sigma\n        prior(student_t(4, 0, 5), class = \"sigma\")\n    ),\n    control = list(adapt_delta = .95),\n    seed = 2107,\n    file = \"11_m4\"\n)\n\n\nm4\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: Reaction10 ~ Days + (Days | Subject) \n   Data: sleepstudy (Number of observations: 180) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~Subject (Number of levels: 18) \n                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)           2.83      0.70     1.68     4.41 1.00     1637     2216\nsd(Days)                0.69      0.16     0.44     1.09 1.00     1875     2371\ncor(Intercept,Days)     0.06      0.31    -0.52     0.67 1.00     1108     1623\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept    25.12      0.78    23.55    26.66 1.00     2342     2378\nDays          1.04      0.18     0.70     1.41 1.00     1745     2239\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     2.59      0.16     2.29     2.92 1.00     3940     2874\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\n20.5.2.1 Fit of Individuals\n\nCodece_m4 &lt;- conditional_effects(m4,\n    re_formula = NULL,\n    conditions = data.frame(Subject = unique(sleepstudy$Subject))\n)\n# Add original outcome variable\nplot(ce_m4, points = TRUE, ncol = 6, plot = FALSE)[[1]] +\n    geom_smooth(\n        data = attr(ce_m4[[1]], \"points\"),\n        aes(x = Days, y = resp__),\n        se = FALSE, col = \"red\",\n        linewidth = 0.8, alpha = 0.5,\n        inherit.aes = FALSE\n    )\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\nFigure 20.12: Marginal model plot by individuals, with varying slopes.\n\n\n\n\nYou can see that the fit is better. You can also visualize the varying regression lines:\n\nplot(\n    conditional_effects(m4,\n        effects = \"Days:Subject\",\n        re_formula = NULL,\n        # suppress credible band\n        prob = 0\n    ),\n    points = TRUE,\n    point_args = list(size = 0.5),\n)\n\n\n\n\n\n\nFigure 20.13: Varying regression lines on the same plot.\n\n\n\n\n\n\n\n\n\n\nInterpretations\n\n\n\nBased on the model, at Day 0, the average reaction time across individuals was 251ms, 90% CI [238ms, 264ms], and the SD at Day 0 was 28.3178086ms, 95% CI [18.060615ms, 40.863435ms].\nThe average rate of change per day in reaction time across individuals was 10ms, 90% CI [7.6ms, 13ms], and the SD of the rates of change at Day 0 was 6.9012462ms, 95% CI [4.6810815ms, 10.04862ms], as shown in Figure 20.13.\n\n\n\n\n\n\n\n\nFixed-Effects Model\n\n\n\nYou can compare the previous model with one that has different slopes for different persons, which can be modelled by including an interaction with the categorical Subject predictor. This is referred to as the fixed-effects model, as opposed to the random-effects model used to describe hierarchical models with partial pooling. Below is an example:\n\nm4_fixed &lt;- brm(Reaction10 ~ Days * I(factor(Subject)),\n    data = sleepstudy,\n    prior = c( # for intercept\n        prior(normal(0, 50), class = \"Intercept\"),\n        # for slope\n        prior(normal(0, 10), class = \"b\"),\n        # for sigma\n        prior(student_t(4, 0, 5), class = \"sigma\")\n    ),\n    control = list(adapt_delta = .95),\n    seed = 2107,\n    file = \"11_m4_fixed\"\n)\n\nYou can compare the two models using LOO-IC:\n\nloo(m4, m4_fixed)\n\nWarning: Found 3 observations with a pareto_k &gt; 0.7 in model 'm4'. We recommend\nto set 'moment_match = TRUE' in order to perform moment matching for\nproblematic observations.\n\n\nWarning: Found 2 observations with a pareto_k &gt; 0.7 in model 'm4_fixed'. We\nrecommend to set 'moment_match = TRUE' in order to perform moment matching for\nproblematic observations.\n\n\nOutput of model 'm4':\n\nComputed from 4000 by 180 log-likelihood matrix.\n\n         Estimate   SE\nelpd_loo   -447.0 22.7\np_loo        34.9  8.8\nlooic       894.0 45.5\n------\nMCSE of elpd_loo is NA.\nMCSE and ESS estimates assume MCMC draws (r_eff in [0.4, 1.6]).\n\nPareto k diagnostic values:\n                         Count Pct.    Min. ESS\n(-Inf, 0.7]   (good)     177   98.3%   593     \n   (0.7, 1]   (bad)        1    0.6%   &lt;NA&gt;    \n   (1, Inf)   (very bad)   2    1.1%   &lt;NA&gt;    \nSee help('pareto-k-diagnostic') for details.\n\nOutput of model 'm4_fixed':\n\nComputed from 4000 by 180 log-likelihood matrix.\n\n         Estimate   SE\nelpd_loo   -448.7 23.0\np_loo        38.7  9.1\nlooic       897.3 45.9\n------\nMCSE of elpd_loo is NA.\nMCSE and ESS estimates assume MCMC draws (r_eff in [0.2, 1.6]).\n\nPareto k diagnostic values:\n                         Count Pct.    Min. ESS\n(-Inf, 0.7]   (good)     178   98.9%   81      \n   (0.7, 1]   (bad)        1    0.6%   &lt;NA&gt;    \n   (1, Inf)   (very bad)   1    0.6%   &lt;NA&gt;    \nSee help('pareto-k-diagnostic') for details.\n\nModel comparisons:\n         elpd_diff se_diff\nm4        0.0       0.0   \nm4_fixed -1.6       2.3   \n\n\nAs you can see, in this case, the hierarchical approach yields a lower LOO (but there was a warning message, so be careful) and estimates fewer parameters. With more clusters and lower ICC, hierarchical models will have an even stronger advantage.\n\n\nSo far, we have yet to talk about including person-level predictors. If such predictors are available, such as gender, we can use those to predict individual differences in intercepts (main effect) and slopes (i.e., interaction with Days). Just add those predictors to the model by:\n\\[\n\\begin{aligned}\n  \\begin{bmatrix}\n    \\beta_{0j} \\\\\n    \\beta_{1j} \\\\\n  \\end{bmatrix} & \\sim N_2\\left(\n  \\begin{bmatrix}\n      \\mu^{[\\beta_0]}_j \\\\\n      \\mu^{[\\beta_1]}_j \\\\\n    \\end{bmatrix}, \\mathbf T\n    \\right)  \\\\\n  \\mathbf T & = \\mathrm{diag}(\\boldsymbol{\\tau}) \\boldsymbol{\\Omega} \\mathrm{diag}(\\boldsymbol{\\tau}) \\\\\n  \\mu^{[\\beta_0]}_j & = \\gamma_{00} + \\gamma_{01} X_j \\\\\n  \\mu^{[\\beta_1]}_j & = \\gamma_{10} + \\gamma_{11} X_j\n\\end{aligned}\n\\] where \\(X_j\\) is a person-level predictor.\n\n20.5.3 Varying \\(\\sigma\\)\n\nFinally, you can also allow \\(\\sigma\\) to differ across individuals. This is typically used to relax the homogeneity of variance assumption, but recently, there has also been some interest in treating varying \\(\\sigma\\) as an important outcome. Examples include fluctuations in mood, as two people with the same mean level of mood may fluctuate very differently, and mood swing can be an important outcome to assess. There have been some interesting applications in health research using ecological momentary assessment data. For an overview, see the paper by Hedeker et al. (2008).\nWithout going into the details, here is the model and the priors:\n\\[\n\\begin{aligned}\n\\text{Repeated-measure level:}  \\\\\n  \\text{Reaction10}_{ij} & \\sim N(\\mu_{ij}, \\sigma_j)  \\\\\n  \\mu_{ij} & = \\beta_{0j} + \\beta_{1j} \\text{Days}_{ij}  \\\\\n\\text{Person level:}  \\\\\n  \\begin{bmatrix}\n    \\beta_{0j} \\\\\n    \\beta_{1j} \\\\\n    \\log(\\sigma_j)\n  \\end{bmatrix} & \\sim N_2\\left(\n    \\begin{bmatrix}\n      \\mu^{[\\beta_0]} \\\\\n      \\mu^{[\\beta_1]} \\\\\n      \\mu^{[s]}\n    \\end{bmatrix}, \\mathbf T\n    \\right)  \\\\\n  \\mathbf T & = \\mathrm{diag}(\\boldsymbol{\\tau}) \\boldsymbol{\\Omega} \\mathrm{diag}(\\boldsymbol{\\tau}) \\\\\n\\text{Priors:}  \\\\\n  \\mu^{[\\beta_0]} & \\sim N(0, 50) \\\\\n  \\mu^{[\\beta_1]} & \\sim N(0, 10) \\\\\n  \\mu^{[s]} & \\sim t^+(4, 0, 1.6) \\\\\n  \\tau^{[\\beta_m]} & \\sim \\mathrm{Gamma}(2, 0.2), \\; m = 0, 1 \\\\\n  \\tau^{[s]} & \\sim \\mathrm{Gamma}(2, 0.625) \\\\\n  \\boldsymbol{\\Omega} & \\sim \\mathrm{LKJ}(1)\n\\end{aligned}\n\\]\n\n# Use |p| to estimate the covariance between the sigma and beta random effects\nm5 &lt;- brm(\n    bf(\n        Reaction10 ~ Days + (Days | p | Subject),\n        sigma ~ (1 | p | Subject)\n    ),\n    data = sleepstudy,\n    prior = c( # for intercept\n        prior(normal(0, 50), class = \"Intercept\"),\n        # for slope\n        prior(normal(0, 10), class = \"b\"),\n        # for tau_beta0\n        prior(gamma(2, 0.2),\n            class = \"sd\", coef = \"Intercept\",\n            group = \"Subject\"\n        ),\n        # for tau_beta1\n        prior(gamma(2, 0.2),\n            class = \"sd\", coef = \"Days\",\n            group = \"Subject\"\n        ),\n        # for correlation\n        prior(lkj(1), class = \"cor\"),\n        # for sigma\n        prior(student_t(4, 0, 1.6), class = \"Intercept\", dpar = \"sigma\"),\n        # for tau_sigma\n        prior(gamma(2, 0.625),\n            class = \"sd\", coef = \"Intercept\",\n            group = \"Subject\", dpar = \"sigma\"\n        )\n    ),\n    control = list(adapt_delta = .95),\n    seed = 2107,\n    file = \"11_m5\"\n)\n\n\nm5\n\n Family: gaussian \n  Links: mu = identity; sigma = log \nFormula: Reaction10 ~ Days + (Days | p | Subject) \n         sigma ~ (1 | p | Subject)\n   Data: sleepstudy (Number of observations: 180) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~Subject (Number of levels: 18) \n                               Estimate Est.Error l-95% CI u-95% CI Rhat\nsd(Intercept)                      3.16      0.71     2.06     4.87 1.00\nsd(Days)                           0.70      0.16     0.46     1.07 1.00\nsd(sigma_Intercept)                0.51      0.12     0.31     0.79 1.00\ncor(Intercept,Days)               -0.01      0.27    -0.50     0.52 1.00\ncor(Intercept,sigma_Intercept)     0.22      0.29    -0.39     0.73 1.00\ncor(Days,sigma_Intercept)          0.45      0.26    -0.13     0.85 1.00\n                               Bulk_ESS Tail_ESS\nsd(Intercept)                      1766     2385\nsd(Days)                           1574     2486\nsd(sigma_Intercept)                1693     2606\ncor(Intercept,Days)                1086     1634\ncor(Intercept,sigma_Intercept)     1580     2292\ncor(Days,sigma_Intercept)          1581     2217\n\nRegression Coefficients:\n                Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept          25.11      0.83    23.52    26.77 1.00     1353     1760\nsigma_Intercept     0.73      0.14     0.44     1.02 1.00     1592     1767\nDays                1.05      0.18     0.70     1.40 1.00     1186     1879\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nHere is the posterior predictive check:\n\npp_check(m5, type = \"ribbon_grouped\", group = \"Subject\", x = \"Days\",\n         facet_args = list(ncol = 6, scales = \"fixed\"))\n\nUsing all posterior draws for ppc type 'ribbon_grouped' by default.",
    "crumbs": [
      "Week 13",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Multilevel Models</span>"
    ]
  },
  {
    "objectID": "11-multilevel.html#model-comparisons",
    "href": "11-multilevel.html#model-comparisons",
    "title": "\n20  Multilevel Models\n",
    "section": "\n20.6 Model Comparisons",
    "text": "20.6 Model Comparisons\nWe can compare the previous models from m3 to m5, with m3 being the least complex and m5 being the most complex. However, it should be noted that, because of the way how STAN computes LOOIC and WAIC,\n\nThe LOOIC and WAIC computed in STAN (including brms) generally cannot be used to compare models with different level-2 predictors.\n\nThe problem is illustrated in this blog post: https://deepthoughtsandsilliness.blogspot.com/2007/12/focus-on-dic.html in the context of DIC.\n\nmsummary(\n    list(\n        `Varying Intercepts` = m3,\n        `Varying Intercepts and Slopes` = m4,\n        `Varying Intercepts, Slopes, and Variances` = m5\n    ),\n    metrics = c(\"WAIC\", \"LOOIC\"),\n    estimate = \"{estimate} [{conf.low}, {conf.high}]\",\n    shape = effect + term ~ model,\n    fmt = 2\n)\n\n\n\neffect\n\n Varying Intercepts\n Varying Intercepts and Slopes\n Varying Intercepts, Slopes, and Variances\n\n\n\nfixed\nb_Intercept\n25.23 [23.16, 27.27]\n25.12 [23.55, 26.66]\n25.11 [23.52, 26.77]\n\n\n\nb_Days\n1.05 [0.89, 1.21]\n1.04 [0.70, 1.41]\n1.04 [0.70, 1.40]\n\n\n\nsigma\n3.11 [2.81, 3.49]\n2.58 [2.29, 2.92]\n\n\n\n\nb_sigma_Intercept\n\n\n0.73 [0.44, 1.02]\n\n\nrandom\nsd_Subject__Intercept\n3.98 [2.85, 6.04]\n2.75 [1.68, 4.41]\n3.06 [2.06, 4.87]\n\n\n\nsd_Subject__Days\n\n0.67 [0.44, 1.09]\n0.68 [0.46, 1.07]\n\n\n\ncor_Subject__Intercept__Days\n\n0.06 [−0.52, 0.67]\n−0.02 [−0.50, 0.52]\n\n\n\nsd_Subject__sigma_Intercept\n\n\n0.49 [0.31, 0.79]\n\n\n\ncor_Subject__Intercept__sigma_Intercept\n\n\n0.25 [−0.39, 0.73]\n\n\n\ncor_Subject__Days__sigma_Intercept\n\n\n0.48 [−0.13, 0.85]\n\n\n\nNum.Obs.\n180\n180\n180\n\n\n\nELPD\n−470.0\n−447.0\n−418.5\n\n\n\nELPD s.e.\n14.3\n22.7\n13.4\n\n\n\nLOOIC\n940.0\n894.0\n837.0\n\n\n\nLOOIC s.e.\n28.6\n45.5\n26.8\n\n\n\nWAIC\n939.5\n891.0\n827.6\n\n\n\n\n\n\n\n\n\n\n\nHedeker, D., Mermelstein, R. J., & Demirtas, H. (2008). An application of a mixed‐effects location scale model for analysis of ecological momentary assessment (EMA) data. Biometrics, 64(2), 627–634. https://doi.org/10.1111/j.1541-0420.2007.00924.x\n\n\nLai, M. H. C., & Kwok, O. (2015). Examining the rule of thumb of not using multilevel modeling: The “design effect smaller than two” rule. The Journal of Experimental Education, 83(3), 423–438. https://doi.org/10.1080/00220973.2014.907229",
    "crumbs": [
      "Week 13",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Multilevel Models</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Brooks, S. P., & Gelman, A. (1998). General methods for monitoring\nconvergence of iterative simulations. Journal of Computational and\nGraphical Statistics, 7(4), 434–455. https://doi.org/10.1080/10618600.1998.10474787\n\n\nCarvalho, C. M., Polson, N. G., & Scott, J. G. (2010). The horseshoe\nestimator for sparse signals. Biometrika, 97(2),\n465–480. https://doi.org/10.1093/biomet/asq017\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other\nstories. Cambridge University Press.\n\n\nGelman, A., & Rubin, D. B. (1992). Inference from iterative\nsimulation using multiple sequences. Statistical Science,\n7(4). https://doi.org/10.1214/ss/1177011136\n\n\nGigerenzer, G. (2004). Mindless statistics. The Journal of\nSocio-Economics, 33(5), 587–606. https://doi.org/10.1016/j.socec.2004.09.033\n\n\nHedeker, D., Mermelstein, R. J., & Demirtas, H. (2008). An\napplication of a mixed‐effects location scale model for analysis of\necological momentary assessment (EMA) data. Biometrics,\n64(2), 627–634. https://doi.org/10.1111/j.1541-0420.2007.00924.x\n\n\nHoeting, J. A., Madigan, D., Raftery, A. E., & Volinsky, C. T.\n(1999). Bayesian model averaging: A tutorial. Statistical\nScience, 14(4). https://doi.org/10.1214/ss/1009212519\n\n\nImai, K., Keele, L., & Tingley, D. (2010). A general approach to\ncausal mediation analysis. Psychological Methods,\n15(4), 309–334. https://doi.org/10.1037/a0020761\n\n\nJohnson, A. A., Ott, M. Q., & Dogucu, M. (2022). Bayes rules! An\nintroduction to Bayesian modeling with R. CRC Press.\n\n\nLai, M. H. C., & Kwok, O. (2015). Examining the rule of thumb of not\nusing multilevel modeling: The “design effect smaller than\ntwo” rule. The Journal of Experimental Education,\n83(3), 423–438. https://doi.org/10.1080/00220973.2014.907229\n\n\nLambert, B. (2018). A student’s guide to Bayesian statistics.\nSAGE.\n\n\nMcCandless, L. C., & Somers, J. M. (2019). Bayesian sensitivity\nanalysis for unmeasured confounding in causal mediation analysis.\nStatistical Methods in Medical Research, 28(2),\n515–531. https://doi.org/10.1177/0962280217729844\n\n\nMcElreath, R. (2020). Statistical rethinking: a Bayesian course with\nexamples in R and Stan (Second edition). CRC Press.\n\n\nMcGrayne, S. B. (2011). The theory that would not die: How Bayes’\nrule cracked the enigma code, hunted down Russian submarines, &\nemerged triumphant from two centuries of controversy. Yale\nuniversity press.\n\n\nPiironen, J., Paasiniemi, M., & Vehtari, A. (2020). Projective\ninference in high-dimensional problems: Prediction and feature\nselection. Electronic Journal of Statistics, 14(1). https://doi.org/10.1214/20-EJS1711\n\n\nPiironen, J., & Vehtari, A. (2017). Sparsity information and\nregularization in the horseshoe and other shrinkage priors.\nElectronic Journal of Statistics, 11(2). https://doi.org/10.1214/17-EJS1337SI\n\n\nVan De Schoot, R., Winter, S. D., Ryan, O., Zondervan-Zwijnenburg, M.,\n& Depaoli, S. (2017). A systematic review of Bayesian articles in\npsychology: The last 25 years. Psychological Methods,\n22(2), 217–239. https://doi.org/10.1037/met0000100\n\n\nVehtari, A., Gelman, A., & Gabry, J. (2017). Practical Bayesian\nmodel evaluation using leave-one-out cross-validation and WAIC.\nStatistics and Computing, 27(5), 1413–1432. https://doi.org/10.1007/s11222-016-9696-4\n\n\nVehtari, A., Gelman, A., Simpson, D., Carpenter, B., & Bürkner,\nP.-C. (2021). Rank-normalization, folding, and localization: An improved\nRˆ for assessing convergence of MCMC (with discussion). Bayesian\nAnalysis, 16(2). https://doi.org/10.1214/20-BA1221\n\n\nYao, Y., Vehtari, A., Simpson, D., & Gelman, A. (2018). Using\nstacking to average Bayesian predictive distributions (with discussion).\nBayesian Analysis, 13(3). https://doi.org/10.1214/17-BA1091\n\n\nYimer, B. B., Lunt, M., Beasley, M., Macfarlane, G. J., & McBeth, J.\n(2023). BayesGmed: An R-package for Bayesian causal mediation analysis.\nPLOS ONE, 18(6), e0287037. https://doi.org/10.1371/journal.pone.0287037",
    "crumbs": [
      "References"
    ]
  }
]