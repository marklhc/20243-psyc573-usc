[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PSYC 573 Bayesian Data Analysis (2024 Fall): Course Notes",
    "section": "",
    "text": "Preface\nThere will be some math in this notes. Don’t worry if you feel the math is challenging; for applied focused students, it is much more important to understand the concepts of Bayesian methods than to understand the mathematical symbols, as they usually can be handled by the software.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "01-intro.html",
    "href": "01-intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 History of Bayesian Statistics\nHere is a nice brief video that covers some of the 250+ years of history of Bayesian statistics:\nIf you are interested in learning more about the story, check out the nice popular science book, “The theory that would not die,” by McGrayne (2011)",
    "crumbs": [
      "Week 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#history-of-bayesian-statistics",
    "href": "01-intro.html#history-of-bayesian-statistics",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1.1 Thomas Bayes (1701–1762)\nYou may find a biography of Bayes from https://www.britannica.com/biography/Thomas-Bayes. There is also a nice story in the book by Lambert (2018). He was an English Presbyterian minister. The important work he wrote that founded Bayesian statistics was “An Essay towards solving a Problem in the Doctrine of Chances”, which he did not publish and was later discovered and edited by his friend, Richard Price, after Bayes’s death 1\n\n\n1.1.2 Pierre-Simon Laplace (1749–1827)\nLaplace, a French Mathematician, was an important figure in not just Bayesian statistics, but also in other areas of mathematics, astronomy, and physics. We actually know much more the work by Laplace than by Bayes, and Laplace has worked independently on the inverse probability problem (i.e., \\(P[\\text{Parameter} | \\text{Data}]\\)). Indeed, he was credited for largely formalizing Bayesian interpretation of probability and most of the machinery for Bayesian statistics, and making it a useful technique to be applied to different problems, despite the discipline being called “Bayesian.” His other contributions include the methods of least square and the central limit theorem. See a short biography of him at https://www.britannica.com/biography/Pierre-Simon-marquis-de-Laplace.\n\n\n1.1.3 20th Century\nUntil early 1920s, the inverse probability method, which is based on what is now called Bayes’s Theorem, is pretty much the predominant point of view of statistics. Then a point of view later known as frequentist statistics arrived, and quickly became the mainstream school of thinking for statistical inferences, and is still the major framework for quantitative research. In the early 1920s, frequentist scholar, most notably R. A. Fisher and Jerzy Neyman, criticized Bayesian inference for the use of subjective elements in an objective discipline. In Fisher’s word,\n\nThe theory of inverse probability is founded upon an error, and must be wholly rejected—Fisher, 1925\n\nIronically, the term Bayesian was first used in one of Fisher’s work. And interestingly, Fisher actually thought he “have been doing almost exactly what Bayes had done in the 18th century.”2\nDespite criticisms from frequentist scholars, Bayesian methods has been used by scholars in the Allies in World War II, such as Alan Turing, in an algorithm to break coded messages in the Enigma machine that the German Navy used to communicate. However, because of the more complex mathematics involved in Bayesian statistics, Bayesian statistics is limited to straight-forward problems and theoretical discussions until the early 1980s, when computing speed increases tremendously and makes Markov Chain Monte Carlo—the major algorithm for Bayesian estimation in modern Bayesian statistics—feasible. With the help of increased computing speed, Bayesian statistics has come back and been used as an alternative way of thinking, especially given growing dissatisfaction towards the misuse of frequentist statistics by some scholars across disciplines. Bayesian estimation methods have also been applied to many new research questions where frequentist approaches work less well, as well as in big data analytics and machine learning.",
    "crumbs": [
      "Week 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#motivations-for-using-bayesian-methods",
    "href": "01-intro.html#motivations-for-using-bayesian-methods",
    "title": "1  Introduction",
    "section": "1.2 Motivations for Using Bayesian Methods",
    "text": "1.2 Motivations for Using Bayesian Methods\nBased on my personal experience, Bayesian methods is used quite often in statistics and related departments, as it is consistent and coherent, as contrast to frequentist where a new and probably ad hoc procedure needed to be developed to handle a new problem. For Bayesian, as long as you can formulate a model, you just run the analysis the same way as you would for simpler problems, or in Bayesian people’s word “turning the Bayesian crank,” and likely the difficulties would be more technical than theoretical, which is usually solved with better computational speed.\nSocial and behavioral scientists are relatively slow to adopt the Bayesian method, but things have been changing. In a recently accepted paper by Van De Schoot et al. (2017), the authors reviewed papers in psychology between 1990 and 2015 and found that whereas less than 10% of the papers in 1990 to 1996 mentioned “Bayesian”, the proportion increased steadily and was found in close to 45% of the psychology papers in 2015. Among studies using Bayesian methods, more than 1/4 cited computational problems (e.g., nonconvergence) in frequentist methods as a reason, and about 13% cited the need to incorporate prior knowledge into the estimation process. The other reasons included the flexibility of Bayesian methods for complex and nonstandard problems, and the use of techniques traditionally attached to Bayesian such as missing data and model comparisons.\n\n1.2.1 Problem with classical (frequentist) statistics\nThe rise of Bayesian methods is also related to the statistical reform movement in the past two decades. The problem is that applied researchers are obsessed with \\(p &lt; .05\\) and often misinterpreted a small \\(p\\)-value as something that it isn’t (read Gigerenzer, 2004). Some scholars coined the term \\(p\\)-hacking to refer to the practice of obtaining statistical significance by choosing to test the data in a certain way, either consciously or subconsciously (e.g., dichotomizing using mean or median, trying the same hypothesis using different measures of the same variable, etc). This is closely related to the recent “replication crisis” in scientific research, with psychology being in the center under close scrutiny.\nBayesian is no panacea to the problem. Indeed, if misused it can give rise to the same problems as statistical significance. My goal in this class is to help you appreciate the Bayesian tradition of embracing the uncertainty in your results, and adopt rigorous model checking and comprehensive reporting rather than relying merely on a \\(p\\)-value. I see this as the most important mission for someone teaching statistics.",
    "crumbs": [
      "Week 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#comparing-bayesian-and-frequentist-statistics",
    "href": "01-intro.html#comparing-bayesian-and-frequentist-statistics",
    "title": "1  Introduction",
    "section": "1.3 Comparing Bayesian and Frequentist Statistics",
    "text": "1.3 Comparing Bayesian and Frequentist Statistics\n\n\n\n\n\n\n\n\nAttributes\nFrequentist\nBayesian\n\n\n\n\nInterpretation of probability\nFrequentist\nSubjectivist\n\n\nUncertainty\nHow estimates vary in repeated sampling from the same population\nHow much prior beliefs about parameters change in light of data\n\n\nWhat’s relevant?\nCurrent data set + all that might have been observed\nOnly the data set that is actually observed\n\n\nHow to proceed with analyses\nMLE; ad hoc and depends on problems\n“Turning the Bayesian crank”",
    "crumbs": [
      "Week 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#software-for-bayesian-statistics",
    "href": "01-intro.html#software-for-bayesian-statistics",
    "title": "1  Introduction",
    "section": "1.4 Software for Bayesian Statistics",
    "text": "1.4 Software for Bayesian Statistics\nThe following summarizes some of the most popular Bayesian software. Currently, JAGS and STAN are the most popular. General statistical programs like SPSS, SAS, and Stata also have some support for Bayesian analyses as well.\n\nWinBUGS\n\nBayesian inference Using Gibbs Sampling\nFree, and most popular until late 2000s. Many Bayesian scholars still use WinBUGS\nNo further development\nOne can communicate from R to WinBUGS using the package R2WinBUGS\n\nJAGS\n\nJust Another Gibbs Sampler\nVery similar to WinBUGS, but written in C++, and support user-defined functionality\nCross-platform compatibility\nOne can communicate from R to JAGS using the package rjags or runjags\n\nSTAN\n\nNamed in honour of Stanislaw Ulam, who invented the Markov Chain Monte Carlo method\nUses new algorithms that are different from Gibbs sampling\nUnder very active development\nCan interface with R through the package rstan, and the R packages rstanarm and brms automates the procedure for fitting models in STAN for many commonly used models\n\n\n\n\n\n\nGigerenzer, G. (2004). Mindless statistics. The Journal of Socio-Economics, 33(5), 587–606. https://doi.org/10.1016/j.socec.2004.09.033\n\n\nLambert, B. (2018). A student’s guide to Bayesian statistics. SAGE.\n\n\nMcGrayne, S. B. (2011). The theory that would not die: How Bayes’ rule cracked the enigma code, hunted down Russian submarines, & emerged triumphant from two centuries of controversy. Yale university press.\n\n\nVan De Schoot, R., Winter, S. D., Ryan, O., Zondervan-Zwijnenburg, M., & Depaoli, S. (2017). A systematic review of Bayesian articles in psychology: The last 25 years. Psychological Methods, 22(2), 217–239. https://doi.org/10.1037/met0000100",
    "crumbs": [
      "Week 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#footnotes",
    "href": "01-intro.html#footnotes",
    "title": "1  Introduction",
    "section": "",
    "text": "Price is another important figure in mathematics and philosopher, and have taken Bayes’ theorem and applied it to insurance and moral philosophy.↩︎\nSee the paper by John Aldrich on this.↩︎",
    "crumbs": [
      "Week 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "02-probability.html",
    "href": "02-probability.html",
    "title": "2  Probability",
    "section": "",
    "text": "2.1 History of Probability",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "02-probability.html#history-of-probability",
    "href": "02-probability.html#history-of-probability",
    "title": "2  Probability",
    "section": "",
    "text": "2.1.1 Games of chance\nCorrespondence between French Mathematicians (Pierre de Fermat and Blaise Pascal) on gambling problem by Antoine Gombaud, Chevalier de Méré. The problem is roughly of the form1:\n\nImagine two people playing a multi-round game. In each round, each person has an equal chance of winning. The first person who wins six rounds will get a huge cash prize. Now, consider a scenario in which A and B have played six rounds, where A has won five and B has won one. At that time, the game had to be stopped due to a thunderstorm. Since neither A and B have reached six wins, instead of giving the prize to either one of them, they agree to divide up the prize. What would be a fair way to do so?\n\nThe discussion led to the formalization of using mathematics to solve the problem. Basically, one way is to say if A has a 97% chance to win the prize eventually and B has a 3% chance, then A should get 97% of the prize.",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "02-probability.html#different-ways-to-interpret-probability",
    "href": "02-probability.html#different-ways-to-interpret-probability",
    "title": "2  Probability",
    "section": "2.2 Different Ways to Interpret Probability",
    "text": "2.2 Different Ways to Interpret Probability\nThere are multiple perspectives for understanding probability.2 What you’ve learned in your statistics training is likely based on the frequentist interpretation of probability (and thus frequentist statistics), whereas what you will learn in this class have the foundation on the subjectivist interpretation of probability. Understanding the different perspectives on probability is helpful for understanding the Bayesian framework.\n\n\n\n\n\n\nYou don’t need to commit to one interpretation of probability in order to conduct Bayesian data analysis.\n\n\n\n\n2.2.1 Classical Interpretation\nThis is an earlier perspective and is based on counting rules. The idea is that probability is equally distributed among all “indifferent” outcomes. “Indifferent” outcomes are those where a person does not have any evidence to say that one outcome is more likely than another. For example, when one throws a die, one does not think that a certain number is more likely than another unless one knows that the die is biased. In this case, there are six equally likely outcomes, so the probability of each outcome is 1 / 6.\n\n\n\n2.2.2 Frequentist Interpretation\nThe frequentist interpretation states that probability is essentially the long-run relative frequency of an outcome. For example, to find the probability of getting a “1” when throwing a die, one can repeat the experiment many times, as illustrated below:\n\n\n\n\n\nTrial\nOutcome\n\n\n\n\n1\n2\n\n\n2\n3\n\n\n3\n1\n\n\n4\n3\n\n\n5\n1\n\n\n6\n1\n\n\n7\n5\n\n\n8\n6\n\n\n9\n3\n\n\n10\n3\n\n\n\n\n\nAnd we can plot the relative frequency of “1”s in the trials:\n\n\n\n\n\n\n\n\nFigure 2.1: Relative frequency when repeatedly rolling a die.\n\n\n\n\n\nAs you can see, with more trials, the relative frequency approaches 1 / 6. It’s the reason why in introductory statistics, many of the concepts require you to think in terms of repeated sampling (e.g., sampling distribution, \\(p\\)-values, standard errors, confidence intervals), because probability in this framework is only possible when the outcome can be repeated. It’s also the reason why we don’t talk about something like:\n\nthe probability of the null hypothesis being true, or\nthe probability that the population mean is in the interval [75.5, 80.5],\n\nbecause the population is fixed and cannot be repeated. Only the samples can be repeated, so probability in frequentist statistics is only about samples.\n\n2.2.2.1 Problem of the single case\nBecause of the frequentist’s reference to long-run relative frequency, under this framework, it does not make sense to talk about the probability of an event that cannot be repeated. For example, it does not make sense to talk about\n\nthe probability that the Democrats/Republicans will win the 2028 US Presidential Election, or\nthe probability that the LA Rams winning the 2024 Super Bowl, or\nthe probability that it will rain on Christmas Day in LA in 2024,\n\nbecause all these are specific events that cannot be repeated. However, it is common for lay people to talk about probabilities or chances for these events.\n\n\n\n2.2.3 Subjectivist Interpretation\nThe frequentist interpretation is sometimes called the “objectivist view,” as the reference of probability is based on empirical evidence of long-run relative frequency (albeit hypothetical in many cases). In contrast, the subjectivist view of probability is based on one’s belief. For example, when I say that the probability of getting a “1” from rolling a die is 1 / 6, it reflects the state of my mind about the die. My belief can arise from different sources: Maybe I make the die and know it is a fair one; maybe I saw someone throwing the die 1,000 times, and the number of “1”s was close to 1,000 / 6, or maybe someone I trust and with authority says that the die has a 1-in-6 chance of showing a “1”.\nThe “subjective” component has been criticized a lot by frequentist scholars, sometimes unfairly. To be clear, what “subjective” here means is that probability reflects the state of one’s mind instead of the state of the world, and so it is totally fine that two people can have different beliefs about the same event. However, it does not mean that probability is arbitrary, as the beliefs are subjected to the constraints of the axioms of probability as well as the condition that the person possessing such beliefs is rational.3 Therefore, if two persons are exposed to the same information, they should form similar, though likely not identical, beliefs about the event.\nThe subjective interpretation works perfectly fine with single events, as one can have a belief about whether it rains on a particular day or a belief about a particular election result.\n\n2.2.3.1 Calibrating a subjective belief\nIn order to represent one’s belief by probability, one needs to assign a nonzero value to every plausible outcome of an event. This has been the job of odds-makers for a long time. Indeed, a lot of the development in the field of probability has to do with coming up with a fair bet. The process of assigning probabilities to outcomes of an event according to one’s belief is called calibration. For example, consider three possible outcomes for tomorrow’s weather. For simplicity, consider three mutually exclusive possible outcomes: sunny, cloudy, and rainy.\nTo calibrate my belief, consider first if you bet $10, and the return is (a) $30 for sunny, (b) $30 for cloudy, and (c) $30 for rainy. Which one will you bet? If you’re like me in LA, I’m pretty sure I’ll bet on (a), as I think that it is more likely to have a sunny day. This means that setting \\(P\\)(sunny) = \\(P\\)(cloudy) = \\(P\\)(rainy) = 1 / 3 is not a good reflection of my belief.\nNow consider the bet with the returns (a) $20 for sunny, (b) $30 for cloudy, and (c) $60 for rainy. This would reflect the belief that there is a 50% chance of a sunny day, 33.33% chance of a cloudy day, and 16.67% chance of a rainy day. Will you take the bet? This is an improvement from the last one, but I would still say a sunny day is a good bet, which suggests that the probability of 50% is too low for a sunny day. The idea is to continue iterating until it is hard to consider (a), (b), or (c) as a clear betting favorite. For me, this would end up being something like (a) $16.7 for sunny, (b) $33.3 for cloudy, and (c) $100 for rainy, which would correspond to 60% sunny, 30% cloudy, and 10% rainy.\nIf it’s hard for you to consider the gambling analogy, an alternative way is to consider how many times is a sunny day more likely than a non-sunny day, and how many times is a cloudy day more likely than a rainy day. For example, I may consider a sunny day to be twice as likely as a non-sunny day, which would give the probability of a sunny day to be 66.67%. Then, if I also think that a cloudy day is three times as likely as a rainy day, I would assign a probability of 33.33% \\(\\times\\) 3 / 4 = 25% for a cloudy day, and a probability of 33.33% \\(\\times\\) 1 / 4 = 8.33% for a rainy day.\nThe process of calibrating one’s belief plays a key role in Bayesian data analysis, namely in the form of formulating a prior probability distribution.",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "02-probability.html#basics-of-probability",
    "href": "02-probability.html#basics-of-probability",
    "title": "2  Probability",
    "section": "2.3 Basics of Probability",
    "text": "2.3 Basics of Probability\n\n\n\n\n\n\nKolmogorov axioms\n\n\n\nFor an event \\(A_i\\) (e.g., getting a “1” from throwing a die)\n\n\\(P(A_i) \\geq 0\\) [All probabilities are non-negative]\n\\(P(A_1 \\cup A_2 \\cup \\cdots) = 1\\) [Union of all possibilities is 1]\n\\(P(A_1) + P(A_2) = P(A_1 \\text{ or } A_2)\\) [Addition rule]\n\n\n\nConsider two events, for example, on throwing a die,\n\n\\(A\\): The number is odd\n\\(B\\): The number is larger than or equal to 4\n\nAssuming that die is (believed to be) fair, you can verify that the probability of \\(A\\) is \\(P(A)\\) = 3 / 6 = 1 / 2, and the probability of \\(B\\) is also \\(P(B)\\) = 3 / 6 = 1 / 2.\n\n2.3.1 Probability Distributions\n\nDiscrete event (e.g., outcome of throwing a die or an election): probability mass. The probability is nonzero, at least for some outcomes. The graph below on the left shows the probability mass of the sum of the numbers from two dice.\nContinuous event (e.g., temperature): probability density.4 The probability is basically zero for any outcome. Instead, the probability density is approximated by \\(P(A \\leq a \\leq A + h) / h\\) for a very small \\(h\\).\n\nFor example, to find the probability density that a person’s well-being score is 80, we first find the probability that a person scores between 80 and 80.5 (or 80 and 80.0005), and divide that probability by 0.5 (or 0.0005). See the shaded area of the graph below on the right.\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Probability mass\n\n\n\n\n\n\n\n\n\n\n\n(b) Probability density\n\n\n\n\n\n\n\nFigure 2.2: Examples of probability distributions\n\n\n\n\n\n\n\n\n\nFor this course, as in the textbook, we use \\(P(x)\\) to mean both the probability mass for an outcome \\(x\\) when the event is discrete, and the probability density at an outcome \\(x\\) when the event is continuous.\n\n\n\n\n2.3.1.1 Example: Normal Distribution\n\\[P(x) = \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp\\left(-\\frac{1}{2}\\left[\\frac{x - \\mu}{\\sigma}\\right]^2\\right)\\]\n\n# Write a function to compute the density of an outcome x\n# for a normal distribution\nmy_normal_density &lt;- function(x, mu, sigma) {\n    exp(- ((x - mu) / sigma) ^2 / 2) / (sigma * sqrt(2 * pi))\n}\n# For example, density at x = 36 in a normal distribution\n# with mu = 50 and sigma = 10\nmy_normal_density(36, mu = 50, sigma = 10)\n\n#&gt; [1] 0.01497275\n\n\n\n\n\n2.3.2 Summarizing a Probability Distribution\nWhile it is useful to know the probability mass/density of every possible outcome, in many situations, it is helpful to summarize a distribution by some numbers.\n\n2.3.2.1 Central Tendency\n\nMean: \\(E(X) = \\int x \\cdot P(x) d x\\)\nMedian: 50th percentile; the median of \\(X\\) is \\(\\mathit{Mdn}_X\\) such that \\(P(X \\leq \\mathit{Mdn}_X)\\) = 1 / 2\nMode: A value with maximum probability mass/density\n\nSee Figure 2.3 (a) for examples.\n\n\n\n\n\n\n\n\n\n\n\n(a) Central Tendency\n\n\n\n\n\n\n\n\n\n\n\n(b) Interval\n\n\n\n\n\n\n\nFigure 2.3: Measures of central tendency and interval\n\n\n\n\n\n2.3.2.2 Dispersion\n\nVariance: \\(V(X) = E[X - E(X)]^2\\)\n\nStandard deviation: \\(\\sigma(X) = \\sqrt{V(X)}\\)\n\nMedian absolute deviation (MAD): \\(1.4826 \\times \\mathit{Mdn}(|X - \\mathit{Mdn}_X|)\\)\n\n\n\n2.3.2.3 Interval\nUse \\(C(X)\\) to denote an interval. A \\(W\\)% interval means \\(P(X \\in C[X]) \\approx W\\%\\)\n\nOne-sided interval: \\(C(X)\\) is half-bounded\nSymmetric \\(W\\)% interval: \\(C(X) = [L(X), U(X)]\\) is bounded, with \\(P(X &lt; L[X]) = P(X &gt; U[X]) \\approx W\\% / 2\\)\n\nAlso called equal-tailed interval\n\nHighest density \\(W\\)% interval (HDI): \\(P(x_c) \\geq P(x_o)\\) for every \\(x_c\\) in \\(C(X)\\) and every \\(x_o\\) outside \\(C(X)\\). In general, the HDI is the shortest \\(W\\)% interval.\n\nThe plot in Figure 2.3 (b) shows several 80% intervals.\n\n\n2.3.2.4 Computing Summaries of Sample Distributions Using R\n\n# Simulate data from a half-Student's t distribution with\n# df = 4, and call it sim_s\nsim_s &lt;- rt(10000, df = 4) # can be both positive and negative\nsim_s &lt;- abs(sim_s) # take the absolute values\nggplot(data.frame(x = sim_s), aes(x = x)) +\n    geom_histogram(binwidth = 0.1)\n\n\n\n\n\n\n\nFigure 2.4: Simulated density of a half-Student’s t distribution\n\n\n\n\n\n\n# Central tendency\n# (note: the mode is difficult to compute for continuous\n# variables, and rarely used in this course.)\nc(mean = mean(sim_s),\n  median = median(sim_s),\n  mode = density(sim_s, bw = \"SJ\")$x[\n      which.max(density(sim_s, bw = \"SJ\")$y)\n  ])\n\n#&gt;      mean    median      mode \n#&gt; 1.0082926 0.7426326 0.1021776\n\n# Dispersion\nc(\n    variance = var(sim_s),\n    sd = sd(sim_s),\n    mad = mad(sim_s)\n)\n\n#&gt;  variance        sd       mad \n#&gt; 1.0231058 1.0114869 0.6996741\n\n# 80% Interval\nc(`0%` = 0, quantile(sim_s, probs = .8)) # right-sided\n\n#&gt;     0%    80% \n#&gt; 0.0000 1.5598\n\nc(quantile(sim_s, probs = .2), `100%` = Inf) # left-sided\n\n#&gt;       20%      100% \n#&gt; 0.2680906       Inf\n\nquantile(sim_s, probs = c(.1, .9)) # equal-tailed/symmetric\n\n#&gt;       10%       90% \n#&gt; 0.1299027 2.1371636\n\nHDInterval::hdi(sim_s)\n\n#&gt;        lower        upper \n#&gt; 0.0003616342 2.7992620765 \n#&gt; attr(,\"credMass\")\n#&gt; [1] 0.95\n\n\n\n\n\n2.3.3 Multiple Variables\n\nJoint probability: \\(P(X, Y)\\)\nMarginal probability: \\[P(X) = \\int P(X, y) dy\\] \\[P(Y) = \\int P(x, Y) dx\\]\n\nThe probability that outcome \\(X\\) happens, regardless of what values \\(Y\\) take.\n\n\n\n\n\n\n\n\n\n\nFigure 2.5: Joint and Marginal Distributions\n\n\n\n\n\n\n2.3.3.1 Conditional Probability\nConditional probability is the probability of an event given some other information. In the real world, you can say that everything is conditional. For example, the probability of getting an odd number on throwing a die is 1/2 is conditional on the die being fair. We use \\(P(A \\mid B)\\) to represent the the conditional probability of event \\(A\\) given event \\(B\\)..\nContinuing from the previous example, \\(P(A \\mid B)\\) is the conditional probability of getting an odd number, knowing that the number is at least 4. By definition, conditional probability is the probability that both \\(A\\) and \\(B\\) happen, divided by the probability that \\(B\\) happens.\n\n\n\n\n\n\nConditional Probability\n\n\n\n\\(P(A \\mid B) = \\dfrac{P(A, B)}{P(B)}\\)\n\n\nIn the example, \\(P(A, B)\\) = 1 / 6, because 5 is the only even number \\(\\geq\\) 4 when throwing a die. Thus, \\[\n\\begin{aligned}\n    P(A \\mid B) & = 1 / 3 \\\\\n             & = \\frac{P(A, B)}{P(B)} \\\\\n             & = \\frac{1 / 6}{1 / 2}\n\\end{aligned}\n\\]\nThis picture should make it clear:\n\n\n\n\n\n\n\n\n\n\n\nPlease recognize that \\(P(A \\mid B) \\neq P(B \\mid A)\\). For example, when throwing a die, \\(P\\)(number is six | even number) = 1/3, but \\(P\\)(even number | number is six) is 1.\n\n\n\n\n\n2.3.3.2 Independence\n\n\n\n\n\n\nTwo events, \\(A\\) and \\(B\\), are independent if \\(P(A \\mid B) = P(A)\\)\n\n\n\nThis means that any knowledge of \\(B\\) does not (or should not) affect one’s belief about \\(A\\). Consider the example:\n\n\\(A\\): A die shows five or more\n\\(B\\): A die shows an odd number\n\nHere is the joint probability\n\n\n\n\n&gt;= 5\n&lt;= 4\n\n\n\n\nodd\n1/6\n2/6\n\n\neven\n1/6\n2/6\n\n\n\nSo the conditional probability of \\(P\\)(&gt;= 5 | odd) = (1/6) / (1/2) = 1/3, which is the same as \\(P\\)(&gt;= 5 | even) = (1/6) / (1/2) = 1/3. Similarly it can be verified that \\(P\\)(&lt;= 4 | odd) = \\(P\\)(&lt;= 4 | even) = 2/3. Therefore, \\(A\\) and \\(B\\) are independent.\nOn the other hand, for the example\n\n\\(A\\): A die shows four or more\n\\(B\\): A die shows an odd number\n\nthe joint probabilities are\n\n\n\n\n&gt;= 4\n&lt;= 3\n\n\n\n\nodd\n1/6\n2/6\n\n\neven\n2/6\n1/6\n\n\n\nObviously, \\(A\\) and \\(B\\) are not independent because once we know that the number is four or above, it changes the probability of whether it is an odd number or not.\n\n\n\n\n\n\nIndependence can also be expressed as\n\nIf A and B are independent, \\(P(A, B) = P(A) P(B)\\)\n\n\n\n\n\n\n\n2.3.4 Law of Total Probability\nWhen we talk about conditional probability, like \\(B_1\\) = 4 or above and \\(B_2\\) = 3 or below, we can get \\(P(A \\mid B_1)\\) and \\(P(A \\mid B_2)\\) (see the figure below), we refer \\(P(A)\\) as the marginal probability, meaning that the probability of \\(A\\)  without knowledge of \\(B\\).\n\n\n\n\n\nIf \\(B_1, B_2, \\cdots, B_n\\) are all mutually exclusive possibilities for an event (so they add up to a probability of 1), then\n\n\n\n\n\n\nLaw of Total Probability\n\n\n\n\\[\n\\begin{aligned}\n  P(A) & = P(A, B_1) + P(A, B_2) + \\cdots + P(A, B_n)  \\\\\n       & = P(A \\mid B_1)P(B_1) + P(A \\mid B_2)P(B_2) + \\cdots + P(A \\mid B_n) P(B_n)  \\\\\n       & = \\sum_{k = 1}^n P(A \\mid B_k) P(B_k)\n\\end{aligned}\n\\]",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "02-probability.html#footnotes",
    "href": "02-probability.html#footnotes",
    "title": "2  Probability",
    "section": "",
    "text": "see the exact form at https://en.wikipedia.org/wiki/Problem_of_points↩︎\nSee http://plato.stanford.edu/entries/probability-interpret/ for more information↩︎\nIn a purely subjectivist view of probability, assigning a probability \\(P\\) to an event does not require any justifications, as long as it follows the axioms of probability. For example, I can say that the probability of me winning the lottery and thus becoming the wealthiest person on earth tomorrow is 95%, which by definition would make the probability of me not winning the lottery 5%. Most Bayesian scholars, however, do not endorse this version of subjectivist probability and require justifications of one’s beliefs (that has some correspondence to the world).↩︎\nFor many problems in the social and behavioral sciences, the measured variables are not truly continuous, but we still use continuous distributions to approximate them.↩︎",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "03-bayes-theorem.html",
    "href": "03-bayes-theorem.html",
    "title": "3  Bayes’s Theorem",
    "section": "",
    "text": "3.1 Example 1: Base rate fallacy (From Wikipedia)",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes's Theorem</span>"
    ]
  },
  {
    "objectID": "03-bayes-theorem.html#example-1-base-rate-fallacy-from-wikipedia",
    "href": "03-bayes-theorem.html#example-1-base-rate-fallacy-from-wikipedia",
    "title": "3  Bayes’s Theorem",
    "section": "",
    "text": "QuestionSolution\n\n\nA police officer stops a driver at random and does a breathalyzer test for the driver. The breathalyzer is known to detect true drunkenness 100% of the time, but in 1% of the cases, it gives a false positive when the driver is sober. We also know that in general, for every 1,000 drivers passing through that spot, one is driving drunk. Suppose that the breathalyzer shows positive for the driver. What is the probability that the driver is truly drunk?\n\n\n\\(P(\\text{positive} | \\text{drunk}) = 1\\)\n\\(P(\\text{positive} | \\text{sober}) = 0.01\\)\n\\(P(\\text{drunk}) = 1 / 1000\\)\n\\(P(\\text{sober}) = 999 / 1000\\)\nUsing Bayes’ Theorem,\n\\[\n\\begin{aligned}\n  P(\\text{drunk} | \\text{positive})\n  & = \\frac{P(\\text{positive} | \\text{drunk}) P(\\text{drunk})}\n           {P(\\text{positive} | \\text{drunk}) P(\\text{drunk}) +\n            P(\\text{positive} | \\text{sober}) P(\\text{sober})}  \\\\\n  & = \\frac{1 \\times 0.001}{1 \\times 0.001 + 0.01 \\times 0.999} \\\\\n  & = 100 / 1099 \\approx 0.091\n\\end{aligned}\n\\]\nSo there is less than a 10% chance that the driver is drunk even when the breathalyzer shows positive.\nYou can verify that with a simulation using R:\n\nset.seed(4)\ntruly_drunk &lt;- c(rep(\"drunk\", 100), rep(\"sober\", 100 * 999))\ntable(truly_drunk)\n\n#&gt; truly_drunk\n#&gt; drunk sober \n#&gt;   100 99900\n\nbreathalyzer_test &lt;- ifelse(truly_drunk == \"drunk\",\n    # If drunk, 100% chance of showing positive\n    \"positive\",\n    # If not drunk, 1% chance of showing positive\n    sample(c(\"positive\", \"negative\"), 999000,\n        replace = TRUE, prob = c(.01, .99)\n    )\n)\n# Check the probability p(positive | sober)\ntable(breathalyzer_test[truly_drunk == \"sober\"])\n\n#&gt; \n#&gt; negative positive \n#&gt;    98903      997\n\n# 997 / 99900 = 0.00997998, so the error rate is less than 1%\n# Now, Check the probability p(drunk | positive)\ntable(truly_drunk[breathalyzer_test == \"positive\"])\n\n#&gt; \n#&gt; drunk sober \n#&gt;   100   997\n\n# 100 / (100 + 997) = 0.0911577, which is only 9.1%!",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes's Theorem</span>"
    ]
  },
  {
    "objectID": "03-bayes-theorem.html#bayesian-statistics",
    "href": "03-bayes-theorem.html#bayesian-statistics",
    "title": "3  Bayes’s Theorem",
    "section": "3.2 Bayesian Statistics",
    "text": "3.2 Bayesian Statistics\nBayesian statistics is a way to estimate some parameter \\(\\theta\\) (i.e., some quantities of interest, such as the population mean, regression coefficient, etc) by applying the Bayes’ Theorem.\n\n\n\n\n\n\n\\[\nP(\\theta | D) \\propto P(D | \\theta) P(\\theta)\n\\]\n\n\n\nThere are three components in the above equality:\n\n\\(P(D | \\theta)\\), the probability that you observe data \\(D\\), given the parameter \\(\\theta\\); this is called the likelihood (Note: It is the likelihood of \\(\\theta\\), but probability about \\(y\\))\n\\(P(\\theta)\\), the probability distribution \\(\\theta\\), without referring to the data \\(D\\). This usually requires appeals to one’s degree of belief, and so is called the prior\n\\(P(\\theta | y)\\), the updated probability distribution of \\(\\theta\\), after observing the data \\(D\\); this is called the posterior\n\nOn the other hand, classical/frequentist statistics focuses solely on the likelihood function.1 In Bayesian statistics, the goal is to update one’s belief about \\(\\theta\\) based on the observed data \\(D\\).",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes's Theorem</span>"
    ]
  },
  {
    "objectID": "03-bayes-theorem.html#example-2-locating-a-plane",
    "href": "03-bayes-theorem.html#example-2-locating-a-plane",
    "title": "3  Bayes’s Theorem",
    "section": "3.3 Example 2: Locating a Plane",
    "text": "3.3 Example 2: Locating a Plane\nConsider a highly simplified scenario of locating a missing plane in the sea. Assume that we know the plane, before missing, happened to be flying on the same latitude, heading west across the Pacific, so we only need to find the longitude of it. We want to go out to collect debris (data) so that we can narrow the location (\\(\\theta\\)) of the plane down.\n\nPriorLikelihoodPosterior\n\n\nWe start with our prior. Assume that we have some rough idea that the plane should be, so we express our belief in a probability distribution like the following:\n\n\n\n\n\n\n\n\nFigure 3.1: Prior distribution.\n\n\n\n\n\nwhich says that our belief is that the plane is about twice more likely to be towards the east than towards the west. Below are two other options for priors (out of infinitely many), one providing virtually no information and the other encoding stronger information:\n\n\n\n\n\n\n\n\n\n\n\n(a) Noninformative prior.\n\n\n\n\n\n\n\n\n\n\n\n(b) Informative prior.\n\n\n\n\n\n\n\nFigure 3.2: More options for prior distribution.\n\n\n\nThe prior is chosen to reflect the researcher’s belief, so it is likely that different researchers will formulate a different prior for the same problem, and that’s okay as long as the prior is reasonable and justified. Later we will learn that in regular Bayesian analyses, with moderate sample size, different priors generally make only negligible differences.\n\n\nNow, assume that we have collected debris in the locations shown in the graph,\n\n\n\n\n\n\n\n\nFigure 3.3\n\n\n\n\n\n\n\nNow, from Bayes’s Theorem,\n\\[\n\\text{Posterior Probability} \\propto \\text{Prior Probability} \\times\n                                       \\text{Likelihood}\n\\]\nSo we can simply multiply the prior probabilities and the likelihood to get the posterior probability for every location. A rescaling step is needed to ensure that the area under the curve will be 1, which is usually performed by the software.\n\n\n\n\n\n\n\n\nFigure 3.4\n\n\n\n\n\n\n\n\nAs illustrated below, the posterior distribution is a synthesis of (a) the prior and (b) the data (likelihood).\n\nInfluence of PriorInfluence of More Data\n\n\nFigure 3.5 shows what happen with a stronger prior:\n\n\n\n\n\n\n\n\nFigure 3.5\n\n\n\n\n\n\n\nFigure 3.6 shows what happen with 20 more data points:\n\n\n\n\n\n\n\n\nFigure 3.6",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes's Theorem</span>"
    ]
  },
  {
    "objectID": "03-bayes-theorem.html#data-order-invariance",
    "href": "03-bayes-theorem.html#data-order-invariance",
    "title": "3  Bayes’s Theorem",
    "section": "3.4 Data-Order Invariance",
    "text": "3.4 Data-Order Invariance\nIn many data analysis applications, researchers collect some data \\(D_1\\), and then collect some more data \\(D_2\\). An example would be researchers conducting two separate experiments to study the same research question. In Bayesian statistics, one can consider three ways to obtain the posterior:\n\nUpdate the belief with \\(D_1\\), and then with \\(D_2\\)\nUpdate the belief with \\(D_2\\), and then with \\(D_1\\)\nUpdate the belief with both \\(D_1\\) and \\(D_2\\) simultaneously\n\nWhether these three ways give the same posterior depends on whether data-order invariance holds. If the inference of \\(D_1\\) does not depend on \\(D_2\\), or vice versa, then all three ways lead to the same posterior. Specifically, if we have conditional independence such that \\[\nP(D_1, D_2 \\mid \\theta) = P(D_1 \\mid \\theta) P(D_2 \\mid \\theta),\n\\] then one can show all three ways give the same posterior (see p. 108 of Kruschke, 2015).\n\n\n\n\n\n\nExchangeability*\n\n\n\nExchangeability is an important concept in Bayesian statistics. Data are exchangeable when the joint distribution, \\(P(D_1, \\ldots, D_N)\\), does not depend on the ordering of the data. A simple way to think about it is if you scramble the order of your outcome variable in your data set and still can obtain the same statistical results, then the data are exchangeable. An example situation where data are not exchangeable is\n\n\\(D_1\\) is from year 1990, \\(D_2\\) is from year 2020, and the parameter \\(\\theta\\) changes from 1990 to 2020\n\nWhen data are exchangeable, the previously discussed conditional independence condition would generally hold.2",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes's Theorem</span>"
    ]
  },
  {
    "objectID": "03-bayes-theorem.html#bernoulli-likelihood",
    "href": "03-bayes-theorem.html#bernoulli-likelihood",
    "title": "3  Bayes’s Theorem",
    "section": "3.5 Bernoulli Likelihood",
    "text": "3.5 Bernoulli Likelihood\nFor binary data \\(y\\) (e.g., coin flip, pass/fail, diagnosed/not), an intuitive way to analyze is to use a Bernoulli model: \\[\n  \\begin{aligned}\n    P(y = 1 \\mid \\theta) = \\theta \\\\\n    P(y = 0 \\mid \\theta) = 1 - \\theta\n  \\end{aligned},\n\\] which is more compactly written as \\[\nP(y \\mid \\theta) = \\theta^y (1 - \\theta)^{(1 - y)},\n\\] where \\(\\theta \\in [0, 1]\\) is the probability of a “1”. You can verify that the compact form is the same as the longer form.\n\n3.5.1 Multiple Observations\nWhen there are more than one \\(y\\), say \\(y_1, \\ldots, y_N\\), that are conditionally independent, we have \\[\n  \\begin{aligned}\n    P(y_1, \\ldots, y_N \\mid \\theta) & = \\prod_{i = 1}^N P(y_i \\mid \\theta) \\\\\n    & = \\theta^{\\sum_{i = 1}^N y_i} (1 - \\theta)^{\\sum_{i = 1}^N (1 - y_i)} \\\\\n    & = \\theta^z (1 - \\theta)^{N - z}\n  \\end{aligned},\n\\] where \\(z\\) is the number of “1”s (e.g., number of heads in coin flips). Note that the likelihood only depends on \\(z\\), not the individual \\(y\\)s. In other words, the likelihood is the same as long as there are \\(z\\) heads, regardless of when those heads occur.\nLet’s say \\(N\\) = 4 and \\(z\\) = 1. We can plot the likelihood in R:\n\n# Write the likelihood as a function of theta\nlik &lt;- function(th, num_flips = 4, num_heads = 1) {\n    th ^ num_heads * (1 - th) ^ (num_flips - num_heads)\n}\n# Likelihood of theta = 0.5\nlik(0.5)\n\n#&gt; [1] 0.0625\n\n# Plot the likelihood\nggplot(data.frame(th = c(0, 1)), aes(x = th)) +\n    # `stat_function` for plotting a function\n    stat_function(fun = lik) +\n    # use `expression()` to get greek letters\n    labs(x = expression(theta),\n    y = \"Likelihood with N = 4 and z = 1\")\n\n\n\n\n\n\n\nFigure 3.7: Binomial likelihood function with \\(N\\) = 4 and \\(z\\) = 1\n\n\n\n\n\n\n\n3.5.2 Setting Priors\nRemember again the relationship between the prior and the posterior: \\[P(\\theta | y) \\propto P(y | \\theta) P(\\theta)\\] The posterior distributions are mathematically determined once the priors and the likelihood are set. However, the mathematical form of the posterior is sometimes very difficult to deal with.\nOne straight forward, brute-force method is to discretize the parameter space into a number of points. For example, by taking \\(\\theta\\) = 0, 0.05, 0.10, . . . , 0.90, 0.95, 1.00, one can evaluate the posterior at these 21 grid points.\nLet’s use a prior that peaks at 0.5 and linearly decreases to both sides. I assume that \\(\\theta\\) = 0.5 is twice as likely as \\(\\theta = 0.25\\) or \\(\\theta = 0.75\\) to reflect my belief that the coin is more likely to be fair.\n\n# Define a grid for the parameter\ngrid_df &lt;- data.frame(th = seq(0, 1, by = 0.05))\n# Set the prior mass for each value on the grid\ngrid_df$pth &lt;- c(0:10, 9:0)  # linearly increasing, then decreasing\n# Convert pth to a proper distribution such that the value\n# sum to one\n1grid_df$pth &lt;- grid_df$pth / sum(grid_df$pth)\n# Plot the prior\nggplot(grid_df, aes(x = th, y = pth)) +\n    geom_col(aes(x = th, y = pth),\n        width = 0.01,\n    ) +\n    labs(y = expression(P(theta)), x = expression(theta))\n\n\n1\n\nNote the line grid_df$pth &lt;- grid_df$pth / sum(grid_df$pth), which ensures that the probability values sum to one. This is a trick we will use to obtain the posterior probability.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrior Predictive Distribution\n\n\n\nOne way to check whether the prior is appropriate is to use the prior predictive distribution. Bayesian models are generative in the sense that they can be used to simulate data. The prior predictive distribution can be obtained by first simulating some \\(\\theta\\) values from the prior distribution and then simulating a data set for each \\(\\theta\\).\n\n# Draw one theta\nnum_trials &lt;- 4  # number of draws\nsim_th1 &lt;- sample(grid_df$th, size = 1,\n                  # based on prior probability\n                  prob = grid_df$pth)\n# Simulate new data of four flips based on model\nsim_y1 &lt;- rbinom(num_trials, size = 1, prob = sim_th1)\n\n# Repeat many times\n# Set number of simulation draws\nnum_draws &lt;- 1000\nsim_th &lt;- sample(grid_df$th, size = num_draws, replace = TRUE,\n                 # based on prior probability\n                 prob = grid_df$pth)\n# Use a for loop\n# Initialize output\nsim_y &lt;- matrix(NA, nrow = num_trials, ncol = num_draws)\nfor (s in seq_len(num_draws)) {\n    # Store simulated data in the sth column\n    sim_y[, s] &lt;- rbinom(num_trials, size = 1, prob = sim_th[s])\n}\n# Show the first 10 simulated data sets based on prior:\nsim_y[, 1:10]\n\n#&gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n#&gt; [1,]    1    0    0    1    0    1    0    0    0     1\n#&gt; [2,]    0    0    0    1    1    0    1    0    1     1\n#&gt; [3,]    1    0    0    1    0    0    0    1    1     1\n#&gt; [4,]    1    0    1    1    1    0    0    1    1     0\n\n# Show the distribution of number of heads\nsim_heads &lt;- colSums(sim_y)\nggplot(data.frame(z = sim_heads), aes(x = z)) +\n    geom_bar()\n\n\n\n\n\n\n\n\nThe outcome seems to fit our intuition that it’s more likely to be half heads and half tails, but there is a lot of uncertainty.\n\n\n\n\n3.5.3 Summarizing the Posterior\n\ngrid_df &lt;- grid_df %&gt;%\n    mutate(\n        # Use our previously defined lik() function\n        py_th = lik(th, num_flips = 4, num_heads = 1),\n        # Product of prior and likelihood\n        `prior x lik` = pth * py_th,\n        # Scaled the posterior\n        pth_y = `prior x lik` / sum(`prior x lik`)\n    )\n# Print a table\nknitr::kable(grid_df)\n\n\n\n\nth\npth\npy_th\nprior x lik\npth_y\n\n\n\n\n0.00\n0.00\n0.0000000\n0.0000000\n0.0000000\n\n\n0.05\n0.01\n0.0428687\n0.0004287\n0.0073359\n\n\n0.10\n0.02\n0.0729000\n0.0014580\n0.0249500\n\n\n0.15\n0.03\n0.0921188\n0.0027636\n0.0472914\n\n\n0.20\n0.04\n0.1024000\n0.0040960\n0.0700927\n\n\n0.25\n0.05\n0.1054688\n0.0052734\n0.0902416\n\n\n0.30\n0.06\n0.1029000\n0.0061740\n0.1056525\n\n\n0.35\n0.07\n0.0961187\n0.0067283\n0.1151381\n\n\n0.40\n0.08\n0.0864000\n0.0069120\n0.1182815\n\n\n0.45\n0.09\n0.0748688\n0.0067382\n0.1153071\n\n\n0.50\n0.10\n0.0625000\n0.0062500\n0.1069530\n\n\n0.55\n0.09\n0.0501187\n0.0045107\n0.0771891\n\n\n0.60\n0.08\n0.0384000\n0.0030720\n0.0525695\n\n\n0.65\n0.07\n0.0278687\n0.0019508\n0.0333832\n\n\n0.70\n0.06\n0.0189000\n0.0011340\n0.0194056\n\n\n0.75\n0.05\n0.0117188\n0.0005859\n0.0100268\n\n\n0.80\n0.04\n0.0064000\n0.0002560\n0.0043808\n\n\n0.85\n0.03\n0.0028687\n0.0000861\n0.0014727\n\n\n0.90\n0.02\n0.0009000\n0.0000180\n0.0003080\n\n\n0.95\n0.01\n0.0001187\n0.0000012\n0.0000203\n\n\n1.00\n0.00\n0.0000000\n0.0000000\n0.0000000\n\n\n\n\n\n\n# Plot the prior/likelihood and the posterior\nggplot(data = grid_df, aes(x = th)) +\n    geom_col(aes(x = th - 0.005, y = pth, fill = \"prior\"),\n        width = 0.01,\n    ) +\n    geom_col(aes(x = th + 0.005, y = py_th / sum(py_th),\n        fill = \"scaled likelihood\"), width = 0.01,\n    ) +\n    labs(fill = NULL, y = NULL, x = expression(theta)) +\n    theme(legend.position = \"top\")\nggplot(data = grid_df, aes(x = th)) +\n    geom_col(aes(x = th, y = pth_y), width = 0.01) +\n    labs(\n        fill = NULL, y = NULL, title = \"Posterior\",\n        x = expression(theta)\n    )\n\n\n\n\n\n\n\n\n\n\n\n(a) Prior and likelihood\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Posterior\n\n\n\n\n\n\n\nFigure 3.8: Bernoulli posterior distribution\n\n\n\n\nFigure 3.8 (b) shows the posterior distribution, which represents our updated belief about \\(\\theta\\). We can summarize it by simulating \\(\\theta\\) values from it and compute summary statistics:\n\n# Define a function for computing posterior summary\nsumm_draw &lt;- function(x) {\n    c(\n        mean = mean(x),\n        median = median(x),\n        sd = sd(x),\n        mad = mad(x),\n        `ci.1` = quantile(x, prob = .1, names = FALSE),\n        `ci.9` = quantile(x, prob = .9, names = FALSE)\n    )\n}\n# Sample from the posterior\npost_samples &lt;- sample(\n    grid_df$th,\n    size = 1000, replace = TRUE,\n    prob = grid_df$pth_y\n)\nsumm_draw(post_samples)\n\n#&gt;      mean    median        sd       mad      ci.1      ci.9 \n#&gt; 0.3848000 0.4000000 0.1538429 0.1482600 0.2000000 0.6000000\n\n# Alternatively, use the `posterior` package\ndata.frame(theta = post_samples) |&gt;\n    posterior::summarize_draws()\n\n\n  \n\n\n\n\nInfluence of Sample SizeInfluence of Prior\n\n\nIf, instead, we have \\(N\\) = 40 and \\(z\\) = 10, the posterior will be more similar to the likelihood.\n\ngrid_df2 &lt;- grid_df %&gt;%\n    mutate(\n        # Use our previously defined lik() function\n        py_th = lik(th, num_flips = 40, num_heads = 10),\n        # Product of prior and likelihood\n        `prior x lik` = pth * py_th,\n        # Scaled the posterior\n        pth_y = `prior x lik` / sum(`prior x lik`)\n    )\n# Plot the prior/likelihood and the posterior\nggplot(data = grid_df2, aes(x = th)) +\n    geom_col(aes(x = th - 0.005, y = pth, fill = \"prior\"),\n        width = 0.01,\n    ) +\n    geom_col(aes(x = th + 0.005, y = py_th / sum(py_th),\n        fill = \"scaled likelihood\"), width = 0.01,\n    ) +\n    labs(fill = NULL, y = NULL, x = expression(theta)) +\n    theme(legend.position = \"top\")\n\n\n\n\n\n\n\nggplot(data = grid_df2, aes(x = th)) +\n    geom_col(aes(x = th, y = pth_y), width = 0.01) +\n    labs(\n        fill = NULL, y = NULL, title = \"Posterior\",\n        x = expression(theta)\n    )\n\n\n\n\n\n\n\n\n\n# Sample from the posterior\npost_samples &lt;- sample(\n    grid_df2$th,\n    size = 1000, replace = TRUE,\n    prob = grid_df2$pth_y\n)\nsumm_draw(post_samples)\n\n#&gt;       mean     median         sd        mad       ci.1       ci.9 \n#&gt; 0.28085000 0.30000000 0.06542215 0.07413000 0.20000000 0.35000000\n\n\n\n\nIf we have a very strong prior concentrated at \\(\\theta\\) = .5, but still with \\(N\\) = 40 and \\(z\\) = 10, the posterior will be more similar to the prior.\n\ngrid_df3 &lt;- grid_df %&gt;%\n    mutate(\n        # stronger prior\n        pth = pth ^ 3,\n        # scale the prior to sume to 1\n        pth = pth / sum(pth),\n        # Use our previously defined lik() function\n        py_th = lik(th, num_flips = 4, num_heads = 1),\n        # Product of prior and likelihood\n        `prior x lik` = pth * py_th,\n        # Scaled the posterior\n        pth_y = `prior x lik` / sum(`prior x lik`)\n    )\n# Plot the prior/likelihood and the posterior\nggplot(data = grid_df3, aes(x = th)) +\n    geom_col(aes(x = th - 0.005, y = pth, fill = \"prior\"),\n        width = 0.01,\n    ) +\n    geom_col(aes(x = th + 0.005, y = py_th / sum(py_th),\n        fill = \"scaled likelihood\"), width = 0.01,\n    ) +\n    labs(fill = NULL, y = NULL, x = expression(theta)) +\n    theme(legend.position = \"top\")\n\n\n\n\n\n\n\nggplot(data = grid_df3, aes(x = th)) +\n    geom_col(aes(x = th, y = pth_y), width = 0.01) +\n    labs(\n        fill = NULL, y = NULL, title = \"Posterior\",\n        x = expression(theta)\n    )\n\n\n\n\n\n\n\n\n\n# Sample from the posterior\npost_samples &lt;- sample(\n    grid_df3$th,\n    size = 1000, replace = TRUE,\n    prob = grid_df3$pth_y\n)\nsumm_draw(post_samples)\n\n#&gt;      mean    median        sd       mad      ci.1      ci.9 \n#&gt; 0.4493000 0.4500000 0.1096656 0.0741300 0.3000000 0.6000000\n\n# Alternatively, use the `posterior` package\ndata.frame(theta = post_samples) |&gt;\n    posterior::summarize_draws()\n\n\n  \n\n\n\n\n\n\n\n\n3.5.4 Remark on Grid Approximation\nIn this note, we discretized \\(\\theta\\) into a finite number of grid points to compute the posterior, mainly for pedagogical purposes. A big limitation is that our posterior will have no density for values other than the chosen grid points. While increasing the number of grid points (e.g., 1,000) can give more precision, the result is still not truly continuous. A bigger issue is that the computation breaks down when there is more than one parameter; if there are \\(p\\) parameters, with 1,000 grid points per parameter, one needs to evaluate the posterior probability for \\(1,000^p\\) grid points, which is not feasible even with modern computers. So more efficient algorithms, namely Markov chain Monte Carlo (MCMC) methods, will be introduced as we progress in the course.",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes's Theorem</span>"
    ]
  },
  {
    "objectID": "03-bayes-theorem.html#footnotes",
    "href": "03-bayes-theorem.html#footnotes",
    "title": "3  Bayes’s Theorem",
    "section": "",
    "text": "The likelihood function in classical/frequentist statistics is usually written as \\(P(y; \\theta)\\). You will notice that here I write the likelihood for classical/frequentist statistics to be different from the one used in Bayesian statistics. This is intentional: In frequentist conceptualization, \\(\\theta\\) is fixed, and it does not make sense to talk about the probability of \\(\\theta\\). This implies that we cannot condition on \\(\\theta\\), because conditional probability is defined only when \\(P(\\theta)\\) is defined.↩︎\nThe de Finetti’s theorem shows that when the data are exchangeable and can be considered an infinite sequence (i.e., not from a tiny finite population), then the data are conditionally independent given some \\(\\theta\\).↩︎",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes's Theorem</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "4  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Gigerenzer, G. (2004). Mindless statistics. The Journal of\nSocio-Economics, 33(5), 587–606. https://doi.org/10.1016/j.socec.2004.09.033\n\n\nLambert, B. (2018). A student’s guide to Bayesian statistics.\nSAGE.\n\n\nMcGrayne, S. B. (2011). The theory that would not die: How Bayes’\nrule cracked the enigma code, hunted down Russian submarines, &\nemerged triumphant from two centuries of controversy. Yale\nuniversity press.\n\n\nVan De Schoot, R., Winter, S. D., Ryan, O., Zondervan-Zwijnenburg, M.,\n& Depaoli, S. (2017). A systematic review of Bayesian articles in\npsychology: The last 25 years. Psychological Methods,\n22(2), 217–239. https://doi.org/10.1037/met0000100",
    "crumbs": [
      "References"
    ]
  }
]