[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PSYC 573 Bayesian Data Analysis (2024 Fall): Course Notes",
    "section": "",
    "text": "Preface\nThere will be some math in this notes. Don’t worry if you feel the math is challenging; for applied focused students, it is much more important to understand the concepts of Bayesian methods than to understand the mathematical symbols, as they usually can be handled by the software.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "01-intro.html",
    "href": "01-intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 History of Bayesian Statistics\nHere is a nice brief video that covers some of the 250+ years of history of Bayesian statistics:\nIf you are interested in learning more about the story, check out the popular science book, “The theory that would not die,” by McGrayne (2011)",
    "crumbs": [
      "Week 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#history-of-bayesian-statistics",
    "href": "01-intro.html#history-of-bayesian-statistics",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1.1 Thomas Bayes (1701–1762)\nYou may find a biography of Bayes from https://www.britannica.com/biography/Thomas-Bayes. There is also a nice story in the book by Lambert (2018). He was an English Presbyterian minister. The important work he wrote that founded Bayesian statistics was “An Essay Towards Solving a Problem in the Doctrine of Chances,” which he did not publish and was later discovered and edited by his friend, Richard Price, after Bayes’s death 1\n\n\n1.1.2 Pierre-Simon Laplace (1749–1827)\nLaplace, a French Mathematician, was an important figure in not just Bayesian statistics but other areas of mathematics, astronomy, and physics. We know much more about the work by Laplace than by Bayes, and Laplace has worked independently on the inverse probability problem (i.e., \\(P[\\text{Parameter} | \\text{Data}]\\)). Indeed, he was credited for largely formalizing the Bayesian interpretation of probability and most of the machinery for Bayesian statistics, and making it a useful technique for different problems, despite the discipline being called “Bayesian.” His other contributions include the methods of least squares and the central limit theorem. See a short biography of him at https://www.britannica.com/biography/Pierre-Simon-marquis-de-Laplace.\n\n\n1.1.3 20th Century\nUntil the early 1920s, the inverse probability method, which is based on what is now called Bayes’s Theorem, was pretty much the predominant point of view of statistics. Then a point of view later known as frequentist statistics arrived, and quickly became the mainstream school of thinking for statistical inferences, and is still the primary framework for quantitative research. In the early 1920s, frequentist scholars, most notably R. A. Fisher and Jerzy Neyman, criticized Bayesian inference for using subjective elements in an objective discipline. In Fisher’s words,\n\nThe theory of inverse probability is founded upon an error, and must be wholly rejected—Fisher, 1925\n\nIronically, the term Bayesian was first used in one of Fisher’s works. And interestingly, Fisher actually thought he “[had] been doing almost exactly what Bayes had done in the 18th century.”2\nDespite criticisms from frequentist scholars, Bayesian methods have been used by scholars in the Allies in World War II, such as Alan Turing, in an algorithm to break coded messages in the Enigma machine that the German Navy used to communicate. However, because of the more complex mathematics involved in Bayesian statistics, Bayesian statistics is limited to straight-forward problems and theoretical discussions until the early 1980s, when computing speed increased tremendously and made Markov Chain Monte Carlo—the primary algorithm for Bayesian estimation in modern Bayesian statistics—feasible. With the help of increased computing speed, Bayesian statistics has come back and been used as an alternative way of thinking, especially given the growing dissatisfaction towards the misuse of frequentist statistics by some scholars across disciplines. Bayesian estimation methods have also been applied to many new research questions where frequentist approaches work less well, as well as in big data analytics and machine learning.",
    "crumbs": [
      "Week 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#motivations-for-using-bayesian-methods",
    "href": "01-intro.html#motivations-for-using-bayesian-methods",
    "title": "1  Introduction",
    "section": "1.2 Motivations for Using Bayesian Methods",
    "text": "1.2 Motivations for Using Bayesian Methods\nBased on my personal experience, Bayesian methods are used quite often in statistics and related departments, as it is consistent and coherent, in contrast to frequentist where a new and probably ad hoc procedure needed to be developed to handle a new problem. For Bayesian, as long as you can formulate a model, you just run the analysis the same way as you would for simpler problems, or in Bayesian people’s words “turning the Bayesian crank,” and likely the difficulties would be more technical than theoretical, which is usually solved with better computational speed.\nSocial and behavioral scientists are relatively slow to adopt the Bayesian method, but things have been changing. In a recently accepted paper by Van De Schoot et al. (2017), the authors reviewed papers in psychology between 1990 and 2015 and found that whereas less than 10% of the papers from 1990 to 1996 mentioned “Bayesian”, the proportion increased steadily and was found in close to 45% of the psychology papers in 2015. Among studies using Bayesian methods, more than 1/4 cited computational problems (e.g., nonconvergence) in frequentist methods as a reason, and about 13% cited the need to incorporate prior knowledge into the estimation process. The other reasons included the flexibility of Bayesian methods for complex and nonstandard problems, and the use of techniques traditionally attached to Bayesian such as missing data and model comparisons.\n\n1.2.1 Problem with classical (frequentist) statistics\nThe rise of Bayesian methods is also related to the statistical reform movement in the past two decades. The problem is that applied researchers are obsessed with \\(p &lt; .05\\) and often misinterpreted a small \\(p\\)-value as something that it isn’t (read Gigerenzer, 2004). Some scholars coined the term \\(p\\)-hacking to refer to the practice of obtaining statistical significance by choosing to test the data in a certain way, either consciously or subconsciously (e.g., dichotomizing using mean or median, trying the same hypothesis using different measures of the same variable, etc). This is closely related to the recent “replication crisis” in scientific research, with psychology being in the center under close scrutiny.\nBayesian is no panacea to the problem. Indeed, if misused, it can give rise to the same problems as statistical significance. My goal in this class is to help you appreciate the Bayesian tradition of embracing the uncertainty in your results, and adopt rigorous model checking and comprehensive reporting rather than relying merely on a \\(p\\)-value. I see this as the most important mission for someone teaching statistics.",
    "crumbs": [
      "Week 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#comparing-bayesian-and-frequentist-statistics",
    "href": "01-intro.html#comparing-bayesian-and-frequentist-statistics",
    "title": "1  Introduction",
    "section": "1.3 Comparing Bayesian and Frequentist Statistics",
    "text": "1.3 Comparing Bayesian and Frequentist Statistics\n\n\n\n\n\n\n\n\nAttributes\nFrequentist\nBayesian\n\n\n\n\nInterpretation of probability\nFrequentist\nSubjectivist\n\n\nUncertainty\nHow estimates vary in repeated sampling from the same population\nHow much prior beliefs about parameters change in light of data\n\n\nWhat’s relevant?\nCurrent data set + all that might have been observed\nOnly the data set that is actually observed\n\n\nHow to proceed with analyses\nMLE; ad hoc and depends on problems\n“Turning the Bayesian crank”",
    "crumbs": [
      "Week 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#software-for-bayesian-statistics",
    "href": "01-intro.html#software-for-bayesian-statistics",
    "title": "1  Introduction",
    "section": "1.4 Software for Bayesian Statistics",
    "text": "1.4 Software for Bayesian Statistics\nThe following summarizes some of the most popular Bayesian software. Currently, JAGS and Stan are the most popular. General statistical programs like SPSS, SAS, and Stata also have some support for Bayesian analyses as well.\n\nWinBUGS\n\nBayesian inference Using Gibbs Sampling\nFree, and most popular until late 2000s. Many Bayesian scholars still use WinBUGS\nNo further development\nOne can communicate from R to WinBUGS using the package R2WinBUGS\n\nJAGS\n\nJust Another Gibbs Sampler\nVery similar to WinBUGS, but written in C++, and supports user-defined functionality\nCross-platform compatibility\nOne can communicate from R to JAGS using the package rjags or runjags\n\nStan\n\nNamed in honour of Stanislaw Ulam, who invented the Markov Chain Monte Carlo method\nUses new algorithms that are different from Gibbs sampling\nUnder very active development\nCan interface with R through the package rstan, and the R packages rstanarm and brms automates the procedure for fitting models in Stan for many commonly used models\n\n\n\n\n\n\n\n\nGigerenzer, G. (2004). Mindless statistics. The Journal of Socio-Economics, 33(5), 587–606. https://doi.org/10.1016/j.socec.2004.09.033\n\n\nLambert, B. (2018). A student’s guide to Bayesian statistics. SAGE.\n\n\nMcGrayne, S. B. (2011). The theory that would not die: How Bayes’ rule cracked the enigma code, hunted down Russian submarines, & emerged triumphant from two centuries of controversy. Yale university press.\n\n\nVan De Schoot, R., Winter, S. D., Ryan, O., Zondervan-Zwijnenburg, M., & Depaoli, S. (2017). A systematic review of Bayesian articles in psychology: The last 25 years. Psychological Methods, 22(2), 217–239. https://doi.org/10.1037/met0000100",
    "crumbs": [
      "Week 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#footnotes",
    "href": "01-intro.html#footnotes",
    "title": "1  Introduction",
    "section": "",
    "text": "Price is another important figure in mathematics and philosophy, and had taken Bayes’ theorem and applied it to insurance and moral philosophy.↩︎\nSee the paper by John Aldrich on this.↩︎",
    "crumbs": [
      "Week 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "02-probability.html",
    "href": "02-probability.html",
    "title": "\n2  Probability\n",
    "section": "",
    "text": "2.1 History of Probability",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "02-probability.html#history-of-probability",
    "href": "02-probability.html#history-of-probability",
    "title": "\n2  Probability\n",
    "section": "",
    "text": "2.1.1 Games of chance\nCorrespondence between French Mathematicians (Pierre de Fermat and Blaise Pascal) on gambling problem by Antoine Gombaud, Chevalier de Méré. The problem is roughly of the form1:\n\nImagine two people playing a multi-round game. In each round, each person has an equal chance of winning. The first person who wins six rounds will get a huge cash prize. Now, consider a scenario in which A and B have played six rounds, where A has won five and B has won one. At that time, the game had to be stopped due to a thunderstorm. Since neither A nor B have reached six wins, instead of giving the prize to either one of them, they agree to divide up the prize. What would be a fair way to do so?\n\nThe discussion led to the formalization of using mathematics to solve the problem. Basically, one way is to say if A has a 97% chance of winning the prize eventually and B has a 3% chance, then A should get 97% of the prize.",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "02-probability.html#different-ways-to-interpret-probability",
    "href": "02-probability.html#different-ways-to-interpret-probability",
    "title": "\n2  Probability\n",
    "section": "\n2.2 Different Ways to Interpret Probability",
    "text": "2.2 Different Ways to Interpret Probability\nThere are multiple perspectives for understanding probability.2 What you’ve learned in your statistics training is likely based on the frequentist interpretation of probability (and thus frequentist statistics), whereas the foundation of what you will learn in this class is the subjectivist interpretation of probability. Understanding the different perspectives on probability is helpful for understanding the Bayesian framework.\n\n\n\n\n\n\nYou don’t need to commit to one interpretation of probability in order to conduct Bayesian data analysis.\n\n\n\n\n2.2.1 Classical Interpretation\nThis is an earlier perspective and is based on counting rules. The idea is that probability is equally distributed among all “indifferent” outcomes. “Indifferent” outcomes are those where a person has no evidence to say that one outcome is more likely than another. For example, when one throws a die, one does not think that a certain number is more likely than another unless one knows that the die is biased. In this case, there are six equally likely outcomes, so the probability of each outcome is 1 / 6.\n\n\n2.2.2 Frequentist Interpretation\nThe frequentist interpretation states that probability is essentially the long-run relative frequency of an outcome. For example, to find the probability of getting a “1” when throwing a die, one can repeat the experiment many times, as illustrated below:\n\n\n\n\nTrial\nOutcome\n\n\n\n1\n2\n\n\n2\n3\n\n\n3\n1\n\n\n4\n3\n\n\n5\n1\n\n\n6\n1\n\n\n7\n5\n\n\n8\n6\n\n\n9\n3\n\n\n10\n3\n\n\n\n\n\nAnd we can plot the relative frequency of “1”s in the trials:\n\n\n\n\n\n\n\nFigure 2.1: Relative frequency when repeatedly rolling a die.\n\n\n\n\nAs you can see, with more trials, the relative frequency approaches 1 / 6. It’s the reason why in introductory statistics, many of the concepts require you to think in terms of repeated sampling (e.g., sampling distribution, \\(p\\)-values, standard errors, confidence intervals), because probability in this framework is only possible when the outcome can be repeated. It’s also the reason why we don’t talk about something like:\n\nthe probability of the null hypothesis being true, or\nthe probability that the population mean is in the interval [75.5, 80.5],\n\nbecause the population is fixed and cannot be repeated. Only the samples can be repeated, so probability in frequentist statistics is only about samples.\n\n2.2.2.1 Problem of the single case\nBecause of the frequentist’s reference to long-run relative frequency, it does not make sense to talk about the probability of an event that cannot be repeated under this framework. For example, it does not make sense to talk about\n\nthe probability that the Democrats/Republicans will win the 2028 US Presidential Election, or\nthe probability that the LA Chargers winning the 2024 Super Bowl, or\nthe probability that it will rain on Christmas Day in LA in 2024,\n\nbecause all these are specific events that cannot be repeated. However, it is common for laypeople to talk about probabilities or chances for these events.\n\n2.2.3 Subjectivist Interpretation\nThe frequentist interpretation is sometimes called the “objectivist view,” as the reference of probability is based on empirical evidence of long-run relative frequency (albeit hypothetical in many cases). In contrast, the subjectivist view of probability is based on one’s belief. For example, when I say that the probability of getting a “1” from rolling a die is 1 / 6, it reflects the state of my mind about the die. My belief can arise from different sources: Maybe I make the die and know it is a fair one; maybe I saw someone throwing the die 1,000 times, and the number of “1”s was close to 1,000 / 6, or maybe someone I trust and with authority says that the die has a 1-in-6 chance of showing a “1”.\nThe “subjective” component has been criticized a lot by frequentist scholars, sometimes unfairly. To be clear, what “subjective” here means is that probability reflects the state of one’s mind instead of the state of the world, and so it is totally fine that two people can have different beliefs about the same event. However, it does not mean that probability is arbitrary, as the beliefs are subjected to the constraints of the axioms of probability as well as the condition that the person possessing such beliefs is rational.3 Therefore, if two persons are exposed to the same information, they should form similar, though likely not identical, beliefs about the event.\nThe subjective interpretation works perfectly fine with single events, as one can have a belief about whether it rains on a particular day or a belief about a particular election result.\n\n2.2.3.1 Calibrating a subjective belief\nIn order to represent one’s belief by probability, one needs to assign a nonzero value to every plausible outcome of an event. This has been the job of odds-makers for a long time. Indeed, a lot of the development in the field of probability has to do with coming up with a fair bet. The process of assigning probabilities to outcomes of an event according to one’s belief is called calibration. For example, consider three possible outcomes for tomorrow’s weather. For simplicity, consider three mutually exclusive possible outcomes: sunny, cloudy, and rainy.\nTo calibrate my belief, consider first if you bet $10, and the return is (a) $30 for sunny, (b) $30 for cloudy, and (c) $30 for rainy. Which one will you bet? If you’re like me in LA, I’m pretty sure I’ll bet on (a), as I think that it is more likely to have a sunny day. This means that setting \\(P\\)(sunny) = \\(P\\)(cloudy) = \\(P\\)(rainy) = 1 / 3 is not a good reflection of my belief.\nNow consider the bet with the returns (a) $20 for sunny, (b) $30 for cloudy, and (c) $60 for rainy. This would reflect the belief that there is a 50% chance of a sunny day, 33.33% chance of a cloudy day, and 16.67% chance of a rainy day. Will you take the bet? This is an improvement from the last one, but I would still say a sunny day is a good bet, which suggests that the probability of 50% is too low for a sunny day. The idea is to continue iterating until it is hard to consider (a), (b), or (c) as a clear betting favorite. For me, this would end up being something like (a) $16.7 for sunny, (b) $33.3 for cloudy, and (c) $100 for rainy, which would correspond to 60% sunny, 30% cloudy, and 10% rainy.\nIf it’s hard for you to consider the gambling analogy, an alternative way is to consider how many times is a sunny day more likely than a non-sunny day, and how many times is a cloudy day more likely than a rainy day. For example, I may consider a sunny day to be twice as likely as a non-sunny day, which would give the probability of a sunny day to be 66.67%. Then, if I also think that a cloudy day is three times as likely as a rainy day, I would assign a probability of 33.33% \\(\\times\\) 3 / 4 = 25% for a cloudy day, and a probability of 33.33% \\(\\times\\) 1 / 4 = 8.33% for a rainy day.\nThe process of calibrating one’s belief plays a key role in Bayesian data analysis, namely in the form of formulating a prior probability distribution.",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "02-probability.html#basics-of-probability",
    "href": "02-probability.html#basics-of-probability",
    "title": "\n2  Probability\n",
    "section": "\n2.3 Basics of Probability",
    "text": "2.3 Basics of Probability\n\n\n\n\n\n\nKolmogorov axioms\n\n\n\nFor an event \\(A_i\\) (e.g., getting a “1” from throwing a die)\n\n\n\\(P(A_i) \\geq 0\\) [All probabilities are non-negative]\n\n\\(P(A_1 \\cup A_2 \\cup \\cdots) = 1\\) [Union of all possibilities is 1]\n\n\\(P(A_1) + P(A_2) = P(A_1 \\text{ or } A_2)\\) [Addition rule]\n\n\n\nConsider two events, for example, on throwing a die,\n\n\n\\(A\\): The number is odd\n\n\\(B\\): The number is larger than or equal to 4\n\nAssuming that die is (believed to be) fair, you can verify that the probability of \\(A\\) is \\(P(A)\\) = 3 / 6 = 1 / 2, and the probability of \\(B\\) is also \\(P(B)\\) = 3 / 6 = 1 / 2.\n\n2.3.1 Probability Distributions\n\nDiscrete event (e.g., the outcome of throwing a die or an election): probability mass. The probability is nonzero, at least for some outcomes. The graph below on the left shows the probability mass of the sum of the numbers from two dice.\n\nContinuous event (e.g., temperature): probability density.4 The probability is basically zero for any outcome. Instead, the probability density is approximated by \\(P(A \\leq a \\leq A + h) / h\\) for a very small \\(h\\).\n\nFor example, to find the probability density that a person’s well-being score is 80, we first find the probability that a person scores between 80 and 80.5 (or 80 and 80.0005), and divide that probability by 0.5 (or 0.0005). See the shaded area of the graph below on the right.\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Probability mass\n\n\n\n\n\n\n\n\n\n(b) Probability density\n\n\n\n\n\n\nFigure 2.2: Examples of probability distributions\n\n\n\n\n\n\n\n\nFor this course, as in the textbook, we use \\(P(x)\\) to mean both the probability mass for an outcome \\(x\\) when the event is discrete, and the probability density at an outcome \\(x\\) when the event is continuous.\n\n\n\n\n2.3.1.1 Example: Normal Distribution\n\\[P(x) = \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp\\left(-\\frac{1}{2}\\left[\\frac{x - \\mu}{\\sigma}\\right]^2\\right)\\]\n\n# Write a function to compute the density of an outcome x\n# for a normal distribution\nmy_normal_density &lt;- function(x, mu, sigma) {\n    exp(- ((x - mu) / sigma) ^2 / 2) / (sigma * sqrt(2 * pi))\n}\n# For example, density at x = 36 in a normal distribution\n# with mu = 50 and sigma = 10\nmy_normal_density(36, mu = 50, sigma = 10)\n\n#&gt; [1] 0.01497275\n\n\n\n2.3.2 Summarizing a Probability Distribution\nWhile it is useful to know the probability mass/density of every possible outcome, in many situations, it is helpful to summarize a distribution by some numbers.\n\n2.3.2.1 Central Tendency\n\nMean: \\(E(X) = \\int x \\cdot P(x) d x\\)\n\nMedian: 50th percentile; the median of \\(X\\) is \\(\\mathit{Mdn}_X\\) such that \\(P(X \\leq \\mathit{Mdn}_X)\\) = 1 / 2\nMode: A value with maximum probability mass/density\n\nSee Figure 2.3 (a) for examples.\n\n\n\n\n\n\n\n\n\n(a) Central Tendency\n\n\n\n\n\n\n\n\n\n(b) Interval\n\n\n\n\n\n\nFigure 2.3: Measures of central tendency and interval\n\n\n\n2.3.2.2 Dispersion\n\nVariance: \\(V(X) = E[X - E(X)]^2\\)\n\nStandard deviation: \\(\\sigma(X) = \\sqrt{V(X)}\\)\n\n\n\nMedian absolute deviation (MAD): \\(1.4826 \\times \\mathit{Mdn}(|X - \\mathit{Mdn}_X|)\\)\n\n\n2.3.2.3 Interval\nUse \\(C(X)\\) to denote an interval. A \\(W\\)% interval means \\(P(X \\in C[X]) \\approx W\\%\\)\n\nOne-sided interval: \\(C(X)\\) is half-bounded\nSymmetric \\(W\\)% interval: \\(C(X) = [L(X), U(X)]\\) is bounded, with \\(P(X &lt; L[X]) = P(X &gt; U[X]) \\approx W\\% / 2\\)\n\nAlso called equal-tailed interval\n\n\nHighest density \\(W\\)% interval (HDI): \\(P(x_c) \\geq P(x_o)\\) for every \\(x_c\\) in \\(C(X)\\) and every \\(x_o\\) outside \\(C(X)\\). In general, the HDI is the shortest \\(W\\)% interval.\n\nThe plot in Figure 2.3 (b) shows several 80% intervals.\n\n2.3.2.4 Computing Summaries of Sample Distributions Using R\n\n# Simulate data from a half-Student's t distribution with\n# df = 4, and call it sim_s\nsim_s &lt;- rt(10000, df = 4) # can be both positive and negative\nsim_s &lt;- abs(sim_s) # take the absolute values\nggplot(data.frame(x = sim_s), aes(x = x)) +\n    geom_histogram(binwidth = 0.1)\n\n\n\n\n\n\nFigure 2.4: Simulated density of a half-Student’s t distribution\n\n\n\n\n\n# Central tendency\n# (note: the mode is difficult to compute for continuous\n# variables, and rarely used in this course.)\nc(mean = mean(sim_s),\n  median = median(sim_s),\n  mode = density(sim_s, bw = \"SJ\")$x[\n      which.max(density(sim_s, bw = \"SJ\")$y)\n  ])\n\n#&gt;      mean    median      mode \n#&gt; 1.0082926 0.7426326 0.1021776\n\n# Dispersion\nc(\n    variance = var(sim_s),\n    sd = sd(sim_s),\n    mad = mad(sim_s)\n)\n\n#&gt;  variance        sd       mad \n#&gt; 1.0231058 1.0114869 0.6996741\n\n# 80% Interval\nc(`0%` = 0, quantile(sim_s, probs = .8)) # right-sided\n\n#&gt;     0%    80% \n#&gt; 0.0000 1.5598\n\nc(quantile(sim_s, probs = .2), `100%` = Inf) # left-sided\n\n#&gt;       20%      100% \n#&gt; 0.2680906       Inf\n\nquantile(sim_s, probs = c(.1, .9)) # equal-tailed/symmetric\n\n#&gt;       10%       90% \n#&gt; 0.1299027 2.1371636\n\nHDInterval::hdi(sim_s)\n\n#&gt;        lower        upper \n#&gt; 0.0003616342 2.7992620765 \n#&gt; attr(,\"credMass\")\n#&gt; [1] 0.95\n\n\n\n2.3.3 Multiple Variables\n\nJoint probability: \\(P(X, Y)\\)\n\nMarginal probability: \\[P(X) = \\int P(X, y) dy\\] \\[P(Y) = \\int P(x, Y) dx\\]\n\nThe probability that outcome \\(X\\) happens, regardless of what values \\(Y\\) take.\n\n\n\n\n\n\n\n\n\n\nFigure 2.5: Joint and Marginal Distributions\n\n\n\n\n\n2.3.3.1 Conditional Probability\nConditional probability is the probability of an event given some other information. In the real world, you can say that everything is conditional. For example, the probability of getting an odd number on throwing a die is 1/2 is conditional on the die being fair. We use \\(P(A \\mid B)\\) to represent the the conditional probability of event \\(A\\) given event \\(B\\)..\nContinuing from the previous example, \\(P(A \\mid B)\\) is the conditional probability of getting an odd number, knowing that the number is at least 4. By definition, conditional probability is the probability that both \\(A\\) and \\(B\\) happen, divided by the probability that \\(B\\) happens.\n\n\n\n\n\n\nConditional Probability\n\n\n\n\\(P(A \\mid B) = \\dfrac{P(A, B)}{P(B)}\\)\n\n\nIn the example, \\(P(A, B)\\) = 1 / 6, because 5 is the only even number \\(\\geq\\) 4 when throwing a die. Thus, \\[\n\\begin{aligned}\n    P(A \\mid B) & = 1 / 3 \\\\\n             & = \\frac{P(A, B)}{P(B)} \\\\\n             & = \\frac{1 / 6}{1 / 2}\n\\end{aligned}\n\\]\nThis picture should make it clear:\n\n\n\n\n\n\n\n\n\n\nPlease recognize that \\(P(A \\mid B) \\neq P(B \\mid A)\\). For example, when throwing a die, \\(P\\)(number is six | even number) = 1/3, but \\(P\\)(even number | number is six) is 1.\n\n\n\n\n2.3.3.2 Independence\n\n\n\n\n\n\nTwo events, \\(A\\) and \\(B\\), are independent if \\(P(A \\mid B) = P(A)\\)\n\n\n\nThis means that any knowledge of \\(B\\) does not (or should not) affect one’s belief about \\(A\\). Consider the example:\n\n\n\\(A\\): A die shows five or more\n\n\\(B\\): A die shows an odd number\n\nHere is the joint probability\n\n\n\n&gt;= 5\n&lt;= 4\n\n\n\nodd\n1/6\n2/6\n\n\neven\n1/6\n2/6\n\n\n\nSo the conditional probability of \\(P\\)(&gt;= 5 | odd) = (1/6) / (1/2) = 1/3, which is the same as \\(P\\)(&gt;= 5 | even) = (1/6) / (1/2) = 1/3. Similarly it can be verified that \\(P\\)(&lt;= 4 | odd) = \\(P\\)(&lt;= 4 | even) = 2/3. Therefore, \\(A\\) and \\(B\\) are independent.\nOn the other hand, for the example\n\n\n\\(A\\): A die shows four or more\n\n\\(B\\): A die shows an odd number\n\nthe joint probabilities are\n\n\n\n&gt;= 4\n&lt;= 3\n\n\n\nodd\n1/6\n2/6\n\n\neven\n2/6\n1/6\n\n\n\nObviously, \\(A\\) and \\(B\\) are not independent because once we know that the number is four or above, the probability of whether it is an odd number or not changes.\n\n\n\n\n\n\nIndependence can also be expressed as\n\nIf A and B are independent, \\(P(A, B) = P(A) P(B)\\)\n\n\n\n\n\n2.3.4 Law of Total Probability\nWhen we talk about conditional probability, like \\(B_1\\) = 4 or above and \\(B_2\\) = 3 or below, we can get \\(P(A \\mid B_1)\\) and \\(P(A \\mid B_2)\\) (see the figure below), we refer \\(P(A)\\) as the marginal probability, meaning that the probability of \\(A\\)  without knowledge of \\(B\\).\n\n\n\n\nIf \\(B_1, B_2, \\cdots, B_n\\) are all mutually exclusive possibilities for an event (so they add up to a probability of 1), then\n\n\n\n\n\n\nLaw of Total Probability\n\n\n\n\\[\n\\begin{aligned}\n  P(A) & = P(A, B_1) + P(A, B_2) + \\cdots + P(A, B_n)  \\\\\n       & = P(A \\mid B_1)P(B_1) + P(A \\mid B_2)P(B_2) + \\cdots + P(A \\mid B_n) P(B_n)  \\\\\n       & = \\sum_{k = 1}^n P(A \\mid B_k) P(B_k)\n\\end{aligned}\n\\]",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "02-probability.html#footnotes",
    "href": "02-probability.html#footnotes",
    "title": "\n2  Probability\n",
    "section": "",
    "text": "see the exact form at https://en.wikipedia.org/wiki/Problem_of_points↩︎\nSee http://plato.stanford.edu/entries/probability-interpret/ for more information↩︎\nIn a purely subjectivist view of probability, assigning a probability \\(P\\) to an event does not require any justifications, as long as it follows the axioms of probability. For example, I can say that the probability of me winning the lottery and thus becoming the wealthiest person on earth tomorrow is 95%, which by definition would make the probability of me not winning the lottery 5%. Most Bayesian scholars, however, do not endorse this version of subjectivist probability and require justifications of one’s beliefs (that have some correspondence to the world).↩︎\nFor many problems in the social and behavioral sciences, the measured variables are not truly continuous, but we still use continuous distributions to approximate them.↩︎",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "03-bayes-theorem.html",
    "href": "03-bayes-theorem.html",
    "title": "3  Bayes’s Theorem",
    "section": "",
    "text": "3.1 Example 1: Base rate fallacy (From Wikipedia)",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes's Theorem</span>"
    ]
  },
  {
    "objectID": "03-bayes-theorem.html#example-1-base-rate-fallacy-from-wikipedia",
    "href": "03-bayes-theorem.html#example-1-base-rate-fallacy-from-wikipedia",
    "title": "3  Bayes’s Theorem",
    "section": "",
    "text": "QuestionSolution\n\n\nA police officer stops a driver at random and does a breathalyzer test for the driver. The breathalyzer is known to detect true drunkenness 100% of the time, but in 1% of the cases, it gives a false positive when the driver is sober. We also know that, in general, for every 1,000 drivers passing through that spot, one is driving drunk. Suppose that the breathalyzer shows positive for the driver. What is the probability that the driver is truly drunk?\n\n\n\\(P(\\text{positive} | \\text{drunk}) = 1\\)\n\\(P(\\text{positive} | \\text{sober}) = 0.01\\)\n\\(P(\\text{drunk}) = 1 / 1000\\)\n\\(P(\\text{sober}) = 999 / 1000\\)\nUsing Bayes’ Theorem,\n\\[\n\\begin{aligned}\n  P(\\text{drunk} | \\text{positive})\n  & = \\frac{P(\\text{positive} | \\text{drunk}) P(\\text{drunk})}\n           {P(\\text{positive} | \\text{drunk}) P(\\text{drunk}) +\n            P(\\text{positive} | \\text{sober}) P(\\text{sober})}  \\\\\n  & = \\frac{1 \\times 0.001}{1 \\times 0.001 + 0.01 \\times 0.999} \\\\\n  & = 100 / 1099 \\approx 0.091\n\\end{aligned}\n\\]\nSo there is less than a 10% chance that the driver is drunk even when the breathalyzer shows positive.\nYou can verify that with a simulation using R:\n\nset.seed(4)\ntruly_drunk &lt;- c(rep(\"drunk\", 100), rep(\"sober\", 100 * 999))\ntable(truly_drunk)\n\n#&gt; truly_drunk\n#&gt; drunk sober \n#&gt;   100 99900\n\nbreathalyzer_test &lt;- ifelse(truly_drunk == \"drunk\",\n    # If drunk, 100% chance of showing positive\n    \"positive\",\n    # If not drunk, 1% chance of showing positive\n    sample(c(\"positive\", \"negative\"), 999000,\n        replace = TRUE, prob = c(.01, .99)\n    )\n)\n# Check the probability p(positive | sober)\ntable(breathalyzer_test[truly_drunk == \"sober\"])\n\n#&gt; \n#&gt; negative positive \n#&gt;    98903      997\n\n# 997 / 99900 = 0.00997998, so the error rate is less than 1%\n# Now, Check the probability p(drunk | positive)\ntable(truly_drunk[breathalyzer_test == \"positive\"])\n\n#&gt; \n#&gt; drunk sober \n#&gt;   100   997\n\n# 100 / (100 + 997) = 0.0911577, which is only 9.1%!",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes's Theorem</span>"
    ]
  },
  {
    "objectID": "03-bayes-theorem.html#bayesian-statistics",
    "href": "03-bayes-theorem.html#bayesian-statistics",
    "title": "3  Bayes’s Theorem",
    "section": "3.2 Bayesian Statistics",
    "text": "3.2 Bayesian Statistics\nBayesian statistics is a way to estimate some parameter \\(\\theta\\) (i.e., some quantities of interest, such as the population mean, regression coefficient, etc) by applying Bayes’ Theorem.\n\n\n\n\n\n\n\\[\nP(\\theta | D) \\propto P(D | \\theta) P(\\theta)\n\\]\n\n\n\nThere are three components in the above equality:\n\n\\(P(D | \\theta)\\), the probability that you observe data \\(D\\), given the parameter \\(\\theta\\); this is called the likelihood (Note: It is the likelihood of \\(\\theta\\), but probability about \\(y\\))\n\\(P(\\theta)\\), the probability distribution \\(\\theta\\), without referring to the data \\(D\\). This usually requires appeals to one’s degree of belief, and so is called the prior\n\\(P(\\theta | y)\\), the updated probability distribution of \\(\\theta\\), after observing the data \\(D\\); this is called the posterior\n\nOn the other hand, classical/frequentist statistics focuses solely on the likelihood function.1 In Bayesian statistics, the goal is to update one’s belief about \\(\\theta\\) based on the observed data \\(D\\).",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes's Theorem</span>"
    ]
  },
  {
    "objectID": "03-bayes-theorem.html#example-2-locating-a-plane",
    "href": "03-bayes-theorem.html#example-2-locating-a-plane",
    "title": "3  Bayes’s Theorem",
    "section": "3.3 Example 2: Locating a Plane",
    "text": "3.3 Example 2: Locating a Plane\nConsider a highly simplified scenario of locating a missing plane in the sea. Assume that we know the plane, before missing, happened to be flying at the same latitude, heading west across the Pacific, so we only need to find its longitude. We want to go out to collect debris (data) so that we can narrow the location (\\(\\theta\\)) of the plane down.\n\nPriorLikelihoodPosterior\n\n\nWe start with our prior. Assume that we have some rough idea where the plane should be, so we express our belief in a probability distribution like the following:\n\n\n\n\n\n\n\n\nFigure 3.1: Prior distribution.\n\n\n\n\n\nwhich says that our belief is that the plane is about twice more likely to be towards the east than towards the west. Below are two other options for priors (out of infinitely many), one providing virtually no information and the other encoding stronger information:\n\n\n\n\n\n\n\n\n\n\n\n(a) Noninformative prior.\n\n\n\n\n\n\n\n\n\n\n\n(b) Informative prior.\n\n\n\n\n\n\n\nFigure 3.2: More options for prior distribution.\n\n\n\nThe prior is chosen to reflect the researcher’s belief, so different researchers will likely formulate a different prior for the same problem, and that’s okay as long as the prior is reasonable and justified. Later, we will learn that in regular Bayesian analyses, with a moderate sample size, different priors generally only make negligible differences.\n\n\nNow, assume that we have collected debris in the locations shown in the graph,\n\n\n\n\n\n\n\n\nFigure 3.3\n\n\n\n\n\n\n\nNow, from Bayes’s Theorem,\n\\[\n\\text{Posterior Probability} \\propto \\text{Prior Probability} \\times\n                                       \\text{Likelihood}\n\\]\nSo we can simply multiply the prior probabilities and the likelihood to get the posterior probability for every location. A rescaling step is needed to ensure that the area under the curve will be 1, which is usually performed by the software.\n\n\n\n\n\n\n\n\nFigure 3.4\n\n\n\n\n\n\n\n\nAs illustrated below, the posterior distribution is a synthesis of (a) the prior and (b) the data (likelihood).\n\nInfluence of PriorInfluence of More Data\n\n\nFigure 3.5 shows what happen with a stronger prior:\n\n\n\n\n\n\n\n\nFigure 3.5\n\n\n\n\n\n\n\nFigure 3.6 shows what happen with 20 more data points:\n\n\n\n\n\n\n\n\nFigure 3.6",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes's Theorem</span>"
    ]
  },
  {
    "objectID": "03-bayes-theorem.html#data-order-invariance",
    "href": "03-bayes-theorem.html#data-order-invariance",
    "title": "3  Bayes’s Theorem",
    "section": "3.4 Data-Order Invariance",
    "text": "3.4 Data-Order Invariance\nIn many data analysis applications, researchers collect some data \\(D_1\\), and then collect some more data \\(D_2\\). An example would be researchers conducting two separate experiments to study the same research question. In Bayesian statistics, one can consider three ways to obtain the posterior:\n\nUpdate the belief with \\(D_1\\), and then with \\(D_2\\)\nUpdate the belief with \\(D_2\\), and then with \\(D_1\\)\nUpdate the belief with both \\(D_1\\) and \\(D_2\\) simultaneously\n\nWhether these three ways give the same posterior depends on whether data-order invariance holds. If the inference of \\(D_1\\) does not depend on \\(D_2\\), or vice versa, then all three ways lead to the same posterior. Specifically, if we have conditional independence such that \\[\nP(D_1, D_2 \\mid \\theta) = P(D_1 \\mid \\theta) P(D_2 \\mid \\theta),\n\\] then one can show all three ways give the same posterior (see section 4.4 and 4.5 of Johnson et al., 2022).\n\n\n\n\n\n\nExchangeability*\n\n\n\nExchangeability is an important concept in Bayesian statistics. Data are exchangeable when the joint distribution, \\(P(D_1, \\ldots, D_N)\\), does not depend on the ordering of the data. A simple way to think about it is if you scramble the order of your outcome variable in your data set and still can obtain the same statistical results, then the data are exchangeable. An example situation where data are not exchangeable is\n\n\\(D_1\\) is from year 1990, \\(D_2\\) is from year 2020, and the parameter \\(\\theta\\) changes from 1990 to 2020\n\nWhen data are exchangeable, conditional independence would generally hold.2",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes's Theorem</span>"
    ]
  },
  {
    "objectID": "03-bayes-theorem.html#bernoulli-likelihood",
    "href": "03-bayes-theorem.html#bernoulli-likelihood",
    "title": "3  Bayes’s Theorem",
    "section": "3.5 Bernoulli Likelihood",
    "text": "3.5 Bernoulli Likelihood\nFor binary data \\(y\\) (e.g., coin flip, pass/fail, diagnosed/not), an intuitive way to analyze is to use a Bernoulli model: \\[\n  \\begin{aligned}\n    P(y = 1 \\mid \\theta) = \\theta \\\\\n    P(y = 0 \\mid \\theta) = 1 - \\theta\n  \\end{aligned},\n\\] which is more compactly written as \\[\nP(y \\mid \\theta) = \\theta^y (1 - \\theta)^{(1 - y)},\n\\] where \\(\\theta \\in [0, 1]\\) is the probability of a “1”. You can verify that the compact form is the same as the longer form.\n\n3.5.1 Multiple Observations\nWhen there are more than one \\(y\\), say \\(y_1, \\ldots, y_N\\), that are conditionally independent, we have \\[\n  \\begin{aligned}\n    P(y_1, \\ldots, y_N \\mid \\theta) & = \\prod_{i = 1}^N P(y_i \\mid \\theta) \\\\\n    & = \\theta^{\\sum_{i = 1}^N y_i} (1 - \\theta)^{\\sum_{i = 1}^N (1 - y_i)} \\\\\n    & = \\theta^z (1 - \\theta)^{N - z}\n  \\end{aligned},\n\\] where \\(z\\) is the number of “1”s (e.g., the number of heads in coin flips). Note that the likelihood only depends on \\(z\\), not the individual \\(y\\)s. In other words, the likelihood is the same as long as there are \\(z\\) heads, regardless of when those heads occur.\nLet’s say \\(N\\) = 4 and \\(z\\) = 1. We can plot the likelihood in R:\n\n# Write the likelihood as a function of theta\nlik &lt;- function(th, num_flips = 4, num_heads = 1) {\n    th ^ num_heads * (1 - th) ^ (num_flips - num_heads)\n}\n# Likelihood of theta = 0.5\nlik(0.5)\n\n#&gt; [1] 0.0625\n\n# Plot the likelihood\nggplot(data.frame(th = c(0, 1)), aes(x = th)) +\n    # `stat_function` for plotting a function\n    stat_function(fun = lik) +\n    # use `expression()` to get greek letters\n    labs(x = expression(theta),\n    y = \"Likelihood with N = 4 and z = 1\")\n\n\n\n\n\n\n\nFigure 3.7: Binomial likelihood function with \\(N\\) = 4 and \\(z\\) = 1\n\n\n\n\n\n\n\n3.5.2 Setting Priors\nRemember again the relationship between the prior and the posterior: \\[P(\\theta | y) \\propto P(y | \\theta) P(\\theta)\\] The posterior distributions are mathematically determined once the priors and the likelihood are set. However, the mathematical form of the posterior is sometimes very difficult to deal with.\nOne straightforward, brute-force method is to discretize the parameter space into a number of points. For example, by taking \\(\\theta\\) = 0, 0.05, 0.10, . . . , 0.90, 0.95, 1.00, one can evaluate the posterior at these 21 grid points.\nLet’s use a prior that peaks at 0.5 and linearly decreases to both sides. I assume that \\(\\theta\\) = 0.5 is twice as likely as \\(\\theta = 0.25\\) or \\(\\theta = 0.75\\) to reflect my belief that the coin is more likely to be fair.\n\n# Define a grid for the parameter\ngrid_df &lt;- data.frame(th = seq(0, 1, by = 0.05))\n# Set the prior mass for each value on the grid\ngrid_df$pth &lt;- c(0:10, 9:0)  # linearly increasing, then decreasing\n# Convert pth to a proper distribution such that the value\n# sum to one\n1grid_df$pth &lt;- grid_df$pth / sum(grid_df$pth)\n# Plot the prior\nggplot(grid_df, aes(x = th, y = pth)) +\n    geom_col(aes(x = th, y = pth),\n        width = 0.01,\n    ) +\n    labs(y = expression(P(theta)), x = expression(theta))\n\n\n1\n\nThis line ensures that the probability values sum to one. This is a trick we will use to obtain the posterior probability.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrior Predictive Distribution\n\n\n\nOne way to check whether the prior is appropriate is to use the prior predictive distribution. Bayesian models are generative because they can be used to simulate data. The prior predictive distribution can be obtained by first simulating some \\(\\theta\\) values from the prior distribution and then simulating a data set for each \\(\\theta\\).\n\n# Draw one theta\nnum_trials &lt;- 4  # number of draws\nsim_th1 &lt;- sample(grid_df$th, size = 1,\n                  # based on prior probability\n                  prob = grid_df$pth)\n# Simulate new data of four flips based on model\nsim_y1 &lt;- rbinom(num_trials, size = 1, prob = sim_th1)\n\n# Repeat many times\n# Set number of simulation draws\nnum_draws &lt;- 1000\nsim_th &lt;- sample(grid_df$th, size = num_draws, replace = TRUE,\n                 # based on prior probability\n                 prob = grid_df$pth)\n# Use a for loop\n# Initialize output\nsim_y &lt;- matrix(NA, nrow = num_trials, ncol = num_draws)\nfor (s in seq_len(num_draws)) {\n    # Store simulated data in the sth column\n    sim_y[, s] &lt;- rbinom(num_trials, size = 1, prob = sim_th[s])\n}\n# Show the first 10 simulated data sets based on prior:\nsim_y[, 1:10]\n\n#&gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n#&gt; [1,]    1    0    0    1    0    1    0    0    0     1\n#&gt; [2,]    0    0    0    1    1    0    1    0    1     1\n#&gt; [3,]    1    0    0    1    0    0    0    1    1     1\n#&gt; [4,]    1    0    1    1    1    0    0    1    1     0\n\n# Show the distribution of number of heads\nsim_heads &lt;- colSums(sim_y)\nggplot(data.frame(z = sim_heads), aes(x = z)) +\n    geom_bar()\n\n\n\n\n\n\n\n\nThe outcome seems to fit our intuition that it’s more likely to be half heads and half tails, but there is a lot of uncertainty.\n\n\n\n\n3.5.3 Summarizing the Posterior\n\ngrid_df &lt;- grid_df |&gt;\n    mutate(\n        # Use our previously defined lik() function\n        py_th = lik(th, num_flips = 4, num_heads = 1),\n        # Product of prior and likelihood\n        `prior x lik` = pth * py_th,\n        # Scaled the posterior\n        pth_y = `prior x lik` / sum(`prior x lik`)\n    )\n# Print a table\nknitr::kable(grid_df)\n\n\n\n\nth\npth\npy_th\nprior x lik\npth_y\n\n\n\n\n0.00\n0.00\n0.0000000\n0.0000000\n0.0000000\n\n\n0.05\n0.01\n0.0428687\n0.0004287\n0.0073359\n\n\n0.10\n0.02\n0.0729000\n0.0014580\n0.0249500\n\n\n0.15\n0.03\n0.0921188\n0.0027636\n0.0472914\n\n\n0.20\n0.04\n0.1024000\n0.0040960\n0.0700927\n\n\n0.25\n0.05\n0.1054688\n0.0052734\n0.0902416\n\n\n0.30\n0.06\n0.1029000\n0.0061740\n0.1056525\n\n\n0.35\n0.07\n0.0961187\n0.0067283\n0.1151381\n\n\n0.40\n0.08\n0.0864000\n0.0069120\n0.1182815\n\n\n0.45\n0.09\n0.0748688\n0.0067382\n0.1153071\n\n\n0.50\n0.10\n0.0625000\n0.0062500\n0.1069530\n\n\n0.55\n0.09\n0.0501187\n0.0045107\n0.0771891\n\n\n0.60\n0.08\n0.0384000\n0.0030720\n0.0525695\n\n\n0.65\n0.07\n0.0278687\n0.0019508\n0.0333832\n\n\n0.70\n0.06\n0.0189000\n0.0011340\n0.0194056\n\n\n0.75\n0.05\n0.0117188\n0.0005859\n0.0100268\n\n\n0.80\n0.04\n0.0064000\n0.0002560\n0.0043808\n\n\n0.85\n0.03\n0.0028687\n0.0000861\n0.0014727\n\n\n0.90\n0.02\n0.0009000\n0.0000180\n0.0003080\n\n\n0.95\n0.01\n0.0001187\n0.0000012\n0.0000203\n\n\n1.00\n0.00\n0.0000000\n0.0000000\n0.0000000\n\n\n\n\n\n\n# Plot the prior/likelihood and the posterior\nggplot(data = grid_df, aes(x = th)) +\n    geom_col(aes(x = th - 0.005, y = pth, fill = \"prior\"),\n        width = 0.01,\n    ) +\n    geom_col(aes(x = th + 0.005, y = py_th / sum(py_th),\n        fill = \"scaled likelihood\"), width = 0.01,\n    ) +\n    labs(fill = NULL, y = NULL, x = expression(theta)) +\n    theme(legend.position = \"top\")\nggplot(data = grid_df, aes(x = th)) +\n    geom_col(aes(x = th, y = pth_y), width = 0.01) +\n    labs(\n        fill = NULL, y = NULL, title = \"Posterior\",\n        x = expression(theta)\n    )\n\n\n\n\n\n\n\n\n\n\n\n(a) Prior and likelihood\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Posterior\n\n\n\n\n\n\n\nFigure 3.8: Bernoulli posterior distribution\n\n\n\n\nFigure 3.8 (b) shows the posterior distribution, which represents our updated belief about \\(\\theta\\). We can summarize it by simulating \\(\\theta\\) values from it and compute summary statistics:\n\n# Define a function for computing posterior summary\nsumm_draw &lt;- function(x) {\n    c(\n        mean = mean(x),\n        median = median(x),\n        sd = sd(x),\n        mad = mad(x),\n        `ci.1` = quantile(x, prob = .1, names = FALSE),\n        `ci.9` = quantile(x, prob = .9, names = FALSE)\n    )\n}\n# Sample from the posterior\npost_samples &lt;- sample(\n    grid_df$th,\n    size = 1000, replace = TRUE,\n    prob = grid_df$pth_y\n)\nsumm_draw(post_samples)\n\n#&gt;      mean    median        sd       mad      ci.1      ci.9 \n#&gt; 0.3848000 0.4000000 0.1538429 0.1482600 0.2000000 0.6000000\n\n# Alternatively, use the `posterior` package\ndata.frame(theta = post_samples) |&gt;\n    posterior::summarize_draws()\n\n\n  \n\n\n\n\nInfluence of Sample SizeInfluence of Prior\n\n\nIf, instead, we have \\(N\\) = 40 and \\(z\\) = 10, the posterior will be more similar to the likelihood.\n\ngrid_df2 &lt;- grid_df |&gt;\n    mutate(\n        # Use our previously defined lik() function\n        py_th = lik(th, num_flips = 40, num_heads = 10),\n        # Product of prior and likelihood\n        `prior x lik` = pth * py_th,\n        # Scaled the posterior\n        pth_y = `prior x lik` / sum(`prior x lik`)\n    )\n# Plot the prior/likelihood and the posterior\nggplot(data = grid_df2, aes(x = th)) +\n    geom_col(aes(x = th - 0.005, y = pth, fill = \"prior\"),\n        width = 0.01,\n    ) +\n    geom_col(aes(x = th + 0.005, y = py_th / sum(py_th),\n        fill = \"scaled likelihood\"), width = 0.01,\n    ) +\n    labs(fill = NULL, y = NULL, x = expression(theta)) +\n    theme(legend.position = \"top\")\n\n\n\n\n\n\n\nggplot(data = grid_df2, aes(x = th)) +\n    geom_col(aes(x = th, y = pth_y), width = 0.01) +\n    labs(\n        fill = NULL, y = NULL, title = \"Posterior\",\n        x = expression(theta)\n    )\n\n\n\n\n\n\n\n\n\n# Sample from the posterior\npost_samples &lt;- sample(\n    grid_df2$th,\n    size = 1000, replace = TRUE,\n    prob = grid_df2$pth_y\n)\nsumm_draw(post_samples)\n\n#&gt;       mean     median         sd        mad       ci.1       ci.9 \n#&gt; 0.28085000 0.30000000 0.06542215 0.07413000 0.20000000 0.35000000\n\n\n\n\nIf we have a very strong prior concentrated at \\(\\theta\\) = .5, but still with \\(N\\) = 40 and \\(z\\) = 10, the posterior will be more similar to the prior.\n\ngrid_df3 &lt;- grid_df |&gt;\n    mutate(\n        # stronger prior\n        pth = pth ^ 3,\n        # scale the prior to sume to 1\n        pth = pth / sum(pth),\n        # Use our previously defined lik() function\n        py_th = lik(th, num_flips = 4, num_heads = 1),\n        # Product of prior and likelihood\n        `prior x lik` = pth * py_th,\n        # Scaled the posterior\n        pth_y = `prior x lik` / sum(`prior x lik`)\n    )\n# Plot the prior/likelihood and the posterior\nggplot(data = grid_df3, aes(x = th)) +\n    geom_col(aes(x = th - 0.005, y = pth, fill = \"prior\"),\n        width = 0.01,\n    ) +\n    geom_col(aes(x = th + 0.005, y = py_th / sum(py_th),\n        fill = \"scaled likelihood\"), width = 0.01,\n    ) +\n    labs(fill = NULL, y = NULL, x = expression(theta)) +\n    theme(legend.position = \"top\")\n\n\n\n\n\n\n\nggplot(data = grid_df3, aes(x = th)) +\n    geom_col(aes(x = th, y = pth_y), width = 0.01) +\n    labs(\n        fill = NULL, y = NULL, title = \"Posterior\",\n        x = expression(theta)\n    )\n\n\n\n\n\n\n\n\n\n# Sample from the posterior\npost_samples &lt;- sample(\n    grid_df3$th,\n    size = 1000, replace = TRUE,\n    prob = grid_df3$pth_y\n)\nsumm_draw(post_samples)\n\n#&gt;      mean    median        sd       mad      ci.1      ci.9 \n#&gt; 0.4493000 0.4500000 0.1096656 0.0741300 0.3000000 0.6000000\n\n# Alternatively, use the `posterior` package\ndata.frame(theta = post_samples) |&gt;\n    posterior::summarize_draws()\n\n\n  \n\n\n\n\n\n\n\n\n3.5.4 Remark on Grid Approximation\nIn this note, we discretized \\(\\theta\\) into a finite number of grid points to compute the posterior, mainly for pedagogical purposes. A big limitation is that our posterior will have no density for values other than the chosen grid points. While increasing the number of grid points (e.g., 1,000) can give more precision, the result is still not truly continuous. A bigger issue is that the computation breaks down when there is more than one parameter; if there are \\(p\\) parameters, with 1,000 grid points per parameter, one needs to evaluate the posterior probability for \\(1,000^p\\) grid points, which is not feasible even with modern computers. So more efficient algorithms, namely Markov chain Monte Carlo (MCMC) methods, will be introduced as we progress in the course.\n\n\n\n\n\n\nJohnson, A. A., Ott, M. Q., & Dogucu, M. (2022). Bayes rules! An introduction to Bayesian modeling with R. CRC Press.",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes's Theorem</span>"
    ]
  },
  {
    "objectID": "03-bayes-theorem.html#footnotes",
    "href": "03-bayes-theorem.html#footnotes",
    "title": "3  Bayes’s Theorem",
    "section": "",
    "text": "The likelihood function in classical/frequentist statistics is usually written as \\(P(y; \\theta)\\). You will notice that here, I write the likelihood for classical/frequentist statistics to be different from the one used in Bayesian statistics. This is intentional: In frequentist conceptualization, \\(\\theta\\) is fixed, and it does not make sense to talk about the probability of \\(\\theta\\). This implies that we cannot condition on \\(\\theta\\), because conditional probability is defined only when \\(P(\\theta)\\) is defined.↩︎\nThe de Finetti’s theorem shows that when the data are exchangeable and can be considered an infinite sequence (i.e., not from a tiny finite population), then the data are conditionally independent given some \\(\\theta\\).↩︎",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes's Theorem</span>"
    ]
  },
  {
    "objectID": "04-beta-bernoulli-model.html",
    "href": "04-beta-bernoulli-model.html",
    "title": "\n4  Beta-Bernoulli Model\n",
    "section": "",
    "text": "4.1 Steps of Bayesian Data Analysis\nSome authors described the process as “turning the Bayesian Crank,” as the same workflow applies to a variety of research scenarios.\nAdapted from Gelman et al. (2020), I conceptualize Bayesian data analysis as the following steps:",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Beta-Bernoulli Model</span>"
    ]
  },
  {
    "objectID": "04-beta-bernoulli-model.html#steps-of-bayesian-data-analysis",
    "href": "04-beta-bernoulli-model.html#steps-of-bayesian-data-analysis",
    "title": "\n4  Beta-Bernoulli Model\n",
    "section": "",
    "text": "Identify/Collect the data required to answer the research questions.\n\nAs a general recommendation, it is helpful to visualize the data to get a sense of how they look, as well as to inspect for potential anomalies in the data collection.\n\n\n\nChoose an initial statistical model for the data in relation to the research questions. The model should have some theoretical justification and have parameters that are meaningful for the research questions. However, it is unlikely that any chosen model will capture everything important in the data, and this initial model will be modified and expanded in later steps.\n\nSpecify prior distributions for the model parameters. Although this is a subjective endeavor, the priors chosen should be sensible to a skeptical audience.\n\nCheck the prior distributions. It is recommended you conduct a prior predictive check, by simulating fake data based on the chosen model and prior distributions. This is especially important for complex models as the parameters are more difficult to interpret.\n\nObtain the posterior distributions for the model parameters. As described below and later in the course, this can be obtained by analytical or various mathematical approximations.\n\nFor mathematical approximations, one should check the algorithms for convergence to make sure the results closely mimic the target posterior distributions.\n\n\nConduct a posterior predictive check to examine the fit between the model and the data, i.e., whether the chosen model with the estimated parameters generates predictions that deviate from the data being analyzed on important features.\nIt is unlikely that your initial model fully describes the major aspects of the data as pertaining to your research questions. Therefore, one should repeat steps 2 to 6 to specify and compare different models.\nIf the fit between the model and the data is deemed satisfactory, one can proceed to interpret the results in the context of the research questions. It is also important to visualize the results in ways that are meaningful for the analysis.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Beta-Bernoulli Model</span>"
    ]
  },
  {
    "objectID": "04-beta-bernoulli-model.html#beta-bernoulli-example",
    "href": "04-beta-bernoulli-model.html#beta-bernoulli-example",
    "title": "\n4  Beta-Bernoulli Model\n",
    "section": "\n4.2 Beta-Bernoulli Example",
    "text": "4.2 Beta-Bernoulli Example\nWe will be using a built-in data set in R about patients diagnosed with AIDS in Australia before July 1, 1991. Here is a description of the variables (from the R documentation):\n\n\nFigure from https://commons.wikimedia.org/wiki/File:Australia_states_1931-present.png\n\n\n\nstate: Grouped state of origin: “NSW”includes ACT and “other” is WA, SA, NT, and TAS.\n\nsex: Sex of patient.\n\ndiag:(Julian) date of diagnosis.\n\ndeath: (Julian) date of death or end of observation.\n\nstatus: “A” (alive) or “D” (dead) at end of observation.\n\nT.categ: Reported transmission category.\n\nage: Age (years) at diagnosis.\n\nYou should always first plot your data and get some summary statistics:\n\ndata(\"Aids2\", package = \"MASS\")\nhead(Aids2)\n\n\n  \n\n\n\n\npairs.panels(Aids2, ellipses = FALSE)\n\n\n\n\n\n\n\nWe will be using the status variable. Our simple research question is:\n\nWhat was the death rate of AIDS in Australia when the data were collected?\n\n\n4.2.1 Bernoulli Model\nIf we assume that the outcomes of the observations are exchangeable, meaning that the observations can be reordered in any way and still give the same inference, then one can choose a model: \\[\ny_i \\sim \\text{Bern}(\\theta) \\text{ for }i = 1, 2, \\ldots, N\n\\]\n\n\n\\(y_i\\) = status of observation \\(i\\) (0 = “A”, 1 = “D”)\n\n\\(N\\) = number of patients in the data set\n\n\\(\\theta\\) = probability of “D”1\n\n\n\nThe model states that: the sample data \\(y\\) follows a Bernoulli distribution with \\(n\\) with a parameter \\(\\theta\\)\n\n\n\n\n\n\n\nWhen the data consist of binary observations, the variable is called a Bernoulli variable. It is conventional to denote one outcome as success and code it as 1, and the other as failure and code it as 0 (poor terminology, maybe, but that’s by convention). Therefore, in the AIDS example, each observation is considered a “Bernoulli” outcome (Alive vs. Dead).\n\n\n\n\n4.2.2 Exchangeability\nTo illustrate exchangeability in an example, say we take 6 rows in our data set:\n\n\n\n  \n\n\n\nNow, when we reorder the column status to something like:\n\n\n\n  \n\n\n\nIf the results are expected to be the same, then we say that the observations are assumed exchangeable. It happens when we assume that all observations have one common mean. However, if we think that there is a mean for females and a different mean for males, we cannot reorder the outcome randomly because they are no longer exchangeable (i.e., you cannot exchange a female score for a male score and expect to get the same results).\n\n\n\n\n\n\nExchangeability\n\n\n\nA set of observations is said to be exchangeable if their joint probability distribution stays the same under all permutations. Roughly speaking, it means that the observations can be reordered and still provide the same inferences.\n\n\n\n4.2.3 Check the Support\nIt is important to identify the support of the parameter, \\(\\theta\\). Because \\(\\theta\\) is a probability, its support is \\([0, 1]\\), meaning it is continuous and can take any value from 0 to 1. For a continuous parameter, there are infinitely many possible values, and it is impossible to specify our beliefs for each value. So, more commonly, we choose a probability density function with the same support as the parameter to express our prior belief.\n\n4.2.4 Conjugate Prior: Beta Distribution\nA commonly used family of prior distributions for a Bernoulli/binomial model is the Beta distribution, which has two parameters. We can write the prior as \\[P(\\theta) \\sim \\text{Beta}(a, b)\\]\n\\(a\\) and \\(b\\) are the two hyperparameters. Here are a few examples:\n\n\n\n\n\n\n\nFigure 4.1: Beta distributions with different a and b values\n\n\n\n\nYou will notice that when \\(a &gt; b\\), there is more density closer to the right region (i.e., larger \\(\\theta\\)), and vice versa. Also, the variance decreases when \\(a\\) and \\(b\\) become larger.2\nA nice interpretation of \\(a\\) and \\(b\\) in a Beta prior distribution is to consider\n\n\n\\(a - 1\\) = number of prior ‘successes’ (e.g., “D”)\n\n\\(b - 1\\) = number of prior ‘failures’ (e.g., “A”)\n\nTherefore, with \\(\\text{Beta}(1, 1)\\), one has seen 0 prior success and 0 failure, meaning that there is no prior information (i.e., noninformative). Therefore, it makes sense that all \\(\\theta\\) values are equally likely. On the other hand, if one chooses \\(\\text{Beta}(10, 20)\\), one has seen 9 prior successes and 19 prior failures, so one has quite a lot of prior information (indeed more than the data with only 10 observations), so this is a strong prior.\n\nThe smaller the variance of the prior distribution, the stronger one’s belief before looking at the data, the more prior information\n\nSo by manipulating the values of \\(a\\) and \\(b\\), which are sometimes called hyperparameters, you can control the shape of the prior distribution as well as its strength, so it is quite flexible. Another advantage of using a beta prior is that it is a conjugate prior of the Bernoulli model, which means that the posterior distribution \\(P(\\theta \\mid y)\\) is also a beta distribution, the same as the prior distribution, although with different parameter values.\n\n\n\n\n\n\nConjugate Prior\n\n\n\nFor a specific model, conjugate priors yield posterior distributions in the same distribution family as the priors\n\n\nConjugacy greatly simplifies the computational burden for Bayesian analyses, so conjugate priors are almost the only ones used in earlier literature. However, this limited the applications of Bayesian methods, as for many problems, no conjugate priors can provide a realistic representation of one’s belief. Modern Bayesian analysis instead relies on simulation-based methods to approximate the posterior distribution, which can accommodate almost any kind of prior distribution. Aside from a few examples in this note, mainly for pedagogical purposes, we will be using simulation-based methods in the coming weeks.\n\n\n\n\n\n\nProof of Conjugacy*\n\n\n\nTo derive the form of the posterior, first recognize that the Beta distribution has the form:\n\\[\n\\begin{aligned}\n  P(\\theta) & = \\mathrm{B}^{-1}(a, b) \\theta^{a - 1} (1 - \\theta)^{b - 1} \\\\\n  & \\propto \\theta^{a - 1} (1 - \\theta)^{b - 1}\n\\end{aligned}\n\\]\nWhere \\(\\mathrm{B}(\\cdot)\\) is the beta function which is not very important for the class. As the density function is a function of \\(\\theta\\), it suffices to write only the terms that involve \\(\\theta\\).\nSimilarly, \\[\nP(\\mathbf{y} \\mid \\theta) \\propto \\theta^z (1 - \\theta)^{N - z}.\n\\]\nTherefore,\n\\[\n\\begin{aligned}\n  P(\\theta \\mid \\mathbf{y}) & \\propto P(y \\mid \\theta) P(\\theta)  \\\\\n                & \\propto \\theta^z (1 - \\theta)^{N - z}\n                          \\theta^{a - 1} (1 - \\theta)^{b - 1}  \\\\\n                & = \\theta^{a + z - 1} (1 - \\theta)^{b + N - z - 1}.\n\\end{aligned}\n\\]\nIf we let \\(a^* = a + z\\), \\(b^* = b + N - z\\), we can see that \\(P(\\theta \\mid \\mathbf{y})\\) is in the same form as the prior with \\(a\\) and \\(b\\) replaced by \\(a^*\\) and \\(b^*\\). Therefore, the posterior is also a beta distribution. So the beta distribution is a conjugate prior for the Bernoulli model.\n\n\nIn this example, we will choose a weakly informative Beta(2, 2) prior, which represents a weak belief as below:\n\nggplot(data.frame(th = c(0, 1)), aes(x = th)) +\n    stat_function(fun = dbeta, args = list(shape1 = 2, shape2 = 2)) +\n    ylim(0, 3) +\n    labs(y = \"\", x = expression(theta), title = \"Beta(2, 2)\")\n\n\n\n\n\n\nFigure 4.2: A weakly informative Beta(2, 2) prior\n\n\n\n\n\n\n\n\n\n\nDon’t Be Stubborn\n\n\n\n\nA good prior should give a non-zero probability/density for all possible values of a parameter\n\nOtherwise, if the prior density for some parameter values is zero, the posterior density will be zero, regardless of how much the data support those parameter values\n\n\n\n4.2.5 Data\n\ncount(Aids2, status)\n\n\n  \n\n\n\nThe likelihood function is highly concentrated. I ran into some numerical issues as the computation gave zero, so I plotted the log-likelihood instead.\n\nloglik &lt;- function(th, N = 1082 + 1761, z = 1761) {\n    z * log(th) + (N - z) * log(1 - th)\n}\nggplot(data.frame(th = c(0.61, 0.63)), aes(x = th)) +\n    stat_function(fun = loglik, n = 501) +\n    labs(x = expression(theta), y = \"Log-likelihood\")\n\n\n\n\n\n\nFigure 4.3: Log-likelihood function of the theta parameter\n\n\n\n\nNote I only show a range of [0.610, 0.630] for the x-axis, which contains where the likelihood (thus also the log-likelihood) peaked.\n\n4.2.6 Posterior\nBased on the conjugacy, the posterior of \\(\\theta\\) is Beta(1,807, 1,116). As we are using a conjugate prior, the posterior is also a Beta distribution: \\[\nP(\\theta \\mid y) \\sim \\text{Beta}(a + z, b + N - z),\n\\] which is a distribution for \\(a + z - 1\\) successes and \\(b + N - z\\) failures. This makes perfect sense as our prior information has \\(a - 1\\) successes and \\(b - 1\\) failures, and from our data, we have \\(y\\) successes and \\(n - y\\) failures, so our updated belief is based on adding up those successes and failures.\n\n4.2.7 Summarize the posterior\n\nset.seed(2119)\nnum_draws &lt;- 1000\nsim_theta &lt;- rbeta(num_draws, shape1 = 1807, shape2 = 1116)\nc(`Bayes estimate` = mean(sim_theta),\n  `Posterior median` = median(sim_theta),\n  `Posterior SD` = sd(sim_theta),\n  `MAD` = mad(sim_theta),\n  `90% Credible interval (equal-tailed)` = quantile(sim_theta, probs = c(.1, .9)),\n  `90% HDI` = HDInterval::hdi(sim_theta, credMass = .9))\n\n                          Bayes estimate \n                             0.618209694 \n                        Posterior median \n                             0.618382945 \n                            Posterior SD \n                             0.008829290 \n                                     MAD \n                             0.009254166 \n90% Credible interval (equal-tailed).10% \n                             0.606862338 \n90% Credible interval (equal-tailed).90% \n                             0.628990588 \n                           90% HDI.lower \n                             0.604051851 \n                           90% HDI.upper \n                             0.632766654 \n\n\n\n4.2.8 Posterior Predictive Check\nNow, we need to know whether the model fits the data well. We do not have much to check for a Bernoulli model if we only have the status variable. However, as there is information for other variables, we can use them to check the exchangeability assumption. For example, we can ask whether the data from different state categories are exchangeable. The death rate across the 4 state categories are\n\n\n       status\nstate      A    D\n  NSW    664 1116\n  Other  107  142\n  QLD     78  148\n  VIC    233  355\n\n\n       status\nstate           A         D\n  NSW   0.3730337 0.6269663\n  Other 0.4297189 0.5702811\n  QLD   0.3451327 0.6548673\n  VIC   0.3962585 0.6037415\n\n\nWe can now generate predictions from our posterior distribution and model.\n\nplist &lt;- vector(\"list\", 12L)\nplist[[1]] &lt;- ggplot(\n    Aids2,\n    aes(x = state, y = mean(status == \"D\"), fill = state)\n) +\n    geom_bar(stat = \"identity\") +\n    guides(fill = \"none\") +\n    labs(x = \"Observed data\", y = \"Number of Deaths\") +\n    theme(axis.title.x = element_text(color = \"red\")) +\n    ylim(0, 1200)\nfor (i in 1:11) {\n    # Get the a value from posterior samples\n    theta_post &lt;- rbeta(1, 1763, 1084)\n    # For each plausible theta value, generate a status variable\n    status_new &lt;- sample(c(\"D\", \"A\"), nrow(Aids2),\n        replace = TRUE,\n        prob = c(theta_post, 1 - theta_post)\n    )\n    df_new &lt;- Aids2 |&gt;\n        mutate(status = factor(status_new))\n    plist[[i + 1]] &lt;- plist[[1]] %+% df_new +\n        labs(x = paste(\"Simulated data\", i)) +\n        theme(axis.title.x = element_text(color = \"black\"))\n}\ngridExtra::grid.arrange(grobs = plist, nrow = 3)\n\n\n\n\n\n\nFigure 4.4: Posterior predictive check by comparing the observed data with 11 simulated data sets based on the model\n\n\n\n\nSo the observed data (the first subplot) look similar to the simulated data. We can also conduct a posterior predictive check by a test statistic for subgroups. Here, we will use the bayesplot package and look at fit across groups:\n\n# Draw posterior samples of theta\npost_sample &lt;- rbeta(1e4, 1807, 1116)\n# Initialize a S by N matrix to store the simulated data\ny_tilde &lt;- matrix(NA,\n                  nrow = length(post_sample),\n                  ncol = length(Aids2$status))\nfor (s in seq_along(post_sample)) {\n    theta_s &lt;- post_sample[s]\n    status_new &lt;- sample(c(\"D\", \"A\"), nrow(Aids2),\n        replace = TRUE,\n        prob = c(theta_s, 1 - theta_s)\n    )\n    y_tilde[s,] &lt;- as.numeric(status_new == \"D\")\n}\nbayesplot::ppc_stat_grouped(\n    as.numeric(Aids2$status == \"D\"),\n    yrep = y_tilde,\n    group = Aids2$state\n)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nFigure 4.5: Posterior predictive check by states\n\n\n\n\nIf the fit is good, the mean, indicated by the darker line, should be within the simulated distribution based on the model. So the model that assumes observations are exchangeable across states is not too off, although it seems fitting less well for Other states.\n\n4.2.8.1 Another check on age\n\n\n# Create an age group indicator\nage50 &lt;- factor(Aids2$age &gt; 50, labels = c(\"&lt;= 50\", \"&gt; 50\"))\n# Draw posterior samples of theta\npost_sample &lt;- rbeta(1e4, 1807, 1116)\n# Initialize a S by N matrix to store the simulated data\ny_tilde &lt;- matrix(NA,\n                  nrow = length(post_sample),\n                  ncol = length(Aids2$status))\nfor (s in seq_along(post_sample)) {\n    theta_s &lt;- post_sample[s]\n    status_new &lt;- sample(c(\"D\", \"A\"), nrow(Aids2),\n        replace = TRUE,\n        prob = c(theta_s, 1 - theta_s)\n    )\n    y_tilde[s,] &lt;- as.numeric(status_new == \"D\")\n}\nbayesplot::ppc_stat_grouped(\n    as.numeric(Aids2$status == \"D\"),\n    yrep = y_tilde,\n    group = age50\n)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nFigure 4.6: Posterior predictive check by age groups (&lt;= 50 vs. &gt; 50)\n\n\n\n\nAs can be seen, the model seems off for those aged 50+.\n\n4.2.9 Comparison to frequentist results\nUsing maximum likelihood, the estimated death rate would be \\(\\hat \\theta = 1761 / 2843 = 0.62\\), with a standard error (SE) of \\(\\sqrt{0.62 (1 - 0.62) / n} = 0.0091\\), with a 90% confidence interval of \\([0.6, 0.63]\\), which is similar to the interval with Bayesian inference.\n\n4.2.10 Sensitivity to different priors\n\n\n\n\n\n\n\nFigure 4.7: Sensitivity of posterior to different priors\n\n\n\n\nYou can see one needs (a) a very strong prior (equivalent to 600 data points) and (b) the prior and the data not agreeing to get a substantially different conclusion.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Beta-Bernoulli Model</span>"
    ]
  },
  {
    "objectID": "04-beta-bernoulli-model.html#footnotes",
    "href": "04-beta-bernoulli-model.html#footnotes",
    "title": "\n4  Beta-Bernoulli Model\n",
    "section": "",
    "text": "An additional thing to note for the Bernoulli/binomial model is that, instead of setting the prior on \\(\\theta\\), sometimes we are more interested in setting the prior for a transformed parameter that has values between \\(-\\infty\\) and \\(\\infty\\), such as one on the logit scale (as related to logistic regression).↩︎\nThe \\(\\mathrm{Beta}(1 / 2, 1 / 2)\\) distribution is called a Jeffreys prior (https://en.wikipedia.org/wiki/Jeffreys_prior), which is derived according to some statistical principles for different models. One big advantage of a Jeffreys prior is that it is invariant, meaning that the prior will stay the same even under reparameterization. However, like conjugate priors, Jeffreys prior limits the choice of prior even when true prior information is available.↩︎",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Beta-Bernoulli Model</span>"
    ]
  },
  {
    "objectID": "04b-beta-bernoulli-stan.html",
    "href": "04b-beta-bernoulli-stan.html",
    "title": "\n5  Beta-Bernoulli Model With Stan\n",
    "section": "",
    "text": "5.1 Installing Stan",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Beta-Bernoulli Model With Stan</span>"
    ]
  },
  {
    "objectID": "04b-beta-bernoulli-stan.html#installing-stan",
    "href": "04b-beta-bernoulli-stan.html#installing-stan",
    "title": "\n5  Beta-Bernoulli Model With Stan\n",
    "section": "",
    "text": "Follow the steps in https://mc-stan.org/cmdstanr/ to install the cmdstanr package.\nLoad the cmdstanr package, and run install_cmdstan()\n\n\n\nlibrary(cmdstanr)\ninstall_cmdstan()\n\n\nIf you run into an error in the previous step related to C++ toolchain, follow the directions here: https://mc-stan.org/cmdstanr/articles/cmdstanr.html",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Beta-Bernoulli Model With Stan</span>"
    ]
  },
  {
    "objectID": "04b-beta-bernoulli-stan.html#fitting-a-beta-bernoulli-model-in-stan",
    "href": "04b-beta-bernoulli-stan.html#fitting-a-beta-bernoulli-model-in-stan",
    "title": "\n5  Beta-Bernoulli Model With Stan\n",
    "section": "\n5.2 Fitting a Beta-Bernoulli Model in Stan",
    "text": "5.2 Fitting a Beta-Bernoulli Model in Stan\n\n5.2.1 Data Import\nFrom last class:\n\ndata(\"Aids2\", package = \"MASS\")\nhead(Aids2)\n\n\n  \n\n\n\n\n5.2.2 Writing Stan syntax\nStan has its own syntax and is different from R. For example, we want to fit the following Beta-Bernoulli model:\n\\[\n\\begin{aligned}\n  y_i & \\sim \\text{Bern}(\\theta) \\text{ for }i = 1, 2, \\ldots, N \\\\\n  P(\\theta) & \\sim \\text{Beta}(2, 2)\n\\end{aligned}\n\\]\nand the model can be written in Stan as follows:\n\ndata {\n  int&lt;lower=0&gt; N;  // number of observations\n  array[N] int&lt;lower=0,upper=1&gt; y;  // y\n}\nparameters {\n  real&lt;lower=0,upper=1&gt; theta;  // theta parameter\n}\nmodel {\n  theta ~ beta(2,2);  // prior: Beta(2, 2)\n  y ~ bernoulli(theta);  // model: Bernoulli\n}\n\n\n\n\n\n\n\nSave the above model syntax in a separate file ending in .stan. For example, I saved the syntax in the file beta-bernoulli.stan in a folder named stan_code.\n\n\n\nIn Stan, anything after // denotes comments (like # in R) and will be ignored by the program. In each block (e.g., data {}), a statement should end with a semicolon (;). There are several blocks in the above Stan code:\n\n\ndata: The data input for Stan is usually not only an R data frame, but a list that includes other information, such as sample size, number of predictors, and prior scales. Each type of data has an input type, such as\n\nint = integer,\nreal = numbers with decimal places,\nmatrix = 2-dimensional data of real numbers,\nvector = 1-dimensional data of real numbers, and\narray = 1- to many-dimensional data. For example, we use array[N] for the data type of y, because it is a vector, but each element is an integer (and cannot take decimals).\n\nWe can set the lower and upper bounds so that Stan can check the input data. In the above, we used &lt;lower=0,upper=1&gt;.\n\nparameters: The parameters to be estimated\ntransformed parameters: optional variables that are transformations of the model parameters. It is usually used for more advanced models to allow more efficient MCMC sampling.\nmodel: It includes expressions of prior distributions for each parameter and the likelihood for the data. There are many possible distributions that can be used in Stan.\ngenerated quantities: Any quantities that are not part of the model but can be computed from the parameters for every iteration. Examples include posterior generated samples, effect sizes, and log-likelihood (for fit computation). We will see an example later.\n\n5.2.3 Compiling the Stan model from R\nTo compile the model, we can call the cmdstan_model function in cmdstanr:\n\nbern_mod &lt;- cmdstan_model(\"stan_code/beta-bernoulli.stan\")\n\n\n5.2.4 Posterior Sampling\nWe need to first prepare the data for input to Stan. In the Stan code, we have two objects in the data block: N and y, so we need to have a list of two elements in R:\n\nAids2_standata &lt;- list(\n    N = nrow(Aids2),\n    y = as.integer(Aids2$status == \"D\")  # integer\n)\n\nNow we can draw posterior samples:\n\nfit &lt;- bern_mod$sample(Aids2_standata)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.6 seconds.\n\n\nFor this simple model, this takes less than a second.\n\n5.2.5 Summarizing and plotting the posterior samples\n\n# Actual posterior samples\nfit$draws(\"theta\", format = \"draws_df\")\n\n\n  \n\n\n\n\n# Summary table\nfit$summary()\n\n\n  \n\n\n\n\n# Histogram\nfit$draws(\"theta\") |&gt;\n    mcmc_hist()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nFigure 5.1: Posterior distribution of the parameter.\n\n\n\n\nThe results are similar to those in last class.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Beta-Bernoulli Model With Stan</span>"
    ]
  },
  {
    "objectID": "04b-beta-bernoulli-stan.html#prior-predictive-check",
    "href": "04b-beta-bernoulli-stan.html#prior-predictive-check",
    "title": "\n5  Beta-Bernoulli Model With Stan\n",
    "section": "\n5.3 Prior Predictive Check",
    "text": "5.3 Prior Predictive Check\nIn Bayesian analyses, it is recommended to check both the prior and the model. This can be done by\n\nPrior predictive check: Simulating data from the prior distribution, and see if the simulated data fit our prior belief.\nPosterior predictive check: Simulating data from the posterior distribution, and see if the simulated data are comparable to the observed data.\n\nWe will use the following Stan code to do prior and posterior predictive checks, which has an additional generated quantity block to obtain\n\n\nprior_theta: simulated values of \\(\\theta\\) based on the prior distribution\n\nprior_ytilde: simulated data based on the prior distribution of \\(\\theta\\)\n\n\nytilde: simulated data based on the posterior distribution of \\(\\theta\\)\n\n\n\ndata {\n  int&lt;lower=0&gt; N;  // number of observations\n  array[N] int&lt;lower=0,upper=1&gt; y;  // y\n}\nparameters {\n  real&lt;lower=0,upper=1&gt; theta;  // theta parameter\n}\nmodel {\n  theta ~ beta(2, 2);  // prior: Beta(2, 2)\n  y ~ bernoulli(theta);  // model: Bernoulli\n}\ngenerated quantities {\n  real prior_theta = beta_rng(2, 2);\n  array[N] int prior_ytilde;\n  array[N] int ytilde;\n  for (i in 1:N) {\n    ytilde[i] = bernoulli_rng(theta);\n    prior_ytilde[i] = bernoulli_rng(prior_theta);\n  }\n}\n\n\nbern_pp_mod &lt;- cmdstan_model(\"stan_code/beta-bernoulli-pp.stan\")\nbern_pp_fit &lt;- bern_pp_mod$sample(\n    Aids2_standata,\n    refresh = 500  # show progress every 500 iterations\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 1.1 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 1.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 1.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 1.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 1.1 seconds.\nTotal execution time: 4.5 seconds.\n\n\nWith Stan, because we obtained 4,000 prior/posterior draws (the software default) of \\(\\theta\\), we also obtained 4,000 simulated data sets. We can see the first one, based on only the prior distribution (i.e., \\(\\theta\\) \\(\\sim\\) \\(\\text{Beta}(2, 2)\\)):\n\nbern_pp_fit$draws(\"prior_ytilde\", format = \"draws_df\")[1, ] |&gt;\n    as.numeric() |&gt;\n    table()\n\n\n   0    1 \n2742  104 \n\n\n\nNote that the data set has more 1’s than 0’s. Our prior is weak, which means that it allows for a lot of variation in how the data would look.\n\nThe distribution of simulated data based on the prior distribution of the parameters is called the prior predictive distribution. Mathematically, we write it as\n\\[\nP(\\tilde y) = \\int P(\\tilde y | \\theta) P(\\theta) \\; \\mathrm{d}\\theta\n\\]\nBecause we have 4,000 data sets, it is not easy to visualize all individual data points. Instead, we can visualize some summary statistics of the simulated data. Here, we will choose the proportion of deaths (i.e., the mean of the variable) in each simulated data set:\n\nbern_pp_fit$draws(\"prior_ytilde\", format = \"draws_matrix\") |&gt;\n    ppd_stat(stat = \"mean\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nFigure 5.2: Prior predictive distribution of the sample mean.\n\n\n\n\nThis represents our prior belief about the proportion of deaths without looking at the actual data. If this doesn’t seem to match our belief, we may want to modify our prior distribution and do the prior predictive check again, until the simulated data matches our actual prior belief.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Beta-Bernoulli Model With Stan</span>"
    ]
  },
  {
    "objectID": "04b-beta-bernoulli-stan.html#posterior-predictive-check",
    "href": "04b-beta-bernoulli-stan.html#posterior-predictive-check",
    "title": "\n5  Beta-Bernoulli Model With Stan\n",
    "section": "\n5.4 Posterior Predictive Check",
    "text": "5.4 Posterior Predictive Check\n\n5.4.1 Check 1: Sample Mean\n\\[\nP(\\tilde y | y) = \\int P(\\tilde y | \\theta, y) P(\\theta | y) \\; \\mathrm{d}\\theta\n\\]\nThe difference here is that we use the posterior distribution \\(P(\\theta | y)\\) instead of the prior distribution \\(P(\\theta)\\). We can obtain the posterior predictive distribution of the death rate, and indicate the actual data in the plot:\n\nbern_pp_fit$draws(\"ytilde\", format = \"draws_matrix\") |&gt;\n    ppc_stat(y = Aids2_standata$y, stat = \"mean\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nFigure 5.3: Posterior predictive distribution of the sample mean.\n\n\n\n\n\n5.4.2 Check 2: Sample Mean by Age Group\n\n# Create binary indicator of two age groups\nage50 &lt;- factor(Aids2$age &gt; 50, labels = c(\"&lt;= 50\", \"&gt; 50\"))\nbern_pp_fit$draws(\"ytilde\", format = \"draws_matrix\") |&gt;\n    ppc_stat_grouped(y = Aids2_standata$y, group = age50,stat = \"mean\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nFigure 5.4: Posterior predictive distribution of the sample mean by age group.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Beta-Bernoulli Model With Stan</span>"
    ]
  },
  {
    "objectID": "04c-poisson-model.html",
    "href": "04c-poisson-model.html",
    "title": "\n6  Poisson Model\n",
    "section": "",
    "text": "6.1 Research Question",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Poisson Model</span>"
    ]
  },
  {
    "objectID": "04c-poisson-model.html#research-question",
    "href": "04c-poisson-model.html#research-question",
    "title": "\n6  Poisson Model\n",
    "section": "",
    "text": "What’s the rate of fatal police shootings in the United States per year?",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Poisson Model</span>"
    ]
  },
  {
    "objectID": "04c-poisson-model.html#data-import-and-pre-processing",
    "href": "04c-poisson-model.html#data-import-and-pre-processing",
    "title": "\n6  Poisson Model\n",
    "section": "\n6.2 Data Import and Pre-Processing",
    "text": "6.2 Data Import and Pre-Processing\n\n# Import data\nfps_dat &lt;- read_csv(\n    \"https://github.com/washingtonpost/data-police-shootings/raw/master/v2/fatal-police-shootings-data.csv\"\n)\n\nWe first count the data by year\n\n# Create a year column\nfps_dat &lt;- fps_dat |&gt;\n    mutate(year = format(date, format = \"%Y\"))\n# Filter out the latest year\nfps_1523 &lt;- filter(fps_dat, year != max(year))\ncount(fps_1523, year)\n\n\n  \n\n\n\nOur interest is the rate of occurrence of fatal police shootings per year. Denote this as \\(\\theta\\). The support of \\(\\theta\\) is \\([0, \\infty)\\).\nA Poisson model is usually a starting point for analyzing count data in a fixed amount of time. It assumes that the data follow a Poisson distribution with a fixed rate parameter: \\[P(y \\mid \\theta) \\propto \\theta^y \\exp(- \\theta),\\] where the data can be any non-negative integers (no decimals).",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Poisson Model</span>"
    ]
  },
  {
    "objectID": "04c-poisson-model.html#choosing-a-prior",
    "href": "04c-poisson-model.html#choosing-a-prior",
    "title": "\n6  Poisson Model\n",
    "section": "\n6.3 Choosing a Prior",
    "text": "6.3 Choosing a Prior\nThe Gamma distribution has support: \\([0, \\infty)\\), and is a conjugate family to the Poisson model. The Gamma distribution has the form \\[\nP(\\theta) \\propto \\theta^{a - 1} \\exp(-b \\theta),\n\\] where \\(a\\) is the prior incidence rate, and \\(b\\) is the number of prior data points to control for the prior strength. Here, without much prior knowledge, I would simply guess there is one fatal shooting per state per month, so 600 shootings per year, but my belief is pretty weak, so I will assume a prior \\(b\\) of 1 / 200 (one observation is one year). The \\(a\\) will be 600 * \\(b\\) = 3.\nHere’s a plot:\n\nggplot(data.frame(th = c(0, 2000)), aes(x = th)) +\n    stat_function(fun = dgamma,\n    args = list(shape = 3, rate = 1 / 200)) +\n    labs(y = \"\", x = expression(theta))\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel Fitting in Stan\n\n\n\n\ndata {\n  int&lt;lower=0&gt; N;  // number of observations\n  array[N] int&lt;lower=0&gt; y;  // y\n  real&lt;lower=0&gt; prior_a;  // prior a for gamma\n  real&lt;lower=0&gt; prior_b;  // prior b for gamma\n}\nparameters {\n  real&lt;lower=0&gt; theta;  // theta parameter\n}\nmodel {\n  // prior: Gamma(3, 1 / 200)\n  // using conjugacy\n  theta ~ gamma(prior_a + sum(y), prior_b + N);\n}\ngenerated quantities {\n  real prior_theta = gamma_rng(3, 0.005);\n  array[N] int prior_ytilde;\n  array[N] int ytilde;\n  for (i in 1:N) {\n    ytilde[i] = poisson_rng(theta);\n    prior_ytilde[i] = poisson_rng(prior_theta);\n  }\n}\n\n\n6.3.1 Compiling\n\npois_mod &lt;- cmdstan_model(\"stan_code/gamma-poisson-pp.stan\")\n\n\n6.3.2 Data for Stan\n\nfps_standata &lt;- list(\n    N = length(unique(fps_1523$year)),\n    y = count(fps_1523, year)[, 2, drop = TRUE],  # integer\n    prior_a = 3,\n    prior_b = 1 / 200\n)\nfps_standata\n\n$N\n[1] 9\n\n$y\n[1]  995  959  984  991  994 1020 1050 1095 1162\n\n$prior_a\n[1] 3\n\n$prior_b\n[1] 0.005\n\n\n\n6.3.3 MCMC Sampling\n\nfit &lt;- pois_mod$sample(\n    fps_standata,\n    refresh = 500  # show progress every 500 iterations\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \n\n\nChain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 1 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 1 \n\n\nChain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 1 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 1 \n\n\nChain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 1 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 1 \n\n\nChain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 1 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 1 \n\n\nChain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 1 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 1 \n\n\nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 2 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 2 \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 2 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 2 \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 2 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 2 \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 2 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 2 \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 2 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 2 \n\n\nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \n\n\nChain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 3 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 3 \n\n\nChain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 3 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 3 \n\n\nChain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 3 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 3 \n\n\nChain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 3 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 3 \n\n\nChain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 3 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 3 \n\n\nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \n\n\nChain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 4 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 4 \n\n\nChain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 4 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 4 \n\n\nChain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 4 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 4 \n\n\nChain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 4 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 4 \n\n\nChain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 4 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 4 \n\n\nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.6 seconds.\n\n\n\n\n\n\n6.3.4 Prior predictive check\nHere I plot simulated trends from the prior distribution.\n\n# Extract predicted y from prior\nfit$draws(\"prior_ytilde\", format = \"draws_matrix\") |&gt;\n    ppd_intervals(x = 2015:2023) +\n    labs(x = \"Year\", y = \"Predicted count\")\n\n\n\n\n\n\n\nThe check is on whether the numbers seem reasonably reflective of my knowledge.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Poisson Model</span>"
    ]
  },
  {
    "objectID": "04c-poisson-model.html#posterior",
    "href": "04c-poisson-model.html#posterior",
    "title": "\n6  Poisson Model\n",
    "section": "\n6.4 Posterior",
    "text": "6.4 Posterior\nWith a conjugate prior, the posterior distribution is Gamma(\\(a\\) + \\(\\sum_{i = 1}^N y_i\\), \\(b\\) + \\(N\\)).\n\nggplot(data.frame(th = c(0, 2000)), aes(x = th)) +\n    stat_function(fun = dgamma,\n    args = list(shape = 3 + nrow(fps_1523),\n                rate = 1 / 200 + fps_standata$N), n = 501) +\n    labs(y = \"\", x = expression(theta))",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Poisson Model</span>"
    ]
  },
  {
    "objectID": "04c-poisson-model.html#posterior-predictive-check",
    "href": "04c-poisson-model.html#posterior-predictive-check",
    "title": "\n6  Poisson Model\n",
    "section": "\n6.5 Posterior Predictive Check",
    "text": "6.5 Posterior Predictive Check\nPlot predicted data from the posterior against observed data\n# Extract predicted y from posterior\nfit$draws(\"ytilde\", format = \"draws_matrix\") |&gt;\n    ppc_intervals(\n        y = fps_standata$y,\n        x = 2015:2023\n    ) +\n    labs(x = \"Year\", y = \"Predicted count\")\n# We can also use `bayesplot::ppc_ribbon()`\nfit$draws(\"ytilde\", format = \"draws_matrix\") |&gt;\n    ppc_ribbon(\n        y = fps_standata$y,\n        x = 2015:2023\n    ) +\n    labs(x = \"Year\", y = \"Predicted count\")\n\n\n\n\n\n\n\n\n\n(a) Interval plots.\n\n\n\n\n\n\n\n\n\n(b) Ribbon plots.\n\n\n\n\n\n\nFigure 6.1: Posterior predictive check.\n\n\n\n\n\n\n\n\nFrom Figure 6.1, one can see that the fit is not good, as there is a large gap between the model prediction and the observed data from recent years. This suggests a need to incorporate the time trend in the model.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Poisson Model</span>"
    ]
  },
  {
    "objectID": "04c-poisson-model.html#summary-of-posterior",
    "href": "04c-poisson-model.html#summary-of-posterior",
    "title": "\n6  Poisson Model\n",
    "section": "\n6.6 Summary of Posterior",
    "text": "6.6 Summary of Posterior\nFor now, we will proceed with interpreting the posterior distribution, despite the apparent misfit.\n\n(summ_theta &lt;- fit$summary(\"theta\"))\n\n\n  \n\n\n\nSo the estimated rate is 1,027 per year, with a 90% CI [1,009, 1,044].",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Poisson Model</span>"
    ]
  },
  {
    "objectID": "05-hierarchical-models.html",
    "href": "05-hierarchical-models.html",
    "title": "\n7  Hierarchical Models\n",
    "section": "",
    "text": "7.1 Hierarchical Bernoulli/Binomial\nWe will first consider a therapeutic touch example (Kruschke, 2015, Chapter 9). Therapeutic touch is a technique in alternative medicine to relieve pain, but scientific evidence does not support its effectiveness. The data here are from an experiment where the experimenter randomly hovered their hand over either the participant’s left or right hand, and the participant had to guess which hand was being hovered without seeing. This is repeated 10 times for each participant. There are a total of 28 participants in the dataset.\nPreviously, we have seen the Bernoulli model for \\(N\\) outcomes (i.e., whether the guess is correct): \\[\ny_i \\sim \\text{Bern}(\\theta), \\text{for }i = 1, \\ldots, N\n\\] We assumed exchangeability with \\(\\theta\\) being the participant’s “ability” to guess correctly.",
    "crumbs": [
      "Week 4",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Hierarchical Models</span>"
    ]
  },
  {
    "objectID": "05-hierarchical-models.html#hierarchical-bernoullibinomial",
    "href": "05-hierarchical-models.html#hierarchical-bernoullibinomial",
    "title": "\n7  Hierarchical Models\n",
    "section": "",
    "text": "Alternative Parameterization of Beta\n\n\n\nIn the last class, we have used the Beta(a, b) prior for a Bernoulli outcome, such that \\[\nP(\\theta \\mid a, b) \\propto \\theta^{a - 1} (1 - \\theta)^{b - 1}.\n\\] However, in hierarchical models to be discussed later, it is beneficial to consider another way to express the Beta distribution, in terms of the prior mean, \\(\\mu = a / (a + b)\\), \\(\\mu \\in [0, 1]\\), and the concentration, \\(\\kappa = a + b\\), \\(\\kappa \\in [0, \\infty)\\). So, instead of the above formula, we can write \\[\nP(\\theta \\mid \\mu, \\kappa) \\propto \\theta^{\\mu \\kappa - 1} (1 - \\theta)^{(1 - \\mu) \\kappa - 1}.\n\\] The two expressions represent exactly the same distribution, but just in terms of parameters of different meanings. Therefore, they are referred to as different parameterization of the Beta distribution.\n\n\n\n\n7.1.1 Multiple Bernoulli = Binomial\nWith \\(N\\) exchangeable Bernoulli observations, an equivalent but more efficient way to code the model is to use the binomial distribution. Let \\(z = \\sum_{i = 1}^N y_i\\), then \\[\nz \\sim \\mathrm{Bin}(N, \\theta)\n\\]\n\n7.1.2 Multiple Binomial Observations\nNow, because we have multiple participants, we could study whether each participant had noticeable differences in their guessing ability. We can use a binomial model for each participant, from participant 1 to participant \\(J\\): \\[\n\\begin{aligned}\n  z_1 \\sim \\mathrm{Bin}(N_1, \\theta_1) \\\\\n  z_2 \\sim \\mathrm{Bin}(N_2, \\theta_2) \\\\\n  \\vdots \\\\\n  z_J \\sim \\mathrm{Bin}(N_J, \\theta_J)\n\\end{aligned}\n\\]\nOr instead of writing \\(J\\) equations, we can use the subscript \\(j\\) to refer to each participant: \\[\nz_{\\textcolor{red}{j}} \\sim \\mathrm{Bin}(N_{\\textcolor{red}{j}}, \\theta_{\\textcolor{red}{j}})\n\\]\nIf we believe that all participants have the same ability, then we could consider the model \\[\nz_j \\sim \\mathrm{Bin}(N_j, \\theta),\n\\] which still contains only one parameter, \\(\\theta\\). However, if we have reason to believe that the coins have different biases, then we should have \\[z_j \\sim \\mathrm{Bin}(N_j, \\theta_{\\color{red}{j}}),\\] with parameters \\(\\theta_1, \\ldots, \\theta_j\\).\nWe can assign priors to each \\(\\theta_j\\). However, suppose our prior belief is that there’s something common among the different participants (e.g., they’re all human beings), so they come from a common distribution. In that case, we can have common parameters for the prior distributions of the \\(\\theta\\)s: \\[\n\\theta_j \\sim \\mathrm{Beta\\_Proportion}(\\mu, \\kappa),\n\\] note I use Beta_Proportion to denote the mean parameterization. Here, we express the prior belief that the mean ability of the different participants is \\(\\mu\\), and how each participant differs from the mean depends on \\(\\kappa\\). Now, \\(\\mu\\) and \\(\\kappa\\) are hyperparameters. We can assign some fixed values to \\(\\mu\\) and \\(\\kappa\\), as if we know what the average ability is. However, the power of the hierarchical model is that we can put priors (or hyper priors) on \\(\\mu\\) and \\(\\kappa\\), and obtain posterior distributions of them, based on what the data say.\nWhat priors to use for \\(\\mu\\) and \\(\\kappa\\)? \\(\\mu\\) is relatively easy because it is the mean ability; if we put a Beta prior for each participant’s ability, we can again use a Beta prior for the mean ability. \\(\\kappa\\) is more challenging. A larger \\(\\kappa\\) means that the participants’ abilities are more similar to each other. We can perform a prior predictive check to see what the data look like. As a starting point, some textbook (e.g., chapter 9 of Kruschke, 2015) suggested using Gamma(0.01, 0.01). So the full model in our case, with a weak Beta(1.5, 1.5) prior on \\(\\mu\\), is\nModel: \\[\n  \\begin{aligned}\n    z_j & \\sim \\mathrm{Bin}(N_j, \\theta_j) \\\\\n    \\theta_j & \\sim \\mathrm{Beta2}(\\mu, \\kappa)\n  \\end{aligned}\n\\] Prior: \\[\n  \\begin{aligned}\n    \\mu & \\sim \\mathrm{Beta}(1.5, 1.5) \\\\\n    \\kappa & \\sim \\mathrm{Gamma}(0.01, 0.01)\n  \\end{aligned}\n\\]\nWe will import the data and fit the model\n\n# Data file from GitHub\ntt_url &lt;- paste0(\n    \"https://github.com/boboppie/kruschke-doing_bayesian_data_analysis/\",\n    \"raw/master/2e/TherapeuticTouchData.csv\"\n)\ntt_dat &lt;- read.csv(tt_url)\n# Get aggregated data by summing the counts\ntt_agg &lt;- tt_dat |&gt;\n    group_by(s) |&gt;\n    summarise(y = sum(y),  # total number of correct\n              n = n())\n# Plot proportion correct distribution\np1 &lt;- ggplot(tt_agg, aes(x = y / n)) +\n    geom_histogram(binwidth = .1) +\n    labs(x = \"Proportion Correct\")\n\n\n\n\n\n\n\n\nFigure 7.2: Distribution of proportions of correct responses across participants.\n\n\n\n\n\n7.1.3 Stan Code\n\ndata {\n  int&lt;lower=0&gt; J;  // number of clusters (e.g., studies, persons)\n  array[J] int y;  // number of \"1\"s in each cluster\n  array[J] int N;  // sample size for each cluster\n}\nparameters {\n  // cluster-specific probabilities\n  vector&lt;lower=0, upper=1&gt;[J] theta;\n  real&lt;lower=0, upper=1&gt; mu;  // overall mean probability\n  real&lt;lower=0&gt; kappa;        // overall concentration\n}\nmodel {\n  y ~ binomial(N, theta);  // each observation is binomial\n  // Priors\n  theta ~ beta_proportion(mu, kappa);\n  mu ~ beta(1.5, 1.5);      // weak prior\n  kappa ~ gamma(.1, .1);  // prior recommended by Kruschke\n}\ngenerated quantities {\n  // Prior and prior predictive\n  real&lt;lower=0, upper=1&gt; prior_mu = beta_rng(1.5, 1.5);\n  real&lt;lower=0&gt; prior_kappa = gamma_rng(.1, .1);\n  vector&lt;lower=0, upper=1&gt;[J] prior_theta;\n  for (j in 1:J) {\n    prior_theta[j] = beta_proportion_rng(prior_mu, prior_kappa);\n  }\n  array[J] int prior_ytilde = binomial_rng(N, prior_theta);\n  // Posterior predictive\n  array[J] int ytilde = binomial_rng(N, theta);\n}\n\n\nhbin_mod &lt;- cmdstan_model(\"stan_code/hierarchical-binomial.stan\")\n\n\n7.1.4 Prior predictive\nYou can use Stan to sample the prior and obtain the prior predictive distribution; here, I show how to do it in R, with a Gamma(.01, .01) prior on \\(\\kappa\\):\n\nset.seed(1706)\nplist &lt;- vector(\"list\", 12L)\nplist[[1]] &lt;- p1 +\n    labs(x = \"Observed data\") +\n    theme(axis.title.x = element_text(color = \"red\"))\nnum_subjects &lt;- 28\nfor (s in 1:11) {\n    # Get prior values of mu and kappa\n    mu_s &lt;- rbeta(1, shape1 = 1.5, shape2 = 1.5)\n    kappa_s &lt;- rgamma(1, shape = 0.01, rate = 0.01)\n    # Generate theta\n    theta &lt;- rbeta(num_subjects,\n                   shape1 = mu_s * kappa_s,\n                   shape2 = (1 - mu_s) * kappa_s)\n    # Generate data\n    new_y &lt;- rbinom(num_subjects, size = tt_agg$n, prob = theta)\n    plist[[s + 1]] &lt;-\n        p1 %+% mutate(tt_agg, y = new_y) +\n        labs(x = paste(\"Simulated data\", s)) +\n        theme(axis.title.x = element_text(color = \"black\"))\n}\ngridExtra::grid.arrange(grobs = plist, nrow = 3)\n\n\n\n\n\n\nFigure 7.3: Prior predictive distribution.\n\n\n\n\nThe prior on \\(\\kappa\\) is not very realistic because it pushes the bias to either 0 or 1. Using something like Gamma(0.1, 0.1) or Gamma(2, 0.01) may be more reasonable (you can try it out yourself).\n\n7.1.5 Calling Stan\n\ntt_fit &lt;- hbin_mod$sample(\n    data = list(J = nrow(tt_agg),\n                y = tt_agg$y,\n                N = tt_agg$n),\n    seed = 1716,  # for reproducibility\n    refresh = 1000\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.3 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 2 Exception: beta_proportion_lpdf: Location parameter is 1, but must be less than 1.000000 (in '/tmp/Rtmp2xNIuz/model-9166e680a2e31.stan', line 15, column 2 to column 37)\n\n\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 2 \n\n\nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.3 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.3 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \n\n\nChain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 4 Exception: beta_proportion_lpdf: Location parameter is 0, but must be positive! (in '/tmp/Rtmp2xNIuz/model-9166e680a2e31.stan', line 15, column 2 to column 37)\n\n\nChain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 4 \n\n\nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.3 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.3 seconds.\nTotal execution time: 1.6 seconds.\n\n\nYou can explore the convergence and posterior distributions using the shinystan package\n\nshinystan::launch_shinystan(tt_fit)\n\n\n7.1.6 Table of coefficients\n\ntt_fit$summary(c(\"theta\", \"mu\", \"kappa\")) |&gt;\n    # Use `knitr::kable()` for tabulation\n    knitr::kable(digits = 2)\n\n\nTable 7.1: Posterior summary of hierarchical binomial model for the therapeutic touch example.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\ntheta[1]\n0.31\n0.31\n0.10\n0.10\n0.15\n0.47\n1\n3268.39\n2404.91\n\n\ntheta[2]\n0.35\n0.35\n0.10\n0.10\n0.19\n0.51\n1\n3741.46\n2422.69\n\n\ntheta[3]\n0.39\n0.39\n0.10\n0.10\n0.23\n0.55\n1\n4744.99\n2794.69\n\n\ntheta[4]\n0.39\n0.39\n0.10\n0.10\n0.23\n0.55\n1\n4859.60\n3056.80\n\n\ntheta[5]\n0.39\n0.39\n0.10\n0.10\n0.22\n0.55\n1\n4817.40\n2485.43\n\n\ntheta[6]\n0.39\n0.38\n0.10\n0.10\n0.23\n0.55\n1\n5260.92\n2493.09\n\n\ntheta[7]\n0.39\n0.38\n0.10\n0.10\n0.23\n0.55\n1\n5586.84\n2968.73\n\n\ntheta[8]\n0.39\n0.39\n0.10\n0.10\n0.23\n0.55\n1\n4926.08\n3008.76\n\n\ntheta[9]\n0.39\n0.39\n0.10\n0.10\n0.23\n0.55\n1\n4802.85\n2558.79\n\n\ntheta[10]\n0.39\n0.39\n0.10\n0.10\n0.22\n0.55\n1\n4743.85\n2910.25\n\n\ntheta[11]\n0.43\n0.42\n0.10\n0.09\n0.27\n0.59\n1\n5041.77\n3066.93\n\n\ntheta[12]\n0.42\n0.42\n0.09\n0.10\n0.27\n0.58\n1\n6055.56\n2896.89\n\n\ntheta[13]\n0.43\n0.42\n0.10\n0.10\n0.27\n0.59\n1\n4898.48\n3112.24\n\n\ntheta[14]\n0.43\n0.42\n0.10\n0.10\n0.27\n0.59\n1\n5909.48\n3065.15\n\n\ntheta[15]\n0.43\n0.42\n0.10\n0.10\n0.27\n0.59\n1\n6304.56\n3049.53\n\n\ntheta[16]\n0.46\n0.46\n0.10\n0.10\n0.31\n0.62\n1\n5642.01\n3230.67\n\n\ntheta[17]\n0.46\n0.46\n0.10\n0.10\n0.30\n0.63\n1\n5517.58\n3108.00\n\n\ntheta[18]\n0.46\n0.46\n0.10\n0.10\n0.30\n0.63\n1\n5622.46\n2837.76\n\n\ntheta[19]\n0.46\n0.46\n0.10\n0.09\n0.31\n0.63\n1\n6228.82\n3062.79\n\n\ntheta[20]\n0.46\n0.46\n0.10\n0.10\n0.30\n0.63\n1\n4758.62\n2538.88\n\n\ntheta[21]\n0.46\n0.46\n0.10\n0.10\n0.30\n0.62\n1\n5922.64\n2921.96\n\n\ntheta[22]\n0.46\n0.46\n0.10\n0.10\n0.31\n0.62\n1\n5218.69\n3180.07\n\n\ntheta[23]\n0.50\n0.50\n0.10\n0.10\n0.34\n0.67\n1\n5424.13\n2936.72\n\n\ntheta[24]\n0.50\n0.50\n0.10\n0.10\n0.34\n0.67\n1\n5321.61\n2733.91\n\n\ntheta[25]\n0.54\n0.54\n0.10\n0.10\n0.38\n0.71\n1\n3861.44\n2248.48\n\n\ntheta[26]\n0.54\n0.54\n0.10\n0.10\n0.37\n0.72\n1\n3808.59\n2430.69\n\n\ntheta[27]\n0.54\n0.54\n0.10\n0.10\n0.38\n0.71\n1\n3679.86\n2556.84\n\n\ntheta[28]\n0.58\n0.57\n0.10\n0.11\n0.41\n0.75\n1\n3005.40\n2460.66\n\n\nmu\n0.44\n0.44\n0.04\n0.04\n0.38\n0.50\n1\n2482.91\n2932.61\n\n\nkappa\n18.65\n16.37\n9.63\n7.92\n7.49\n36.92\n1\n992.72\n1793.53\n\n\n\n\n\n\n\n\n\n7.1.7 Posterior Predictive Check\nWith hierarchical models, there are two types of posterior predictive distributions:\n\n\nSame participants but new observations. We can use the model to generate new observations, but the individual parameters (e.g., \\(\\theta_j\\)) remain the same. In our example, this would be the situation where we ask the same 28 participants to each do 10 more trials.\n\nNew participants and new observations. We can use the model to generate new observations with new parameters from the higher-order distribution (e.g., the Beta distribution for \\(\\theta_j\\)). In our example, this would be the situation where we ask a new set of 28 participants to each do 10 more trials.\n\nIn our Stan code, I used (1) to check the fit of the observed data. However, (2) can be helpful when one wants to use the model to make predictions of future data, as future data are unlikely to concern exactly the same participants.\n\n# The bayesplot::ppc_bars() unfortunately contains a bug\n# (https://github.com/stan-dev/bayesplot/issues/266) at\n# the time when I wrote this, so I'll use my own code.\n# tt_fit$draws(\"ytilde\", format = \"draws_matrix\") |&gt;\n#     ppc_bars(y = tt_agg$y)\nyrep &lt;- tt_fit$draws(\"ytilde\", format = \"draws_matrix\")\nyrep_intervals &lt;- apply(\n    yrep, MARGIN = 1, FUN = \\(x) table(factor(x, levels = 0:10))\n    ) |&gt;\n    apply(MARGIN = 1, FUN = \\(x) {\n        c(\n            lo = quantile(x, .05)[[1]],\n            me = median(x),\n            hi = quantile(x, .95)[[1]]\n        )\n    })\ndata.frame(\n    y = table(factor(tt_agg$y, levels = 0:10))\n) |&gt;\n    setNames(c(\"x\", \"y\")) |&gt;\n    cbind(t(yrep_intervals)) |&gt;\n    ggplot(aes(x = x, y = y)) +\n    geom_col(alpha = 0.5) +\n    geom_pointrange(aes(y = me, ymin = lo, ymax = hi)) +\n    labs(y = \"count\", x = NULL)\n\n\n\n\n\n\nFigure 7.4: Posterior predictive check. The bar graph shows the observed data, and the error bars show the 90% posterior predictive interval in replicated data. The dots are the medians in the posterior predictive distribution.\n\n\n\n\n\n7.1.8 Derived coefficients\nOne nice thing about MCMC is that it is straightforward to obtain posterior distributions that are functions of the parameters. For example, even though we only sampled from the posteriors of the \\(\\theta\\)s, we can ask questions like whether there is evidence for a nonzero difference in \\(\\theta\\) between person 1 and person 28.\n\ntt_fit$draws() |&gt;\n    mutate_variables(\n        theta1_minus14 = `theta[1]` - `theta[14]`,\n        theta1_minus28 = `theta[1]` - `theta[28]`,\n        theta14_minus28 = `theta[14]` - `theta[28]`\n    ) |&gt;\n    subset(variable = c(\"theta1_minus14\", \"theta1_minus28\",\n                        \"theta14_minus28\")) |&gt;\n    summarise_draws() |&gt;\n    knitr::kable(digits = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\ntheta1_minus14\n-0.11\n-0.11\n0.13\n0.13\n-0.34\n0.09\n1\n4950.80\n2632.63\n\n\ntheta1_minus28\n-0.27\n-0.26\n0.15\n0.16\n-0.53\n-0.03\n1\n2312.44\n3115.27\n\n\ntheta14_minus28\n-0.15\n-0.15\n0.14\n0.14\n-0.38\n0.06\n1\n4309.81\n3013.97\n\n\n\n\n\n\n7.1.9 Conclusion\nAs 0.5 is included in the 95% CI of \\(\\theta\\) for all participants, there is insufficient evidence that people can sense “therapeutic touch.”\n\n7.1.10 Shrinkage\n\nmcmc_intervals(tt_fit$draws(),\n               # plot only parameters matching \"theta\"\n               regex_pars = \"^theta\") +\n    geom_point(\n        data = tibble(\n            parameter = paste0(\"theta[\", 1:28, \"]\"),\n            x = tt_agg$y / tt_agg$n\n        ),\n        aes(x = x, y = parameter),\n        col = \"red\"\n    ) +\n    xlim(0, 1)\n\nScale for x is already present.\nAdding another scale for x, which will replace the existing scale.\n\n\n\n\nShrinkage effect in a hierarchical model.\n\n\n\nAs can be seen, the posterior distributions are closer to the center than the data (in red). This pooling results from the belief that the participants have something in common.\n\n7.1.11 Multiple Comparisons?\nAnother benefit of a Bayesian hierarchical model is that you don’t need to worry about multiple comparisons. There are multiple angles on why this is the case, but the basic answer is that the use of common prior distributions builds in the prior belief that the clusters/groups are likely to be equal. See discussion here and here.",
    "crumbs": [
      "Week 4",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Hierarchical Models</span>"
    ]
  },
  {
    "objectID": "05-hierarchical-models.html#hierarchical-normal-model",
    "href": "05-hierarchical-models.html#hierarchical-normal-model",
    "title": "\n7  Hierarchical Models\n",
    "section": "\n7.2 Hierarchical Normal Model",
    "text": "7.2 Hierarchical Normal Model\n\n7.2.1 Eight Schools Example\nThis is a classic data set first analyzed by Rubin (1981). It is also the example used in the RStan Getting Started page. The data contains the effect of coaching from randomized experiments in eight schools. The numbers shown (labelled as y) are the mean difference (i.e., effect size) in performance between the treatment and control groups on SAT-V scores.\n\nschools_dat &lt;- list(\n    J = 8,\n    y = c(28, 8, -3, 7, -1, 1, 18, 12),\n    sigma = c(15, 10, 16, 11, 9, 11, 10, 18)\n)\n\nIn the above data, some numbers are positive, and some are negative. Because the sample sizes are different, the data also contained the standard errors (labelled as sigma) of the effect sizes. Generally speaking, a larger sample size corresponds to a smaller standard error. The research question is\n\n\nWhat is the average treatment effect of coaching?\nAre the treatment effects similar across schools?\n\n\n\n7.2.2 Model\nModel: \\[\n  \\begin{aligned}\n    d_j & \\sim N(\\theta_j, s_j) \\\\\n    \\theta_j & \\sim N(\\mu, \\tau)\n  \\end{aligned}\n\\] Prior: \\[\n  \\begin{aligned}\n    \\mu & \\sim N(0, 100) \\\\\n    \\tau & \\sim t^+_4(0, 100)\n  \\end{aligned}\n\\]\nGiven the SAT score range, it is unlikely that a coaching program will improve scores by 100 or so, so we use a prior of \\(\\mu \\sim N(0, 100)\\) and \\(\\tau \\sim t^+_4(0, 100)\\).\n\n\n\n\n\n\nThe model above is the same as one used in a random-effect meta-analysis. See this paper for an introduction.\n\n\n\n\n7.2.3 Non-Centered Parameterization\nThe hierarchical model is known to create issues in MCMC sampling, such that the posterior draws tend to be highly correlated even with more advanced techniques like HMC. One way to alleviate that is to reparameterize the model using what is called the non-centered parameterization. The basic idea is that, instead of treating the \\(\\theta\\)s as parameters, one uses the standardized deviation from the mean to be parameters. You can think about it as converting the \\(\\theta\\)s into \\(z\\) scores, and then sample the \\(z\\) scores instead of the original \\(\\theta\\)s.\nModel: \\[\n  \\begin{aligned}\n    d_j & \\sim N(\\theta_j, s_j) \\\\\n    \\theta_j & = \\mu + \\tau \\eta_j \\\\\n    \\eta_j & \\sim N(0, 1)\n  \\end{aligned}\n\\]\n\ndata {\n  int&lt;lower=0&gt; J;            // number of schools \n  vector[J] y;               // estimated treatment effects\n  vector&lt;lower=0&gt;[J] sigma;  // s.e. of effect estimates \n}\nparameters {\n  real mu;                   // overall mean\n  real&lt;lower=0&gt; tau;         // between-school SD\n  vector[J] eta;             // standardized deviation (z score)\n}\ntransformed parameters {\n  vector[J] theta;\n  theta = mu + tau * eta;    // non-centered parameterization\n}\nmodel {\n  eta ~ std_normal();        // same as eta ~ normal(0, 1);\n  y ~ normal(theta, sigma);\n  // priors\n  mu ~ normal(0, 100);\n  tau ~ student_t(4, 0, 100);\n}\n\n\nhnorm_mod &lt;- cmdstan_model(\"stan_code/hierarchical-normal.stan\")\n\n\nfit &lt;- hnorm_mod$sample(\n    data = schools_dat,\n    seed = 1804,  # for reproducibility\n    refresh = 1000,\n    adapt_delta = 0.9  # to improve convergence\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.1 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.1 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.1 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.8 seconds.\n\n\nTreatment effect estimates of individual schools (\\(\\theta\\)), average treatment effect (\\(\\mu\\)), and treatment effect heterogeneity (\\(\\tau\\)).\n\nfit$summary(c(\"theta\", \"mu\", \"tau\")) |&gt;\n    knitr::kable(digits = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\ntheta[1]\n11.70\n10.60\n8.69\n7.38\n-0.20\n27.60\n1.00\n3475.69\n3347.72\n\n\ntheta[2]\n7.98\n7.93\n6.31\n5.82\n-2.18\n18.34\n1.00\n5870.22\n3353.39\n\n\ntheta[3]\n6.13\n6.77\n7.97\n6.50\n-7.14\n17.85\n1.00\n4318.80\n2941.48\n\n\ntheta[4]\n7.69\n7.75\n6.75\n6.15\n-3.43\n18.53\n1.00\n5452.05\n3268.65\n\n\ntheta[5]\n5.22\n5.53\n6.22\n5.82\n-5.64\n14.70\n1.00\n4118.93\n3165.15\n\n\ntheta[6]\n6.15\n6.52\n6.87\n6.15\n-5.19\n16.86\n1.00\n4526.45\n3352.39\n\n\ntheta[7]\n10.80\n10.14\n6.78\n6.32\n0.88\n23.09\n1.00\n4445.48\n3533.95\n\n\ntheta[8]\n8.55\n8.33\n7.74\n6.42\n-3.59\n21.11\n1.00\n4978.08\n3232.97\n\n\nmu\n7.95\n8.00\n5.26\n4.97\n-0.43\n16.20\n1.00\n2917.45\n1987.36\n\n\ntau\n6.75\n5.31\n5.91\n4.84\n0.55\n17.53\n1.01\n1316.86\n1673.79\n\n\n\n\n\nOn average, based on the 90% CI, coaching seemed to improve SAT-V by -0.43 to 16.2 points. There was substantial heterogeneity across schools.\nWe can also get the probability that the treatment effect was &gt; 0:\n\n# Obtain draws\ndraws_mu &lt;- fit$draws(\"mu\", format = \"draws_matrix\")\nmean(draws_mu &gt; 0)\n\n[1] 0.93975\n\n\nHere are the individual-school treatment effects:\n\nmcmc_areas_ridges(fit$draws(), regex_pars = \"theta\")\n\n\n\n\n\n\nFigure 7.5: Posterior distribution of the true effect size in the eight schools example.\n\n\n\n\n\n7.2.4 Prediction Interval\nPosterior distribution of the true effect size of a new study, \\(\\tilde \\theta\\)\n\n# Prediction Interval\n# (can also be done in Stan, as in the previous example)\nfit$draws(c(\"mu\", \"tau\")) |&gt;\n    mutate_variables(\n        theta_tilde = rnorm(4000, mean = mu, sd = tau)) |&gt;\n    summarise_draws() |&gt;\n    knitr::kable(digits = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\nmu\n7.95\n8.00\n5.26\n4.97\n-0.43\n16.20\n1.00\n2917.45\n1987.36\n\n\ntau\n6.75\n5.31\n5.91\n4.84\n0.55\n17.53\n1.01\n1316.86\n1673.79\n\n\ntheta_tilde\n8.03\n7.87\n10.19\n7.00\n-6.69\n22.89\n1.00\n3947.08\n3042.56\n\n\n\n\n\nThe posterior interval for \\(\\tilde \\theta\\) indicates a range of the treatment effect for a new study.",
    "crumbs": [
      "Week 4",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Hierarchical Models</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Gigerenzer, G. (2004). Mindless statistics. The Journal of\nSocio-Economics, 33(5), 587–606. https://doi.org/10.1016/j.socec.2004.09.033\n\n\nJohnson, A. A., Ott, M. Q., & Dogucu, M. (2022). Bayes rules! An\nintroduction to Bayesian modeling with R. CRC Press.\n\n\nLambert, B. (2018). A student’s guide to Bayesian statistics.\nSAGE.\n\n\nMcGrayne, S. B. (2011). The theory that would not die: How Bayes’\nrule cracked the enigma code, hunted down Russian submarines, &\nemerged triumphant from two centuries of controversy. Yale\nuniversity press.\n\n\nVan De Schoot, R., Winter, S. D., Ryan, O., Zondervan-Zwijnenburg, M.,\n& Depaoli, S. (2017). A systematic review of Bayesian articles in\npsychology: The last 25 years. Psychological Methods,\n22(2), 217–239. https://doi.org/10.1037/met0000100",
    "crumbs": [
      "References"
    ]
  }
]