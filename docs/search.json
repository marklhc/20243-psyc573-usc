[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PSYC 573 Bayesian Data Analysis (2024 Fall): Course Notes",
    "section": "",
    "text": "Preface\nThere will be some math in this notes. Don’t worry if you feel the math is challenging; for applied focused students, it is much more important to understand the concepts of Bayesian methods than to understand the mathematical symbols, as they usually can be handled by the software.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "01-intro.html",
    "href": "01-intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 History of Bayesian Statistics\nHere is a nice brief video that covers some of the 250+ years of history of Bayesian statistics:\nIf you are interested in learning more about the story, check out the popular science book, “The theory that would not die,” by McGrayne (2011)",
    "crumbs": [
      "Week 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#history-of-bayesian-statistics",
    "href": "01-intro.html#history-of-bayesian-statistics",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1.1 Thomas Bayes (1701–1762)\nYou may find a biography of Bayes from https://www.britannica.com/biography/Thomas-Bayes. There is also a nice story in the book by Lambert (2018). He was an English Presbyterian minister. The important work he wrote that founded Bayesian statistics was “An Essay Towards Solving a Problem in the Doctrine of Chances,” which he did not publish and was later discovered and edited by his friend, Richard Price, after Bayes’s death 1\n\n\n1.1.2 Pierre-Simon Laplace (1749–1827)\nLaplace, a French Mathematician, was an important figure in not just Bayesian statistics but other areas of mathematics, astronomy, and physics. We know much more about the work by Laplace than by Bayes, and Laplace has worked independently on the inverse probability problem (i.e., \\(P[\\text{Parameter} | \\text{Data}]\\)). Indeed, he was credited for largely formalizing the Bayesian interpretation of probability and most of the machinery for Bayesian statistics, and making it a useful technique for different problems, despite the discipline being called “Bayesian.” His other contributions include the methods of least squares and the central limit theorem. See a short biography of him at https://www.britannica.com/biography/Pierre-Simon-marquis-de-Laplace.\n\n\n1.1.3 20th Century\nUntil the early 1920s, the inverse probability method, which is based on what is now called Bayes’s Theorem, was pretty much the predominant point of view of statistics. Then a point of view later known as frequentist statistics arrived, and quickly became the mainstream school of thinking for statistical inferences, and is still the primary framework for quantitative research. In the early 1920s, frequentist scholars, most notably R. A. Fisher and Jerzy Neyman, criticized Bayesian inference for using subjective elements in an objective discipline. In Fisher’s words,\n\nThe theory of inverse probability is founded upon an error, and must be wholly rejected—Fisher, 1925\n\nIronically, the term Bayesian was first used in one of Fisher’s works. And interestingly, Fisher actually thought he “[had] been doing almost exactly what Bayes had done in the 18th century.”2\nDespite criticisms from frequentist scholars, Bayesian methods have been used by scholars in the Allies in World War II, such as Alan Turing, in an algorithm to break coded messages in the Enigma machine that the German Navy used to communicate. However, because of the more complex mathematics involved in Bayesian statistics, Bayesian statistics is limited to straight-forward problems and theoretical discussions until the early 1980s, when computing speed increased tremendously and made Markov Chain Monte Carlo—the primary algorithm for Bayesian estimation in modern Bayesian statistics—feasible. With the help of increased computing speed, Bayesian statistics has come back and been used as an alternative way of thinking, especially given the growing dissatisfaction towards the misuse of frequentist statistics by some scholars across disciplines. Bayesian estimation methods have also been applied to many new research questions where frequentist approaches work less well, as well as in big data analytics and machine learning.",
    "crumbs": [
      "Week 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#motivations-for-using-bayesian-methods",
    "href": "01-intro.html#motivations-for-using-bayesian-methods",
    "title": "1  Introduction",
    "section": "1.2 Motivations for Using Bayesian Methods",
    "text": "1.2 Motivations for Using Bayesian Methods\nBased on my personal experience, Bayesian methods are used quite often in statistics and related departments, as it is consistent and coherent, in contrast to frequentist where a new and probably ad hoc procedure needed to be developed to handle a new problem. For Bayesian, as long as you can formulate a model, you just run the analysis the same way as you would for simpler problems, or in Bayesian people’s words “turning the Bayesian crank,” and likely the difficulties would be more technical than theoretical, which is usually solved with better computational speed.\nSocial and behavioral scientists are relatively slow to adopt the Bayesian method, but things have been changing. In a recently accepted paper by Van De Schoot et al. (2017), the authors reviewed papers in psychology between 1990 and 2015 and found that whereas less than 10% of the papers from 1990 to 1996 mentioned “Bayesian”, the proportion increased steadily and was found in close to 45% of the psychology papers in 2015. Among studies using Bayesian methods, more than 1/4 cited computational problems (e.g., nonconvergence) in frequentist methods as a reason, and about 13% cited the need to incorporate prior knowledge into the estimation process. The other reasons included the flexibility of Bayesian methods for complex and nonstandard problems, and the use of techniques traditionally attached to Bayesian such as missing data and model comparisons.\n\n1.2.1 Problem with classical (frequentist) statistics\nThe rise of Bayesian methods is also related to the statistical reform movement in the past two decades. The problem is that applied researchers are obsessed with \\(p &lt; .05\\) and often misinterpreted a small \\(p\\)-value as something that it isn’t (read Gigerenzer, 2004). Some scholars coined the term \\(p\\)-hacking to refer to the practice of obtaining statistical significance by choosing to test the data in a certain way, either consciously or subconsciously (e.g., dichotomizing using mean or median, trying the same hypothesis using different measures of the same variable, etc). This is closely related to the recent “replication crisis” in scientific research, with psychology being in the center under close scrutiny.\nBayesian is no panacea to the problem. Indeed, if misused, it can give rise to the same problems as statistical significance. My goal in this class is to help you appreciate the Bayesian tradition of embracing the uncertainty in your results, and adopt rigorous model checking and comprehensive reporting rather than relying merely on a \\(p\\)-value. I see this as the most important mission for someone teaching statistics.",
    "crumbs": [
      "Week 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#comparing-bayesian-and-frequentist-statistics",
    "href": "01-intro.html#comparing-bayesian-and-frequentist-statistics",
    "title": "1  Introduction",
    "section": "1.3 Comparing Bayesian and Frequentist Statistics",
    "text": "1.3 Comparing Bayesian and Frequentist Statistics\n\n\n\n\n\n\n\n\nAttributes\nFrequentist\nBayesian\n\n\n\n\nInterpretation of probability\nFrequentist\nSubjectivist\n\n\nUncertainty\nHow estimates vary in repeated sampling from the same population\nHow much prior beliefs about parameters change in light of data\n\n\nWhat’s relevant?\nCurrent data set + all that might have been observed\nOnly the data set that is actually observed\n\n\nHow to proceed with analyses\nMLE; ad hoc and depends on problems\n“Turning the Bayesian crank”",
    "crumbs": [
      "Week 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#software-for-bayesian-statistics",
    "href": "01-intro.html#software-for-bayesian-statistics",
    "title": "1  Introduction",
    "section": "1.4 Software for Bayesian Statistics",
    "text": "1.4 Software for Bayesian Statistics\nThe following summarizes some of the most popular Bayesian software. Currently, JAGS and Stan are the most popular. General statistical programs like SPSS, SAS, and Stata also have some support for Bayesian analyses as well.\n\nWinBUGS\n\nBayesian inference Using Gibbs Sampling\nFree, and most popular until late 2000s. Many Bayesian scholars still use WinBUGS\nNo further development\nOne can communicate from R to WinBUGS using the package R2WinBUGS\n\nJAGS\n\nJust Another Gibbs Sampler\nVery similar to WinBUGS, but written in C++, and supports user-defined functionality\nCross-platform compatibility\nOne can communicate from R to JAGS using the package rjags or runjags\n\nStan\n\nNamed in honour of Stanislaw Ulam, who invented the Markov Chain Monte Carlo method\nUses new algorithms that are different from Gibbs sampling\nUnder very active development\nCan interface with R through the package rstan, and the R packages rstanarm and brms automates the procedure for fitting models in Stan for many commonly used models\n\n\n\n\n\n\n\n\nGigerenzer, G. (2004). Mindless statistics. The Journal of Socio-Economics, 33(5), 587–606. https://doi.org/10.1016/j.socec.2004.09.033\n\n\nLambert, B. (2018). A student’s guide to Bayesian statistics. SAGE.\n\n\nMcGrayne, S. B. (2011). The theory that would not die: How Bayes’ rule cracked the enigma code, hunted down Russian submarines, & emerged triumphant from two centuries of controversy. Yale university press.\n\n\nVan De Schoot, R., Winter, S. D., Ryan, O., Zondervan-Zwijnenburg, M., & Depaoli, S. (2017). A systematic review of Bayesian articles in psychology: The last 25 years. Psychological Methods, 22(2), 217–239. https://doi.org/10.1037/met0000100",
    "crumbs": [
      "Week 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#footnotes",
    "href": "01-intro.html#footnotes",
    "title": "1  Introduction",
    "section": "",
    "text": "Price is another important figure in mathematics and philosophy, and had taken Bayes’ theorem and applied it to insurance and moral philosophy.↩︎\nSee the paper by John Aldrich on this.↩︎",
    "crumbs": [
      "Week 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "02-probability.html",
    "href": "02-probability.html",
    "title": "\n2  Probability\n",
    "section": "",
    "text": "2.1 History of Probability",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "02-probability.html#history-of-probability",
    "href": "02-probability.html#history-of-probability",
    "title": "\n2  Probability\n",
    "section": "",
    "text": "2.1.1 Games of chance\nCorrespondence between French Mathematicians (Pierre de Fermat and Blaise Pascal) on gambling problem by Antoine Gombaud, Chevalier de Méré. The problem is roughly of the form1:\n\nImagine two people playing a multi-round game. In each round, each person has an equal chance of winning. The first person who wins six rounds will get a huge cash prize. Now, consider a scenario in which A and B have played six rounds, where A has won five and B has won one. At that time, the game had to be stopped due to a thunderstorm. Since neither A nor B have reached six wins, instead of giving the prize to either one of them, they agree to divide up the prize. What would be a fair way to do so?\n\nThe discussion led to the formalization of using mathematics to solve the problem. Basically, one way is to say if A has a 97% chance of winning the prize eventually and B has a 3% chance, then A should get 97% of the prize.",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "02-probability.html#different-ways-to-interpret-probability",
    "href": "02-probability.html#different-ways-to-interpret-probability",
    "title": "\n2  Probability\n",
    "section": "\n2.2 Different Ways to Interpret Probability",
    "text": "2.2 Different Ways to Interpret Probability\nThere are multiple perspectives for understanding probability.2 What you’ve learned in your statistics training is likely based on the frequentist interpretation of probability (and thus frequentist statistics), whereas the foundation of what you will learn in this class is the subjectivist interpretation of probability. Understanding the different perspectives on probability is helpful for understanding the Bayesian framework.\n\n\n\n\n\n\nYou don’t need to commit to one interpretation of probability in order to conduct Bayesian data analysis.\n\n\n\n\n2.2.1 Classical Interpretation\nThis is an earlier perspective and is based on counting rules. The idea is that probability is equally distributed among all “indifferent” outcomes. “Indifferent” outcomes are those where a person has no evidence to say that one outcome is more likely than another. For example, when one throws a die, one does not think that a certain number is more likely than another unless one knows that the die is biased. In this case, there are six equally likely outcomes, so the probability of each outcome is 1 / 6.\n\n\n2.2.2 Frequentist Interpretation\nThe frequentist interpretation states that probability is essentially the long-run relative frequency of an outcome. For example, to find the probability of getting a “1” when throwing a die, one can repeat the experiment many times, as illustrated below:\n\n\n\n\nTrial\nOutcome\n\n\n\n1\n2\n\n\n2\n3\n\n\n3\n1\n\n\n4\n3\n\n\n5\n1\n\n\n6\n1\n\n\n7\n5\n\n\n8\n6\n\n\n9\n3\n\n\n10\n3\n\n\n\n\n\nAnd we can plot the relative frequency of “1”s in the trials:\n\n\n\n\n\n\n\nFigure 2.1: Relative frequency when repeatedly rolling a die.\n\n\n\n\nAs you can see, with more trials, the relative frequency approaches 1 / 6. It’s the reason why in introductory statistics, many of the concepts require you to think in terms of repeated sampling (e.g., sampling distribution, \\(p\\)-values, standard errors, confidence intervals), because probability in this framework is only possible when the outcome can be repeated. It’s also the reason why we don’t talk about something like:\n\nthe probability of the null hypothesis being true, or\nthe probability that the population mean is in the interval [75.5, 80.5],\n\nbecause the population is fixed and cannot be repeated. Only the samples can be repeated, so probability in frequentist statistics is only about samples.\n\n2.2.2.1 Problem of the single case\nBecause of the frequentist’s reference to long-run relative frequency, it does not make sense to talk about the probability of an event that cannot be repeated under this framework. For example, it does not make sense to talk about\n\nthe probability that the Democrats/Republicans will win the 2028 US Presidential Election, or\nthe probability that the LA Chargers winning the 2024 Super Bowl, or\nthe probability that it will rain on Christmas Day in LA in 2024,\n\nbecause all these are specific events that cannot be repeated. However, it is common for laypeople to talk about probabilities or chances for these events.\n\n2.2.3 Subjectivist Interpretation\nThe frequentist interpretation is sometimes called the “objectivist view,” as the reference of probability is based on empirical evidence of long-run relative frequency (albeit hypothetical in many cases). In contrast, the subjectivist view of probability is based on one’s belief. For example, when I say that the probability of getting a “1” from rolling a die is 1 / 6, it reflects the state of my mind about the die. My belief can arise from different sources: Maybe I make the die and know it is a fair one; maybe I saw someone throwing the die 1,000 times, and the number of “1”s was close to 1,000 / 6, or maybe someone I trust and with authority says that the die has a 1-in-6 chance of showing a “1”.\nThe “subjective” component has been criticized a lot by frequentist scholars, sometimes unfairly. To be clear, what “subjective” here means is that probability reflects the state of one’s mind instead of the state of the world, and so it is totally fine that two people can have different beliefs about the same event. However, it does not mean that probability is arbitrary, as the beliefs are subjected to the constraints of the axioms of probability as well as the condition that the person possessing such beliefs is rational.3 Therefore, if two persons are exposed to the same information, they should form similar, though likely not identical, beliefs about the event.\nThe subjective interpretation works perfectly fine with single events, as one can have a belief about whether it rains on a particular day or a belief about a particular election result.\n\n2.2.3.1 Calibrating a subjective belief\nIn order to represent one’s belief by probability, one needs to assign a nonzero value to every plausible outcome of an event. This has been the job of odds-makers for a long time. Indeed, a lot of the development in the field of probability has to do with coming up with a fair bet. The process of assigning probabilities to outcomes of an event according to one’s belief is called calibration. For example, consider three possible outcomes for tomorrow’s weather. For simplicity, consider three mutually exclusive possible outcomes: sunny, cloudy, and rainy.\nTo calibrate my belief, consider first if you bet $10, and the return is (a) $30 for sunny, (b) $30 for cloudy, and (c) $30 for rainy. Which one will you bet? If you’re like me in LA, I’m pretty sure I’ll bet on (a), as I think that it is more likely to have a sunny day. This means that setting \\(P\\)(sunny) = \\(P\\)(cloudy) = \\(P\\)(rainy) = 1 / 3 is not a good reflection of my belief.\nNow consider the bet with the returns (a) $20 for sunny, (b) $30 for cloudy, and (c) $60 for rainy. This would reflect the belief that there is a 50% chance of a sunny day, 33.33% chance of a cloudy day, and 16.67% chance of a rainy day. Will you take the bet? This is an improvement from the last one, but I would still say a sunny day is a good bet, which suggests that the probability of 50% is too low for a sunny day. The idea is to continue iterating until it is hard to consider (a), (b), or (c) as a clear betting favorite. For me, this would end up being something like (a) $16.7 for sunny, (b) $33.3 for cloudy, and (c) $100 for rainy, which would correspond to 60% sunny, 30% cloudy, and 10% rainy.\nIf it’s hard for you to consider the gambling analogy, an alternative way is to consider how many times is a sunny day more likely than a non-sunny day, and how many times is a cloudy day more likely than a rainy day. For example, I may consider a sunny day to be twice as likely as a non-sunny day, which would give the probability of a sunny day to be 66.67%. Then, if I also think that a cloudy day is three times as likely as a rainy day, I would assign a probability of 33.33% \\(\\times\\) 3 / 4 = 25% for a cloudy day, and a probability of 33.33% \\(\\times\\) 1 / 4 = 8.33% for a rainy day.\nThe process of calibrating one’s belief plays a key role in Bayesian data analysis, namely in the form of formulating a prior probability distribution.",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "02-probability.html#basics-of-probability",
    "href": "02-probability.html#basics-of-probability",
    "title": "\n2  Probability\n",
    "section": "\n2.3 Basics of Probability",
    "text": "2.3 Basics of Probability\n\n\n\n\n\n\nKolmogorov axioms\n\n\n\nFor an event \\(A_i\\) (e.g., getting a “1” from throwing a die)\n\n\n\\(P(A_i) \\geq 0\\) [All probabilities are non-negative]\n\n\\(P(A_1 \\cup A_2 \\cup \\cdots) = 1\\) [Union of all possibilities is 1]\n\n\\(P(A_1) + P(A_2) = P(A_1 \\text{ or } A_2)\\) [Addition rule]\n\n\n\nConsider two events, for example, on throwing a die,\n\n\n\\(A\\): The number is odd\n\n\\(B\\): The number is larger than or equal to 4\n\nAssuming that die is (believed to be) fair, you can verify that the probability of \\(A\\) is \\(P(A)\\) = 3 / 6 = 1 / 2, and the probability of \\(B\\) is also \\(P(B)\\) = 3 / 6 = 1 / 2.\n\n2.3.1 Probability Distributions\n\nDiscrete event (e.g., the outcome of throwing a die or an election): probability mass. The probability is nonzero, at least for some outcomes. The graph below on the left shows the probability mass of the sum of the numbers from two dice.\n\nContinuous event (e.g., temperature): probability density.4 The probability is basically zero for any outcome. Instead, the probability density is approximated by \\(P(A \\leq a \\leq A + h) / h\\) for a very small \\(h\\).\n\nFor example, to find the probability density that a person’s well-being score is 80, we first find the probability that a person scores between 80 and 80.5 (or 80 and 80.0005), and divide that probability by 0.5 (or 0.0005). See the shaded area of the graph below on the right.\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Probability mass\n\n\n\n\n\n\n\n\n\n(b) Probability density\n\n\n\n\n\n\nFigure 2.2: Examples of probability distributions\n\n\n\n\n\n\n\n\nFor this course, as in the textbook, we use \\(P(x)\\) to mean both the probability mass for an outcome \\(x\\) when the event is discrete, and the probability density at an outcome \\(x\\) when the event is continuous.\n\n\n\n\n2.3.1.1 Example: Normal Distribution\n\\[P(x) = \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp\\left(-\\frac{1}{2}\\left[\\frac{x - \\mu}{\\sigma}\\right]^2\\right)\\]\n\n# Write a function to compute the density of an outcome x\n# for a normal distribution\nmy_normal_density &lt;- function(x, mu, sigma) {\n    exp(- ((x - mu) / sigma) ^2 / 2) / (sigma * sqrt(2 * pi))\n}\n# For example, density at x = 36 in a normal distribution\n# with mu = 50 and sigma = 10\nmy_normal_density(36, mu = 50, sigma = 10)\n\n#&gt; [1] 0.01497275\n\n\n\n2.3.2 Summarizing a Probability Distribution\nWhile it is useful to know the probability mass/density of every possible outcome, in many situations, it is helpful to summarize a distribution by some numbers.\n\n2.3.2.1 Central Tendency\n\nMean: \\(E(X) = \\int x \\cdot P(x) d x\\)\n\nMedian: 50th percentile; the median of \\(X\\) is \\(\\mathit{Mdn}_X\\) such that \\(P(X \\leq \\mathit{Mdn}_X)\\) = 1 / 2\nMode: A value with maximum probability mass/density\n\nSee Figure 2.3 (a) for examples.\n\n\n\n\n\n\n\n\n\n(a) Central Tendency\n\n\n\n\n\n\n\n\n\n(b) Interval\n\n\n\n\n\n\nFigure 2.3: Measures of central tendency and interval\n\n\n\n2.3.2.2 Dispersion\n\nVariance: \\(V(X) = E[X - E(X)]^2\\)\n\nStandard deviation: \\(\\sigma(X) = \\sqrt{V(X)}\\)\n\n\n\nMedian absolute deviation (MAD): \\(1.4826 \\times \\mathit{Mdn}(|X - \\mathit{Mdn}_X|)\\)\n\n\n2.3.2.3 Interval\nUse \\(C(X)\\) to denote an interval. A \\(W\\)% interval means \\(P(X \\in C[X]) \\approx W\\%\\)\n\nOne-sided interval: \\(C(X)\\) is half-bounded\nSymmetric \\(W\\)% interval: \\(C(X) = [L(X), U(X)]\\) is bounded, with \\(P(X &lt; L[X]) = P(X &gt; U[X]) \\approx W\\% / 2\\)\n\nAlso called equal-tailed interval\n\n\nHighest density \\(W\\)% interval (HDI): \\(P(x_c) \\geq P(x_o)\\) for every \\(x_c\\) in \\(C(X)\\) and every \\(x_o\\) outside \\(C(X)\\). In general, the HDI is the shortest \\(W\\)% interval.\n\nThe plot in Figure 2.3 (b) shows several 80% intervals.\n\n2.3.2.4 Computing Summaries of Sample Distributions Using R\n\n# Simulate data from a half-Student's t distribution with\n# df = 4, and call it sim_s\nsim_s &lt;- rt(10000, df = 4) # can be both positive and negative\nsim_s &lt;- abs(sim_s) # take the absolute values\nggplot(data.frame(x = sim_s), aes(x = x)) +\n    geom_histogram(binwidth = 0.1)\n\n\n\n\n\n\nFigure 2.4: Simulated density of a half-Student’s t distribution\n\n\n\n\n\n# Central tendency\n# (note: the mode is difficult to compute for continuous\n# variables, and rarely used in this course.)\nc(mean = mean(sim_s),\n  median = median(sim_s),\n  mode = density(sim_s, bw = \"SJ\")$x[\n      which.max(density(sim_s, bw = \"SJ\")$y)\n  ])\n\n#&gt;      mean    median      mode \n#&gt; 1.0082926 0.7426326 0.1021776\n\n# Dispersion\nc(\n    variance = var(sim_s),\n    sd = sd(sim_s),\n    mad = mad(sim_s)\n)\n\n#&gt;  variance        sd       mad \n#&gt; 1.0231058 1.0114869 0.6996741\n\n# 80% Interval\nc(`0%` = 0, quantile(sim_s, probs = .8)) # right-sided\n\n#&gt;     0%    80% \n#&gt; 0.0000 1.5598\n\nc(quantile(sim_s, probs = .2), `100%` = Inf) # left-sided\n\n#&gt;       20%      100% \n#&gt; 0.2680906       Inf\n\nquantile(sim_s, probs = c(.1, .9)) # equal-tailed/symmetric\n\n#&gt;       10%       90% \n#&gt; 0.1299027 2.1371636\n\nHDInterval::hdi(sim_s)\n\n#&gt;        lower        upper \n#&gt; 0.0003616342 2.7992620765 \n#&gt; attr(,\"credMass\")\n#&gt; [1] 0.95\n\n\n\n2.3.3 Multiple Variables\n\nJoint probability: \\(P(X, Y)\\)\n\nMarginal probability: \\[P(X) = \\int P(X, y) dy\\] \\[P(Y) = \\int P(x, Y) dx\\]\n\nThe probability that outcome \\(X\\) happens, regardless of what values \\(Y\\) take.\n\n\n\n\n\n\n\n\n\n\nFigure 2.5: Joint and Marginal Distributions\n\n\n\n\n\n2.3.3.1 Conditional Probability\nConditional probability is the probability of an event given some other information. In the real world, you can say that everything is conditional. For example, the probability of getting an odd number on throwing a die is 1/2 is conditional on the die being fair. We use \\(P(A \\mid B)\\) to represent the the conditional probability of event \\(A\\) given event \\(B\\)..\nContinuing from the previous example, \\(P(A \\mid B)\\) is the conditional probability of getting an odd number, knowing that the number is at least 4. By definition, conditional probability is the probability that both \\(A\\) and \\(B\\) happen, divided by the probability that \\(B\\) happens.\n\n\n\n\n\n\nConditional Probability\n\n\n\n\\(P(A \\mid B) = \\dfrac{P(A, B)}{P(B)}\\)\n\n\nIn the example, \\(P(A, B)\\) = 1 / 6, because 5 is the only even number \\(\\geq\\) 4 when throwing a die. Thus, \\[\n\\begin{aligned}\n    P(A \\mid B) & = 1 / 3 \\\\\n             & = \\frac{P(A, B)}{P(B)} \\\\\n             & = \\frac{1 / 6}{1 / 2}\n\\end{aligned}\n\\]\nThis picture should make it clear:\n\n\n\n\n\n\n\n\n\n\nPlease recognize that \\(P(A \\mid B) \\neq P(B \\mid A)\\). For example, when throwing a die, \\(P\\)(number is six | even number) = 1/3, but \\(P\\)(even number | number is six) is 1.\n\n\n\n\n2.3.3.2 Independence\n\n\n\n\n\n\nTwo events, \\(A\\) and \\(B\\), are independent if \\(P(A \\mid B) = P(A)\\)\n\n\n\nThis means that any knowledge of \\(B\\) does not (or should not) affect one’s belief about \\(A\\). Consider the example:\n\n\n\\(A\\): A die shows five or more\n\n\\(B\\): A die shows an odd number\n\nHere is the joint probability\n\n\n\n&gt;= 5\n&lt;= 4\n\n\n\nodd\n1/6\n2/6\n\n\neven\n1/6\n2/6\n\n\n\nSo the conditional probability of \\(P\\)(&gt;= 5 | odd) = (1/6) / (1/2) = 1/3, which is the same as \\(P\\)(&gt;= 5 | even) = (1/6) / (1/2) = 1/3. Similarly it can be verified that \\(P\\)(&lt;= 4 | odd) = \\(P\\)(&lt;= 4 | even) = 2/3. Therefore, \\(A\\) and \\(B\\) are independent.\nOn the other hand, for the example\n\n\n\\(A\\): A die shows four or more\n\n\\(B\\): A die shows an odd number\n\nthe joint probabilities are\n\n\n\n&gt;= 4\n&lt;= 3\n\n\n\nodd\n1/6\n2/6\n\n\neven\n2/6\n1/6\n\n\n\nObviously, \\(A\\) and \\(B\\) are not independent because once we know that the number is four or above, the probability of whether it is an odd number or not changes.\n\n\n\n\n\n\nIndependence can also be expressed as\n\nIf A and B are independent, \\(P(A, B) = P(A) P(B)\\)\n\n\n\n\n\n2.3.4 Law of Total Probability\nWhen we talk about conditional probability, like \\(B_1\\) = 4 or above and \\(B_2\\) = 3 or below, we can get \\(P(A \\mid B_1)\\) and \\(P(A \\mid B_2)\\) (see the figure below), we refer \\(P(A)\\) as the marginal probability, meaning that the probability of \\(A\\)  without knowledge of \\(B\\).\n\n\n\n\nIf \\(B_1, B_2, \\cdots, B_n\\) are all mutually exclusive possibilities for an event (so they add up to a probability of 1), then\n\n\n\n\n\n\nLaw of Total Probability\n\n\n\n\\[\n\\begin{aligned}\n  P(A) & = P(A, B_1) + P(A, B_2) + \\cdots + P(A, B_n)  \\\\\n       & = P(A \\mid B_1)P(B_1) + P(A \\mid B_2)P(B_2) + \\cdots + P(A \\mid B_n) P(B_n)  \\\\\n       & = \\sum_{k = 1}^n P(A \\mid B_k) P(B_k)\n\\end{aligned}\n\\]",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "02-probability.html#footnotes",
    "href": "02-probability.html#footnotes",
    "title": "\n2  Probability\n",
    "section": "",
    "text": "see the exact form at https://en.wikipedia.org/wiki/Problem_of_points↩︎\nSee http://plato.stanford.edu/entries/probability-interpret/ for more information↩︎\nIn a purely subjectivist view of probability, assigning a probability \\(P\\) to an event does not require any justifications, as long as it follows the axioms of probability. For example, I can say that the probability of me winning the lottery and thus becoming the wealthiest person on earth tomorrow is 95%, which by definition would make the probability of me not winning the lottery 5%. Most Bayesian scholars, however, do not endorse this version of subjectivist probability and require justifications of one’s beliefs (that have some correspondence to the world).↩︎\nFor many problems in the social and behavioral sciences, the measured variables are not truly continuous, but we still use continuous distributions to approximate them.↩︎",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "03-bayes-theorem.html",
    "href": "03-bayes-theorem.html",
    "title": "3  Bayes’s Theorem",
    "section": "",
    "text": "3.1 Example 1: Base rate fallacy (From Wikipedia)",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes's Theorem</span>"
    ]
  },
  {
    "objectID": "03-bayes-theorem.html#example-1-base-rate-fallacy-from-wikipedia",
    "href": "03-bayes-theorem.html#example-1-base-rate-fallacy-from-wikipedia",
    "title": "3  Bayes’s Theorem",
    "section": "",
    "text": "QuestionSolution\n\n\nA police officer stops a driver at random and does a breathalyzer test for the driver. The breathalyzer is known to detect true drunkenness 100% of the time, but in 1% of the cases, it gives a false positive when the driver is sober. We also know that, in general, for every 1,000 drivers passing through that spot, one is driving drunk. Suppose that the breathalyzer shows positive for the driver. What is the probability that the driver is truly drunk?\n\n\n\\(P(\\text{positive} | \\text{drunk}) = 1\\)\n\\(P(\\text{positive} | \\text{sober}) = 0.01\\)\n\\(P(\\text{drunk}) = 1 / 1000\\)\n\\(P(\\text{sober}) = 999 / 1000\\)\nUsing Bayes’ Theorem,\n\\[\n\\begin{aligned}\n  P(\\text{drunk} | \\text{positive})\n  & = \\frac{P(\\text{positive} | \\text{drunk}) P(\\text{drunk})}\n           {P(\\text{positive} | \\text{drunk}) P(\\text{drunk}) +\n            P(\\text{positive} | \\text{sober}) P(\\text{sober})}  \\\\\n  & = \\frac{1 \\times 0.001}{1 \\times 0.001 + 0.01 \\times 0.999} \\\\\n  & = 100 / 1099 \\approx 0.091\n\\end{aligned}\n\\]\nSo there is less than a 10% chance that the driver is drunk even when the breathalyzer shows positive.\nYou can verify that with a simulation using R:\n\nset.seed(4)\ntruly_drunk &lt;- c(rep(\"drunk\", 100), rep(\"sober\", 100 * 999))\ntable(truly_drunk)\n\n#&gt; truly_drunk\n#&gt; drunk sober \n#&gt;   100 99900\n\nbreathalyzer_test &lt;- ifelse(truly_drunk == \"drunk\",\n    # If drunk, 100% chance of showing positive\n    \"positive\",\n    # If not drunk, 1% chance of showing positive\n    sample(c(\"positive\", \"negative\"), 999000,\n        replace = TRUE, prob = c(.01, .99)\n    )\n)\n# Check the probability p(positive | sober)\ntable(breathalyzer_test[truly_drunk == \"sober\"])\n\n#&gt; \n#&gt; negative positive \n#&gt;    98903      997\n\n# 997 / 99900 = 0.00997998, so the error rate is less than 1%\n# Now, Check the probability p(drunk | positive)\ntable(truly_drunk[breathalyzer_test == \"positive\"])\n\n#&gt; \n#&gt; drunk sober \n#&gt;   100   997\n\n# 100 / (100 + 997) = 0.0911577, which is only 9.1%!",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes's Theorem</span>"
    ]
  },
  {
    "objectID": "03-bayes-theorem.html#bayesian-statistics",
    "href": "03-bayes-theorem.html#bayesian-statistics",
    "title": "3  Bayes’s Theorem",
    "section": "3.2 Bayesian Statistics",
    "text": "3.2 Bayesian Statistics\nBayesian statistics is a way to estimate some parameter \\(\\theta\\) (i.e., some quantities of interest, such as the population mean, regression coefficient, etc) by applying Bayes’ Theorem.\n\n\n\n\n\n\n\\[\nP(\\theta | D) \\propto P(D | \\theta) P(\\theta)\n\\]\n\n\n\nThere are three components in the above equality:\n\n\\(P(D | \\theta)\\), the probability that you observe data \\(D\\), given the parameter \\(\\theta\\); this is called the likelihood (Note: It is the likelihood of \\(\\theta\\), but probability about \\(y\\))\n\\(P(\\theta)\\), the probability distribution \\(\\theta\\), without referring to the data \\(D\\). This usually requires appeals to one’s degree of belief, and so is called the prior\n\\(P(\\theta | y)\\), the updated probability distribution of \\(\\theta\\), after observing the data \\(D\\); this is called the posterior\n\nOn the other hand, classical/frequentist statistics focuses solely on the likelihood function.1 In Bayesian statistics, the goal is to update one’s belief about \\(\\theta\\) based on the observed data \\(D\\).",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes's Theorem</span>"
    ]
  },
  {
    "objectID": "03-bayes-theorem.html#example-2-locating-a-plane",
    "href": "03-bayes-theorem.html#example-2-locating-a-plane",
    "title": "3  Bayes’s Theorem",
    "section": "3.3 Example 2: Locating a Plane",
    "text": "3.3 Example 2: Locating a Plane\nConsider a highly simplified scenario of locating a missing plane in the sea. Assume that we know the plane, before missing, happened to be flying at the same latitude, heading west across the Pacific, so we only need to find its longitude. We want to go out to collect debris (data) so that we can narrow the location (\\(\\theta\\)) of the plane down.\n\nPriorLikelihoodPosterior\n\n\nWe start with our prior. Assume that we have some rough idea where the plane should be, so we express our belief in a probability distribution like the following:\n\n\n\n\n\n\n\n\nFigure 3.1: Prior distribution.\n\n\n\n\n\nwhich says that our belief is that the plane is about twice more likely to be towards the east than towards the west. Below are two other options for priors (out of infinitely many), one providing virtually no information and the other encoding stronger information:\n\n\n\n\n\n\n\n\n\n\n\n(a) Noninformative prior.\n\n\n\n\n\n\n\n\n\n\n\n(b) Informative prior.\n\n\n\n\n\n\n\nFigure 3.2: More options for prior distribution.\n\n\n\nThe prior is chosen to reflect the researcher’s belief, so different researchers will likely formulate a different prior for the same problem, and that’s okay as long as the prior is reasonable and justified. Later, we will learn that in regular Bayesian analyses, with a moderate sample size, different priors generally only make negligible differences.\n\n\nNow, assume that we have collected debris in the locations shown in the graph,\n\n\n\n\n\n\n\n\nFigure 3.3\n\n\n\n\n\n\n\nNow, from Bayes’s Theorem,\n\\[\n\\text{Posterior Probability} \\propto \\text{Prior Probability} \\times\n                                       \\text{Likelihood}\n\\]\nSo we can simply multiply the prior probabilities and the likelihood to get the posterior probability for every location. A rescaling step is needed to ensure that the area under the curve will be 1, which is usually performed by the software.\n\n\n\n\n\n\n\n\nFigure 3.4\n\n\n\n\n\n\n\n\nAs illustrated below, the posterior distribution is a synthesis of (a) the prior and (b) the data (likelihood).\n\nInfluence of PriorInfluence of More Data\n\n\nFigure 3.5 shows what happen with a stronger prior:\n\n\n\n\n\n\n\n\nFigure 3.5\n\n\n\n\n\n\n\nFigure 3.6 shows what happen with 20 more data points:\n\n\n\n\n\n\n\n\nFigure 3.6",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes's Theorem</span>"
    ]
  },
  {
    "objectID": "03-bayes-theorem.html#data-order-invariance",
    "href": "03-bayes-theorem.html#data-order-invariance",
    "title": "3  Bayes’s Theorem",
    "section": "3.4 Data-Order Invariance",
    "text": "3.4 Data-Order Invariance\nIn many data analysis applications, researchers collect some data \\(D_1\\), and then collect some more data \\(D_2\\). An example would be researchers conducting two separate experiments to study the same research question. In Bayesian statistics, one can consider three ways to obtain the posterior:\n\nUpdate the belief with \\(D_1\\), and then with \\(D_2\\)\nUpdate the belief with \\(D_2\\), and then with \\(D_1\\)\nUpdate the belief with both \\(D_1\\) and \\(D_2\\) simultaneously\n\nWhether these three ways give the same posterior depends on whether data-order invariance holds. If the inference of \\(D_1\\) does not depend on \\(D_2\\), or vice versa, then all three ways lead to the same posterior. Specifically, if we have conditional independence such that \\[\nP(D_1, D_2 \\mid \\theta) = P(D_1 \\mid \\theta) P(D_2 \\mid \\theta),\n\\] then one can show all three ways give the same posterior (see section 4.4 and 4.5 of Johnson et al., 2022).\n\n\n\n\n\n\nExchangeability*\n\n\n\nExchangeability is an important concept in Bayesian statistics. Data are exchangeable when the joint distribution, \\(P(D_1, \\ldots, D_N)\\), does not depend on the ordering of the data. A simple way to think about it is if you scramble the order of your outcome variable in your data set and still can obtain the same statistical results, then the data are exchangeable. An example situation where data are not exchangeable is\n\n\\(D_1\\) is from year 1990, \\(D_2\\) is from year 2020, and the parameter \\(\\theta\\) changes from 1990 to 2020\n\nWhen data are exchangeable, conditional independence would generally hold.2",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes's Theorem</span>"
    ]
  },
  {
    "objectID": "03-bayes-theorem.html#bernoulli-likelihood",
    "href": "03-bayes-theorem.html#bernoulli-likelihood",
    "title": "3  Bayes’s Theorem",
    "section": "3.5 Bernoulli Likelihood",
    "text": "3.5 Bernoulli Likelihood\nFor binary data \\(y\\) (e.g., coin flip, pass/fail, diagnosed/not), an intuitive way to analyze is to use a Bernoulli model: \\[\n  \\begin{aligned}\n    P(y = 1 \\mid \\theta) = \\theta \\\\\n    P(y = 0 \\mid \\theta) = 1 - \\theta\n  \\end{aligned},\n\\] which is more compactly written as \\[\nP(y \\mid \\theta) = \\theta^y (1 - \\theta)^{(1 - y)},\n\\] where \\(\\theta \\in [0, 1]\\) is the probability of a “1”. You can verify that the compact form is the same as the longer form.\n\n3.5.1 Multiple Observations\nWhen there are more than one \\(y\\), say \\(y_1, \\ldots, y_N\\), that are conditionally independent, we have \\[\n  \\begin{aligned}\n    P(y_1, \\ldots, y_N \\mid \\theta) & = \\prod_{i = 1}^N P(y_i \\mid \\theta) \\\\\n    & = \\theta^{\\sum_{i = 1}^N y_i} (1 - \\theta)^{\\sum_{i = 1}^N (1 - y_i)} \\\\\n    & = \\theta^z (1 - \\theta)^{N - z}\n  \\end{aligned},\n\\] where \\(z\\) is the number of “1”s (e.g., the number of heads in coin flips). Note that the likelihood only depends on \\(z\\), not the individual \\(y\\)s. In other words, the likelihood is the same as long as there are \\(z\\) heads, regardless of when those heads occur.\nLet’s say \\(N\\) = 4 and \\(z\\) = 1. We can plot the likelihood in R:\n\n# Write the likelihood as a function of theta\nlik &lt;- function(th, num_flips = 4, num_heads = 1) {\n    th ^ num_heads * (1 - th) ^ (num_flips - num_heads)\n}\n# Likelihood of theta = 0.5\nlik(0.5)\n\n#&gt; [1] 0.0625\n\n# Plot the likelihood\nggplot(data.frame(th = c(0, 1)), aes(x = th)) +\n    # `stat_function` for plotting a function\n    stat_function(fun = lik) +\n    # use `expression()` to get greek letters\n    labs(x = expression(theta),\n    y = \"Likelihood with N = 4 and z = 1\")\n\n\n\n\n\n\n\nFigure 3.7: Binomial likelihood function with \\(N\\) = 4 and \\(z\\) = 1\n\n\n\n\n\n\n\n3.5.2 Setting Priors\nRemember again the relationship between the prior and the posterior: \\[P(\\theta | y) \\propto P(y | \\theta) P(\\theta)\\] The posterior distributions are mathematically determined once the priors and the likelihood are set. However, the mathematical form of the posterior is sometimes very difficult to deal with.\nOne straightforward, brute-force method is to discretize the parameter space into a number of points. For example, by taking \\(\\theta\\) = 0, 0.05, 0.10, . . . , 0.90, 0.95, 1.00, one can evaluate the posterior at these 21 grid points.\nLet’s use a prior that peaks at 0.5 and linearly decreases to both sides. I assume that \\(\\theta\\) = 0.5 is twice as likely as \\(\\theta = 0.25\\) or \\(\\theta = 0.75\\) to reflect my belief that the coin is more likely to be fair.\n\n# Define a grid for the parameter\ngrid_df &lt;- data.frame(th = seq(0, 1, by = 0.05))\n# Set the prior mass for each value on the grid\ngrid_df$pth &lt;- c(0:10, 9:0)  # linearly increasing, then decreasing\n# Convert pth to a proper distribution such that the value\n# sum to one\n1grid_df$pth &lt;- grid_df$pth / sum(grid_df$pth)\n# Plot the prior\nggplot(grid_df, aes(x = th, y = pth)) +\n    geom_col(aes(x = th, y = pth),\n        width = 0.01,\n    ) +\n    labs(y = expression(P(theta)), x = expression(theta))\n\n\n1\n\nThis line ensures that the probability values sum to one. This is a trick we will use to obtain the posterior probability.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrior Predictive Distribution\n\n\n\nOne way to check whether the prior is appropriate is to use the prior predictive distribution. Bayesian models are generative because they can be used to simulate data. The prior predictive distribution can be obtained by first simulating some \\(\\theta\\) values from the prior distribution and then simulating a data set for each \\(\\theta\\).\n\n# Draw one theta\nnum_trials &lt;- 4  # number of draws\nsim_th1 &lt;- sample(grid_df$th, size = 1,\n                  # based on prior probability\n                  prob = grid_df$pth)\n# Simulate new data of four flips based on model\nsim_y1 &lt;- rbinom(num_trials, size = 1, prob = sim_th1)\n\n# Repeat many times\n# Set number of simulation draws\nnum_draws &lt;- 1000\nsim_th &lt;- sample(grid_df$th, size = num_draws, replace = TRUE,\n                 # based on prior probability\n                 prob = grid_df$pth)\n# Use a for loop\n# Initialize output\nsim_y &lt;- matrix(NA, nrow = num_trials, ncol = num_draws)\nfor (s in seq_len(num_draws)) {\n    # Store simulated data in the sth column\n    sim_y[, s] &lt;- rbinom(num_trials, size = 1, prob = sim_th[s])\n}\n# Show the first 10 simulated data sets based on prior:\nsim_y[, 1:10]\n\n#&gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n#&gt; [1,]    1    0    0    1    0    1    0    0    0     1\n#&gt; [2,]    0    0    0    1    1    0    1    0    1     1\n#&gt; [3,]    1    0    0    1    0    0    0    1    1     1\n#&gt; [4,]    1    0    1    1    1    0    0    1    1     0\n\n# Show the distribution of number of heads\nsim_heads &lt;- colSums(sim_y)\nggplot(data.frame(z = sim_heads), aes(x = z)) +\n    geom_bar()\n\n\n\n\n\n\n\n\nThe outcome seems to fit our intuition that it’s more likely to be half heads and half tails, but there is a lot of uncertainty.\n\n\n\n\n3.5.3 Summarizing the Posterior\n\ngrid_df &lt;- grid_df |&gt;\n    mutate(\n        # Use our previously defined lik() function\n        py_th = lik(th, num_flips = 4, num_heads = 1),\n        # Product of prior and likelihood\n        `prior x lik` = pth * py_th,\n        # Scaled the posterior\n        pth_y = `prior x lik` / sum(`prior x lik`)\n    )\n# Print a table\nknitr::kable(grid_df)\n\n\n\n\nth\npth\npy_th\nprior x lik\npth_y\n\n\n\n\n0.00\n0.00\n0.0000000\n0.0000000\n0.0000000\n\n\n0.05\n0.01\n0.0428687\n0.0004287\n0.0073359\n\n\n0.10\n0.02\n0.0729000\n0.0014580\n0.0249500\n\n\n0.15\n0.03\n0.0921188\n0.0027636\n0.0472914\n\n\n0.20\n0.04\n0.1024000\n0.0040960\n0.0700927\n\n\n0.25\n0.05\n0.1054688\n0.0052734\n0.0902416\n\n\n0.30\n0.06\n0.1029000\n0.0061740\n0.1056525\n\n\n0.35\n0.07\n0.0961187\n0.0067283\n0.1151381\n\n\n0.40\n0.08\n0.0864000\n0.0069120\n0.1182815\n\n\n0.45\n0.09\n0.0748688\n0.0067382\n0.1153071\n\n\n0.50\n0.10\n0.0625000\n0.0062500\n0.1069530\n\n\n0.55\n0.09\n0.0501187\n0.0045107\n0.0771891\n\n\n0.60\n0.08\n0.0384000\n0.0030720\n0.0525695\n\n\n0.65\n0.07\n0.0278687\n0.0019508\n0.0333832\n\n\n0.70\n0.06\n0.0189000\n0.0011340\n0.0194056\n\n\n0.75\n0.05\n0.0117188\n0.0005859\n0.0100268\n\n\n0.80\n0.04\n0.0064000\n0.0002560\n0.0043808\n\n\n0.85\n0.03\n0.0028687\n0.0000861\n0.0014727\n\n\n0.90\n0.02\n0.0009000\n0.0000180\n0.0003080\n\n\n0.95\n0.01\n0.0001187\n0.0000012\n0.0000203\n\n\n1.00\n0.00\n0.0000000\n0.0000000\n0.0000000\n\n\n\n\n\n\n# Plot the prior/likelihood and the posterior\nggplot(data = grid_df, aes(x = th)) +\n    geom_col(aes(x = th - 0.005, y = pth, fill = \"prior\"),\n        width = 0.01,\n    ) +\n    geom_col(aes(x = th + 0.005, y = py_th / sum(py_th),\n        fill = \"scaled likelihood\"), width = 0.01,\n    ) +\n    labs(fill = NULL, y = NULL, x = expression(theta)) +\n    theme(legend.position = \"top\")\nggplot(data = grid_df, aes(x = th)) +\n    geom_col(aes(x = th, y = pth_y), width = 0.01) +\n    labs(\n        fill = NULL, y = NULL, title = \"Posterior\",\n        x = expression(theta)\n    )\n\n\n\n\n\n\n\n\n\n\n\n(a) Prior and likelihood\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Posterior\n\n\n\n\n\n\n\nFigure 3.8: Bernoulli posterior distribution\n\n\n\n\nFigure 3.8 (b) shows the posterior distribution, which represents our updated belief about \\(\\theta\\). We can summarize it by simulating \\(\\theta\\) values from it and compute summary statistics:\n\n# Define a function for computing posterior summary\nsumm_draw &lt;- function(x) {\n    c(\n        mean = mean(x),\n        median = median(x),\n        sd = sd(x),\n        mad = mad(x),\n        `ci.1` = quantile(x, prob = .1, names = FALSE),\n        `ci.9` = quantile(x, prob = .9, names = FALSE)\n    )\n}\n# Sample from the posterior\npost_samples &lt;- sample(\n    grid_df$th,\n    size = 1000, replace = TRUE,\n    prob = grid_df$pth_y\n)\nsumm_draw(post_samples)\n\n#&gt;      mean    median        sd       mad      ci.1      ci.9 \n#&gt; 0.3848000 0.4000000 0.1538429 0.1482600 0.2000000 0.6000000\n\n# Alternatively, use the `posterior` package\ndata.frame(theta = post_samples) |&gt;\n    posterior::summarize_draws()\n\n\n  \n\n\n\n\nInfluence of Sample SizeInfluence of Prior\n\n\nIf, instead, we have \\(N\\) = 40 and \\(z\\) = 10, the posterior will be more similar to the likelihood.\n\ngrid_df2 &lt;- grid_df |&gt;\n    mutate(\n        # Use our previously defined lik() function\n        py_th = lik(th, num_flips = 40, num_heads = 10),\n        # Product of prior and likelihood\n        `prior x lik` = pth * py_th,\n        # Scaled the posterior\n        pth_y = `prior x lik` / sum(`prior x lik`)\n    )\n# Plot the prior/likelihood and the posterior\nggplot(data = grid_df2, aes(x = th)) +\n    geom_col(aes(x = th - 0.005, y = pth, fill = \"prior\"),\n        width = 0.01,\n    ) +\n    geom_col(aes(x = th + 0.005, y = py_th / sum(py_th),\n        fill = \"scaled likelihood\"), width = 0.01,\n    ) +\n    labs(fill = NULL, y = NULL, x = expression(theta)) +\n    theme(legend.position = \"top\")\n\n\n\n\n\n\n\nggplot(data = grid_df2, aes(x = th)) +\n    geom_col(aes(x = th, y = pth_y), width = 0.01) +\n    labs(\n        fill = NULL, y = NULL, title = \"Posterior\",\n        x = expression(theta)\n    )\n\n\n\n\n\n\n\n\n\n# Sample from the posterior\npost_samples &lt;- sample(\n    grid_df2$th,\n    size = 1000, replace = TRUE,\n    prob = grid_df2$pth_y\n)\nsumm_draw(post_samples)\n\n#&gt;       mean     median         sd        mad       ci.1       ci.9 \n#&gt; 0.28085000 0.30000000 0.06542215 0.07413000 0.20000000 0.35000000\n\n\n\n\nIf we have a very strong prior concentrated at \\(\\theta\\) = .5, but still with \\(N\\) = 40 and \\(z\\) = 10, the posterior will be more similar to the prior.\n\ngrid_df3 &lt;- grid_df |&gt;\n    mutate(\n        # stronger prior\n        pth = pth ^ 3,\n        # scale the prior to sume to 1\n        pth = pth / sum(pth),\n        # Use our previously defined lik() function\n        py_th = lik(th, num_flips = 4, num_heads = 1),\n        # Product of prior and likelihood\n        `prior x lik` = pth * py_th,\n        # Scaled the posterior\n        pth_y = `prior x lik` / sum(`prior x lik`)\n    )\n# Plot the prior/likelihood and the posterior\nggplot(data = grid_df3, aes(x = th)) +\n    geom_col(aes(x = th - 0.005, y = pth, fill = \"prior\"),\n        width = 0.01,\n    ) +\n    geom_col(aes(x = th + 0.005, y = py_th / sum(py_th),\n        fill = \"scaled likelihood\"), width = 0.01,\n    ) +\n    labs(fill = NULL, y = NULL, x = expression(theta)) +\n    theme(legend.position = \"top\")\n\n\n\n\n\n\n\nggplot(data = grid_df3, aes(x = th)) +\n    geom_col(aes(x = th, y = pth_y), width = 0.01) +\n    labs(\n        fill = NULL, y = NULL, title = \"Posterior\",\n        x = expression(theta)\n    )\n\n\n\n\n\n\n\n\n\n# Sample from the posterior\npost_samples &lt;- sample(\n    grid_df3$th,\n    size = 1000, replace = TRUE,\n    prob = grid_df3$pth_y\n)\nsumm_draw(post_samples)\n\n#&gt;      mean    median        sd       mad      ci.1      ci.9 \n#&gt; 0.4493000 0.4500000 0.1096656 0.0741300 0.3000000 0.6000000\n\n# Alternatively, use the `posterior` package\ndata.frame(theta = post_samples) |&gt;\n    posterior::summarize_draws()\n\n\n  \n\n\n\n\n\n\n\n\n3.5.4 Remark on Grid Approximation\nIn this note, we discretized \\(\\theta\\) into a finite number of grid points to compute the posterior, mainly for pedagogical purposes. A big limitation is that our posterior will have no density for values other than the chosen grid points. While increasing the number of grid points (e.g., 1,000) can give more precision, the result is still not truly continuous. A bigger issue is that the computation breaks down when there is more than one parameter; if there are \\(p\\) parameters, with 1,000 grid points per parameter, one needs to evaluate the posterior probability for \\(1,000^p\\) grid points, which is not feasible even with modern computers. So more efficient algorithms, namely Markov chain Monte Carlo (MCMC) methods, will be introduced as we progress in the course.\n\n\n\n\n\n\nJohnson, A. A., Ott, M. Q., & Dogucu, M. (2022). Bayes rules! An introduction to Bayesian modeling with R. CRC Press.",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes's Theorem</span>"
    ]
  },
  {
    "objectID": "03-bayes-theorem.html#footnotes",
    "href": "03-bayes-theorem.html#footnotes",
    "title": "3  Bayes’s Theorem",
    "section": "",
    "text": "The likelihood function in classical/frequentist statistics is usually written as \\(P(y; \\theta)\\). You will notice that here, I write the likelihood for classical/frequentist statistics to be different from the one used in Bayesian statistics. This is intentional: In frequentist conceptualization, \\(\\theta\\) is fixed, and it does not make sense to talk about the probability of \\(\\theta\\). This implies that we cannot condition on \\(\\theta\\), because conditional probability is defined only when \\(P(\\theta)\\) is defined.↩︎\nThe de Finetti’s theorem shows that when the data are exchangeable and can be considered an infinite sequence (i.e., not from a tiny finite population), then the data are conditionally independent given some \\(\\theta\\).↩︎",
    "crumbs": [
      "Week 2",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bayes's Theorem</span>"
    ]
  },
  {
    "objectID": "04-beta-bernoulli-model.html",
    "href": "04-beta-bernoulli-model.html",
    "title": "\n4  Beta-Bernoulli Model\n",
    "section": "",
    "text": "4.1 Steps of Bayesian Data Analysis\nSome authors described the process as “turning the Bayesian Crank,” as the same workflow applies to a variety of research scenarios.\nAdapted from Gelman et al. (2020), I conceptualize Bayesian data analysis as the following steps:",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Beta-Bernoulli Model</span>"
    ]
  },
  {
    "objectID": "04-beta-bernoulli-model.html#steps-of-bayesian-data-analysis",
    "href": "04-beta-bernoulli-model.html#steps-of-bayesian-data-analysis",
    "title": "\n4  Beta-Bernoulli Model\n",
    "section": "",
    "text": "Identify/Collect the data required to answer the research questions.\n\nAs a general recommendation, it is helpful to visualize the data to get a sense of how they look, as well as to inspect for potential anomalies in the data collection.\n\n\n\nChoose an initial statistical model for the data in relation to the research questions. The model should have some theoretical justification and have parameters that are meaningful for the research questions. However, it is unlikely that any chosen model will capture everything important in the data, and this initial model will be modified and expanded in later steps.\n\nSpecify prior distributions for the model parameters. Although this is a subjective endeavor, the priors chosen should be sensible to a skeptical audience.\n\nCheck the prior distributions. It is recommended you conduct a prior predictive check, by simulating fake data based on the chosen model and prior distributions. This is especially important for complex models as the parameters are more difficult to interpret.\n\nObtain the posterior distributions for the model parameters. As described below and later in the course, this can be obtained by analytical or various mathematical approximations.\n\nFor mathematical approximations, one should check the algorithms for convergence to make sure the results closely mimic the target posterior distributions.\n\n\nConduct a posterior predictive check to examine the fit between the model and the data, i.e., whether the chosen model with the estimated parameters generates predictions that deviate from the data being analyzed on important features.\nIt is unlikely that your initial model fully describes the major aspects of the data as pertaining to your research questions. Therefore, one should repeat steps 2 to 6 to specify and compare different models.\nIf the fit between the model and the data is deemed satisfactory, one can proceed to interpret the results in the context of the research questions. It is also important to visualize the results in ways that are meaningful for the analysis.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Beta-Bernoulli Model</span>"
    ]
  },
  {
    "objectID": "04-beta-bernoulli-model.html#beta-bernoulli-example",
    "href": "04-beta-bernoulli-model.html#beta-bernoulli-example",
    "title": "\n4  Beta-Bernoulli Model\n",
    "section": "\n4.2 Beta-Bernoulli Example",
    "text": "4.2 Beta-Bernoulli Example\nWe will be using a built-in data set in R about patients diagnosed with AIDS in Australia before July 1, 1991. Here is a description of the variables (from the R documentation):\n\n\nFigure from https://commons.wikimedia.org/wiki/File:Australia_states_1931-present.png\n\n\n\nstate: Grouped state of origin: “NSW”includes ACT and “other” is WA, SA, NT, and TAS.\n\nsex: Sex of patient.\n\ndiag:(Julian) date of diagnosis.\n\ndeath: (Julian) date of death or end of observation.\n\nstatus: “A” (alive) or “D” (dead) at end of observation.\n\nT.categ: Reported transmission category.\n\nage: Age (years) at diagnosis.\n\nYou should always first plot your data and get some summary statistics:\n\ndata(\"Aids2\", package = \"MASS\")\nhead(Aids2)\n\n\n  \n\n\n\n\npairs.panels(Aids2, ellipses = FALSE)\n\n\n\n\n\n\n\nWe will be using the status variable. Our simple research question is:\n\nWhat was the death rate of AIDS in Australia when the data were collected?\n\n\n4.2.1 Bernoulli Model\nIf we assume that the outcomes of the observations are exchangeable, meaning that the observations can be reordered in any way and still give the same inference, then one can choose a model: \\[\ny_i \\sim \\text{Bern}(\\theta) \\text{ for }i = 1, 2, \\ldots, N\n\\]\n\n\n\\(y_i\\) = status of observation \\(i\\) (0 = “A”, 1 = “D”)\n\n\\(N\\) = number of patients in the data set\n\n\\(\\theta\\) = probability of “D”1\n\n\n\nThe model states that: the sample data \\(y\\) follows a Bernoulli distribution with \\(n\\) with a parameter \\(\\theta\\)\n\n\n\n\n\n\n\nWhen the data consist of binary observations, the variable is called a Bernoulli variable. It is conventional to denote one outcome as success and code it as 1, and the other as failure and code it as 0 (poor terminology, maybe, but that’s by convention). Therefore, in the AIDS example, each observation is considered a “Bernoulli” outcome (Alive vs. Dead).\n\n\n\n\n4.2.2 Exchangeability\nTo illustrate exchangeability in an example, say we take 6 rows in our data set:\n\n\n\n  \n\n\n\nNow, when we reorder the column status to something like:\n\n\n\n  \n\n\n\nIf the results are expected to be the same, then we say that the observations are assumed exchangeable. It happens when we assume that all observations have one common mean. However, if we think that there is a mean for females and a different mean for males, we cannot reorder the outcome randomly because they are no longer exchangeable (i.e., you cannot exchange a female score for a male score and expect to get the same results).\n\n\n\n\n\n\nExchangeability\n\n\n\nA set of observations is said to be exchangeable if their joint probability distribution stays the same under all permutations. Roughly speaking, it means that the observations can be reordered and still provide the same inferences.\n\n\n\n4.2.3 Check the Support\nIt is important to identify the support of the parameter, \\(\\theta\\). Because \\(\\theta\\) is a probability, its support is \\([0, 1]\\), meaning it is continuous and can take any value from 0 to 1. For a continuous parameter, there are infinitely many possible values, and it is impossible to specify our beliefs for each value. So, more commonly, we choose a probability density function with the same support as the parameter to express our prior belief.\n\n4.2.4 Conjugate Prior: Beta Distribution\nA commonly used family of prior distributions for a Bernoulli/binomial model is the Beta distribution, which has two parameters. We can write the prior as \\[P(\\theta) \\sim \\text{Beta}(a, b)\\]\n\\(a\\) and \\(b\\) are the two hyperparameters. Here are a few examples:\n\n\n\n\n\n\n\nFigure 4.1: Beta distributions with different a and b values\n\n\n\n\nYou will notice that when \\(a &gt; b\\), there is more density closer to the right region (i.e., larger \\(\\theta\\)), and vice versa. Also, the variance decreases when \\(a\\) and \\(b\\) become larger.2\nA nice interpretation of \\(a\\) and \\(b\\) in a Beta prior distribution is to consider\n\n\n\\(a - 1\\) = number of prior ‘successes’ (e.g., “D”)\n\n\\(b - 1\\) = number of prior ‘failures’ (e.g., “A”)\n\nTherefore, with \\(\\text{Beta}(1, 1)\\), one has seen 0 prior success and 0 failure, meaning that there is no prior information (i.e., noninformative). Therefore, it makes sense that all \\(\\theta\\) values are equally likely. On the other hand, if one chooses \\(\\text{Beta}(10, 20)\\), one has seen 9 prior successes and 19 prior failures, so one has quite a lot of prior information (indeed more than the data with only 10 observations), so this is a strong prior.\n\nThe smaller the variance of the prior distribution, the stronger one’s belief before looking at the data, the more prior information\n\nSo by manipulating the values of \\(a\\) and \\(b\\), which are sometimes called hyperparameters, you can control the shape of the prior distribution as well as its strength, so it is quite flexible. Another advantage of using a beta prior is that it is a conjugate prior of the Bernoulli model, which means that the posterior distribution \\(P(\\theta \\mid y)\\) is also a beta distribution, the same as the prior distribution, although with different parameter values.\n\n\n\n\n\n\nConjugate Prior\n\n\n\nFor a specific model, conjugate priors yield posterior distributions in the same distribution family as the priors\n\n\nConjugacy greatly simplifies the computational burden for Bayesian analyses, so conjugate priors are almost the only ones used in earlier literature. However, this limited the applications of Bayesian methods, as for many problems, no conjugate priors can provide a realistic representation of one’s belief. Modern Bayesian analysis instead relies on simulation-based methods to approximate the posterior distribution, which can accommodate almost any kind of prior distribution. Aside from a few examples in this note, mainly for pedagogical purposes, we will be using simulation-based methods in the coming weeks.\n\n\n\n\n\n\nProof of Conjugacy*\n\n\n\nTo derive the form of the posterior, first recognize that the Beta distribution has the form:\n\\[\n\\begin{aligned}\n  P(\\theta) & = \\mathrm{B}^{-1}(a, b) \\theta^{a - 1} (1 - \\theta)^{b - 1} \\\\\n  & \\propto \\theta^{a - 1} (1 - \\theta)^{b - 1}\n\\end{aligned}\n\\]\nWhere \\(\\mathrm{B}(\\cdot)\\) is the beta function which is not very important for the class. As the density function is a function of \\(\\theta\\), it suffices to write only the terms that involve \\(\\theta\\).\nSimilarly, \\[\nP(\\mathbf{y} \\mid \\theta) \\propto \\theta^z (1 - \\theta)^{N - z}.\n\\]\nTherefore,\n\\[\n\\begin{aligned}\n  P(\\theta \\mid \\mathbf{y}) & \\propto P(y \\mid \\theta) P(\\theta)  \\\\\n                & \\propto \\theta^z (1 - \\theta)^{N - z}\n                          \\theta^{a - 1} (1 - \\theta)^{b - 1}  \\\\\n                & = \\theta^{a + z - 1} (1 - \\theta)^{b + N - z - 1}.\n\\end{aligned}\n\\]\nIf we let \\(a^* = a + z\\), \\(b^* = b + N - z\\), we can see that \\(P(\\theta \\mid \\mathbf{y})\\) is in the same form as the prior with \\(a\\) and \\(b\\) replaced by \\(a^*\\) and \\(b^*\\). Therefore, the posterior is also a beta distribution. So the beta distribution is a conjugate prior for the Bernoulli model.\n\n\nIn this example, we will choose a weakly informative Beta(2, 2) prior, which represents a weak belief as below:\n\nggplot(data.frame(th = c(0, 1)), aes(x = th)) +\n    stat_function(fun = dbeta, args = list(shape1 = 2, shape2 = 2)) +\n    ylim(0, 3) +\n    labs(y = \"\", x = expression(theta), title = \"Beta(2, 2)\")\n\n\n\n\n\n\nFigure 4.2: A weakly informative Beta(2, 2) prior\n\n\n\n\n\n\n\n\n\n\nDon’t Be Stubborn\n\n\n\n\nA good prior should give a non-zero probability/density for all possible values of a parameter\n\nOtherwise, if the prior density for some parameter values is zero, the posterior density will be zero, regardless of how much the data support those parameter values\n\n\n\n4.2.5 Data\n\ncount(Aids2, status)\n\n\n  \n\n\n\nThe likelihood function is highly concentrated. I ran into some numerical issues as the computation gave zero, so I plotted the log-likelihood instead.\n\nloglik &lt;- function(th, N = 1082 + 1761, z = 1761) {\n    z * log(th) + (N - z) * log(1 - th)\n}\nggplot(data.frame(th = c(0.61, 0.63)), aes(x = th)) +\n    stat_function(fun = loglik, n = 501) +\n    labs(x = expression(theta), y = \"Log-likelihood\")\n\n\n\n\n\n\nFigure 4.3: Log-likelihood function of the theta parameter\n\n\n\n\nNote I only show a range of [0.610, 0.630] for the x-axis, which contains where the likelihood (thus also the log-likelihood) peaked.\n\n4.2.6 Posterior\nBased on the conjugacy, the posterior of \\(\\theta\\) is Beta(1,807, 1,116). As we are using a conjugate prior, the posterior is also a Beta distribution: \\[\nP(\\theta \\mid y) \\sim \\text{Beta}(a + z, b + N - z),\n\\] which is a distribution for \\(a + z - 1\\) successes and \\(b + N - z\\) failures. This makes perfect sense as our prior information has \\(a - 1\\) successes and \\(b - 1\\) failures, and from our data, we have \\(y\\) successes and \\(n - y\\) failures, so our updated belief is based on adding up those successes and failures.\n\n4.2.7 Summarize the posterior\n\nset.seed(2119)\nnum_draws &lt;- 1000\nsim_theta &lt;- rbeta(num_draws, shape1 = 1807, shape2 = 1116)\nc(`Bayes estimate` = mean(sim_theta),\n  `Posterior median` = median(sim_theta),\n  `Posterior SD` = sd(sim_theta),\n  `MAD` = mad(sim_theta),\n  `90% Credible interval (equal-tailed)` = quantile(sim_theta, probs = c(.1, .9)),\n  `90% HDI` = HDInterval::hdi(sim_theta, credMass = .9))\n\n                          Bayes estimate \n                             0.618209694 \n                        Posterior median \n                             0.618382945 \n                            Posterior SD \n                             0.008829290 \n                                     MAD \n                             0.009254166 \n90% Credible interval (equal-tailed).10% \n                             0.606862338 \n90% Credible interval (equal-tailed).90% \n                             0.628990588 \n                           90% HDI.lower \n                             0.604051851 \n                           90% HDI.upper \n                             0.632766654 \n\n\n\n4.2.8 Posterior Predictive Check\nNow, we need to know whether the model fits the data well. We do not have much to check for a Bernoulli model if we only have the status variable. However, as there is information for other variables, we can use them to check the exchangeability assumption. For example, we can ask whether the data from different state categories are exchangeable. The death rate across the 4 state categories are\n\n\n       status\nstate      A    D\n  NSW    664 1116\n  Other  107  142\n  QLD     78  148\n  VIC    233  355\n\n\n       status\nstate           A         D\n  NSW   0.3730337 0.6269663\n  Other 0.4297189 0.5702811\n  QLD   0.3451327 0.6548673\n  VIC   0.3962585 0.6037415\n\n\nWe can now generate predictions from our posterior distribution and model.\n\nplist &lt;- vector(\"list\", 12L)\nplist[[1]] &lt;- ggplot(\n    Aids2,\n    aes(x = state, y = mean(status == \"D\"), fill = state)\n) +\n    geom_bar(stat = \"identity\") +\n    guides(fill = \"none\") +\n    labs(x = \"Observed data\", y = \"Number of Deaths\") +\n    theme(axis.title.x = element_text(color = \"red\")) +\n    ylim(0, 1200)\nfor (i in 1:11) {\n    # Get the a value from posterior samples\n    theta_post &lt;- rbeta(1, 1763, 1084)\n    # For each plausible theta value, generate a status variable\n    status_new &lt;- sample(c(\"D\", \"A\"), nrow(Aids2),\n        replace = TRUE,\n        prob = c(theta_post, 1 - theta_post)\n    )\n    df_new &lt;- Aids2 |&gt;\n        mutate(status = factor(status_new))\n    plist[[i + 1]] &lt;- plist[[1]] %+% df_new +\n        labs(x = paste(\"Simulated data\", i)) +\n        theme(axis.title.x = element_text(color = \"black\"))\n}\ngridExtra::grid.arrange(grobs = plist, nrow = 3)\n\n\n\n\n\n\nFigure 4.4: Posterior predictive check by comparing the observed data with 11 simulated data sets based on the model\n\n\n\n\nSo the observed data (the first subplot) look similar to the simulated data. We can also conduct a posterior predictive check by a test statistic for subgroups. Here, we will use the bayesplot package and look at fit across groups:\n\n# Draw posterior samples of theta\npost_sample &lt;- rbeta(1e4, 1807, 1116)\n# Initialize a S by N matrix to store the simulated data\ny_tilde &lt;- matrix(NA,\n                  nrow = length(post_sample),\n                  ncol = length(Aids2$status))\nfor (s in seq_along(post_sample)) {\n    theta_s &lt;- post_sample[s]\n    status_new &lt;- sample(c(\"D\", \"A\"), nrow(Aids2),\n        replace = TRUE,\n        prob = c(theta_s, 1 - theta_s)\n    )\n    y_tilde[s,] &lt;- as.numeric(status_new == \"D\")\n}\nbayesplot::ppc_stat_grouped(\n    as.numeric(Aids2$status == \"D\"),\n    yrep = y_tilde,\n    group = Aids2$state\n)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nFigure 4.5: Posterior predictive check by states\n\n\n\n\nIf the fit is good, the mean, indicated by the darker line, should be within the simulated distribution based on the model. So the model that assumes observations are exchangeable across states is not too off, although it seems fitting less well for Other states.\n\n4.2.8.1 Another check on age\n\n\n# Create an age group indicator\nage50 &lt;- factor(Aids2$age &gt; 50, labels = c(\"&lt;= 50\", \"&gt; 50\"))\n# Draw posterior samples of theta\npost_sample &lt;- rbeta(1e4, 1807, 1116)\n# Initialize a S by N matrix to store the simulated data\ny_tilde &lt;- matrix(NA,\n                  nrow = length(post_sample),\n                  ncol = length(Aids2$status))\nfor (s in seq_along(post_sample)) {\n    theta_s &lt;- post_sample[s]\n    status_new &lt;- sample(c(\"D\", \"A\"), nrow(Aids2),\n        replace = TRUE,\n        prob = c(theta_s, 1 - theta_s)\n    )\n    y_tilde[s,] &lt;- as.numeric(status_new == \"D\")\n}\nbayesplot::ppc_stat_grouped(\n    as.numeric(Aids2$status == \"D\"),\n    yrep = y_tilde,\n    group = age50\n)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nFigure 4.6: Posterior predictive check by age groups (&lt;= 50 vs. &gt; 50)\n\n\n\n\nAs can be seen, the model seems off for those aged 50+.\n\n4.2.9 Comparison to frequentist results\nUsing maximum likelihood, the estimated death rate would be \\(\\hat \\theta = 1761 / 2843 = 0.62\\), with a standard error (SE) of \\(\\sqrt{0.62 (1 - 0.62) / n} = 0.0091\\), with a 90% confidence interval of \\([0.6, 0.63]\\), which is similar to the interval with Bayesian inference.\n\n4.2.10 Sensitivity to different priors\n\n\n\n\n\n\n\nFigure 4.7: Sensitivity of posterior to different priors\n\n\n\n\nYou can see one needs (a) a very strong prior (equivalent to 600 data points) and (b) the prior and the data not agreeing to get a substantially different conclusion.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Beta-Bernoulli Model</span>"
    ]
  },
  {
    "objectID": "04-beta-bernoulli-model.html#footnotes",
    "href": "04-beta-bernoulli-model.html#footnotes",
    "title": "\n4  Beta-Bernoulli Model\n",
    "section": "",
    "text": "An additional thing to note for the Bernoulli/binomial model is that, instead of setting the prior on \\(\\theta\\), sometimes we are more interested in setting the prior for a transformed parameter that has values between \\(-\\infty\\) and \\(\\infty\\), such as one on the logit scale (as related to logistic regression).↩︎\nThe \\(\\mathrm{Beta}(1 / 2, 1 / 2)\\) distribution is called a Jeffreys prior (https://en.wikipedia.org/wiki/Jeffreys_prior), which is derived according to some statistical principles for different models. One big advantage of a Jeffreys prior is that it is invariant, meaning that the prior will stay the same even under reparameterization. However, like conjugate priors, Jeffreys prior limits the choice of prior even when true prior information is available.↩︎",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Beta-Bernoulli Model</span>"
    ]
  },
  {
    "objectID": "04b-beta-bernoulli-stan.html",
    "href": "04b-beta-bernoulli-stan.html",
    "title": "\n5  Beta-Bernoulli Model With Stan\n",
    "section": "",
    "text": "5.1 Installing Stan",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Beta-Bernoulli Model With Stan</span>"
    ]
  },
  {
    "objectID": "04b-beta-bernoulli-stan.html#installing-stan",
    "href": "04b-beta-bernoulli-stan.html#installing-stan",
    "title": "\n5  Beta-Bernoulli Model With Stan\n",
    "section": "",
    "text": "Follow the steps in https://mc-stan.org/cmdstanr/ to install the cmdstanr package.\nLoad the cmdstanr package, and run install_cmdstan()\n\n\n\nlibrary(cmdstanr)\ninstall_cmdstan()\n\n\nIf you run into an error in the previous step related to C++ toolchain, follow the directions here: https://mc-stan.org/cmdstanr/articles/cmdstanr.html",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Beta-Bernoulli Model With Stan</span>"
    ]
  },
  {
    "objectID": "04b-beta-bernoulli-stan.html#fitting-a-beta-bernoulli-model-in-stan",
    "href": "04b-beta-bernoulli-stan.html#fitting-a-beta-bernoulli-model-in-stan",
    "title": "\n5  Beta-Bernoulli Model With Stan\n",
    "section": "\n5.2 Fitting a Beta-Bernoulli Model in Stan",
    "text": "5.2 Fitting a Beta-Bernoulli Model in Stan\n\n5.2.1 Data Import\nFrom last class:\n\ndata(\"Aids2\", package = \"MASS\")\nhead(Aids2)\n\n\n  \n\n\n\n\n5.2.2 Writing Stan syntax\nStan has its own syntax and is different from R. For example, we want to fit the following Beta-Bernoulli model:\n\\[\n\\begin{aligned}\n  y_i & \\sim \\text{Bern}(\\theta) \\text{ for }i = 1, 2, \\ldots, N \\\\\n  P(\\theta) & \\sim \\text{Beta}(2, 2)\n\\end{aligned}\n\\]\nand the model can be written in Stan as follows:\n\ndata {\n  int&lt;lower=0&gt; N;  // number of observations\n  array[N] int&lt;lower=0,upper=1&gt; y;  // y\n}\nparameters {\n  real&lt;lower=0,upper=1&gt; theta;  // theta parameter\n}\nmodel {\n  theta ~ beta(2,2);  // prior: Beta(2, 2)\n  y ~ bernoulli(theta);  // model: Bernoulli\n}\n\n\n\n\n\n\n\nSave the above model syntax in a separate file ending in .stan. For example, I saved the syntax in the file beta-bernoulli.stan in a folder named stan_code.\n\n\n\nIn Stan, anything after // denotes comments (like # in R) and will be ignored by the program. In each block (e.g., data {}), a statement should end with a semicolon (;). There are several blocks in the above Stan code:\n\n\ndata: The data input for Stan is usually not only an R data frame, but a list that includes other information, such as sample size, number of predictors, and prior scales. Each type of data has an input type, such as\n\nint = integer,\nreal = numbers with decimal places,\nmatrix = 2-dimensional data of real numbers,\nvector = 1-dimensional data of real numbers, and\narray = 1- to many-dimensional data. For example, we use array[N] for the data type of y, because it is a vector, but each element is an integer (and cannot take decimals).\n\nWe can set the lower and upper bounds so that Stan can check the input data. In the above, we used &lt;lower=0,upper=1&gt;.\n\nparameters: The parameters to be estimated\ntransformed parameters: optional variables that are transformations of the model parameters. It is usually used for more advanced models to allow more efficient MCMC sampling.\nmodel: It includes expressions of prior distributions for each parameter and the likelihood for the data. There are many possible distributions that can be used in Stan.\ngenerated quantities: Any quantities that are not part of the model but can be computed from the parameters for every iteration. Examples include posterior generated samples, effect sizes, and log-likelihood (for fit computation). We will see an example later.\n\n5.2.3 Compiling the Stan model from R\nTo compile the model, we can call the cmdstan_model function in cmdstanr:\n\nbern_mod &lt;- cmdstan_model(\"stan_code/beta-bernoulli.stan\")\n\n\n5.2.4 Posterior Sampling\nWe need to first prepare the data for input to Stan. In the Stan code, we have two objects in the data block: N and y, so we need to have a list of two elements in R:\n\nAids2_standata &lt;- list(\n    N = nrow(Aids2),\n    y = as.integer(Aids2$status == \"D\")  # integer\n)\n\nNow we can draw posterior samples:\n\nfit &lt;- bern_mod$sample(Aids2_standata)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.8 seconds.\n\n\nFor this simple model, this takes less than a second.\n\n5.2.5 Summarizing and plotting the posterior samples\n\n# Actual posterior samples\nfit$draws(\"theta\", format = \"draws_df\")\n\n\n  \n\n\n\n\n# Summary table\nfit$summary()\n\n\n  \n\n\n\n\n# Histogram\nfit$draws(\"theta\") |&gt;\n    mcmc_hist()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nFigure 5.1: Posterior distribution of the parameter.\n\n\n\n\nThe results are similar to those in last class.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Beta-Bernoulli Model With Stan</span>"
    ]
  },
  {
    "objectID": "04b-beta-bernoulli-stan.html#prior-predictive-check",
    "href": "04b-beta-bernoulli-stan.html#prior-predictive-check",
    "title": "\n5  Beta-Bernoulli Model With Stan\n",
    "section": "\n5.3 Prior Predictive Check",
    "text": "5.3 Prior Predictive Check\nIn Bayesian analyses, it is recommended to check both the prior and the model. This can be done by\n\nPrior predictive check: Simulating data from the prior distribution, and see if the simulated data fit our prior belief.\nPosterior predictive check: Simulating data from the posterior distribution, and see if the simulated data are comparable to the observed data.\n\nWe will use the following Stan code to do prior and posterior predictive checks, which has an additional generated quantity block to obtain\n\n\nprior_theta: simulated values of \\(\\theta\\) based on the prior distribution\n\nprior_ytilde: simulated data based on the prior distribution of \\(\\theta\\)\n\n\nytilde: simulated data based on the posterior distribution of \\(\\theta\\)\n\n\n\ndata {\n  int&lt;lower=0&gt; N;  // number of observations\n  array[N] int&lt;lower=0,upper=1&gt; y;  // y\n}\nparameters {\n  real&lt;lower=0,upper=1&gt; theta;  // theta parameter\n}\nmodel {\n  theta ~ beta(2, 2);  // prior: Beta(2, 2)\n  y ~ bernoulli(theta);  // model: Bernoulli\n}\ngenerated quantities {\n  real prior_theta = beta_rng(2, 2);\n  array[N] int prior_ytilde;\n  array[N] int ytilde;\n  for (i in 1:N) {\n    ytilde[i] = bernoulli_rng(theta);\n    prior_ytilde[i] = bernoulli_rng(prior_theta);\n  }\n}\n\n\nbern_pp_mod &lt;- cmdstan_model(\"stan_code/beta-bernoulli-pp.stan\")\nbern_pp_fit &lt;- bern_pp_mod$sample(\n    Aids2_standata,\n    refresh = 500  # show progress every 500 iterations\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 1.3 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 1.3 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 1.3 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 1.4 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 1.3 seconds.\nTotal execution time: 5.6 seconds.\n\n\nWith Stan, because we obtained 4,000 prior/posterior draws (the software default) of \\(\\theta\\), we also obtained 4,000 simulated data sets. We can see the first one, based on only the prior distribution (i.e., \\(\\theta\\) \\(\\sim\\) \\(\\text{Beta}(2, 2)\\)):\n\nbern_pp_fit$draws(\"prior_ytilde\", format = \"draws_df\")[1, ] |&gt;\n    as.numeric() |&gt;\n    table()\n\n\n   0    1 \n2133  713 \n\n\n\nNote that the data set has more 1’s than 0’s. Our prior is weak, which means that it allows for a lot of variation in how the data would look.\n\nThe distribution of simulated data based on the prior distribution of the parameters is called the prior predictive distribution. Mathematically, we write it as\n\\[\nP(\\tilde y) = \\int P(\\tilde y | \\theta) P(\\theta) \\; \\mathrm{d}\\theta\n\\]\nBecause we have 4,000 data sets, it is not easy to visualize all individual data points. Instead, we can visualize some summary statistics of the simulated data. Here, we will choose the proportion of deaths (i.e., the mean of the variable) in each simulated data set:\n\nbern_pp_fit$draws(\"prior_ytilde\", format = \"draws_matrix\") |&gt;\n    ppd_stat(stat = \"mean\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nFigure 5.2: Prior predictive distribution of the sample mean.\n\n\n\n\nThis represents our prior belief about the proportion of deaths without looking at the actual data. If this doesn’t seem to match our belief, we may want to modify our prior distribution and do the prior predictive check again, until the simulated data matches our actual prior belief.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Beta-Bernoulli Model With Stan</span>"
    ]
  },
  {
    "objectID": "04b-beta-bernoulli-stan.html#posterior-predictive-check",
    "href": "04b-beta-bernoulli-stan.html#posterior-predictive-check",
    "title": "\n5  Beta-Bernoulli Model With Stan\n",
    "section": "\n5.4 Posterior Predictive Check",
    "text": "5.4 Posterior Predictive Check\n\n5.4.1 Check 1: Sample Mean\n\\[\nP(\\tilde y | y) = \\int P(\\tilde y | \\theta, y) P(\\theta | y) \\; \\mathrm{d}\\theta\n\\]\nThe difference here is that we use the posterior distribution \\(P(\\theta | y)\\) instead of the prior distribution \\(P(\\theta)\\). We can obtain the posterior predictive distribution of the death rate, and indicate the actual data in the plot:\n\nbern_pp_fit$draws(\"ytilde\", format = \"draws_matrix\") |&gt;\n    ppc_stat(y = Aids2_standata$y, stat = \"mean\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nFigure 5.3: Posterior predictive distribution of the sample mean.\n\n\n\n\n\n5.4.2 Check 2: Sample Mean by Age Group\n\n# Create binary indicator of two age groups\nage50 &lt;- factor(Aids2$age &gt; 50, labels = c(\"&lt;= 50\", \"&gt; 50\"))\nbern_pp_fit$draws(\"ytilde\", format = \"draws_matrix\") |&gt;\n    ppc_stat_grouped(y = Aids2_standata$y, group = age50,stat = \"mean\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nFigure 5.4: Posterior predictive distribution of the sample mean by age group.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Beta-Bernoulli Model With Stan</span>"
    ]
  },
  {
    "objectID": "04c-poisson-model.html",
    "href": "04c-poisson-model.html",
    "title": "\n6  Poisson Model\n",
    "section": "",
    "text": "6.1 Research Question",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Poisson Model</span>"
    ]
  },
  {
    "objectID": "04c-poisson-model.html#research-question",
    "href": "04c-poisson-model.html#research-question",
    "title": "\n6  Poisson Model\n",
    "section": "",
    "text": "What’s the rate of fatal police shootings in the United States per year?",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Poisson Model</span>"
    ]
  },
  {
    "objectID": "04c-poisson-model.html#data-import-and-pre-processing",
    "href": "04c-poisson-model.html#data-import-and-pre-processing",
    "title": "\n6  Poisson Model\n",
    "section": "\n6.2 Data Import and Pre-Processing",
    "text": "6.2 Data Import and Pre-Processing\n\n# Import data\nfps_dat &lt;- read_csv(\n    \"https://github.com/washingtonpost/data-police-shootings/raw/master/v2/fatal-police-shootings-data.csv\"\n)\n\nWe first count the data by year\n\n# Create a year column\nfps_dat &lt;- fps_dat |&gt;\n    mutate(year = format(date, format = \"%Y\"))\n# Filter out the latest year\nfps_1523 &lt;- filter(fps_dat, year != max(year))\ncount(fps_1523, year)\n\n\n  \n\n\n\nOur interest is the rate of occurrence of fatal police shootings per year. Denote this as \\(\\theta\\). The support of \\(\\theta\\) is \\([0, \\infty)\\).\nA Poisson model is usually a starting point for analyzing count data in a fixed amount of time. It assumes that the data follow a Poisson distribution with a fixed rate parameter: \\[P(y \\mid \\theta) \\propto \\theta^y \\exp(- \\theta),\\] where the data can be any non-negative integers (no decimals).",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Poisson Model</span>"
    ]
  },
  {
    "objectID": "04c-poisson-model.html#choosing-a-prior",
    "href": "04c-poisson-model.html#choosing-a-prior",
    "title": "\n6  Poisson Model\n",
    "section": "\n6.3 Choosing a Prior",
    "text": "6.3 Choosing a Prior\nThe Gamma distribution has support: \\([0, \\infty)\\), and is a conjugate family to the Poisson model. The Gamma distribution has the form \\[\nP(\\theta) \\propto \\theta^{a - 1} \\exp(-b \\theta),\n\\] where \\(a\\) is the prior incidence rate, and \\(b\\) is the number of prior data points to control for the prior strength. Here, without much prior knowledge, I would simply guess there is one fatal shooting per state per month, so 600 shootings per year, but my belief is pretty weak, so I will assume a prior \\(b\\) of 1 / 200 (one observation is one year). The \\(a\\) will be 600 * \\(b\\) = 3.\nHere’s a plot:\n\nggplot(data.frame(th = c(0, 2000)), aes(x = th)) +\n    stat_function(fun = dgamma,\n    args = list(shape = 3, rate = 1 / 200)) +\n    labs(y = \"\", x = expression(theta))\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel Fitting in Stan\n\n\n\n\ndata {\n  int&lt;lower=0&gt; N;  // number of observations\n  array[N] int&lt;lower=0&gt; y;  // y\n  real&lt;lower=0&gt; prior_a;  // prior a for gamma\n  real&lt;lower=0&gt; prior_b;  // prior b for gamma\n}\nparameters {\n  real&lt;lower=0&gt; theta;  // theta parameter\n}\nmodel {\n  // prior: Gamma(3, 1 / 200)\n  // using conjugacy\n  theta ~ gamma(prior_a + sum(y), prior_b + N);\n}\ngenerated quantities {\n  real prior_theta = gamma_rng(3, 0.005);\n  array[N] int prior_ytilde;\n  array[N] int ytilde;\n  for (i in 1:N) {\n    ytilde[i] = poisson_rng(theta);\n    prior_ytilde[i] = poisson_rng(prior_theta);\n  }\n}\n\n\n6.3.1 Compiling\n\npois_mod &lt;- cmdstan_model(\"stan_code/gamma-poisson-pp.stan\")\n\n\n6.3.2 Data for Stan\n\nfps_standata &lt;- list(\n    N = length(unique(fps_1523$year)),\n    y = count(fps_1523, year)[, 2, drop = TRUE],  # integer\n    prior_a = 3,\n    prior_b = 1 / 200\n)\nfps_standata\n\n$N\n[1] 9\n\n$y\n[1]  995  959  984  991  994 1020 1049 1095 1164\n\n$prior_a\n[1] 3\n\n$prior_b\n[1] 0.005\n\n\n\n6.3.3 MCMC Sampling\n\nfit &lt;- pois_mod$sample(\n    fps_standata,\n    refresh = 500  # show progress every 500 iterations\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \n\n\nChain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 1 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 1 \n\n\nChain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 1 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 1 \n\n\nChain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 1 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 1 \n\n\nChain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 1 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 1 \n\n\nChain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 1 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 1 \n\n\nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 2 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 2 \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 2 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 2 \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 2 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 2 \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 2 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 2 \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 2 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 2 \n\n\nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \n\n\nChain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 3 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 3 \n\n\nChain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 3 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 3 \n\n\nChain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 3 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 3 \n\n\nChain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 3 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 3 \n\n\nChain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 3 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 3 \n\n\nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \n\n\nChain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 4 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 4 \n\n\nChain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 4 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 4 \n\n\nChain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 4 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 4 \n\n\nChain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 4 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 4 \n\n\nChain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 4 Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/Rtmptr69JG/model-2756e8977df2.stan', line 13, column 2 to column 47)\n\n\nChain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 4 \n\n\nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.7 seconds.\n\n\n\n\n\n\n6.3.4 Prior predictive check\nHere I plot simulated trends from the prior distribution.\n\n# Extract predicted y from prior\nfit$draws(\"prior_ytilde\", format = \"draws_matrix\") |&gt;\n    ppd_intervals(x = 2015:2023) +\n    labs(x = \"Year\", y = \"Predicted count\")\n\n\n\n\n\n\n\nThe check is on whether the numbers seem reasonably reflective of my knowledge.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Poisson Model</span>"
    ]
  },
  {
    "objectID": "04c-poisson-model.html#posterior",
    "href": "04c-poisson-model.html#posterior",
    "title": "\n6  Poisson Model\n",
    "section": "\n6.4 Posterior",
    "text": "6.4 Posterior\nWith a conjugate prior, the posterior distribution is Gamma(\\(a\\) + \\(\\sum_{i = 1}^N y_i\\), \\(b\\) + \\(N\\)).\n\nggplot(data.frame(th = c(0, 2000)), aes(x = th)) +\n    stat_function(fun = dgamma,\n    args = list(shape = 3 + nrow(fps_1523),\n                rate = 1 / 200 + fps_standata$N), n = 501) +\n    labs(y = \"\", x = expression(theta))",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Poisson Model</span>"
    ]
  },
  {
    "objectID": "04c-poisson-model.html#posterior-predictive-check",
    "href": "04c-poisson-model.html#posterior-predictive-check",
    "title": "\n6  Poisson Model\n",
    "section": "\n6.5 Posterior Predictive Check",
    "text": "6.5 Posterior Predictive Check\nPlot predicted data from the posterior against observed data\n# Extract predicted y from posterior\nfit$draws(\"ytilde\", format = \"draws_matrix\") |&gt;\n    ppc_intervals(\n        y = fps_standata$y,\n        x = 2015:2023\n    ) +\n    labs(x = \"Year\", y = \"Predicted count\")\n# We can also use `bayesplot::ppc_ribbon()`\nfit$draws(\"ytilde\", format = \"draws_matrix\") |&gt;\n    ppc_ribbon(\n        y = fps_standata$y,\n        x = 2015:2023\n    ) +\n    labs(x = \"Year\", y = \"Predicted count\")\n\n\n\n\n\n\n\n\n\n(a) Interval plots.\n\n\n\n\n\n\n\n\n\n(b) Ribbon plots.\n\n\n\n\n\n\nFigure 6.1: Posterior predictive check.\n\n\n\n\n\n\n\n\nFrom Figure 6.1, one can see that the fit is not good, as there is a large gap between the model prediction and the observed data from recent years. This suggests a need to incorporate the time trend in the model.",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Poisson Model</span>"
    ]
  },
  {
    "objectID": "04c-poisson-model.html#summary-of-posterior",
    "href": "04c-poisson-model.html#summary-of-posterior",
    "title": "\n6  Poisson Model\n",
    "section": "\n6.6 Summary of Posterior",
    "text": "6.6 Summary of Posterior\nFor now, we will proceed with interpreting the posterior distribution, despite the apparent misfit.\n\n(summ_theta &lt;- fit$summary(\"theta\"))\n\n\n  \n\n\n\nSo the estimated rate is 1,028 per year, with a 90% CI [1,010, 1,044].",
    "crumbs": [
      "Week 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Poisson Model</span>"
    ]
  },
  {
    "objectID": "05-hierarchical-models.html",
    "href": "05-hierarchical-models.html",
    "title": "\n7  Hierarchical Models\n",
    "section": "",
    "text": "7.1 Hierarchical Bernoulli/Binomial\nWe will first consider a therapeutic touch example (Kruschke, 2015, Chapter 9). Therapeutic touch is a technique in alternative medicine to relieve pain, but scientific evidence does not support its effectiveness. The data here are from an experiment where the experimenter randomly hovered their hand over either the participant’s left or right hand, and the participant had to guess which hand was being hovered without seeing. This is repeated 10 times for each participant. There are a total of 28 participants in the dataset.\nPreviously, we have seen the Bernoulli model for \\(N\\) outcomes (i.e., whether the guess is correct): \\[\ny_i \\sim \\text{Bern}(\\theta), \\text{for }i = 1, \\ldots, N\n\\] We assumed exchangeability with \\(\\theta\\) being the participant’s “ability” to guess correctly.",
    "crumbs": [
      "Week 4",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Hierarchical Models</span>"
    ]
  },
  {
    "objectID": "05-hierarchical-models.html#hierarchical-bernoullibinomial",
    "href": "05-hierarchical-models.html#hierarchical-bernoullibinomial",
    "title": "\n7  Hierarchical Models\n",
    "section": "",
    "text": "Alternative Parameterization of Beta\n\n\n\nIn the last class, we have used the Beta(a, b) prior for a Bernoulli outcome, such that \\[\nP(\\theta \\mid a, b) \\propto \\theta^{a - 1} (1 - \\theta)^{b - 1}.\n\\] However, in hierarchical models to be discussed later, it is beneficial to consider another way to express the Beta distribution, in terms of the prior mean, \\(\\mu = a / (a + b)\\), \\(\\mu \\in [0, 1]\\), and the concentration, \\(\\kappa = a + b\\), \\(\\kappa \\in [0, \\infty)\\). So, instead of the above formula, we can write \\[\nP(\\theta \\mid \\mu, \\kappa) \\propto \\theta^{\\mu \\kappa - 1} (1 - \\theta)^{(1 - \\mu) \\kappa - 1}.\n\\] The two expressions represent exactly the same distribution, but just in terms of parameters of different meanings. Therefore, they are referred to as different parameterization of the Beta distribution.\n\n\n\n\n7.1.1 Multiple Bernoulli = Binomial\nWith \\(N\\) exchangeable Bernoulli observations, an equivalent but more efficient way to code the model is to use the binomial distribution. Let \\(z = \\sum_{i = 1}^N y_i\\), then \\[\nz \\sim \\mathrm{Bin}(N, \\theta)\n\\]\n\n7.1.2 Multiple Binomial Observations\nNow, because we have multiple participants, we could study whether each participant had noticeable differences in their guessing ability. We can use a binomial model for each participant, from participant 1 to participant \\(J\\): \\[\n\\begin{aligned}\n  z_1 \\sim \\mathrm{Bin}(N_1, \\theta_1) \\\\\n  z_2 \\sim \\mathrm{Bin}(N_2, \\theta_2) \\\\\n  \\vdots \\\\\n  z_J \\sim \\mathrm{Bin}(N_J, \\theta_J)\n\\end{aligned}\n\\]\nOr instead of writing \\(J\\) equations, we can use the subscript \\(j\\) to refer to each participant: \\[\nz_{\\textcolor{red}{j}} \\sim \\mathrm{Bin}(N_{\\textcolor{red}{j}}, \\theta_{\\textcolor{red}{j}})\n\\]\nIf we believe that all participants have the same ability, then we could consider the model \\[\nz_j \\sim \\mathrm{Bin}(N_j, \\theta),\n\\] which still contains only one parameter, \\(\\theta\\). However, if we have reason to believe that the coins have different biases, then we should have \\[z_j \\sim \\mathrm{Bin}(N_j, \\theta_{\\color{red}{j}}),\\] with parameters \\(\\theta_1, \\ldots, \\theta_j\\).\nWe can assign priors to each \\(\\theta_j\\). However, suppose our prior belief is that there’s something common among the different participants (e.g., they’re all human beings), so they come from a common distribution. In that case, we can have common parameters for the prior distributions of the \\(\\theta\\)s: \\[\n\\theta_j \\sim \\mathrm{Beta\\_Proportion}(\\mu, \\kappa),\n\\] note I use Beta_Proportion to denote the mean parameterization. Here, we express the prior belief that the mean ability of the different participants is \\(\\mu\\), and how each participant differs from the mean depends on \\(\\kappa\\). Now, \\(\\mu\\) and \\(\\kappa\\) are hyperparameters. We can assign some fixed values to \\(\\mu\\) and \\(\\kappa\\), as if we know what the average ability is. However, the power of the hierarchical model is that we can put priors (or hyper priors) on \\(\\mu\\) and \\(\\kappa\\), and obtain posterior distributions of them, based on what the data say.\nWhat priors to use for \\(\\mu\\) and \\(\\kappa\\)? \\(\\mu\\) is relatively easy because it is the mean ability; if we put a Beta prior for each participant’s ability, we can again use a Beta prior for the mean ability. \\(\\kappa\\) is more challenging. A larger \\(\\kappa\\) means that the participants’ abilities are more similar to each other. We can perform a prior predictive check to see what the data look like. As a starting point, some textbook (e.g., chapter 9 of Kruschke, 2015) suggested using Gamma(0.01, 0.01). So the full model in our case, with a weak Beta(1.5, 1.5) prior on \\(\\mu\\), is\nModel: \\[\n  \\begin{aligned}\n    z_j & \\sim \\mathrm{Bin}(N_j, \\theta_j) \\\\\n    \\theta_j & \\sim \\mathrm{Beta2}(\\mu, \\kappa)\n  \\end{aligned}\n\\] Prior: \\[\n  \\begin{aligned}\n    \\mu & \\sim \\mathrm{Beta}(1.5, 1.5) \\\\\n    \\kappa & \\sim \\mathrm{Gamma}(0.01, 0.01)\n  \\end{aligned}\n\\]\nWe will import the data and fit the model\n\n# Data file from GitHub\ntt_url &lt;- paste0(\n    \"https://github.com/boboppie/kruschke-doing_bayesian_data_analysis/\",\n    \"raw/master/2e/TherapeuticTouchData.csv\"\n)\ntt_dat &lt;- read.csv(tt_url)\n# Get aggregated data by summing the counts\ntt_agg &lt;- tt_dat |&gt;\n    group_by(s) |&gt;\n    summarise(y = sum(y),  # total number of correct\n              n = n())\n# Plot proportion correct distribution\np1 &lt;- ggplot(tt_agg, aes(x = y / n)) +\n    geom_histogram(binwidth = .1) +\n    labs(x = \"Proportion Correct\")\n\n\n\n\n\n\n\n\nFigure 7.2: Distribution of proportions of correct responses across participants.\n\n\n\n\n\n7.1.3 Stan Code\n\ndata {\n  int&lt;lower=0&gt; J;  // number of clusters (e.g., studies, persons)\n  array[J] int y;  // number of \"1\"s in each cluster\n  array[J] int N;  // sample size for each cluster\n}\nparameters {\n  // cluster-specific probabilities\n  vector&lt;lower=0, upper=1&gt;[J] theta;\n  real&lt;lower=0, upper=1&gt; mu;  // overall mean probability\n  real&lt;lower=0&gt; kappa;        // overall concentration\n}\nmodel {\n  y ~ binomial(N, theta);  // each observation is binomial\n  // Priors\n  theta ~ beta_proportion(mu, kappa);\n  mu ~ beta(1.5, 1.5);      // weak prior\n  kappa ~ gamma(.1, .1);  // prior recommended by Kruschke\n}\ngenerated quantities {\n  // Prior and posterior predictive\n  real&lt;lower=0, upper=1&gt; prior_mu = beta_rng(1.5, 1.5);\n  real&lt;lower=0&gt; prior_kappa = gamma_rng(.1, .1);\n  vector&lt;lower=0, upper=1&gt;[J] prior_theta;\n  for (j in 1:J) {\n    prior_theta[j] = beta_proportion_rng(prior_mu, prior_kappa);\n  }\n  array[J] int prior_ytilde = binomial_rng(N, prior_theta);\n  // Posterior predictive\n  array[J] int ytilde = binomial_rng(N, theta);\n}\n\n\nhbin_mod &lt;- cmdstan_model(\"stan_code/hierarchical-binomial.stan\")\n\n\n7.1.4 Prior predictive\nYou can use Stan to sample the prior and obtain the prior predictive distribution; here, I show how to do it in R, with a Gamma(.01, .01) prior on \\(\\kappa\\):\n\nset.seed(1706)\nplist &lt;- vector(\"list\", 12L)\nplist[[1]] &lt;- p1 +\n    labs(x = \"Observed data\") +\n    theme(axis.title.x = element_text(color = \"red\"))\nnum_subjects &lt;- 28\nfor (s in 1:11) {\n    # Get prior values of mu and kappa\n    mu_s &lt;- rbeta(1, shape1 = 1.5, shape2 = 1.5)\n    kappa_s &lt;- rgamma(1, shape = 0.01, rate = 0.01)\n    # Generate theta\n    theta &lt;- rbeta(num_subjects,\n                   shape1 = mu_s * kappa_s,\n                   shape2 = (1 - mu_s) * kappa_s)\n    # Generate data\n    new_y &lt;- rbinom(num_subjects, size = tt_agg$n, prob = theta)\n    plist[[s + 1]] &lt;-\n        p1 %+% mutate(tt_agg, y = new_y) +\n        labs(x = paste(\"Simulated data\", s)) +\n        theme(axis.title.x = element_text(color = \"black\"))\n}\ngridExtra::grid.arrange(grobs = plist, nrow = 3)\n\n\n\n\n\n\nFigure 7.3: Prior predictive distribution.\n\n\n\n\nThe prior on \\(\\kappa\\) is not very realistic because it pushes the bias to either 0 or 1. Using something like Gamma(0.1, 0.1) or Gamma(2, 0.01) may be more reasonable (you can try it out yourself).\n\n7.1.5 Calling Stan\n\ntt_fit &lt;- hbin_mod$sample(\n    data = list(J = nrow(tt_agg),\n                y = tt_agg$y,\n                N = tt_agg$n),\n    seed = 1716,  # for reproducibility\n    refresh = 1000\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.2 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 2 Exception: beta_proportion_lpdf: Location parameter is 1, but must be less than 1.000000 (in '/tmp/RtmpjKgfHa/model-2caa6a28826c92.stan', line 15, column 2 to column 37)\n\n\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 2 \n\n\nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.2 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.2 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \n\n\nChain 4 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 4 Exception: beta_proportion_lpdf: Location parameter is 0, but must be positive! (in '/tmp/RtmpjKgfHa/model-2caa6a28826c92.stan', line 15, column 2 to column 37)\n\n\nChain 4 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 4 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 4 \n\n\nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.4 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.3 seconds.\nTotal execution time: 1.4 seconds.\n\n\nYou can explore the convergence and posterior distributions using the shinystan package\n\nshinystan::launch_shinystan(tt_fit)\n\n\n7.1.6 Table of coefficients\n\ntt_fit$summary(c(\"theta\", \"mu\", \"kappa\")) |&gt;\n    # Use `knitr::kable()` for tabulation\n    knitr::kable(digits = 2)\n\n\nTable 7.1: Posterior summary of hierarchical binomial model for the therapeutic touch example.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\ntheta[1]\n0.31\n0.31\n0.10\n0.10\n0.15\n0.47\n1\n3268.39\n2404.91\n\n\ntheta[2]\n0.35\n0.35\n0.10\n0.10\n0.19\n0.51\n1\n3741.46\n2422.69\n\n\ntheta[3]\n0.39\n0.39\n0.10\n0.10\n0.23\n0.55\n1\n4744.99\n2794.69\n\n\ntheta[4]\n0.39\n0.39\n0.10\n0.10\n0.23\n0.55\n1\n4859.60\n3056.80\n\n\ntheta[5]\n0.39\n0.39\n0.10\n0.10\n0.22\n0.55\n1\n4817.40\n2485.43\n\n\ntheta[6]\n0.39\n0.38\n0.10\n0.10\n0.23\n0.55\n1\n5260.92\n2493.09\n\n\ntheta[7]\n0.39\n0.38\n0.10\n0.10\n0.23\n0.55\n1\n5586.84\n2968.73\n\n\ntheta[8]\n0.39\n0.39\n0.10\n0.10\n0.23\n0.55\n1\n4926.08\n3008.76\n\n\ntheta[9]\n0.39\n0.39\n0.10\n0.10\n0.23\n0.55\n1\n4802.85\n2558.79\n\n\ntheta[10]\n0.39\n0.39\n0.10\n0.10\n0.22\n0.55\n1\n4743.85\n2910.25\n\n\ntheta[11]\n0.43\n0.42\n0.10\n0.09\n0.27\n0.59\n1\n5041.77\n3066.93\n\n\ntheta[12]\n0.42\n0.42\n0.09\n0.10\n0.27\n0.58\n1\n6055.56\n2896.89\n\n\ntheta[13]\n0.43\n0.42\n0.10\n0.10\n0.27\n0.59\n1\n4898.48\n3112.24\n\n\ntheta[14]\n0.43\n0.42\n0.10\n0.10\n0.27\n0.59\n1\n5909.48\n3065.15\n\n\ntheta[15]\n0.43\n0.42\n0.10\n0.10\n0.27\n0.59\n1\n6304.56\n3049.53\n\n\ntheta[16]\n0.46\n0.46\n0.10\n0.10\n0.31\n0.62\n1\n5642.01\n3230.67\n\n\ntheta[17]\n0.46\n0.46\n0.10\n0.10\n0.30\n0.63\n1\n5517.58\n3108.00\n\n\ntheta[18]\n0.46\n0.46\n0.10\n0.10\n0.30\n0.63\n1\n5622.46\n2837.76\n\n\ntheta[19]\n0.46\n0.46\n0.10\n0.09\n0.31\n0.63\n1\n6228.82\n3062.79\n\n\ntheta[20]\n0.46\n0.46\n0.10\n0.10\n0.30\n0.63\n1\n4758.62\n2538.88\n\n\ntheta[21]\n0.46\n0.46\n0.10\n0.10\n0.30\n0.62\n1\n5922.64\n2921.96\n\n\ntheta[22]\n0.46\n0.46\n0.10\n0.10\n0.31\n0.62\n1\n5218.69\n3180.07\n\n\ntheta[23]\n0.50\n0.50\n0.10\n0.10\n0.34\n0.67\n1\n5424.13\n2936.72\n\n\ntheta[24]\n0.50\n0.50\n0.10\n0.10\n0.34\n0.67\n1\n5321.61\n2733.91\n\n\ntheta[25]\n0.54\n0.54\n0.10\n0.10\n0.38\n0.71\n1\n3861.44\n2248.48\n\n\ntheta[26]\n0.54\n0.54\n0.10\n0.10\n0.37\n0.72\n1\n3808.59\n2430.69\n\n\ntheta[27]\n0.54\n0.54\n0.10\n0.10\n0.38\n0.71\n1\n3679.86\n2556.84\n\n\ntheta[28]\n0.58\n0.57\n0.10\n0.11\n0.41\n0.75\n1\n3005.40\n2460.66\n\n\nmu\n0.44\n0.44\n0.04\n0.04\n0.38\n0.50\n1\n2482.91\n2932.61\n\n\nkappa\n18.65\n16.37\n9.63\n7.92\n7.49\n36.92\n1\n992.72\n1793.53\n\n\n\n\n\n\n\n\n\n7.1.7 Posterior Predictive Check\nWith hierarchical models, there are two types of posterior predictive distributions:\n\n\nSame participants but new observations. We can use the model to generate new observations, but the individual parameters (e.g., \\(\\theta_j\\)) remain the same. In our example, this would be the situation where we ask the same 28 participants to each do 10 more trials.\n\nNew participants and new observations. We can use the model to generate new observations with new parameters from the higher-order distribution (e.g., the Beta distribution for \\(\\theta_j\\)). In our example, this would be the situation where we ask a new set of 28 participants to each do 10 more trials.\n\nIn our Stan code, I used (1) to check the fit of the observed data. However, (2) can be helpful when one wants to use the model to make predictions of future data, as future data are unlikely to concern exactly the same participants.\n\n# The bayesplot::ppc_bars() unfortunately contains a bug\n# (https://github.com/stan-dev/bayesplot/issues/266) at\n# the time when I wrote this, so I'll use my own code.\n# tt_fit$draws(\"ytilde\", format = \"draws_matrix\") |&gt;\n#     ppc_bars(y = tt_agg$y)\nyrep &lt;- tt_fit$draws(\"ytilde\", format = \"draws_matrix\")\nyrep_intervals &lt;- apply(\n    yrep, MARGIN = 1, FUN = \\(x) table(factor(x, levels = 0:10))\n    ) |&gt;\n    apply(MARGIN = 1, FUN = \\(x) {\n        c(\n            lo = quantile(x, .05)[[1]],\n            me = median(x),\n            hi = quantile(x, .95)[[1]]\n        )\n    })\ndata.frame(\n    y = table(factor(tt_agg$y, levels = 0:10))\n) |&gt;\n    setNames(c(\"x\", \"y\")) |&gt;\n    cbind(t(yrep_intervals)) |&gt;\n    ggplot(aes(x = x, y = y)) +\n    geom_col(alpha = 0.5) +\n    geom_pointrange(aes(y = me, ymin = lo, ymax = hi)) +\n    labs(y = \"count\", x = NULL)\n\n\n\n\n\n\nFigure 7.4: Posterior predictive check. The bar graph shows the observed data, and the error bars show the 90% posterior predictive interval in replicated data. The dots are the medians in the posterior predictive distribution.\n\n\n\n\n\n7.1.8 Derived coefficients\nOne nice thing about MCMC is that it is straightforward to obtain posterior distributions that are functions of the parameters. For example, even though we only sampled from the posteriors of the \\(\\theta\\)s, we can ask questions like whether there is evidence for a nonzero difference in \\(\\theta\\) between person 1 and person 28.\n\ntt_fit$draws() |&gt;\n    mutate_variables(\n        theta1_minus14 = `theta[1]` - `theta[14]`,\n        theta1_minus28 = `theta[1]` - `theta[28]`,\n        theta14_minus28 = `theta[14]` - `theta[28]`\n    ) |&gt;\n    subset(variable = c(\"theta1_minus14\", \"theta1_minus28\",\n                        \"theta14_minus28\")) |&gt;\n    summarise_draws() |&gt;\n    knitr::kable(digits = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\ntheta1_minus14\n-0.11\n-0.11\n0.13\n0.13\n-0.34\n0.09\n1\n4950.80\n2632.63\n\n\ntheta1_minus28\n-0.27\n-0.26\n0.15\n0.16\n-0.53\n-0.03\n1\n2312.44\n3115.27\n\n\ntheta14_minus28\n-0.15\n-0.15\n0.14\n0.14\n-0.38\n0.06\n1\n4309.81\n3013.97\n\n\n\n\n\n\n7.1.9 Conclusion\nAs 0.5 is included in the 95% CI of \\(\\theta\\) for all participants, there is insufficient evidence that people can sense “therapeutic touch.”\n\n7.1.10 Shrinkage\n\nmcmc_intervals(tt_fit$draws(),\n               # plot only parameters matching \"theta\"\n               regex_pars = \"^theta\") +\n    geom_point(\n        data = tibble(\n            parameter = paste0(\"theta[\", 1:28, \"]\"),\n            x = tt_agg$y / tt_agg$n\n        ),\n        aes(x = x, y = parameter),\n        col = \"red\"\n    ) +\n    xlim(0, 1)\n\nScale for x is already present.\nAdding another scale for x, which will replace the existing scale.\n\n\n\n\nShrinkage effect in a hierarchical model.\n\n\n\nAs can be seen, the posterior distributions are closer to the center than the data (in red). This pooling results from the belief that the participants have something in common.\n\n7.1.11 Multiple Comparisons?\nAnother benefit of a Bayesian hierarchical model is that you don’t need to worry about multiple comparisons. There are multiple angles on why this is the case, but the basic answer is that the use of common prior distributions builds in the prior belief that the clusters/groups are likely to be equal. See discussion here and here.",
    "crumbs": [
      "Week 4",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Hierarchical Models</span>"
    ]
  },
  {
    "objectID": "05-hierarchical-models.html#hierarchical-normal-model",
    "href": "05-hierarchical-models.html#hierarchical-normal-model",
    "title": "\n7  Hierarchical Models\n",
    "section": "\n7.2 Hierarchical Normal Model",
    "text": "7.2 Hierarchical Normal Model\n\n7.2.1 Eight Schools Example\nThis is a classic data set first analyzed by Rubin (1981). It is also the example used in the RStan Getting Started page. The data contains the effect of coaching from randomized experiments in eight schools. The numbers shown (labelled as y) are the mean difference (i.e., effect size) in performance between the treatment and control groups on SAT-V scores.\n\nschools_dat &lt;- list(\n    J = 8,\n    y = c(28, 8, -3, 7, -1, 1, 18, 12),\n    sigma = c(15, 10, 16, 11, 9, 11, 10, 18)\n)\n\nIn the above data, some numbers are positive, and some are negative. Because the sample sizes are different, the data also contained the standard errors (labelled as sigma) of the effect sizes. Generally speaking, a larger sample size corresponds to a smaller standard error. The research question is\n\n\nWhat is the average treatment effect of coaching?\nAre the treatment effects similar across schools?\n\n\n\n7.2.2 Model\nModel: \\[\n  \\begin{aligned}\n    d_j & \\sim N(\\theta_j, s_j) \\\\\n    \\theta_j & \\sim N(\\mu, \\tau)\n  \\end{aligned}\n\\] Prior: \\[\n  \\begin{aligned}\n    \\mu & \\sim N(0, 100) \\\\\n    \\tau & \\sim t^+_4(0, 100)\n  \\end{aligned}\n\\]\nGiven the SAT score range, it is unlikely that a coaching program will improve scores by 100 or so, so we use a prior of \\(\\mu \\sim N(0, 100)\\) and \\(\\tau \\sim t^+_4(0, 100)\\).\n\n\n\n\n\n\nThe model above is the same as one used in a random-effect meta-analysis. See this paper for an introduction.\n\n\n\n\n7.2.3 Non-Centered Parameterization\nThe hierarchical model is known to create issues in MCMC sampling, such that the posterior draws tend to be highly correlated even with more advanced techniques like HMC. One way to alleviate that is to reparameterize the model using what is called the non-centered parameterization. The basic idea is that, instead of treating the \\(\\theta\\)s as parameters, one uses the standardized deviation from the mean to be parameters. You can think about it as converting the \\(\\theta\\)s into \\(z\\) scores, and then sample the \\(z\\) scores instead of the original \\(\\theta\\)s.\nModel: \\[\n  \\begin{aligned}\n    d_j & \\sim N(\\theta_j, s_j) \\\\\n    \\theta_j & = \\mu + \\tau \\eta_j \\\\\n    \\eta_j & \\sim N(0, 1)\n  \\end{aligned}\n\\]\n\ndata {\n  int&lt;lower=0&gt; J;            // number of schools \n  vector[J] y;               // estimated treatment effects\n  vector&lt;lower=0&gt;[J] sigma;  // s.e. of effect estimates \n}\nparameters {\n  real mu;                   // overall mean\n  real&lt;lower=0&gt; tau;         // between-school SD\n  vector[J] eta;             // standardized deviation (z score)\n}\ntransformed parameters {\n  vector[J] theta;\n  theta = mu + tau * eta;    // non-centered parameterization\n}\nmodel {\n  eta ~ std_normal();        // same as eta ~ normal(0, 1);\n  y ~ normal(theta, sigma);\n  // priors\n  mu ~ normal(0, 100);\n  tau ~ student_t(4, 0, 100);\n}\n\n\nhnorm_mod &lt;- cmdstan_model(\"stan_code/hierarchical-normal.stan\")\n\n\nfit &lt;- hnorm_mod$sample(\n    data = schools_dat,\n    seed = 1804,  # for reproducibility\n    refresh = 1000,\n    adapt_delta = 0.9  # to improve convergence\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.1 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.1 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.1 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.5 seconds.\n\n\nTreatment effect estimates of individual schools (\\(\\theta\\)), average treatment effect (\\(\\mu\\)), and treatment effect heterogeneity (\\(\\tau\\)).\n\nfit$summary(c(\"theta\", \"mu\", \"tau\")) |&gt;\n    knitr::kable(digits = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\ntheta[1]\n11.70\n10.60\n8.69\n7.38\n-0.20\n27.60\n1.00\n3475.69\n3347.72\n\n\ntheta[2]\n7.98\n7.93\n6.31\n5.82\n-2.18\n18.34\n1.00\n5870.22\n3353.39\n\n\ntheta[3]\n6.13\n6.77\n7.97\n6.50\n-7.14\n17.85\n1.00\n4318.80\n2941.48\n\n\ntheta[4]\n7.69\n7.75\n6.75\n6.15\n-3.43\n18.53\n1.00\n5452.05\n3268.65\n\n\ntheta[5]\n5.22\n5.53\n6.22\n5.82\n-5.64\n14.70\n1.00\n4118.93\n3165.15\n\n\ntheta[6]\n6.15\n6.52\n6.87\n6.15\n-5.19\n16.86\n1.00\n4526.45\n3352.39\n\n\ntheta[7]\n10.80\n10.14\n6.78\n6.32\n0.88\n23.09\n1.00\n4445.48\n3533.95\n\n\ntheta[8]\n8.55\n8.33\n7.74\n6.42\n-3.59\n21.11\n1.00\n4978.08\n3232.97\n\n\nmu\n7.95\n8.00\n5.26\n4.97\n-0.43\n16.20\n1.00\n2917.45\n1987.36\n\n\ntau\n6.75\n5.31\n5.91\n4.84\n0.55\n17.53\n1.01\n1316.86\n1673.79\n\n\n\n\n\nOn average, based on the 90% CI, coaching seemed to improve SAT-V by -0.43 to 16.2 points. There was substantial heterogeneity across schools.\nWe can also get the probability that the treatment effect was &gt; 0:\n\n# Obtain draws\ndraws_mu &lt;- fit$draws(\"mu\", format = \"draws_matrix\")\nmean(draws_mu &gt; 0)\n\n[1] 0.93975\n\n\nHere are the individual-school treatment effects:\n\nmcmc_areas_ridges(fit$draws(), regex_pars = \"theta\")\n\n\n\n\n\n\nFigure 7.5: Posterior distribution of the true effect size in the eight schools example.\n\n\n\n\n\n7.2.4 Prediction Interval\nPosterior distribution of the true effect size of a new study, \\(\\tilde \\theta\\)\n\n# Prediction Interval\n# (can also be done in Stan, as in the previous example)\nfit$draws(c(\"mu\", \"tau\")) |&gt;\n    mutate_variables(\n        theta_tilde = rnorm(4000, mean = mu, sd = tau)) |&gt;\n    summarise_draws() |&gt;\n    knitr::kable(digits = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\nmu\n7.95\n8.00\n5.26\n4.97\n-0.43\n16.20\n1.00\n2917.45\n1987.36\n\n\ntau\n6.75\n5.31\n5.91\n4.84\n0.55\n17.53\n1.01\n1316.86\n1673.79\n\n\ntheta_tilde\n8.03\n7.87\n10.19\n7.00\n-6.69\n22.89\n1.00\n3947.08\n3042.56\n\n\n\n\n\nThe posterior interval for \\(\\tilde \\theta\\) indicates a range of the treatment effect for a new study.",
    "crumbs": [
      "Week 4",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Hierarchical Models</span>"
    ]
  },
  {
    "objectID": "06-linear-models.html",
    "href": "06-linear-models.html",
    "title": "\n8  Linear Models\n",
    "section": "",
    "text": "8.1 What is Regression?\nRegression is a class of statistical techniques to understand the relationship between an outcome variable (also called a criterion/response/dependent variable) and one or more predictor variables (also called explanatory/independent variables). For example, if we have the following scatter plot between two variables (\\(Y\\) and \\(X\\)):\nset.seed(1)\nx &lt;- round(runif(10, 1, 5), 3)\ny &lt;- 0.7 + 0.5 * log(x - 1) + rnorm(10, sd = 0.2)\ndf &lt;- data.frame(x, y)\nggplot(df, aes(x, y)) +\n    geom_point() +\n    xlim(1, 5) +\n    ylim(-1, 2)\nWe want to find some pattern in this relationship. In conventional regression, we model the conditional distribution of \\(Y\\) given \\(X\\), \\(P(Y \\mid X)\\), by separating the outcome variable \\(Y\\) into (a) a systematic component that depends on the predictor, and (b) a random/probabilistic component that does not depend on the predictor. For example, we can start with a systematic component which only depends on the predictor:\nAs you can see, all the red dots fall exactly on the curve in the graph above, meaning that as long as one knows the \\(X\\) value, one can predict the \\(Y\\) value with 100% accuracy. We can thus write \\(Y^* = f(X)\\) (where \\(Y^*\\) is the systematic component of \\(Y\\)).\nHowever, in almost all scientific inquiries, one can never predict with 100% certainty (e.g., there are measurement errors and college randomness in physics). The uncertainty stems from the fact that we rarely measure all the factors that determine \\(Y\\), and there are genuinely random things (as in quantum physics). Therefore, we need to expand our model to incorporate this randomness by adding a probabilistic component. Therefore, instead of saying that \\(Y\\) depends just on \\(X\\), we say \\(Y\\) is random, but the information about \\(X\\) provides information about how \\(Y\\) is distributed. In regression, one studies the conditional distribution \\(P(Y \\mid X)\\) such that the conditional expectation, \\(E(Y \\mid X)\\), is determined by \\(X\\); on top of the conditional expectation, we assume that the observed \\(Y\\) values scatter around the conditional expectations, like the graph on the left below:\nWe can write the systematic part as:\n\\[E(Y \\mid X) = f(X; \\beta_1, \\beta_2, \\ldots), \\]\nwhere \\(\\beta_1\\), \\(\\beta_2\\), \\(\\ldots\\) are the parameters for some arbitrary function \\(f(\\cdot)\\). The random part is about \\(P(Y \\mid X)\\), which can take some arbitrary distributions. In reality, even if such a model holds, we do not know what \\(f(\\cdot)\\) and the true distribution of \\(Y \\mid X\\) are, as we only have data like those illustrated in the graph on the right above.",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Linear Models</span>"
    ]
  },
  {
    "objectID": "06-linear-models.html#what-is-regression",
    "href": "06-linear-models.html#what-is-regression",
    "title": "\n8  Linear Models\n",
    "section": "",
    "text": "ggplot(df, aes(x, yhat)) +\n    stat_function(fun = function(x) 0.7 + 0.5 * log(x - 1), n = 501) +\n    geom_point(col = \"red\") +\n    xlim(1, 5) +\n    ylim(-1, 2) +\n    ylab(\"y\") +\n    geom_curve(aes(x = x, y = yhat + 0.5, xend = x, yend = yhat - 0.5),\n        curvature = -0.4, col = \"red\", linetype = \"dotdash\"\n    ) +\n    geom_vline(aes(xintercept = x), linetype = \"dotted\") +\n    geom_point(aes(x, y), size = 2)\nggplot(df, aes(x, y)) +\n    geom_point(size = 2) +\n    xlim(1, 5) +\n    ylim(-1, 2)\n\n\n\n\n\n\n\n\n\n(a) With the true underlying relationship shown\n\n\n\n\n\n\n\n\n\n(b) With the true underlying relationship hidden, as is always the case in real life\n\n\n\n\n\n\nFigure 8.1: Sample regression function.",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Linear Models</span>"
    ]
  },
  {
    "objectID": "06-linear-models.html#linear-regression",
    "href": "06-linear-models.html#linear-regression",
    "title": "\n8  Linear Models\n",
    "section": "\n8.2 Linear Regression",
    "text": "8.2 Linear Regression\nThe linear regression model assumes that\n\nthe function for the systematic component, \\(f(\\cdot)\\), is a linear function (in the \\(\\beta\\)s),\n\n\\(Y \\mid X\\) is normally distributed, and\n\n\\(Y_i\\)’s are conditionally exchangeable given \\(X\\) with equal variance \\(\\sigma^2\\) (which can be relaxed).\n\nUnder these conditions, we have a model\n\\[\n  \\begin{aligned}\n    Y_i & \\sim N(\\mu_i, \\sigma)  \\\\\n    \\mu_i & = \\eta_i \\\\\n    \\eta_i & = \\beta_0 + \\beta_1 X_{i}\n  \\end{aligned}\n\\]\nWith parameters:\n\n\n\\(\\beta_0\\): regression intercept; predicted \\(Y\\) value for observations with \\(X\\) = 0\n\n\\(\\beta_1\\): regression slope/coefficient; predicted difference in \\(Y\\) for one unit difference in \\(X\\)\n\n\n\\(\\sigma\\): standard deviation of prediction error; roughly speaking, the margin of error in prediction\n\n\n8.2.1 Example\nWe will use an example based on the “bread and peace” model by political scientist Douglas Hibbs, which can be used to forecast the U.S. presidential election outcome based on some weighted metric of personal income growth. The example is taken from chapter 7 of the book Regression and Other Stories.1\nFigure 8.2 is a graph showing the data from 1952 to 2012, with one variable being personal income growth in the four years prior to an election, and the other being the vote share (in %) of the incumbent’s party.\n\n# Economy and elections data\nif (!file.exists(\"data/hibbs.dat\")) {\n    download.file(\n        \"https://github.com/avehtari/ROS-Examples/raw/master/ElectionsEconomy/data/hibbs.dat\",\n        \"data/hibbs.dat\"\n    )\n}\nhibbs &lt;- read.table(\"data/hibbs.dat\", header = TRUE)\n\n\nggplot(hibbs, aes(x = growth, y = vote, label = year)) +\n    geom_point() +\n    ggrepel::geom_text_repel() +\n    labs(x = \"Average recent growth in personal income\",\n         y = \"Incumbent party's vote share (%)\")\n\n\n\n\n\n\nFigure 8.2: Scatter plot of personal income growth and vote share.",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Linear Models</span>"
    ]
  },
  {
    "objectID": "06-linear-models.html#model-and-priors",
    "href": "06-linear-models.html#model-and-priors",
    "title": "\n8  Linear Models\n",
    "section": "\n8.3 Model and Priors",
    "text": "8.3 Model and Priors\nModel:\n\\[\n\\begin{aligned}\n  \\text{vote}_i & \\sim N(\\mu_i, \\sigma) \\\\\n  \\mu_i & = \\beta_0 + \\beta_1 \\text{growth}_i\n\\end{aligned}\n\\]\n\\(\\sigma\\): SD (margin) of prediction error\nPriors:\n\\[\n\\begin{aligned}\n  \\beta_0 & \\sim N(45, 10)  \\\\\n  \\beta_1 & \\sim N(0, 10)  \\\\\n  \\sigma & \\sim t^+_4(0, 5)\n\\end{aligned}\n\\]",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Linear Models</span>"
    ]
  },
  {
    "objectID": "06-linear-models.html#model-fitting-with-stan",
    "href": "06-linear-models.html#model-fitting-with-stan",
    "title": "\n8  Linear Models\n",
    "section": "\n8.4 Model Fitting With Stan",
    "text": "8.4 Model Fitting With Stan\nOnce you’ve written the model, it’s straightforward to code the model in Stan to perform MCMC sampling, like the code below.\n\ndata {\n  int&lt;lower=0&gt; N;  // number of observations\n  vector[N] y;  // outcome;\n  vector[N] x;  // predictor;\n  int&lt;lower=0,upper=1&gt; prior_only;  // whether to sample prior only\n}\nparameters {\n  real beta0;  // regression intercept\n  real beta1;  // regression coefficient\n  real&lt;lower=0&gt; sigma;  // SD of prediction error\n}\nmodel {\n  // model\n  if (!prior_only) {\n    y ~ normal(beta0 + beta1 * x, sigma);\n  }\n  // prior\n  beta0 ~ normal(45, 10);\n  beta1 ~ normal(0, 10);\n  sigma ~ student_t(4, 0, 5);\n}\ngenerated quantities {\n  // Prior/posterior predictive\n  array[N] real ytilde = normal_rng(beta0 + beta1 * x, sigma);\n}\n\n\nlinear_reg &lt;- cmdstan_model(\"stan_code/linear_reg.stan\")\n\n\n8.4.1 Prior Predictive\n\nm1_prior &lt;- linear_reg$sample(\n    data = list(N = nrow(hibbs),\n                y = hibbs$vote,\n                x = hibbs$growth,\n                prior_only = TRUE),\n    seed = 1227,  # for reproducibility\n    refresh = 1000\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.6 seconds.\n\n\n\nm1_prior$draws(\"ytilde\", format = \"matrix\") |&gt;\n    ppc_ribbon(y = hibbs$vote, x = hibbs$growth,\n               y_draw = \"points\") +\n    labs(x = \"Average recent growth in personal income\",\n         y = \"Incumbent party's vote share (%)\") +\n    coord_cartesian(ylim = c(0, 100))\n\n\n\n\n\n\nFigure 8.3: Prior predictive distribution of the linear regression model for vote share against personal income.\n\n\n\n\nWe can also visualize the prior regression lines based on the prior distributions:\n\nprior_draws_beta &lt;- m1_prior$draws(c(\"beta0\", \"beta1\"), format = \"data.frame\")\nggplot(hibbs, aes(x = growth, y = vote, label = year)) +\n    geom_point() +\n    geom_abline(data = prior_draws_beta, aes(intercept = beta0, slope = beta1),\n    linewidth = 0.1, alpha = 0.1) +\n    ggrepel::geom_text_repel() +\n    labs(x = \"Average recent growth in personal income\",\n         y = \"Incumbent party's vote share (%)\") +\n    coord_cartesian(ylim = c(0, 100))\n\n\n\n\n\n\nFigure 8.4: Prior predictive distribution of the regression lines.\n\n\n\n\n\n8.4.2 Results\nWe’ll now fit the model (without prior_only = TRUE).\n\nm1_post &lt;- linear_reg$sample(\n    data = list(N = nrow(hibbs),\n                y = hibbs$vote,\n                x = hibbs$growth,\n                prior_only = FALSE),\n    seed = 1227,  # for reproducibility\n    refresh = 1000\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\n\n\nm1_summ &lt;- m1_post$summary(c(\"beta0\", \"beta1\", \"sigma\"))\n# Use `knitr::kable()` for tabulation\nknitr::kable(m1_summ, digits = 2)\n\n\nTable 8.1: Posterior summary of linear regression model.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\nbeta0\n46.25\n46.26\n1.73\n1.66\n43.42\n49.06\n1\n1582.97\n1590.35\n\n\nbeta1\n3.05\n3.06\n0.75\n0.71\n1.83\n4.26\n1\n1605.18\n1745.88\n\n\nsigma\n4.03\n3.91\n0.78\n0.70\n2.97\n5.48\n1\n2047.68\n2056.33\n\n\n\n\n\n\n\n\nThe parameter estimates are shown in Table 13.1. Here’s a paragraph for the results:\n\n\n\n\n\n\nThe model predicts that when personal income growth is 0, the vote share for the incumbent party is # A tibble: 1 × 1%, 90% CI [# A tibble: 1 × 1%, # A tibble: 1 × 1%], mean%, 90% CI [ q5%, q95%], %, 90% CI [ %, %], 1 46.2%, 90% CI [1 43.4%, 1 49.1%]. A 1-unit difference in personal income growth corresponds to a difference in vote share by # A tibble: 1 × 1 percentage points, 90% CI [# A tibble: 1 × 1, # A tibble: 1 × 1], mean percentage points, 90% CI [ q5, q95],  percentage points, 90% CI [ , ], 1 3.05 percentage points, 90% CI [1 1.83, 1 4.26].\n\n\n\n\n8.4.3 Convergence\nWe will talk about convergence more in a future week. For now, you want to see that\n\nThe chains mix well\nthe rank histograms are close to uniform distributions\n\n\nm1_post_draws &lt;- m1_post$draws(c(\"beta0\", \"beta1\", \"sigma\"))\nmcmc_trace(m1_post_draws)\nmcmc_rank_hist(m1_post_draws)\n\n\n\n\n\n\n\n\n\n(a) Trace plot\n\n\n\n\n\n\n\n\n\n\n\n(b) Rank histogram\n\n\n\n\n\n\nFigure 8.5: Convergence diagnostics for the linear regression model.\n\n\n\n\n8.4.4 Posterior plots\nThere are many ways to visualize the results of a regression model. The most important thing is to be as familiar with what the results mean as possible. Statistics is not magic that gives you numbers that either support or do not support your theory or hypothesis. It is a way to describe your data. If you do not want to do the work to understand what your data tell you, why bother to collect the data in the first place?\n\n8.4.4.1 Posterior density\nPosterior distributions of the three parameters\n\nmcmc_dens(m1_post_draws)\n\n\n\n\n\n\nFigure 8.6: Posterior density plots for \\(\\beta_0\\), \\(\\beta_1\\), and \\(\\sigma\\) in the linear regression model.\n\n\n\n\nYou can also combine the density plot and the trace plot\n\nmcmc_combo(m1_post_draws)\n\n\n\n\n\n\nFigure 8.7: Diagnostic plots for MCMC sampling.\n\n\n\n\n\n8.4.4.2 Plot regression prediction\nFigure 13.4 shows the 50% and 90% prediction intervals based on the posterior samples and the model. For example, with the 90% intervals, one expects 90% of the data should be within those intervals. If many data points lie outside the intervals, the linear model is not a good fit.\n\nm1_post$draws(\"ytilde\", format = \"matrix\") |&gt;\n    ppc_intervals(y = hibbs$vote, x = hibbs$growth) +\n    labs(x = \"Average recent growth in personal income\",\n         y = \"Predicted incumbent party's vote share (%)\") +\n    ggrepel::geom_label_repel(\n        aes(y = hibbs$vote, label = hibbs$year)\n    )\n\n\n\n\n\n\nFigure 8.8: Posterior predictive intervals of vote share against personal income growth.",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Linear Models</span>"
    ]
  },
  {
    "objectID": "06-linear-models.html#predicting-a-new-data-point",
    "href": "06-linear-models.html#predicting-a-new-data-point",
    "title": "\n8  Linear Models\n",
    "section": "\n8.5 Predicting a New Data Point",
    "text": "8.5 Predicting a New Data Point\nIn the four years before 2016, the weighted average personal income growth was 2.0 (based on Hibbs’ calculation). So, based on the model, we can obtain a posterior distribution for the predicted vote share of the Democratic Party, which is the incumbent party prior to the 2016 presidential election.\n\nlinear_pred &lt;- cmdstan_model(\"stan_code/linear_reg_pred.stan\")\n\n\nm1_pred &lt;- linear_pred$sample(\n    data = list(N = nrow(hibbs),\n                y = hibbs$vote,\n                x = hibbs$growth,\n                prior_only = FALSE,\n                xpred = 2),\n    seed = 1227,  # for reproducibility\n    refresh = 1000\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 0.1 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 0.1 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 0.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.5 seconds.\n\n\n\nm1_pred$draws(\"ypred\") |&gt;\n    mcmc_dens()\n\n\n\n\n\n\nFigure 8.9: Posterior predictive distribution of predicted vote share when growth = 2.\n\n\n\n\nThe mean of the incumbent’s predicted vote share with average income growth = 2 is 52.3006575. The actual outcome of the election was that the Democratic Party received about 51.1% of the votes among the two parties, so it was below the posterior predictive mean but within the range of possible outcomes. Of course, we know that the actual election outcome is based on the Eelectoral College, not the majority vote.",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Linear Models</span>"
    ]
  },
  {
    "objectID": "06-linear-models.html#robust-regression",
    "href": "06-linear-models.html#robust-regression",
    "title": "\n8  Linear Models\n",
    "section": "\n8.6 Robust Regression",
    "text": "8.6 Robust Regression\nThe linear model assuming normally distributed errors is not robust to outliers or influential observations. It can be robustified by assuming a more heavy-tailed distribution, such as the \\(t\\) distribution:\n\\[\n\\text{vote}_i \\sim t_\\nu(\\mu_i, \\sigma),\n\\]\nwhere \\(\\nu\\) is an additional degrees of freedom parameter controlling for the “heaviness” of the tails. When \\(\\nu\\) is close to 0 (e.g., 3 or 4), the outliers/influential cases are weighed less; when \\(\\nu\\) is close to infinity, the \\(t\\) distribution becomes a normal distribution.\nWith Bayesian methods, we can let the model learn from the data about the \\(\\nu\\) parameter. In this case, we assume a hyperprior for \\(\\nu\\); \\(\\mathrm{Gamma}(2, 0.1)\\) is something recommended in the literature.\n\ndata {\n  int&lt;lower=0&gt; N;  // number of observations\n  vector[N] y;  // outcome;\n  vector[N] x;  // predictor;\n  int&lt;lower=0,upper=1&gt; prior_only;  // whether to sample prior only\n}\nparameters {\n  real beta0;  // regression intercept\n  real beta1;  // regression coefficient\n  real&lt;lower=0&gt; sigma;  // SD of prediction error\n  real&lt;lower=1&gt; nu;  // df parameter\n}\nmodel {\n  // model\n  if (!prior_only) {\n    y ~ student_t(nu, beta0 + beta1 * x, sigma);\n  }\n  // prior\n  beta0 ~ normal(45, 10);\n  beta1 ~ normal(0, 10);\n  sigma ~ student_t(4, 0, 5);\n  nu ~ gamma(2, 0.1); // prior for df parameter\n}\ngenerated quantities {\n  vector[N] ytilde;  // place holder\n  for (i in 1:N)\n    ytilde[i] = normal_rng(beta0 + beta1 * x[i], sigma);\n}\n\n\nrobust_reg &lt;- cmdstan_model(\"stan_code/robust_reg.stan\")\n\n\nm1_robust &lt;- robust_reg$sample(\n    data = list(N = nrow(hibbs),\n                y = hibbs$vote,\n                x = hibbs$growth,\n                prior_only = FALSE),\n    seed = 1227,  # for reproducibility\n    refresh = 0\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.0 seconds.\nChain 3 finished in 0.0 seconds.\nChain 4 finished in 0.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.5 seconds.\n\n\n\nm1r_summ &lt;- m1_robust$summary(c(\"beta0\", \"beta1\", \"sigma\", \"nu\"))\n# Use `knitr::kable()` for tabulation\nknitr::kable(m1r_summ, digits = 2)\n\n\nTable 8.2: Posterior summary of Student t regression model.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\nbeta0\n46.17\n46.18\n1.55\n1.45\n43.55\n48.64\n1\n1628.35\n1673.90\n\n\nbeta1\n3.20\n3.22\n0.69\n0.66\n2.01\n4.30\n1\n1598.75\n1914.04\n\n\nsigma\n3.56\n3.49\n0.92\n0.83\n2.20\n5.10\n1\n1044.24\n586.21\n\n\nnu\n18.26\n14.64\n13.86\n11.60\n2.97\n45.62\n1\n1234.64\n638.30\n\n\n\n\n\n\n\n\n\nm1_robust$draws(\"ytilde\", format = \"matrix\") |&gt;\n    ppc_intervals(y = hibbs$vote, x = hibbs$growth) +\n    labs(x = \"Average recent growth in personal income\",\n         y = \"Predicted incumbent party's vote share (%)\") +\n    ggrepel::geom_label_repel(\n        aes(y = hibbs$vote, label = hibbs$year)\n    )\n\n\n\n\n\n\nFigure 8.10: Posterior predictive intervals of vote share against personal income growth based on Student t regression.",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Linear Models</span>"
    ]
  },
  {
    "objectID": "06-linear-models.html#footnotes",
    "href": "06-linear-models.html#footnotes",
    "title": "\n8  Linear Models\n",
    "section": "",
    "text": "See https://douglas-hibbs.com/background-information-on-bread-and-peace-voting-in-us-presidential-elections/ for more information on the “bread and peace” model.↩︎",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Linear Models</span>"
    ]
  },
  {
    "objectID": "06b-multiple-predictors.html",
    "href": "06b-multiple-predictors.html",
    "title": "9  Multiple Predictors",
    "section": "",
    "text": "9.1 Stratified Analysis\nLet’s consider whether the association between MedianAgeMarriage and Divorce differs between Southern and non-Southern states. Because (and only because) the groups are independent, we can fit a linear regression for each subset of states.\nggplot(waffle_divorce,\n       aes(x = MedianAgeMarriage, y = Divorce, col = South)) +\n    geom_point() +\n    geom_smooth() +\n    labs(x = \"Median age marriage (10 years)\",\n         y = \"Divorce rate (per 10 adults)\") +\n    ggrepel::geom_text_repel(aes(label = Loc), max.overlaps = 15)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\nFigure 9.1: State-level association between median age of marriage and divorce rate.",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Multiple Predictors</span>"
    ]
  },
  {
    "objectID": "06b-multiple-predictors.html#introducing-the-brms-package",
    "href": "06b-multiple-predictors.html#introducing-the-brms-package",
    "title": "9  Multiple Predictors",
    "section": "\n9.2 Introducing the brms package",
    "text": "9.2 Introducing the brms package\nWhile Stan is very flexible, because the linear model and some related models are so widely used, some authors have created packages that would further simplify the fitting of such models. One of those packages is brms, which I believe stands for “Bayesian regression models with Stan.” It allows one to do MCMC sampling using Stan, but with syntax similar to that in R functions lm(), glm(), and lme4::lmer(). brms probably supports more models than any R packages that statisticians routinely used; there are models, like factor analysis, that are not directly supported. If you came across some fancy regression models, chances are you can do something similar in brms. You can find some resources for learning brms on this page: https://paul-buerkner.github.io/brms/.\nModel formula\nbrms comes with some default prior options, but I recommend you always check what priors are used and think about whether they make sense for your data. You can use get_priors() to show the default priors used in brms.\nTo do MCMC sampling, we use the brm() function. The first argument is a formula in R. The variable before ~ is the outcome, whereas the ones after ~ are the predictors. For example,\nvote ~ 1 + growth\nmeans the model\n\\[\nE(\\text{vote}_i) = \\beta_0 (1) + \\beta_1 (\\text{growth}_i).\n\\]\nUsually, I write vote ~ 1 + growth as vote ~ growth, as the 1 + part is automatically added.\nSetting Priors\nbrms comes with some default prior options, but over the years, the package maintainers have changed those priors, so the default today may be different from the one next year. Therefore, you should always check what priors are used and think about whether they make sense for your data. You can use get_priors() to show the default priors used in brms. For example,\n\nget_prior(Divorce ~ MedianAgeMarriage,\n          data = waffle_divorce)\n\n\n  \n\n\n\n\nm_nonsouth &lt;-\n    brm(Divorce ~ MedianAgeMarriage,\n        # Filter `waffle_divorce` to only include non-southern states\n        data = filter(waffle_divorce, South == \"non-south\"),\n        # Use N(0, 2) and N(0, 10) as priors for beta1 and beta0,\n        # and use t_4(0, 3) as a prior for sigma\n        prior = prior(normal(0, 2), class = \"b\") +          \n            prior(normal(0, 10), class = \"Intercept\") +     \n            prior(student_t(4, 0, 3), class = \"sigma\"),     \n        seed = 941,\n        iter = 4000,\n        file = \"m_nonsouth\"\n    )\n\n\nm_south &lt;-\n    brm(Divorce ~ MedianAgeMarriage,\n        data = filter(waffle_divorce, South == \"south\"),\n        prior = prior(normal(0, 2), class = \"b\") +\n            prior(normal(0, 10), class = \"Intercept\") +\n            prior(student_t(4, 0, 3), class = \"sigma\"),\n        seed = 2157,  # use a different seed\n        iter = 4000,\n        file = \"m_south\"\n    )\n\nWe can make a table like Table 9.1 for brms results using the modelsummary::msummary() function.\n\nmsummary(list(South = m_south, `Non-South` = m_nonsouth),\n         estimate = \"{estimate} [{conf.low}, {conf.high}]\",\n         statistic = NULL, fmt = 2,\n         gof_omit = \"^(?!Num)\"  # only include number of observations\n)\n\nWarning: \n`modelsummary` uses the `performance` package to extract goodness-of-fit\nstatistics from models of this class. You can specify the statistics you wish\nto compute by supplying a `metrics` argument to `modelsummary`, which will then\npush it forward to `performance`. Acceptable values are: \"all\", \"common\",\n\"none\", or a character vector of metrics names. For example: `modelsummary(mod,\nmetrics = c(\"RMSE\", \"R2\")` Note that some metrics are computationally\nexpensive. See `?performance::performance` for details.\n This warning appears once per session.\n\n\n\nTable 9.1: Intercepts and slopes for south and non-south states.\n\n\n\n\n    \n\n      \n\n \n                South\n                Non-South\n              \n\n\nb_Intercept        \n                  6.09 [3.60, 8.45]   \n                  2.74 [1.75, 3.74]   \n                \n\nb_MedianAgeMarriage\n                  -1.96 [-2.89, -0.98]\n                  -0.69 [-1.07, -0.31]\n                \n\nsigma              \n                  0.11 [0.07, 0.17]   \n                  0.15 [0.12, 0.20]   \n                \n\nNum.Obs.           \n                  14                  \n                  36                  \n                \n\n\n\n\n\n\n\n\n\nWe can now ask two questions:\n\nIs the intercept different across southern and non-southern states?\nIs the slope different across southern and non-southern states?\n\nThe correct way to answer the above questions is to obtain the posterior distribution of the difference in the coefficients. Repeat: obtain the posterior distribution of the difference. The incorrect way is to compare whether the CIs overlap.\nHere are the posteriors of the differences (\\(\\beta_0^\\text{south} - \\beta_0^\\text{nonsouth}\\) and \\(\\beta_1^\\text{south} - \\beta_1^\\text{nonsouth}\\)):\n\n# Extract draws\ndraws_south &lt;- as_draws_matrix(m_south,\n    variable = c(\"b_Intercept\", \"b_MedianAgeMarriage\")\n)\ndraws_nonsouth &lt;- as_draws_matrix(m_nonsouth,\n    variable = c(\"b_Intercept\", \"b_MedianAgeMarriage\")\n)\n# Difference in coefficients\ndraws_diff &lt;- draws_south - draws_nonsouth\n# Rename the columns\ncolnames(draws_diff) &lt;- paste0(\"d\", colnames(draws_diff))\n# Summarize\nsummarize_draws(draws_diff) |&gt;\n    knitr::kable(digits = 2)\n\n\nTable 9.2: Difference in intercept and slope for south and non-south states.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\ndb_Intercept\n3.32\n3.34\n1.34\n1.29\n1.14\n5.45\n1\n6115.12\n5017.01\n\n\ndb_MedianAgeMarriage\n-1.26\n-1.27\n0.52\n0.50\n-2.09\n-0.41\n1\n6112.20\n5034.56\n\n\n\n\n\n\n\n\nAs you can see, the southern states have a higher intercept and a lower slope.\nplot(\n    conditional_effects(m_nonsouth),\n    points = TRUE, plot = FALSE\n)[[1]] + ggtitle(\"Non-South\") + lims(x = c(2.3, 3), y = c(0.6, 1.4))\nplot(\n    conditional_effects(m_south),\n    points = TRUE, plot = FALSE\n)[[1]] + ggtitle(\"South\") + lims(x = c(2.3, 3), y = c(0.6, 1.4))\n\n\n\n\n\n\n\n\n\n(a) Non-southern states\n\n\n\n\n\n\n\n\n\n(b) Southern states\n\n\n\n\n\n\nFigure 9.2: Model-implied regression lines",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Multiple Predictors</span>"
    ]
  },
  {
    "objectID": "06b-multiple-predictors.html#additive-model",
    "href": "06b-multiple-predictors.html#additive-model",
    "title": "9  Multiple Predictors",
    "section": "\n9.3 Additive Model",
    "text": "9.3 Additive Model\nAn additive model assumes that the difference between predicted \\(Y\\) for two levels of \\(X_1\\) is the same regardless of the level of \\(X_2\\). In our example, we assume that the predicted difference in divorce rate associated with the median age of marriage does not depend on whether the state is southern or not. Equivalently, we assume that the predicted difference in Southern and non-Southern states does not depend on the median age of marriage.\n\\[\n\\begin{aligned}\n  D_i & \\sim N(\\mu_i, \\sigma)  \\\\\n  \\mu_i & = \\beta_0 + \\beta_1 S_i + \\beta_2 A_i \\\\\n  \\beta_0 & \\sim N(0, 10) \\\\\n  \\beta_1 & \\sim N(0, 10) \\\\\n  \\beta_2 & \\sim N(0, 1)  \\\\\n  \\sigma & \\sim t^+_4(0, 3)\n\\end{aligned}\n\\]\n\n\n\\(\\beta_1\\): Expected difference in divorce rate between southern and non-southern states with the same median age of marriage.\n\n\\(\\beta_2\\): Expected difference in divorce rate for one unit difference in median age of marriage, when both states are southern (or non-southern).\n\nIn the model, the variable S, southern state, is a dummy variable with 0 = non-southern and 1 = southern. Therefore,\n\n\n\n\n\n\nDummy Coding\n\n\n\n\nFor non-southern states, \\(\\mu = (\\beta_0) + (\\beta_2) A\\);\nFor southern states, \\(\\mu = (\\beta_0 + \\beta_1) + \\beta_2 A\\)\n\n\n\n\n\nm_additive &lt;- brm(\n    Divorce ~ South + MedianAgeMarriage,\n    data = waffle_divorce,\n    prior = prior(normal(0, 2), class = \"b\") +\n        prior(normal(0, 10), class = \"b\", coef = \"Southsouth\") +\n        prior(normal(0, 10), class = \"Intercept\") +\n        prior(student_t(4, 0, 3), class = \"sigma\"),\n    seed = 941,\n    iter = 4000,\n    file = \"m_additive\"\n)\n\n\nm_additive\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: Divorce ~ South + MedianAgeMarriage \n   Data: waffle_divorce (Number of observations: 50) \n  Draws: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;\n         total post-warmup draws = 8000\n\nPopulation-Level Effects: \n                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept             3.00      0.46     2.10     3.89 1.00     7435     5360\nSouthsouth            0.08      0.05    -0.01     0.18 1.00     7847     5519\nMedianAgeMarriage    -0.79      0.18    -1.13    -0.45 1.00     7406     5423\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.15      0.02     0.12     0.18 1.00     7217     5426\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Multiple Predictors</span>"
    ]
  },
  {
    "objectID": "06b-multiple-predictors.html#interaction-model-different-slopes-across-two-groups",
    "href": "06b-multiple-predictors.html#interaction-model-different-slopes-across-two-groups",
    "title": "9  Multiple Predictors",
    "section": "\n9.4 Interaction Model: Different Slopes Across Two Groups",
    "text": "9.4 Interaction Model: Different Slopes Across Two Groups\nAn alternative is to include an interaction term\n\\[\n\\begin{aligned}\n  D_i & \\sim N(\\mu_i, \\sigma)  \\\\\n  \\mu_i & = \\beta_0 + \\beta_1 S_i + \\beta_2 A_i + \\beta_3 S_i \\times A_i \\\\\n  \\beta_0 & \\sim N(0, 10) \\\\\n  \\beta_1 & \\sim N(0, 10) \\\\\n  \\beta_2 & \\sim N(0, 1) \\\\\n  \\beta_3 & \\sim N(0, 2) \\\\\n  \\sigma & \\sim t^+_4(0, 3)\n\\end{aligned}\n\\]\n\n\n\\(\\beta_1\\): Difference in intercept between southern and non-southern states.\n\n\\(\\beta_3\\): Difference in the coefficient for A → D between southern and non-southern states\n\n\n\n\n\n\n\nDummy Coding in Interaction Model\n\n\n\n\nFor non-southern states, \\(\\mu = (\\beta_0) + (\\beta_2) A\\);\nFor southern states, \\(\\mu = (\\beta_0 + \\beta_1) + (\\beta_2 + \\beta_3) A\\)\n\n\n\n\n\nm_inter &lt;- brm(\n    Divorce ~ South * MedianAgeMarriage,\n    data = waffle_divorce,\n    prior = prior(normal(0, 2), class = \"b\") +\n        prior(normal(0, 10), class = \"b\", coef = \"Southsouth\") +\n        prior(normal(0, 10), class = \"Intercept\") +\n        prior(student_t(4, 0, 3), class = \"sigma\"),\n    seed = 941,\n    iter = 4000,\n    file = \"m_inter\"\n)\n\nThe formula Divorce ~ South * MedianAgeMarriage is the same as\nDivorce ~ South + MedianAgeMarriage + South:MedianAgeMarriage\nwhere : is the symbol in R for a product term.\n\n# Print summary of the model\nm_inter\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: Divorce ~ South * MedianAgeMarriage \n   Data: waffle_divorce (Number of observations: 50) \n  Draws: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;\n         total post-warmup draws = 8000\n\nPopulation-Level Effects: \n                             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept                        2.78      0.46     1.87     3.68 1.00     4716\nSouthsouth                       3.20      1.60     0.19     6.30 1.00     2863\nMedianAgeMarriage               -0.70      0.18    -1.05    -0.35 1.00     4714\nSouthsouth:MedianAgeMarriage    -1.22      0.62    -2.42    -0.03 1.00     2876\n                             Tail_ESS\nIntercept                        4042\nSouthsouth                       3608\nMedianAgeMarriage                4085\nSouthsouth:MedianAgeMarriage     3584\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.14      0.02     0.12     0.18 1.00     4244     4998\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\n9.4.1 Posterior predictive checks\n\n# Check density (normality)\npp_check(m_inter, type = \"dens_overlay_grouped\", group = \"South\")\n\nUsing 10 posterior draws for ppc type 'dens_overlay_grouped' by default.\n\n# Check prediction (a few outliers)\npp_check(m_inter,\n    type = \"ribbon_grouped\", x = \"MedianAgeMarriage\",\n    group = \"South\",\n    y_draw = \"points\"\n)\n\nUsing all posterior draws for ppc type 'ribbon_grouped' by default.\n\n\n\n\n\n\n\n\n\n(a) Density overlayed plots\n\n\n\n\n\n\n\n\n\n(b) Prediction intervals\n\n\n\n\n\nFigure 9.3: Posterior predictive checks for the interaction model.\n\n\n\n\n# Check errors (no clear pattern)\npp_check(m_inter,\n    type = \"error_scatter_avg_vs_x\", x = \"MedianAgeMarriage\"\n)\n\nUsing all posterior draws for ppc type 'error_scatter_avg_vs_x' by default.\n\n\n\n\n\n\n\nFigure 9.4: Average prediction error against the predictor. No clear pattern should be observed for a correctly specified model.\n\n\n\n\n\n9.4.2 Conditional effects/simple slopes\nSlope of MedianAgeMarriage when South = 0: \\(\\beta_1\\)\nSlope of MedianAgeMarriage when South = 1: \\(\\beta_1 + \\beta_3\\)\n\nas_draws(m_inter) |&gt;\n    mutate_variables(\n        b_nonsouth = b_MedianAgeMarriage,\n        b_south = b_MedianAgeMarriage + `b_Southsouth:MedianAgeMarriage`\n    ) |&gt;\n    posterior::subset_draws(\n        variable = c(\"b_nonsouth\", \"b_south\")\n    ) |&gt;\n    summarize_draws() |&gt;\n    knitr::kable(digits = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nmean\nmedian\nsd\nmad\nq5\nq95\nrhat\ness_bulk\ness_tail\n\n\n\nb_nonsouth\n-0.70\n-0.71\n0.18\n0.18\n-1.00\n-0.41\n1\n4713.61\n4085.16\n\n\nb_south\n-1.92\n-1.91\n0.60\n0.60\n-2.91\n-0.93\n1\n3168.15\n3659.43\n\n\n\n\n\n\nplot(\n    conditional_effects(m_inter,\n        effects = \"MedianAgeMarriage\",\n        conditions = data.frame(South = c(\"south\", \"non-south\"),\n                                cond__ = c(\"South\", \"Non-South\"))\n    ),\n    points = TRUE\n)\n\n\n\n\n\n\nFigure 9.5: Model-implied simple slopes based on the interaction model.",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Multiple Predictors</span>"
    ]
  },
  {
    "objectID": "06b-multiple-predictors.html#interaction-of-continuous-predictors",
    "href": "06b-multiple-predictors.html#interaction-of-continuous-predictors",
    "title": "9  Multiple Predictors",
    "section": "\n9.5 Interaction of Continuous Predictors",
    "text": "9.5 Interaction of Continuous Predictors\n\nplotly::plot_ly(waffle_divorce,\n                x = ~Marriage,\n                y = ~MedianAgeMarriage,\n                z = ~Divorce)\n\nNo trace type specified:\n  Based on info supplied, a 'scatter3d' trace seems appropriate.\n  Read more about this trace type -&gt; https://plotly.com/r/reference/#scatter3d\n\n\nNo scatter3d mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -&gt; https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\n\nFigure 9.6: 3-D plot visualizing one outcome and two predictors.\n\n\n\n\\[\n\\begin{aligned}\n  D_i & \\sim N(\\mu_i, \\sigma)  \\\\\n  \\mu_i & = \\beta_0 + \\beta_1 M_i + \\beta_2 A_i + \\beta_3 M_i \\times A_i \\\\\n\\end{aligned}\n\\]\n\n# Use default priors (just for convenience here)\nm_inter2 &lt;- brm(Divorce ~ Marriage * MedianAgeMarriage,\n    data = waffle_divorce,\n    seed = 941,\n    iter = 4000,\n    file = \"m_inter2\"\n)",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Multiple Predictors</span>"
    ]
  },
  {
    "objectID": "06b-multiple-predictors.html#centering",
    "href": "06b-multiple-predictors.html#centering",
    "title": "9  Multiple Predictors",
    "section": "\n9.6 Centering",
    "text": "9.6 Centering\nIn the previous model, \\(\\beta_1\\) is the slope of M → D when A is 0 (i.e., median marriage age = 0), and \\(\\beta_2\\) is the slope of A → D when M is 0 (i.e., marriage rate is 0). These two are not very meaningful. Therefore, it is common to make the zero values more meaningful by doing centering.\nHere, I use M - 2 as the predictor, so the zero point means a marriage rate of 2 per 10 adults; I use A - 2.5 as the other predictor, so the zero point means a median marriage rate of 25 years old.\n\\[\n\\mu_i = \\beta_0 + \\beta_1 (M_i - 2) + \\beta_2 (A_i - 2.5) + \\beta_3 (M_i - 2) \\times (A_i - 2.5)\n\\]\n\n# Use default priors (just for convenience here)\nm_inter2c &lt;- brm(Divorce ~ I(Marriage - 2) * I(MedianAgeMarriage - 2.5),\n    data = waffle_divorce,\n    seed = 941,\n    iter = 4000,\n    file = \"m_inter2c\"\n)\n\n\nmsummary(list(`No centering` = m_inter2, `centered` = m_inter2c),\n         estimate = \"{estimate} [{conf.low}, {conf.high}]\",\n         statistic = NULL, fmt = 2)\n\n\n\n    \n\n      \n\n \n                No centering\n                centered\n              \n\n\nb_Intercept                           \n                  7.38 [3.02, 11.58]  \n                  1.09 [1.02, 1.16]   \n                \n\nb_Marriage                            \n                  -1.93 [-4.00, 0.16] \n                                      \n                \n\nb_MedianAgeMarriage                   \n                  -2.45 [-4.07, -0.78]\n                                      \n                \n\nb_Marriage × MedianAgeMarriage        \n                  0.74 [-0.07, 1.56]  \n                                      \n                \n\nsigma                                 \n                  0.15 [0.12, 0.18]   \n                  0.15 [0.12, 0.18]   \n                \n\nb_IMarriageM2                         \n                                      \n                  -0.08 [-0.24, 0.09] \n                \n\nb_IMedianAgeMarriageM2.5              \n                                      \n                  -0.94 [-1.44, -0.44]\n                \n\nb_IMarriageM2 × IMedianAgeMarriageM2.5\n                                      \n                  0.75 [-0.08, 1.59]  \n                \n\nNum.Obs.                              \n                  50                  \n                  50                  \n                \n\nR2                                    \n                  0.414               \n                  0.413               \n                \n\nR2 Adj.                               \n                  0.278               \n                  0.270               \n                \n\nELPD                                  \n                  21.5                \n                  21.2                \n                \n\nELPD s.e.                             \n                  6.1                 \n                  6.2                 \n                \n\nLOOIC                                 \n                  -42.9               \n                  -42.5               \n                \n\nLOOIC s.e.                            \n                  12.2                \n                  12.5                \n                \n\nWAIC                                  \n                  -43.5               \n                  -43.1               \n                \n\nRMSE                                  \n                  0.14                \n                  0.14                \n                \n\n\n\n\n\n\nAs shown in the table above, while the two models are equivalent in fit and give the same posterior distribution for \\(\\beta_3\\), they differ in \\(\\beta_0\\), \\(\\beta_1\\), and \\(\\beta_2\\).\n\nplot(\n    conditional_effects(m_inter2c,\n        effects = \"Marriage:MedianAgeMarriage\",\n        int_conditions = list(MedianAgeMarriage = c(2.3, 2.5, 2.7)),\n    ),\n    points = TRUE\n)\n\n\n\n\n\n\nFigure 9.7: Model-implied simple slopes of marriage for different levels of median age of marriage.\n\n\n\n\n\n\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: a Bayesian course with examples in R and Stan (Second edition). CRC Press.",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Multiple Predictors</span>"
    ]
  },
  {
    "objectID": "06c-regression-diagnostics.html",
    "href": "06c-regression-diagnostics.html",
    "title": "\n10  Model Diagnostics\n",
    "section": "",
    "text": "10.1 Assumptions of Linear Models\nThe assumptions of the linear model is encoded in the model. The model is\n\\[\n\\begin{aligned}\n  Y_i & \\sim N(\\mu_i, \\sigma)  \\\\\n  \\mu_i & = \\beta_0 + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\ldots\n\\end{aligned}\n\\]\nFrom the model, we have the following assumptions, in the order of the most important one to the least important one:",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Model Diagnostics</span>"
    ]
  },
  {
    "objectID": "06c-regression-diagnostics.html#assumptions-of-linear-models",
    "href": "06c-regression-diagnostics.html#assumptions-of-linear-models",
    "title": "\n10  Model Diagnostics\n",
    "section": "",
    "text": "Correct specification of the model. This means that all relevant predictors for \\(Y\\) have been included in the model. This is probably an assumption that is never satisfied in real data analysis, as one can never include all relevant factors that can have an impact on \\(Y\\), be it small or large. However, it is important to be thoughtful to include major predictors that have been shown to relate to \\(Y\\). Leaving out key predictors can bias the coefficients \\(\\beta\\).\n\nLinearity. This is about the conditional mean, \\(\\mu = E(Y | X_1, X_2, \\ldots)\\), being a linear function. If you have a function like \\(\\mu = \\exp[\\beta_1 X_1 \\sin (\\beta_2 X_2)]\\), the conditional mean is not a linear function. Note that linearity does not require \\(\\mu\\) to be a linear function of predictors; quadratic and exponential relationships, interaction, and polynomials can all be handled by linear models. (And technically, linearity requires \\(\\mu\\) to be a linear function of the coefficients.)\n\nIndependent observations. This assumption is not directly encoded in the model equation above, mainly because I omit that part when writing out the model. This assumption requires that the value of one observation is independent of the value of another observation after taking into account the conditional mean, \\(\\mu\\). This will be discussed more in multilevel models.\n\nEqual variance of errors. This means that \\(\\sigma^2\\) has to be constant for each observation. In general, Violating this assumption is generally a minor issue, although it can affect the posterior standard deviation (analogous to standard errors).\n\nNormality. This requires that the conditional distribution of \\(Y\\) is normal. Violating of the normality assumption generally does not affect the estimation of the coefficients, and will be a minor issue when the sample size is large enough (&gt; 30) and when the degree of nonnormality is small to moderate.",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Model Diagnostics</span>"
    ]
  },
  {
    "objectID": "06c-regression-diagnostics.html#diagnostic-tools",
    "href": "06c-regression-diagnostics.html#diagnostic-tools",
    "title": "\n10  Model Diagnostics\n",
    "section": "\n10.2 Diagnostic Tools",
    "text": "10.2 Diagnostic Tools\nNow let’s review some tools for regression diagnostics for Bayesian regression. There are hundreds of plots available that I will not cover here, and you can treat what is discussed in this note as a minimal requirement for regression diagnostics. The first one is about a correct specification of the model, which can be partly assessed with posterior predictive check.\n\n10.2.1 Posterior Predictive Check\nWe’ve already seen a few examples of posterior predictive checks in the previous chapters. Continuing with the example of predicting the divorce rate, here are a few more plots.\nBelow is the posterior predictive graphical check for the interaction model we fit for the state-level divorce rate data:\n\n\n\n\n\n\n\n\n\n\n(a) Density overlayed plots\n\n\n\n\n\n\n\n\n\n(b) Prediction intervals\n\n\n\n\n\nFigure 10.1: Posterior predictive checks for the interaction model.\n\n\n\n\nBased on the graphical check, we do not see any major systematic discrepancies between the distribution of our data and what can be predicted from our model. The ribbon plot shows that some points are outside the 90% predictive intervals but not too far off.\nWe should do the posterior predictive check with test statistics too. The following functions show the mean, maximum value, and minimum value of the outcome.\n\n# PPC for the mean (it should always fit)\npp_check(m_inter, type = \"stat_grouped\", stat = \"mean\", group = \"South\")\n\nUsing all posterior draws for ppc type 'stat_grouped' by default.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nFigure 10.2: Posterior predictive check for the sample mean.\n\n\n\n\n\n# PPC for the mean (it should always fit)\n# PPC for the maximum and minimum values\npp_check(m_inter, type = \"stat_2d\", stat = c(\"max\", \"min\"))\n\nUsing all posterior draws for ppc type 'stat_2d' by default.\n\n\n\n\n\n\n\nFigure 10.3: Posterior predictive check for the sample maximum and minimum.\n\n\n\n\n\n10.2.2 Marginal model plots\nTo check the linearity assumption, we need to ensure that the conditional mean of \\(Y\\) fits according to the model. A marginal model plot compares the model predicted relationship between the outcome and each predictor, and the relationship obtained using nonparametric methods with smoothing.\n\npp_check(m_inter, type = \"intervals_grouped\",\n         x = \"MedianAgeMarriage\", group = \"South\") +\n    geom_smooth(se = FALSE, col = \"blue\") +\n    geom_smooth(aes(y = y_obs), se = FALSE, col = \"red\", linetype = \"dashed\")\n\nUsing all posterior draws for ppc type 'intervals_grouped' by default.\n\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: The following aesthetics were dropped during statistical transformation: ymin,\nymax\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\nThe following aesthetics were dropped during statistical transformation: ymin,\nymax\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: The following aesthetics were dropped during statistical transformation: ymin,\nymax\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\nThe following aesthetics were dropped during statistical transformation: ymin,\nymax\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n# Alternative code\n# plot(\n#     conditional_effects(m_inter,\n#         effects = \"MedianAgeMarriage\",\n#         conditions = data.frame(South = c(\"south\", \"non-south\"),\n#                                 cond__ = c(\"South\", \"Non-South\"))\n#     ),\n#     plot = FALSE\n# )[[1]] +\n#     # Add data points\n#     geom_point(\n#         data = m_inter$data,\n#         aes(x = MedianAgeMarriage, y = Divorce),\n#         inherit.aes = FALSE\n#     ) +\n#     # Add smoother\n#     geom_smooth(\n#         data = m_inter$data,\n#         aes(x = MedianAgeMarriage, y = Divorce),\n#         col = \"red\", linetype = \"dashed\",\n#         inherit.aes = FALSE,\n#         se = FALSE) +\n#     facet_wrap(~ South)\n\n\n\n\n\n\nFigure 10.4: Marginal model plots with the model-implied (blue solid) and the nonparametric (red dashed) smoother.\n\n\n\n\nMarginal model plots are more appropriate for ordinal or continuous predictors. As you can see above, the red line (for nonparametric fit) and the blue line (from the linear model) fit the data well, but not for the left tail area, where some of the non-Southern states have lower divorce rates than predicted. If the linearity assumption holds, these two lines should be very similar. Generally speaking, deviations in the middle indicate a strong misspecification that needs to be fixed.\nAlso, we want to check outliers that lie way outside the predictive interval. With a 95% predictive interval, we generally expect 5% to lie outside of the predictive interval band. In this example, we don’t see a great problem with outliers.\n\n10.2.2.1 LOO PIT plots\nHere’s a check using probability integral transform. Roughly speaking, you can think of it as a flattened version of the marginal model plots, where you’d like to see the darkened line be relatively flat and within the range of the model prediction.\n\npp_check(m_inter, type = \"loo_pit_overlay\")\n\nUsing 10 posterior draws for ppc type 'loo_pit_overlay' by default.\n\n\nWarning: Not enough tail samples to fit the generalized Pareto distribution in some or all columns of matrix of log importance ratios. Skipping the following columns: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, ... [40 more not printed].\n\n\nWarning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details.\n\n\nWarning: Not enough tail samples to fit the generalized Pareto distribution in some or all columns of matrix of log importance ratios. Skipping the following columns: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, ... [40 more not printed].\n\n\nWarning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details.\n\n\nNOTE: The kernel density estimate assumes continuous observations and is not optimal for discrete observations.\n\n\n\n\n\n\n\n\n\n10.2.3 Residual plots\nFor regression analyses, one can learn a lot about model fit from the residuals, which is \\(y_i - \\tilde{y}_i | \\theta\\), i.e., subtracting the observed \\(y_i\\) values by the posterior predictions. Because in Bayesian, there is not just one predicted value, but a whole predictive distribution, one also has an entire posterior distribution for each residual. Figure 10.5 is a check of the average residual \\(Y\\) (i.e., \\(Y\\) - \\(\\hat Y\\)) and the true value of \\(Y\\). If the model fit the data well, the points should be scattered with no specific pattern, like in Figure 10.5.\n\n\n\n\n\n\n\n\nFigure 10.5: Average prediction error against the predictor. No clear pattern should be observed for a correctly specified model.\n\n\n\n\n\nNo big problem was found in the residuals. If you see that the SD of the residuals is not uniform, or the residuals have some non-linear relationships with the predictor, there can be some problems.\n\n10.2.4 Multicollinearity\nStrictly speaking, multicollinearity is not an assumption of regression. However, especially in frequentist analysis, having predictors that are strongly correlated can increase the uncertainty of the posterior distributions of the regression coefficients. On the other hand, the use of the prior distribution in Bayesian analyses can somewhat come to the rescue, as it makes it less likely for the posteriors to have extremely large posterior mean and standard deviation    \nYou can look at the posterior density of the coefficients to see how correlated they are:\n\npairs(m_inter,\n    variable = \"^b\",  # for all variables starting with b\n    regex = TRUE,\n    off_diag_args = # arguments of the scatterplots\n        list(\n            size = 0.5, # point size\n            alpha = 0.25 # transparency\n        )\n)\n\n\n\n\n\n\n\nIf some coefficients are particularly strongly correlated, you may need to think about using a stronger prior or combining some predictors. In this case, the collinearity is a result of the interactions. Principal component and factor analysis are some approaches for that.",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Model Diagnostics</span>"
    ]
  },
  {
    "objectID": "06c-regression-diagnostics.html#other-topics",
    "href": "06c-regression-diagnostics.html#other-topics",
    "title": "\n10  Model Diagnostics\n",
    "section": "\n10.3 Other Topics",
    "text": "10.3 Other Topics\nThere are other topics we have yet to discuss here for diagnostics of multiple regression, but are just as important, including:\n\nTransformation (e.g., logarithm transformation with skewed outcomes and predictors, like income);\nLeverage points and influential observations (e.g., hat values, Cook’s \\(D\\))\nMeasurement error of predictors",
    "crumbs": [
      "Week 5--6",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Model Diagnostics</span>"
    ]
  },
  {
    "objectID": "07-model-comparison.html",
    "href": "07-model-comparison.html",
    "title": "\n11  Model Comparison\n",
    "section": "",
    "text": "11.1 Overfitting and Underfitting\nIn statistical modeling, a more complex model almost always results in a better fit to the data. Roughly speaking, a more complex model means a model with more parameters. However, as you will see later, determining the number of parameters in Bayesian analyses is not straightforward. On the extreme side, if one has 10 observations, a model with 10 parameters will perfectly predict every single data point (by just having a parameter to predict each data point). However, there are two problems with too complex a model. First, an increasingly complex model makes it increasingly hard to extract useful information from the data. Instead of describing the relationship between two variables, like Marriage and Divorce, by a straight line, one ends up with a crazy model that is difficult to make sense of. Second, as you will also see, the more complex a model, the more is the risk that it overfits the current data, such that it does not work for future observations.\nFor example, let’s randomly sample 10 states in the waffle_divorce data set and build some models.\nwaffle_divorce &lt;- read_delim(  # read delimited files\n    \"data/WaffleDivorce.csv\",\n    delim = \";\"\n)\n\nRows: 50 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr  (2): Location, Loc\ndbl (11): Population, MedianAgeMarriage, Marriage, Marriage SE, Divorce, Div...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Rescale Marriage and Divorce by dividing by 10\nwaffle_divorce$Marriage &lt;- waffle_divorce$Marriage / 10\nwaffle_divorce$Divorce &lt;- waffle_divorce$Divorce / 10\nwaffle_divorce$MedianAgeMarriage &lt;- waffle_divorce$MedianAgeMarriage / 10\n# Recode `South` to a factor variable\nwaffle_divorce$South &lt;- factor(waffle_divorce$South,\n    levels = c(0, 1),\n    labels = c(\"non-south\", \"south\")\n)\nset.seed(1547)  # set the seed for reproducibility\n# Sample 10 observations\ntrain &lt;- sample.int(nrow(waffle_divorce), 10L)\nwd_sub &lt;- waffle_divorce[train, ]\nbase &lt;- ggplot(aes(x = Marriage, y = Divorce),\n               data = wd_sub) +\n    geom_point() +\n    coord_cartesian(ylim = c(0.6, 1.4)) +\n    xlim(range(waffle_divorce$Marriage))\nggplot(waffle_divorce,\n       aes(x = Marriage, y = Divorce)) + \n    geom_point(col = \"lightblue\") +\n    geom_point(size = 1.5, data = wd_sub, col = \"red\") +\n    coord_cartesian(ylim = c(0.6, 1.4)) +\n    xlim(range(waffle_divorce$Marriage))\nWhen using Marriage to predict Divorce, we can use beyond a linear regression line by using higher-order polynomials. For example, a second-order polynomial represents a quadratic effect (with one turning point); it goes to cubic, quartic, and more. The figure below shows the fit from a linear effect of Marriage, a quadratic effect, and increasingly complex models up to a sixth-degree polynomial. As you can see, as the model gets more complex, the fitted line tries to capture all the 10 points really well, with an increasing \\(R^2\\). However, the standard error around the fitted line also gets larger and bizarre, meaning more uncertainty in the model parameters.\nCoder2 &lt;- function(object, newresp, newdata) {\n    # Function for computing R^2\n    ypred &lt;- predict(object, newdata = newdata)\n    cor(ypred, newresp)^2\n}\nrmse &lt;- function(object, newresp, newdata) {\n    # Function for RMSE\n    ypred &lt;- predict(object, newdata = newdata)\n    sqrt(mean((ypred - newresp)^2))\n}\n# Create six plots through a loop\np_list &lt;- map(1:6, function(i) {\n    # Use frequentist analyses for speed\n    mod &lt;- lm(Divorce ~ poly(Marriage, degree = i), data = wd_sub)\n    base +\n        geom_smooth(method = \"lm\", formula = y ~ poly(x, i), level = .80,\n                    fullrange = TRUE) +\n        annotate(\"text\", x = 1.7, y = 1.4,\n                 label = paste0(\"italic(R)^2 == \",\n                                round(r2(mod, wd_sub$Divorce), 2)),\n                 parse = TRUE) +\n        annotate(\"text\", x = 1.7, y = 1.2,\n                 label = paste0(\"RMSE == \",\n                                round(rmse(mod, wd_sub$Divorce), 2)),\n                 parse = TRUE)\n})\ndo.call(grid.arrange, c(p_list, nrow = 2))\n\n\n\n\n\n\nFigure 11.1: Fit of models on the 10 random cases. Top panel: linear, quadratic, and cubic; bottom panel: 4th, 5th, and 6th degree polynomials\nAnother way to look at model accuracy is the Root Mean Squared Error (RMSE), defined as the square root of the average squared prediction error. RMSE is a measure of prediction error. The smaller the RMSE, the better the prediction is. As you can see in the above figure, more complex models always reduce the RMSE in the data we use to fit the model (also called training data).\nHowever, if I take the estimated regression line/curve based on the subsample of 10 observations, and predict the remaining cases in the data set, things will be different. As you can see in the figure below, whereas prediction error is comparable for the linear and the quadratic model, polynomials of higher degrees predict the data really badly. When you use a complex model in a data set, it tailors the coefficients to any sampling errors and noise in the data such that it will not generalize to new observations. Therefore, our goal in model comparison is to choose a model complex enough to capture the essence of the data generation process (and thus avoid underfitting), but not too complex such that it suffers from overfitting.\nCodebase2 &lt;- ggplot(aes(x = Marriage, y = Divorce),\n               data = waffle_divorce[-train, ]) +\n    geom_point() +\n    coord_cartesian(ylim = c(0.6, 1.4)) +\n    xlim(range(waffle_divorce$Marriage))\n# Create six plots through a loop\np_list2 &lt;- map(1:6, function(i) {\n    # Use frequentist analyses for speed\n    mod &lt;- lm(Divorce ~ poly(Marriage, degree = i), data = wd_sub)\n    # New data and response\n    test_dat &lt;- waffle_divorce[-train, ]\n    ynew &lt;- test_dat$Divorce\n    base2 +\n        geom_smooth(data = wd_sub, method = \"lm\", formula = y ~ poly(x, i),\n                    level = .80, fullrange = TRUE) +\n        annotate(\"text\", x = 1.7, y = 1.4,\n                 label = paste0(\"italic(R)^2 == \",\n                                round(r2(mod, ynew, test_dat), 2)),\n                 parse = TRUE) +\n        annotate(\"text\", x = 1.7, y = 1.2,\n                 label = paste0(\"RMSE == \",\n                                round(rmse(mod, ynew, test_dat), 2)),\n                 parse = TRUE)\n})\ndo.call(grid.arrange, c(p_list2, nrow = 2))\n\n\n\n\n\n\nFigure 11.2: Using the regression lines based on 10 random cases to predict the remaining 40 cases. Top panel: linear, quadratic, and cubic; bottom panel: 4th, 5th, and 6th degree polynomials\nThe goal of statistical modeling is to choose an optimal model between the overfitting/underfitting dichotomy. In machine learning, this is also commonly referred to as the bias-variance trade-off, as a model that is too simple tends to produce biased predictions because it does not capture the essence of the data generating process. In contrast, a overly complex model is unbiased but results in a lot of uncertainty in the prediction because there are too many unnecessary components that can affect predictions, as indicated in the confidence bands around the 6th-degree polynomial line.\nPolynomials of varying degrees are merely one example of comparing simple to complex models. You can think about:\nWhereas one can always avoid underfitting by fitting a more and more complex model, we need tools to keep us from overfitting. This lecture is about finding an optimal model that avoids overfitting and avoids underfitting. You will learn to perform model comparisons with information criteria to find a model that has a better balance between overfitting and underfitting.",
    "crumbs": [
      "Week 7",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Model Comparison</span>"
    ]
  },
  {
    "objectID": "07-model-comparison.html#overfitting-and-underfitting",
    "href": "07-model-comparison.html#overfitting-and-underfitting",
    "title": "\n11  Model Comparison\n",
    "section": "",
    "text": "models with and without interactions,\nmodels with a few predictors versus hundreds of predictors,\nregression analyses versus multilevel models, etc.",
    "crumbs": [
      "Week 7",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Model Comparison</span>"
    ]
  },
  {
    "objectID": "07-model-comparison.html#kullback-leibler-divergence",
    "href": "07-model-comparison.html#kullback-leibler-divergence",
    "title": "\n11  Model Comparison\n",
    "section": "\n11.2 Kullback-Leibler Divergence",
    "text": "11.2 Kullback-Leibler Divergence\nWhen comparing models (e.g., linear vs. quadratic), we prefer models closer to the “true” data-generating process. To do so, we need some ways to quantify the degree of “closeness” to the true model. In this context, models comprise both the distributional family and the parameter values. For example, the model \\(y_i \\sim N(5, 2)\\) is a different model than \\(y_i \\sim N(3, 2)\\), which is a different model than \\(y_i \\sim \\mathrm{Gamma}(2, 2)\\). The first two have the same family but different parameter values (different means, same \\(\\mathit{SD}\\)). In contrast, the last two have different distributional families (Normal vs. Gamma).\nTo measure the degree of “closeness” between two models, \\(M_0\\) and \\(M_1\\), by far the most popular metric in statistics is the Kullback-Liebler Divergence (or Kullback-Liebler discrepancy; \\(D_\\textrm{KL}\\)). By definition,\n\\[\n\\begin{aligned}\nD_\\textrm{KL}(M_0 \\mid M_1) & = \\int_{-\\infty}^\\infty p_{M_0} (\\boldsymbol{\\mathbf{y}})\n                    \\log \\frac{p_{M_0}(\\boldsymbol{\\mathbf{y}})}{p_{M_1}(\\boldsymbol{\\mathbf{y}})} \\; \\mathrm{d}\\boldsymbol{\\mathbf{y}} \\\\\n                & = \\int_{-\\infty}^\\infty p_{M_0} (\\boldsymbol{\\mathbf{y}})\n                          \\log p_{M_0}(\\boldsymbol{\\mathbf{y}}) \\; \\mathrm{d}\\boldsymbol{\\mathbf{y}} -\n                    \\int_{-\\infty}^\\infty p_{M_0} (\\boldsymbol{\\mathbf{y}})\n                          \\log p_{M_1}(\\boldsymbol{\\mathbf{y}}) \\; \\mathrm{d}\\boldsymbol{\\mathbf{y}}.\n\\end{aligned}\n\\]\nNote that strictly speaking, \\(D_\\textrm{KL}\\) cannot be called a “distance” between two models because in general, \\(D_\\textrm{KL}(M_0 \\mid M_1) \\neq D_\\textrm{KL}(M_1 \\mid M_0)\\). As an example, assume that the data are generated by a true model \\(M_0\\), and we have two candidate models \\(M_1\\) and \\(M_2\\), where\n\n\\(M_0: y \\sim N(3, 2)\\)\n\\(M_1: y \\sim N(3.5, 2.5)\\)\n\\(M_2: y \\sim \\mathrm{Cauchy}(3, 2)\\)\n\n\nCodeggplot(data.frame(x = c(-3, 9)), aes(x = x)) +\n    stat_function(fun = dnorm, args = list(mean = 3, sd = 2),\n                  aes(col = \"M0\"), linewidth = 1) +\n    stat_function(fun = dnorm, args = list(mean = 3.5, sd = 2.5),\n                  aes(col = \"M1\"), linewidth = 2) +\n    stat_function(fun = dcauchy, args = list(location = 3, scale = 2),\n                  aes(col = \"M2\"), linewidth = 2) +\n    scale_color_manual(values = c(\"black\", \"red\", \"blue\"),\n                       labels = c(\"M0\", \"M1\", \"M2\")) +\n    labs(x = \"y\", y = \"density\", col = NULL)\n\n\n\n\n\n\nFigure 11.3: Density for \\(M_0\\), \\(M_1\\), and \\(M_2\\)\n\n\n\n\n\nf1 &lt;- function(x) {\n    dnorm(x, 3, 2) * (dnorm(x, 3, 2, log = TRUE) -\n        dnorm(x, 3.5, 2.5, log = TRUE))\n}\nf2 &lt;- function(x) {\n    dnorm(x, 3, 2) * (dnorm(x, 3, 2, log = TRUE) -\n        dcauchy(x, 3, 2, log = TRUE))\n}\n\nOne can compute that \\(D_\\textrm{KL}(M_0 \\mid M_1) = 0.0631436\\) and \\(D_\\textrm{KL}(M_0 \\mid M_1) = 0.2592445\\), and so \\(M_1\\) is a better model than \\(M_2\\).\nNote that in the expression of \\(D_\\textrm{KL}\\), when talking about the same target model, the first term is always the same and describes the “true” model, \\(M_0\\). Therefore, it is sufficient to compare models on the second term, \\(\\int_{-\\infty}^\\infty p_{M_0} (\\boldsymbol{\\mathbf{y}}) \\log p_{M_1}(\\boldsymbol{\\mathbf{y}}) \\; \\mathrm{d}\\boldsymbol{\\mathbf{y}}\\), which can also be written as \\(\\mathrm{E}=[\\log p_{M_1} (\\boldsymbol{\\mathbf{y}})]\\), i.e., the expected log predictive density (elpd). In other words, a model with a larger elpd is preferred over a model with a smaller elpd.\nHowever, we don’t know what \\(M_0\\) is in real data analysis. If we knew, then we would just need to choose \\(M_0\\) as our model, and there will be no need for model comparisons. In addition, even if we know that the true model is, e.g., a normal model (which never happens in real data analysis), we still need to estimate the parameter values, and the estimates will not be exactly the same as the true parameter values. However, elpd is defined as the expected value over the true predictive distribution, \\(p_{M_0}(y)\\), which cannot be obtained without knowing what \\(M_0\\) is.\nSo instead, we need to estimate the elpd. A naive way to estimate it is to use the data distribution in place of the true model, but that will lead to an overly optimistic estimate as the sample data are noisy. Computing elpd this way will always favor a more complex model. The ideal way is to collect data on a new, independent sample that share the same data generating process as the current sample, and estimate elpd on the new sample. This is called out-of-sample validation. The problem, of course, is that we usually do not have the resources to collect a new sample.\nTherefore, statisticians have worked hard to find ways to estimate elpd from the current sample, and there are two broad approaches:\n\nInformation criteria: AIC, DIC, and WAIC, which estimate the elpd in the current sample, minus a correction factor\nCross-validation, which splits the current sample into \\(K\\) parts, estimates the parameters in \\(K - 1\\) parts, and estimates the elpd in the remaining part. A special case is when \\(K\\) = \\(N\\), each time one uses \\(N\\) - 1 data points to estimate the model parameters, and estimate the elpd for the observation that was left out. This is called leave-one-out cross-validation (LOO-CV).",
    "crumbs": [
      "Week 7",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Model Comparison</span>"
    ]
  },
  {
    "objectID": "07-model-comparison.html#deviance",
    "href": "07-model-comparison.html#deviance",
    "title": "\n11  Model Comparison\n",
    "section": "\n11.3 Deviance",
    "text": "11.3 Deviance\nWithout going too deep into the underlying math, it can be shown that a good estimate of elpd is\n\\[\n\\sum_{i = 1}^n \\log p_{M_1}(y_i) - p,\n\\]\nwhere \\(p\\) is some measure of the number of parameters in \\(M_1\\). The first term is the likelihood of the model in the current sample. The second term is an adjustment factor so that the quantity above represents the average likelihood of the model in a new sample. It is more common to work with deviance by multiplying the log-likelihood by \\(-2\\), i.e.,\n\\[\nD = -2 \\sum_{i = 1}^n \\log p_{M_1}(y_i).\n\\]\n\n11.3.1 Experiment on Deviance\nNow, let’s check the in-sample deviance and out-of-sample deviance of our waffle_divorce data with different polynomial functions. Here is a sample function for computing elpd (with frequentist, just for speed) for polynomials of different degrees:\n\nCode# Function for computing deviance with different polynomial\ndeviance_divorce &lt;- function(degree = 1,\n                             train = 10,\n                             y = waffle_divorce$Divorce,\n                             x = waffle_divorce$Marriage) {\n    N &lt;- length(y)\n    # get training sample\n    if (length(train) == 1) {\n        train &lt;- sample.int(N, train)\n    }\n    ntrain &lt;- length(train)\n    # Obtain design matrix\n    X &lt;- cbind(1, poly(x, degree, simple = TRUE))\n    # Get elpd for training sample\n    Xtrain &lt;- X[train, ]\n    ytrain &lt;- y[train]\n    betahat &lt;- qr.solve(Xtrain, ytrain)  # estimated betas\n    res_train &lt;- ytrain - Xtrain %*% betahat\n    sigmahat &lt;- sqrt(sum(res_train^2) /\n        (ntrain - 1 - degree)) # estimated sigma\n    deviance_train &lt;- -2 * sum(dnorm(res_train, sd = sigmahat, log = TRUE))\n    res_test &lt;- y[-train] - X[-train, ] %*% betahat\n    deviance_test &lt;- -2 * sum(dnorm(res_test, sd = sigmahat, log = TRUE))\n    data.frame(\n        degree = degree,\n        sample = c(\"in-sample\", \"out-of-sample\"),\n        deviance = c(deviance_train / ntrain,\n                     deviance_test / (N - ntrain))\n    )\n}\n\n\nBelow shows the in-sample and out-of-sample elpd for the linear model:\n\ndeviance_divorce(degree = 1, train = train)\n\n\n  \n\n\n\nAnd for quadratic:\n\ndeviance_divorce(degree = 2, train = train)\n\n\n  \n\n\n\nIn general, as you can see, the deviance is smaller for the current data than for the hold-out data. Note that because the training and testing data sets have different sizes, I divided the deviance by the sample size so that they can be compared.\nNow let’s run an experiment to check the elpd with different degrees polynomial, with a training sample size of 25:\n\nset.seed(1733)\n# Use the `map` function to run different polynomials, and use the `rerun`\n# function run the deviance 100 times. The code below runs `deviance_divorce` by\n# randomly sampling 25 training samples 100 times, and compute the in-sample\n# and out-of-sample deviance for each.\n# rerun(100, deviance_divorce(degree = 1, train = 25L)) |&gt;\n#     bind_rows()\n# Now run 1 to 4 degree polynomial, each 1000 times:\ndev_list &lt;- lapply(1:4, FUN = function(p) {\n    results &lt;- replicate(1000, deviance_divorce(degree = p, train = 25L), simplify = FALSE)\n    do.call(rbind, results)\n})\ndev_df &lt;- do.call(rbind, dev_list)\n# Plot the results\ndev_df |&gt;\n    ggplot(aes(x = degree, y = deviance, col = sample)) +\n    stat_summary() +\n    stat_summary(geom = \"line\") +\n    labs(col = NULL)\n\nNo summary function supplied, defaulting to `mean_se()`\nNo summary function supplied, defaulting to `mean_se()`\n\n\n\n\n\n\n\n\nAs you can see, the in-sample deviance (red line) keeps decreasing, indicating that a more complex model fits the data better, which is always the case. So if one were to use deviance to determine what model is optimal, one would always choose the most complex model, just like using \\(R^2\\) (indeed, for linear models, deviance is basically the same as \\(R^2\\)).\nNow, look at the blue line, which represents the deviance computed using the coefficients obtained from the training set but applied to the remaining data. As you can see, the deviance achieves its minimum around the linear and the quadratic model, and starts to increase, meaning that the more complex models do not fit the hold-out data.\nA statistical model is used to learn something from a data set that can generalize to other observations. Therefore, we should care about the blue line, instead of the red one. The indices you will see in the remaining of this note are all attempts to approximate the blue line.\n\nMore complex models always fit the current data better, but may not generalize to other data. In other words, models that are too complex are not generalizable.",
    "crumbs": [
      "Week 7",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Model Comparison</span>"
    ]
  },
  {
    "objectID": "07-model-comparison.html#information-criteria",
    "href": "07-model-comparison.html#information-criteria",
    "title": "\n11  Model Comparison\n",
    "section": "\n11.4 Information Criteria",
    "text": "11.4 Information Criteria\nWe will illustrate the computation of information criteria with Marriage predicting Divorce:\n\nm1 &lt;- brm(Divorce ~ Marriage, data = waffle_divorce,\n          prior = c(prior(student_t(4, 0, 5), class = \"Intercept\"),\n                    prior(normal(0, 2), class = \"b\"),\n                    prior(student_t(4, 0, 1), class = \"sigma\")),\n          iter = 4000,\n          seed = 2302,\n          file = \"07_m1\"\n)\n\nStart sampling\n\n\nChain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 1 Exception: normal_id_glm_lpdf: Scale vector is inf, but must be positive finite! (in '/tmp/RtmpAQpdSH/model-3727d4f7e02e7.stan', line 36, column 4 to column 62)\n\n\nChain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 1 \n\n\nChain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 2 Exception: normal_id_glm_lpdf: Scale vector is inf, but must be positive finite! (in '/tmp/RtmpAQpdSH/model-3727d4f7e02e7.stan', line 36, column 4 to column 62)\n\n\nChain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 2 \n\n\nChain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n\n\nChain 3 Exception: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in '/tmp/RtmpAQpdSH/model-3727d4f7e02e7.stan', line 36, column 4 to column 62)\n\n\nChain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n\n\nChain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n\n\nChain 3 \n\n\n\n11.4.1 Akaike Information Criteria (AIC)\nMultiplying the quantity of elpd - \\(p\\) by \\(-2\\), or deviance + 2\\(p\\), with the deviance obtained using the maximum likelihood estimates (MLEs) for the parameters, gives you the formula for AIC:\n\\[\n\\textrm{AIC} = D(\\hat \\theta) + 2p,\n\\]\nand \\(p\\) in AIC is just the number of parameters. As we have multiplied by a negative number, maximizing the estimate of elpd is equivalent to minimizing the AIC, so one would prefer a model with the smallest AIC.\nThe AIC is not Bayesian because it only uses point estimates (MLEs) of parameters rather than their posterior distributions. Also, it does not take into account any prior information.\n\n# Frequentist model\nm1_freq &lt;- lm(m1$formula, data = m1$data)\nAIC(m1_freq)\n\n[1] -30.96869\n\n\n\n11.4.2 Deviance Information Criteria (DIC)\nThe definition of AIC assumes that the parameter estimates are known or are maximum likelihood estimates. The DIC, instead, replaces those with the posterior distribution of the parameters. The general formula for DIC is\n\\[\n\\textrm{DIC} = \\mathrm{E}(D \\mid \\boldsymbol{\\mathbf{y}}) + 2 p_D,\n\\]\nwhere \\(p_D\\) is the effective number of parameters estimated in the Markov chain. Although DIC does take into account the prior distributions, it does not consider the full posterior distributions of the parameters.\n\n# Function to compute DIC\ndic_brmsfit &lt;- function(object) {\n    Dbar &lt;- -2 * mean(rowSums(log_lik(object)))\n    res &lt;- residuals(object)[ , \"Estimate\"]\n    sigma &lt;- posterior_summary(object, variable = \"sigma\")[ , \"Estimate\"]\n    Dhat &lt;- -2 * sum(dnorm(res, sd = sigma, log = TRUE))\n    p &lt;- Dbar - Dhat\n    elpd &lt;- Dhat / -2 - p\n    data.frame(elpd_dic = elpd, p_dic = p, dic = Dhat + 2 * p,\n               row.names = \"Estimate\")\n}\ndic_brmsfit(m1)\n\n\n  \n\n\n\n\n11.4.3 Watanabe-Akaike Information Criteria (WAIC)\nA further modification is to use the log pointwise posterior predictive density, with the effective number of parameters computed using the posterior variance of the likelihood.\n\\[\n\\textrm{WAIC} = -2 \\sum_{i = 1}^n \\log \\mathrm{E}[p(y_i \\mid \\boldsymbol{\\mathbf{\\theta}}, \\boldsymbol{\\mathbf{y}})] +\n                  2 p_\\textrm{WAIC},\n\\]\nwhere \\(\\mathrm{E}[p(y_i \\mid \\boldsymbol{\\mathbf{\\theta}}, \\boldsymbol{\\mathbf{y}})]\\) is the posterior mean of the likelihood of the \\(i\\)th observation. The WAIC incorporates prior information, and the use of pointwise likelihood makes it more robust when the posterior distributions deviate from normality. In general, WAIC is a better estimate of the out-of-sample deviance than AIC and DIC.\n\nwaic(m1)  # built-in function in brms\n\nWarning: \n1 (2.0%) p_waic estimates greater than 0.4. We recommend trying loo instead.\n\n\n\nComputed from 8000 by 50 log-likelihood matrix\n\n          Estimate  SE\nelpd_waic     15.2 4.9\np_waic         3.2 0.9\nwaic         -30.3 9.9\n\n1 (2.0%) p_waic estimates greater than 0.4. We recommend trying loo instead. \n\n\n\n11.4.4 Leave-One-Out Cross-Validation\nThe idea of cross-validation is to split the sample so that it imitates the scenario of estimating the parameters in part of the data and predicting the remaining part. The part used for estimation is called the training set, and the part used for prediction is called the validation set. Leave-one-out information criteria (LOO-IC) means that one uses \\(N - 1\\) observations as the training set and 1 observation as the validation sample and repeat the process \\(N\\) times so that a different observation is being predicted each time. Adding up the prediction results will give an estimate of elpd that closely approximates the results that would be obtained by collecting new data and doing the validation. To make it more concrete, we can go back to the waffle_divorce data with Marriage predicting Divorce. We can do this for case #1 (Alabama), as an example:\n\n# Estimate the model without case #1\nm1_no1 &lt;- update(m1, newdata = waffle_divorce[-1, ])\n\n\n# The log predictive density for case #1\nmean(log_lik(m1_no1, newdata = waffle_divorce[1, ]))\n\n[1] -0.8087106\n\n\nBecause LOO-IC requires fitting the model \\(N\\) times, it is generally very computationally intensive. There are, however, shortcuts for some models to make the computation faster. WAIC can also be treated as a fast approximation of LOO-IC, although LOO-IC is more robust and will be a better estimate of out-of-sample deviance. The loo package uses the so-called Pareto smoothed importance sampling (PSIS) to approximate LOO-IC without repeating the process \\(N\\) times.\nHere is the LOO-IC for the model:\n\nloo(m1)\n\n\nComputed from 8000 by 50 log-likelihood matrix\n\n         Estimate  SE\nelpd_loo     15.1 5.0\np_loo         3.3 1.0\nlooic       -30.2 9.9\n------\nMonte Carlo SE of elpd_loo is 0.0.\n\nAll Pareto k estimates are good (k &lt; 0.5).\nSee help('pareto-k-diagnostic') for details.\n\n\nYou can save the WAIC and the LOO-IC information to the fitted result:\n\nm1 &lt;- add_criterion(m1, criterion = c(\"loo\", \"waic\"))\n\nWarning: \n1 (2.0%) p_waic estimates greater than 0.4. We recommend trying loo instead.\n\n\nAutomatically saving the model object in '07_m1.rds'\n\n\nSee Vehtari et al. (2017) for more discussions on WAIC and LOO-IC.\n\n11.4.5 Example\nConsider four potential models in predicting Divorce:\n\\[\n\\texttt{Divorce}_i \\sim N(\\mu_i, \\sigma)\n\\]\n\nM1: Marriage\n\nM2: Marriage, South, Marriage \\(\\times\\) South\n\nM3: South, smoothing spline of Marriage by South\n\nM4: Marriage, South, MedianAgeMarriage, Marriage \\(\\times\\) South, Marriage \\(\\times\\) MedianAgeMarriage, South \\(\\times\\) MedianAgeMarriage, Marriage \\(\\times\\) South \\(\\times\\) MedianAgeMarriage\n\n\n\n# Note, m1 has been fit before; the `update()` function\n# can be used to simply change the formula, and brms will\n# determine whether it needs re-compiling.\n# M2: Add South and interaction\nm2 &lt;- update(m1, formula = Divorce ~ Marriage * South,\n             newdata = waffle_divorce)\nm2 &lt;- add_criterion(m2, c(\"loo\", \"waic\"))\n\nWarning: \n1 (2.0%) p_waic estimates greater than 0.4. We recommend trying loo instead.\n\n# M3: Spline function for Marriage\nm3 &lt;- update(m1, formula = Divorce ~ South + s(Marriage, by = South),\n             newdata = waffle_divorce,\n             control = list(adapt_delta = .999))\nm3 &lt;- add_criterion(m3, c(\"loo\", \"waic\"))\n\nWarning: Found 1 observations with a pareto_k &gt; 0.7 in model 'm3'. It is\nrecommended to set 'moment_match = TRUE' in order to perform moment matching\nfor problematic observations.\n\n\nWarning: \n4 (8.0%) p_waic estimates greater than 0.4. We recommend trying loo instead.\n\n# M4: Three-way interactions\nm4 &lt;- update(m1, formula = Divorce ~ Marriage * MedianAgeMarriage * South,\n             newdata = waffle_divorce,\n             control = list(max_treedepth = 12))  # increase due to warning\nm4 &lt;- add_criterion(m4, c(\"loo\", \"waic\"))\n\nWarning: \n3 (6.0%) p_waic estimates greater than 0.4. We recommend trying loo instead.\n\n\nThe first model only has Marriage as a predictor, which means that the coefficients for South and MedianAgeMarriage are assumed to be zero. The second model added South and its interaction with Marriage as a predictor. The third model includes a smoothing spline term (a flexible non-linear function, within the class of linear models), whereas the fourth model also includes MedianAgeMarriage and all two-way and three-way interactions. Now, we can compare the four models:\n\nloo_compare(m1, m2, m3, m4)\n\n   elpd_diff se_diff\nm4  0.0       0.0   \nm2 -5.1       4.0   \nm3 -5.7       4.0   \nm1 -8.6       4.2   \n\n# m4 is the best\n\n\nmsummary(list(M1 = m1, M2 = m2, M3 = m3, M4 = m4),\n         estimate = \"{estimate} [{conf.low}, {conf.high}]\",\n         statistic = NULL, fmt = 2)\n\nWarning: \n`modelsummary` uses the `performance` package to extract goodness-of-fit\nstatistics from models of this class. You can specify the statistics you wish\nto compute by supplying a `metrics` argument to `modelsummary`, which will then\npush it forward to `performance`. Acceptable values are: \"all\", \"common\",\n\"none\", or a character vector of metrics names. For example: `modelsummary(mod,\nmetrics = c(\"RMSE\", \"R2\")` Note that some metrics are computationally\nexpensive. See `?performance::performance` for details.\n This warning appears once per session.\n\n\n\n\n    \n\n      \n\n \n                M1\n                M2\n                M3\n                M4\n              \n\n\nb_Intercept                                \n                  0.61 [0.35, 0.87]\n                  0.67 [0.41, 0.93]  \n                  0.94 [0.89, 0.99]  \n                  5.51 [1.90, 9.04]   \n                \n\nb_Marriage                                 \n                  0.18 [0.05, 0.31]\n                  0.13 [0.00, 0.26]  \n                                     \n                  -1.20 [-2.87, 0.50] \n                \n\nsigma                                      \n                  0.17 [0.14, 0.21]\n                  0.16 [0.13, 0.20]  \n                  0.15 [0.12, 0.19]  \n                  0.14 [0.11, 0.18]   \n                \n\nb_Southsouth                               \n                                   \n                  -0.63 [-1.43, 0.15]\n                  0.10 [-0.03, 0.22] \n                  0.30 [-3.15, 3.76]  \n                \n\nb_Marriage × Southsouth                    \n                                   \n                  0.37 [-0.01, 0.76] \n                                     \n                  0.50 [-1.69, 2.72]  \n                \n\nbs_sMarriage × SouthnonMsouth_1            \n                                   \n                                     \n                  -0.44 [-3.35, 1.49]\n                                      \n                \n\nbs_sMarriage × Southsouth_1                \n                                   \n                                     \n                  1.28 [-2.07, 3.52] \n                                      \n                \n\nsds_sMarriageSouthnonMsouth_1              \n                                   \n                                     \n                  0.86 [0.04, 2.58]  \n                                      \n                \n\nsds_sMarriageSouthsouth_1                  \n                                   \n                                     \n                  0.48 [0.02, 2.52]  \n                                      \n                \n\nb_MedianAgeMarriage                        \n                                   \n                                     \n                                     \n                  -1.72 [-3.07, -0.35]\n                \n\nb_Marriage × MedianAgeMarriage             \n                                   \n                                     \n                                     \n                  0.45 [-0.23, 1.11]  \n                \n\nb_MedianAgeMarriage × Southsouth           \n                                   \n                                     \n                                     \n                  -0.35 [-1.68, 0.99] \n                \n\nb_Marriage × MedianAgeMarriage × Southsouth\n                                   \n                                     \n                                     \n                  -0.07 [-1.07, 0.92] \n                \n\nNum.Obs.                                   \n                  50               \n                  50                 \n                  50                 \n                  50                  \n                \n\nR2                                         \n                  0.139            \n                  0.304              \n                  0.389              \n                  0.489               \n                \n\nR2 Adj.                                    \n                  0.072            \n                  0.211              \n                  0.183              \n                  0.369               \n                \n\nELPD                                       \n                  15.1             \n                  18.5               \n                  18.0               \n                  23.7                \n                \n\nELPD s.e.                                  \n                  5.0              \n                  5.4                \n                  5.6                \n                  6.1                 \n                \n\nLOOIC                                      \n                  -30.2            \n                  -37.1              \n                  -35.9              \n                  -47.3               \n                \n\nLOOIC s.e.                                 \n                  9.9              \n                  10.8               \n                  11.3               \n                  12.2                \n                \n\nWAIC                                       \n                  -30.3            \n                  -37.2              \n                  -36.9              \n                  -48.0               \n                \n\nRMSE                                       \n                  0.17             \n                  0.15               \n                  0.14               \n                  0.13                \n                \n\n\n\n\n\n\nModel 4 has the lowest LOO-IC, so one may conclude that Model 4 is the best model among the four, for prediction purposes.\n\n\n\n\n\n\n\nVehtari, A., Gelman, A., & Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC. Statistics and Computing, 27(5), 1413–1432. https://doi.org/10.1007/s11222-016-9696-4",
    "crumbs": [
      "Week 7",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Model Comparison</span>"
    ]
  },
  {
    "objectID": "07b-stacking-and-regularization.html",
    "href": "07b-stacking-and-regularization.html",
    "title": "\n12  Stacking, Regularization, and Variable Selection\n",
    "section": "",
    "text": "12.1 Stacking/Model Averaging\nSometimes it may not be a good practice to only choose one model with low WAIC or LOO-IC, especially when several models have very imilar WAIC/LOO-IC, but they make somewhat different predictions. Instead, we can perform stacking or model averaging by weighting the predictions from multiple models, using weights that are based on their information criteria performance. Stacking approaches this by optimizing the leave-one-out mean squared error in the resulting prediction, whereas model averaging preserves the uncertainty and was not optimized for that task. The technical details can be found in Yao et al. (2018).\nNote that the conventional Bayesian model averaging used the posterior model probability (Hoeting et al., 1999), which are approximated by the BIC. The discussion in this note is based on more recent discussion in, e.g., Yao et al. (2018).\nWe’ll use a data set kidiq that is used in the textbook by Gelman et al. (2021), which can be downloaded and imported with the direct link:\nkidiq &lt;- haven::read_dta(\"http://www.stat.columbia.edu/~gelman/arm/examples/child.iq/kidiq.dta\")\nhead(kidiq)\nLet’s run four models. First rescale some of the variables:\nkidiq100 &lt;- kidiq |&gt;\n  mutate(mom_iq = mom_iq / 100,  # divid mom_iq by 100\n         kid_score = kid_score / 100,   # divide kid_score by 100\n         mom_iq_c = mom_iq - 1,\n         mom_hs = factor(mom_hs, labels = c(\"no\", \"yes\")),\n         mom_age_c = (mom_age - 18) / 10)\nI will run four models, which is from the last note\n\\[\n\\texttt{kidscore}_i \\sim N(\\mu_i, \\sigma)\n\\]\n\\[\n\\begin{aligned}\n  \\mu_i & = \\beta_0 + \\beta_1 (\\texttt{mom\\_iq}_i)  \\\\\n  \\mu_i & = \\beta_0 + \\beta_1 (\\texttt{mom\\_iq}_i) +\n            \\beta_2 (\\texttt{mom\\_hs}_i) \\\\\n  \\mu_i & = \\beta_0 + \\beta_1 (\\texttt{mom\\_iq}_i) +\n            \\beta_2 (\\texttt{mom\\_hs}_i) + \\beta_3 (\\texttt{mom\\_iq}_i \\times\n                                                    \\texttt{mom\\_hs}_i)  \\\\\n  \\mu_i & = \\beta_0 + \\beta_1 (\\texttt{mom\\_iq}_i) +\n            \\beta_2 (\\texttt{mom\\_hs}_i) +\n            \\beta_3 (\\texttt{mom\\_iq}_i \\times \\texttt{mom\\_hs}_i) +\n            \\beta_4 (\\texttt{mom\\_age}_i)\n\\end{aligned}\n\\]\nm1 &lt;- brm(kid_score ~ mom_iq_c,\n    data = kidiq100,\n    prior = c(\n        prior(normal(0, 1), class = \"Intercept\"),\n        prior(normal(0, 1), class = \"b\"),\n        prior(student_t(4, 0, 1), class = \"sigma\")\n    ),\n    seed = 2302,\n    file = \"07b_m1\"\n)\nm1 &lt;- add_criterion(m1, c(\"loo\", \"waic\"))\n# Use `update` will sometimes avoid recompiling\nm2 &lt;- update(m1, kid_score ~ mom_iq_c + mom_hs,\n    newdata = kidiq100,\n    file = \"07b_m2\"\n)\n\nThe desired updates require recompiling the model\n\nm2 &lt;- add_criterion(m2, c(\"loo\", \"waic\"))\nm3 &lt;- update(m2, kid_score ~ mom_iq_c * mom_hs,\n    prior = c(prior(normal(0, 0.5),\n        class = \"b\",\n        coef = \"mom_iq_c:mom_hsyes\"\n    )),\n    file = \"07b_m3\"\n)\n\nThe desired updates require recompiling the model\n\nm3 &lt;- add_criterion(m3, c(\"loo\", \"waic\"))\nm4 &lt;- update(m3, kid_score ~ mom_iq_c * mom_hs + mom_age_c,\n    newdata = kidiq100,\n    file = \"07b_m4\"\n)\n\nThe desired updates require recompiling the model\n\nm4 &lt;- add_criterion(m4, c(\"loo\", \"waic\"))",
    "crumbs": [
      "Week 7",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Stacking, Regularization, and Variable Selection</span>"
    ]
  },
  {
    "objectID": "07b-stacking-and-regularization.html#stackingmodel-averaging",
    "href": "07b-stacking-and-regularization.html#stackingmodel-averaging",
    "title": "\n12  Stacking, Regularization, and Variable Selection\n",
    "section": "",
    "text": "12.1.1 Model Weights\nWe can see that m3 and m4 gave the best LOO-IC and WAIC:\n\nloo_compare(m1, m2, m3, m4)\n\n   elpd_diff se_diff\nm3  0.0       0.0   \nm4 -0.5       1.2   \nm2 -3.3       2.5   \nm1 -5.9       3.9   \n\n\nSo it makes sense that if we’re to assign weights, m4 should get most weights. Let’s check the following:\n\n# Weights based on WAIC\nwaic_wts &lt;- model_weights(m1, m2, m3, m4, weights = \"waic\")\n# Weights based on Stacking (based on the posterior predictive distribution)\nstack_wts &lt;- loo_model_weights(m1, m2, m3, m4)\n# Print out the weights\nround(cbind(waic_wts, stack_wts), 3)\n\n   waic_wts stack_wts\nm1    0.002     0.105\nm2    0.023     0.000\nm3    0.613     0.767\nm4    0.363     0.128\n\n\nYou can see m3 would get the highest weight, but it’s only 0.6125895 and thus less than half of the weights when all four models are considered together.\nIn Bayesian, we want to preserve all the uncertainty in our analyses. Therefore, if we’re not certain which models to use and have tried multiple ones, it would make sense to use all of them to get the best information. So unlike what is commonly done in practice where a researcher would test multiple models and present the best model as if they intended only to test this model, Bayesian analysts should do the honest thing and use all models. The reward is usually better prediction!\n\n12.1.2 Stacking\nStacking is one way to combine the predictions of different models. The technical details can be found in Yao et al. (2018), but you can obtain the predictions using the pp_average function:\n\n# Prediction from stacking by Yao et al. (2018)\npred_stacking &lt;- pp_average(m1, m2, m3, m4)\n# Compare the weights\nplot(pred_stacking)\n\n\n\n\n\n\n\n\n12.1.3 Prediction example\nConsider a kid whose mother’s IQ is 120 (mom_iq = .2), mother’s age is 40, (mom_age_c = 2.2), mother does not have a high school degree, and mother did not work in first three years of child’s life (mom_work = 1). Then the prediction based on the various models are:\n\nnewkid &lt;- data.frame(mom_iq_c = .2,\n                     mom_age_c = 2.2,\n                     mom_work = 1,\n                     mom_hs = \"no\")\n# Visualize the prediction by different models\ndata.frame(stacking = pp_average(m1, m2, m3, m4, newdata = newkid,\n                                 summary = FALSE),\n           m4 = posterior_predict(m4, newdata = newkid),\n           m3 = posterior_predict(m3, newdata = newkid),\n           m2 = posterior_predict(m2, newdata = newkid),\n           m1 = posterior_predict(m1, newdata = newkid)) |&gt;\n    mcmc_intervals()\n\n\n\n\n\n\n\nCheck out this blog post https://mc-stan.org/loo/articles/loo2-weights.html for more information on stacking and Averaging.",
    "crumbs": [
      "Week 7",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Stacking, Regularization, and Variable Selection</span>"
    ]
  },
  {
    "objectID": "07b-stacking-and-regularization.html#shrinkage-priors",
    "href": "07b-stacking-and-regularization.html#shrinkage-priors",
    "title": "\n12  Stacking, Regularization, and Variable Selection\n",
    "section": "\n12.2 Shrinkage Priors",
    "text": "12.2 Shrinkage Priors\nWhen the number of parameters to be estimated is large relative to the amount of data available, ordinary least square (in frequentist) and estimation using non-informative or weakly informative priors tend to overfit. For example, fitting a 6th degree polynomial (with 8 parameters) on a data set with only 10 observations will severely overfit the data, making the results not generalizable. One way to avoid overfitting is to perform regularization, that is, to shrink some of the parameters to closer to zero. This makes the model fit less well to the existing data, but will be much more generalizable to an independent data set.\n\n12.2.1 Number of parameters\nIn Bayesian analyses, the concept of number of parameters is a little vague. This is because the posterior distribution is a function of both the prior and the data. For non-informative priors, it would make sense to simply count the number of parameters. However, say one put a very strong prior on one of the regression coefficients, which has about 9 times the weights of the information contributed by the data:\n\nCodeggplot(data.frame(th = c(-3, 3)), aes(x = th)) +\n    stat_function(\n        fun = dnorm, args = list(mean = 0, sd = 1 / 9),\n        aes(col = \"prior\"), n = 501\n    ) +\n    stat_function(\n        fun = dnorm, args = list(mean = 0.3, sd = 1),\n        aes(col = \"likelihood\"), n = 501\n    ) +\n    labs(y = \"Density\", x = expression(theta), col = \"\")\n\n\n\n\n\n\n\nThen the posterior for the parameter only uses 1/10 of the information from the data! Therefore, it would make more sense to count this as 0.1 parameter, instead of 1 full parameter.\nThe concept of regularization is essentially to introduce a stronger prior so that the posterior is less likely to overfit the data, and the resulting model will have lower effective number of parameters, which, when done appropriately, would find a model that is more likely to generalize to external data sets.\nIn Bayesian methods, regularization can be done by choosing a prior on the coefficient that has a sharp peak at 0, but also has a heavy tail. One such prior is what is called the horseshoe prior. The discussion here is based on the blog pot by Michael Betancourt: https://betanalpha.github.io/assets/case_studies/bayes_sparse_regression.html\nIt should first be pointed out that these priors were based on the assumption that the predictors and the outcome has been scaled to have a standard deviation of one. So we will do this here:\n\n# For variable selection, scale the predictor and outcome to have unit variance\nkidiq_std &lt;- scale(kidiq)\nhead(kidiq_std)\n\n       kid_score    mom_hs     mom_iq    mom_work    mom_age\n[1,] -1.06793237  0.521631  1.4078352  0.93422435  1.5602285\n[2,]  0.54886757  0.521631 -0.7092079  0.93422435  0.8197811\n[3,] -0.08805362  0.521631  1.0295443  0.93422435  1.5602285\n[4,] -0.18604150  0.521631 -0.0366907  0.08776638  0.8197811\n[5,]  1.38176451  0.521631 -0.4836193  0.93422435  1.5602285\n[6,]  0.54886757 -1.912647  0.5267892 -1.60514956 -1.7717849\n\n\n\n12.2.2 Sparsity-Inducing Priors\nThe horseshoe prior (Carvalho et al., 2010) is a type of hierarchical prior for regression models by introducing a global scale, \\(\\tau\\), and local scale,\\(\\lambda_m\\), parameters on the priors for the regression coefficients (Piironen & Vehtari, 2017). Specifically, with \\(p\\) predictors,\n\\[\n\\begin{aligned}\n  Y_i & \\sim N(\\mu_i, \\sigma^2) \\\\\n  \\mu_i & = \\beta_0 + \\sum_{m = 1}^p \\beta_m X_m \\\\\n  \\beta_0 & \\sim N(0, 1) \\\\\n  \\beta_m & \\sim N(0, \\tau \\lambda_m) \\\\\n  \\lambda_m & \\sim \\textrm{Cauchy}^+(0, 1)  \\\\\n  \\tau & \\sim \\textrm{Cauchy}^+(0, \\tau_0)\n\\end{aligned}\n\\]\nThe local scale, \\(\\lambda_m\\), can flexibly shrink the coefficient to close to zero. Below is the implication of the prior on the shrinkage of \\(\\beta\\):\n\nggplot(data.frame(shrinkage = c(0, 1)), aes(x = shrinkage)) +\n    stat_function(fun = function(x) {\n        dcauchy(sqrt(1 / x - 1)) * 2 * (1 / x - 1)^(-1 / 2) * x^(-2) / 2\n    }, n = 501) +\n    theme(\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank()\n    ) +\n    labs(y = \"\")\n\nWarning: Removed 1 row containing missing values (`geom_function()`).\n\n\n\n\n\n\n\n\nThe U-shape here means that, for coefficients that are weakly supported by the data, the horseshoe will shrink it to very close to zero, whereas for coefficients that are more strongly supported by the data, the horseshoe will not shrink it much.\nThe red curve in the following is one example for the resulting prior distribution on \\(\\beta\\):\n\ndhs &lt;- Vectorize(\n    function(y, df = 1) {\n        ff &lt;- function(lam) dnorm(y, 0, sd = lam) * dt(lam, df) * 2\n        if (y != 0) {\n            integrate(ff, lower = 0, upper = Inf)$value\n        } else {\n            Inf\n        }\n    }\n)\nggplot(data.frame(x = c(-6, 6)), aes(x = x)) +\n    stat_function(\n        fun = dhs, args = list(df = 3), n = 501,\n        aes(col = \"HS\"), linetype = 1\n    ) +\n    stat_function(\n        fun = dnorm, n = 501,\n        aes(col = \"norm\"), linetype = 2\n    ) +\n    scale_color_manual(\"\",\n        values = c(\"red\", \"black\"),\n        labels = c(\"horseshoe(3)\", \"N(0, 1)\")\n    ) +\n    xlab(\"y\") +\n    ylab(\"density\") +\n    ylim(0, 0.75)\n\n\n\nDensity for the regularized horseshoe prior with 3 degrees of freedom\n\n\n\nSuch a prior has more density at 0, but also more density for extreme values, as compared to a normal distribution. Thus, for coefficients with very weak evidence, the regularizing prior will shrink it to zero, whereas for coefficients with strong evidence, the shrinkage will be very small. This is called a horseshoe prior. In brms, one can specify it with horseshoe(), which is a stabilized version of the original horseshoe prior (Carvalho et al., 2010).\n\n12.2.3 Regularized Horseshoe/Hierarchical Shrinkage\nThe regularized horseshoe (https://projecteuclid.org/euclid.ejs/1513306866) prior is\n\\[\n\\begin{aligned}\n  \\beta_m & \\sim N(0, \\tau \\tilde \\lambda_m) \\\\\n  \\tilde \\lambda_m & = \\frac{c \\lambda_m}{\\sqrt{c^2 + \\tau^2 \\lambda^2_m}} \\\\\n  \\lambda_m & \\sim \\textrm{Cauchy}^+(0, 1)  \\\\\n  c^2 & \\sim \\textrm{Inv-Gamma}(\\nu / 2, nu / 2 s^2) \\\\\n  \\tau & \\sim \\textrm{Cauchy}^+(0, \\tau_0)\n\\end{aligned}\n\\]\nThe additional parameters are chosen in the code below. First, fit a model without shrinkage:\n\n# A model with all main and interaction effects\nm5 &lt;- brm(kid_score ~ (.)^2,\n    data = kidiq_std,\n    prior = c(\n        prior(normal(0, 1), class = \"Intercept\"),\n        prior(normal(0, 1), class = \"b\"),\n        prior(student_t(4, 0, 1), class = \"sigma\")\n    ),\n    seed = 2217,\n    file = \"07b_m5\"\n)\n\n\n# A model with all main and interaction effects, and regularization\nm_hs &lt;- brm(kid_score ~ (.)^2,\n    data = kidiq_std,\n    prior = c(\n        prior(normal(0, 1), class = \"Intercept\"),\n        # Prior guess of 20% of the terms are non-zero\n        prior(horseshoe(par_ratio = 2 / 8), class = \"b\"),\n        prior(student_t(4, 0, 1), class = \"sigma\")\n    ),\n    # Need higher adapt_delta\n    control = list(adapt_delta = .995, max_treedepth = 12),\n    seed = 2217,\n    file = \"07b_m_hs\"\n)\n\nWe can plot the coefficients:\n\nmcmc_plot(m_hs, variable = \"^b_\",\n          regex = TRUE) +\n    # Show the shrinkage as orange, transparent dots\n    geom_point(\n        data = posterior_summary(m5) |&gt;\n            as_tibble(rownames = \"parameter\") |&gt;\n            filter(parameter != \"lp__\"),\n        aes(x = Estimate, y = parameter), alpha = 0.8,\n        col = \"orange\"\n    ) +\n    geom_vline(xintercept = c(-.05, .05), col = \"red\")\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\nAn arbitrary cutoff is to select only coefficients with posterior means larger than .05, in which case only mom_iq and mom_hs and their interaction were supported by the data.\nYou can also double check that the regularized version has better LOO-IC:\n\nloo(m5, m_hs)\n\nOutput of model 'm5':\n\nComputed from 4000 by 434 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo   -567.3 14.4\np_loo        12.8  1.4\nlooic      1134.6 28.8\n------\nMonte Carlo SE of elpd_loo is 0.1.\n\nPareto k diagnostic values:\n                         Count Pct.    Min. n_eff\n(-Inf, 0.5]   (good)     433   99.8%   2098      \n (0.5, 0.7]   (ok)         1    0.2%   527       \n   (0.7, 1]   (bad)        0    0.0%   &lt;NA&gt;      \n   (1, Inf)   (very bad)   0    0.0%   &lt;NA&gt;      \n\nAll Pareto k estimates are ok (k &lt; 0.7).\nSee help('pareto-k-diagnostic') for details.\n\nOutput of model 'm_hs':\n\nComputed from 4000 by 434 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo   -565.2 14.4\np_loo         8.5  0.9\nlooic      1130.5 28.9\n------\nMonte Carlo SE of elpd_loo is 0.1.\n\nAll Pareto k estimates are good (k &lt; 0.5).\nSee help('pareto-k-diagnostic') for details.\n\nModel comparisons:\n     elpd_diff se_diff\nm_hs  0.0       0.0   \nm5   -2.1       2.3   \n\n\nAnd also that the effective number of parameters was smaller in m_hs.",
    "crumbs": [
      "Week 7",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Stacking, Regularization, and Variable Selection</span>"
    ]
  },
  {
    "objectID": "07b-stacking-and-regularization.html#variable-selection",
    "href": "07b-stacking-and-regularization.html#variable-selection",
    "title": "\n12  Stacking, Regularization, and Variable Selection\n",
    "section": "\n12.3 Variable Selection",
    "text": "12.3 Variable Selection\nOne way to identify variables that are relevant to predict a certain outcome is to use the projection-based method, as discussed in https://mc-stan.org/projpred/articles/projpred.html and in Piironen et al. (2020).\nBuilding from the full model with shrinkage priors, we first do a trial run to identify the importance of various variables in terms of their importance for prediction:\n\n# Get reference model\nrefm_obj &lt;- get_refmodel(m_hs)\n# Preliminary run to find `nterms_max`\ncvvs_fast &lt;- cv_varsel(\n    refm_obj,\n    validate_search = FALSE\n)\n\n-----\nRunning the search ...\n10% of terms selected\n20% of terms selected\n30% of terms selected\n40% of terms selected\n50% of terms selected\n60% of terms selected\n70% of terms selected\n80% of terms selected\n90% of terms selected\n100% of terms selected\n-----\n-----\nRunning the performance evaluation with `refit_prj = TRUE` ...\n-----\n\n# mlpd = mean log predictive density\nplot(cvvs_fast, stats = \"mlpd\", ranking_nterms_max = NA)\n\n\n\n\n\n\n\nFrom the plot, we find when the predictive performance starts to level off when we keep adding more terms to the model. In this case, it seems to be 4. Given that this is a trial run, we’ll set nterms_max to 5, which is slightly higher.\nWe then set validate_search = FALSE for a final run. For computational feasibility, we’ll use 10-fold validation.\n\n# With 10-fold cross-validation\ncvvs &lt;- cv_varsel(\n    refm_obj,\n    validate_search = TRUE,\n    cv_method = \"kfold\",\n    K = 10,\n    nterms_max = 5\n)\n\n-----\nRunning the search using the full dataset ...\n20% of terms selected\n40% of terms selected\n60% of terms selected\n80% of terms selected\n100% of terms selected\n-----\n-----\nRefitting the reference model K = 10 times (using the fold-wise training data) ...\n-----\n-----\nRunning the search and the performance evaluation with `refit_prj = TRUE` for each of the K = 10 CV folds separately ...\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |======================================================================| 100%\n-----\n\nplot(cvvs, stats = \"mlpd\", deltas = TRUE)\n\n\n\n\n\n\n\n\n# model size suggested by the program\nsuggest_size(cvvs, stat = \"mlpd\")\n\n[1] 1\n\n# Same with RMSE\nsuggest_size(cvvs, stat = \"rmse\")\n\n[1] 1\n\n# Summary of the variable selection results\nsummary(cvvs,\n    stats = \"mlpd\", type = c(\"mean\", \"lower\", \"upper\"),\n    deltas = TRUE\n)\n\n\nFamily: gaussian \nLink function: identity \n\nFormula: kid_score ~ mom_hs + mom_iq + mom_work + mom_age + mom_hs:mom_iq + \n    mom_hs:mom_work + mom_hs:mom_age + mom_iq:mom_work + mom_iq:mom_age + \n    mom_work:mom_age\nObservations: 434\nProjection method: traditional\nCV method: K-fold CV with K = 10 and search included (i.e., fold-wise searches)\nSearch method: forward\nMaximum submodel size for the search: 5\nNumber of projected draws in the search: 20 (from clustered projection)\nNumber of projected draws in the performance evaluation: 400\nArgument `refit_prj`: TRUE\n\nSubmodel performance evaluation summary with `deltas = TRUE` and `cumulate = FALSE`:\n size ranking_fulldata cv_proportions_diag     mlpd mlpd.lower mlpd.upper\n    0      (Intercept)                  NA -0.11719   -1.4e-01    -0.0958\n    1           mom_iq                 1.0 -0.00542   -1.3e-02     0.0023\n    2           mom_hs                 1.0 -0.00196   -8.1e-03     0.0042\n    3    mom_hs:mom_iq                 1.0  0.00268   -2.4e-04     0.0056\n    4          mom_age                 1.0  0.00279   -4.8e-06     0.0056\n    5   mom_hs:mom_age                 0.9  0.00089   -1.6e-03     0.0033\n\nReference model performance evaluation summary with `deltas = TRUE`:\n      mlpd mlpd.lower mlpd.upper \n         0          0          0 \n\n# Predictor ranking(s)\nrk &lt;- ranking(cvvs)\nplot(cv_proportions(rk, cumulate = TRUE))\n\n\n\n\n\n\n\nHere it suggests to either include only mom_iq and mom_hs, or to also include their interactions.\n\n12.3.1 Projection-Based Method\nThe projection-based method will obtain the posterior distributions based on a projection from the full model on the simplified model. In other words, we’re asking the question:\n\nIf we want a model with only mom_iq and mom_hs, what coefficients should be obtained so that the resulting prediction accuracy is as closed to the full model as possible?\n\nNote that the coefficients will be different from if you were to directly estimate the model using the two predictors (i.e., m2). In this case, simulation results showed that the projection-based method will yield a model with better predictive performance.\n\n# Fit m2 with the standardized data\nm2_std &lt;- brm(kid_score ~ mom_hs + mom_iq,\n    data = kidiq_std,\n    prior = c(\n        prior(normal(0, 1), class = \"Intercept\"),\n        prior(normal(0, 1), class = \"b\"),\n        prior(student_t(4, 0, 1), class = \"sigma\")\n    ),\n    seed = 2302,\n    file = \"07b_m2_std\"\n)\n\n\n# Visualise the projected three most relevant variables\nprj &lt;- project(refm_obj,\n    predictor_terms = c(\"mom_iq\", \"mom_hs\"),\n    verbose = FALSE\n)\nmcmc_intervals(as.matrix(prj)) +\n    # Show the non-projection version as black, transparent dots\n    geom_point(\n        data =\n            posterior_summary(m2_std) |&gt;\n                as_tibble(rownames = \"parameter\"),\n        aes(x = Estimate, y = parameter), alpha = 0.8,\n        col = \"orange\"\n    )\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCarvalho, C. M., Polson, N. G., & Scott, J. G. (2010). The horseshoe estimator for sparse signals. Biometrika, 97(2), 465–480. https://doi.org/10.1093/biomet/asq017\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nHoeting, J. A., Madigan, D., Raftery, A. E., & Volinsky, C. T. (1999). Bayesian model averaging: A tutorial. Statistical Science, 14(4). https://doi.org/10.1214/ss/1009212519\n\n\nPiironen, J., Paasiniemi, M., & Vehtari, A. (2020). Projective inference in high-dimensional problems: Prediction and feature selection. Electronic Journal of Statistics, 14(1). https://doi.org/10.1214/20-EJS1711\n\n\nPiironen, J., & Vehtari, A. (2017). Sparsity information and regularization in the horseshoe and other shrinkage priors. Electronic Journal of Statistics, 11(2). https://doi.org/10.1214/17-EJS1337SI\n\n\nYao, Y., Vehtari, A., Simpson, D., & Gelman, A. (2018). Using stacking to average Bayesian predictive distributions (with discussion). Bayesian Analysis, 13(3). https://doi.org/10.1214/17-BA1091",
    "crumbs": [
      "Week 7",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Stacking, Regularization, and Variable Selection</span>"
    ]
  },
  {
    "objectID": "08-causal-inference.html",
    "href": "08-causal-inference.html",
    "title": "\n13  Causal Inference\n",
    "section": "",
    "text": "13.1 Potential Outcomes\nConsider a binary treatment variable. For each individual, there are two potential outcomes: one if they receive the treatment (T = 1) and one if they do not (T = 0). Here is a hypothetical data set of a new drug for improving statistics knowledge, with the treatment condition receiving the drug and the control condition receiving a placebo:\nCodepo_dat &lt;- data.frame(\n    person = c(1, 2, 3, 4, 5, 6, 7, 8),\n    attitude = c(4, 7, 3, 9, 5, 6, 8, 2),\n    treat = c(75, 80, 70, 90, 85, 82, 95, 78),\n    control = c(70, 88, 75, 92, 82, 85, 90, 78)\n)\nknitr::kable(po_dat,\n    col.names = c(\"Person\", \"Math Attitude\", \"Y (if T = 1)\", \"Y (if T = 0)\"))\n\n\n\nPerson\nMath Attitude\nY (if T = 1)\nY (if T = 0)\n\n\n\n1\n4\n75\n70\n\n\n2\n7\n80\n88\n\n\n3\n3\n70\n75\n\n\n4\n9\n90\n92\n\n\n5\n5\n85\n82\n\n\n6\n6\n82\n85\n\n\n7\n8\n95\n90\n\n\n8\n2\n78\n78\nIf one could observe the two potential outcomes for each person (which is impossible in the real world), one could compute the treatment effect for each person:\n(te &lt;- po_dat$treat - po_dat$control)\n\n[1]  5 -8 -5 -2  3 -3  5  0\nand the average treatment effect (ATE) (here we just compute it on the sample, so the sample ATE):\n(ate &lt;- mean(te))\n\n[1] -0.625\nHowever, in practice, we can only observe one of the two potential outcomes. For example, if persons 2, 4, 6, 7 are in the treatment condition, we have\nCodepo_dat$t &lt;- ifelse(po_dat$person %in% c(2, 4, 6, 7), 1, 0)\npo_dat$y &lt;- ifelse(po_dat$t, po_dat$treat, po_dat$control)\npo_dat[c(\"t\", \"y\")] |&gt;\n    knitr::kable(col.names = c(\"Treatment\", \"Observed Y\"))\n\n\n\nTreatment\nObserved Y\n\n\n\n0\n70\n\n\n1\n80\n\n\n0\n75\n\n\n1\n90\n\n\n0\n82\n\n\n1\n82\n\n\n1\n95\n\n\n0\n78\nand the naive comparison of those in the treatment condition and those in the control condition will have a mean difference of\nmean(po_dat$y[po_dat$t == 1]) - mean(po_dat$y[po_dat$t == 0])\n\n[1] 10.5\nwhich gives a misleading estimate of the ATE.",
    "crumbs": [
      "Week 9",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Causal Inference</span>"
    ]
  },
  {
    "objectID": "08-causal-inference.html#directed-acyclic-graph-dag",
    "href": "08-causal-inference.html#directed-acyclic-graph-dag",
    "title": "\n13  Causal Inference\n",
    "section": "\n13.2 Directed Acyclic Graph (DAG)",
    "text": "13.2 Directed Acyclic Graph (DAG)\nDAG is a tool for encoding causal assumptions. It contains nodes and paths. A node is usually a variable that can be measured in the data or unmeasured. Generally, paths in a DAG are directional (as implied by directed), which indicates the directions of causal relations. Acyclic means the causal chain does not close in a loop.\nWe will use an example described in McElreath (2020), chapter 5, about data from 50 U.S. states from the 2009 American Community Survey (ACS), which we have already seen in Chapter 9 and Figure 9.1.\n\nwaffle_divorce &lt;- read_delim(  # read delimited files\n    \"https://raw.githubusercontent.com/rmcelreath/rethinking/master/data/WaffleDivorce.csv\",\n    delim = \";\"\n)\n\nRows: 50 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr  (2): Location, Loc\ndbl (11): Population, MedianAgeMarriage, Marriage, Marriage SE, Divorce, Div...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Rescale Marriage and Divorce by dividing by 10\nwaffle_divorce$Marriage &lt;- waffle_divorce$Marriage / 10\nwaffle_divorce$Divorce &lt;- waffle_divorce$Divorce / 10\nwaffle_divorce$MedianAgeMarriage &lt;- waffle_divorce$MedianAgeMarriage / 10\n# See data description at https://rdrr.io/github/rmcelreath/rethinking/man/WaffleDivorce.html\n\nThe outcome of interest is the divorce rate. Remember the plot shows how marriage rate is related to divorce rate at the state level. It looks like marriage rate can predict divorce rate. A causal interpretation would be a stronger assertion, such that we expect a higher divorce rate if policymakers encourage more people to get married. In order to make a causal claim, we need to remove potential confounders.\nA potential confounder is when people get married. Suppose people are forced to get married later in life. In that case, fewer people in the population will be married, and people may have less time, opportunity, and motivation to get divorced (as it may be harder to find a new partner). Therefore, we can use the following DAG:\n\ndag1 &lt;- dagitty(\"dag{ A -&gt; D; A -&gt; M; M -&gt; D }\")\ncoordinates(dag1) &lt;- list(x = c(M = 0, A = 1, D = 2),\n                          y = c(M = 0, A = 1, D = 0))\n# Plot\nggdag(dag1) + theme_dag()\n\n\n\n\n\n\nFigure 13.1: DAG for the relationship between marriage rate (M) and divorce rate (D) example, with median age of marriage (A) as a potential confounder.\n\n\n\n\nWe can look at how the median age people get married in different states relates to the divorce rate:\n\nggplot(waffle_divorce,\n       aes(x = MedianAgeMarriage, y = Divorce)) +\n    geom_point() +\n    geom_smooth() +\n    labs(x = \"Median age marriage (10 years)\",\n         y = \"Divorce rate (per 10 adults)\") +\n    ggrepel::geom_text_repel(aes(label = Loc))\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\nFigure 13.2: Scatter plot of divorce rate (y) vs median age of marriage (x).\n\n\n\n\n\n13.2.1 Assumptions in a DAG\nIn a graphical model, there are usually two kinds of assumptions conveyed. Perhaps counterintuitively, the weaker assumptions are the ones you can see, whereas the stronger assumptions are ones you do not see.\nFor example, a weak assumption is:\n\nMarriage age may directly influence the number of people who are married\n\nOn the other hand, examples of a strong assumption are:\n\nMarriage rate does not directly influence the age people get married\nthere is no other variable in the causal pathway M → D\n\nThe last assumption will not hold if there is a common cause of M and D other than A.\n\n13.2.2 Basic Types of Junctions\n\nFork: A ← B → C\n\nA and C are correlated due to a common cause B\n\n\nChain/Pipe: A → B → C\n\nB is on the causal pathway of A to C\n\n\nCollider: A → B ← C\n\nB is a descendant of both A and C\n\n\n\nGoing back to our example, there is a fork relation: M → A → D. In this case, A is a confounder when estimating the causal relation between M and D. In this case, the causal effect of M to D can be obtained by adjusting for A, which means looking at the subsets of data where A is constant. In regression, adjustment is obtained by including both M and A as predictors of D.",
    "crumbs": [
      "Week 9",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Causal Inference</span>"
    ]
  },
  {
    "objectID": "08-causal-inference.html#the-back-door-criterion-estimating-causal-effect-in-nonexperimental-data",
    "href": "08-causal-inference.html#the-back-door-criterion-estimating-causal-effect-in-nonexperimental-data",
    "title": "\n13  Causal Inference\n",
    "section": "\n13.3 The Back-Door Criterion: Estimating Causal Effect in Nonexperimental Data",
    "text": "13.3 The Back-Door Criterion: Estimating Causal Effect in Nonexperimental Data\nRandomization is one—but not the only—way to rule out confounding variables. Much progress has been made in clarifying that causal effects can be estimated in nonexperimental data. After all, researchers have not randomly assigned individuals to smoke \\(x\\) cigarettes per day, but we are confident that smoking causes cancer; we never manipulated the moon’s gravitational force, but we are pretty sure that the moon is a cause of high and low tides.\nIn a DAG, the back-door criterion can be used to identify variables that we should adjust for to obtain a causal effect. The set of variables to be adjusted should (a) blocks every path between X and Y that contains an arrow entering X and (b) does not contain variables that are descendant of X.\n\ndag4 &lt;- dagitty(\n    \"dag{\n      X -&gt; Y; W1 -&gt; X; U -&gt; W2; W2 -&gt; X; W1 -&gt; Y; U -&gt; Y\n    }\"\n)\nlatents(dag4) &lt;- \"U\"\ncoordinates(dag4) &lt;- list(x = c(X = 0, W1 = 0.66, U = 1.32, W2 = 0.66, Y = 2),\n                          y = c(X = 0, W1 = 1, U = 1, W2 = 0.5, Y = 0))\nggdag(dag4) + theme_dag()\n\n\n\n\n\n\nFigure 13.3: DAG for a hypothetical model with two measured and one unobserved confounder.\n\n\n\n\nWe can use a function in the daggity package to identify the set of variables that satisfy the back-door criterion. In this case, we say that X and Y are \\(d\\)-separated by this set of adjusted variables:\n\nadjustmentSets(dag4, exposure = \"X\", outcome = \"Y\",\n               effect = \"direct\")\n\n{ W1, W2 }",
    "crumbs": [
      "Week 9",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Causal Inference</span>"
    ]
  },
  {
    "objectID": "08-causal-inference.html#using-multiple-regression-model",
    "href": "08-causal-inference.html#using-multiple-regression-model",
    "title": "\n13  Causal Inference\n",
    "section": "\n13.4 Using Multiple Regression Model",
    "text": "13.4 Using Multiple Regression Model\n\\[\n  \\begin{aligned}\n    D_i & \\sim N(\\mu_i, \\sigma)  \\\\\n    \\mu_i & = \\beta_0 + \\beta_1 A_i + \\beta_2 M_i \\\\\n    \\beta_0 & \\sim N(0, 1) \\\\\n    \\beta_1 & \\sim N(0, 1) \\\\\n    \\beta_2 & \\sim N(0, 1) \\\\\n  \\end{aligned}\n\\]\nAssuming a correctly specified DAG, all all assumptions of a linear model are met, \\(\\beta_2\\) is the causal effect of M on D. Here is the brms code:\n\nm1 &lt;- brm(Divorce ~ MedianAgeMarriage + Marriage,\n          data = waffle_divorce,\n          prior = prior(std_normal(), class = \"b\") +\n              prior(normal(0, 5), class = \"Intercept\") +\n              prior(student_t(4, 0, 3), class = \"sigma\"),\n          seed = 941,\n          iter = 4000,\n          file = \"08_m1\"\n)\n\n\n13.4.1 Table\n\nmsummary(m1,\n         estimate = \"{estimate} [{conf.low}, {conf.high}]\",\n         statistic = NULL, fmt = 2\n)\n\nWarning: \n`modelsummary` uses the `performance` package to extract goodness-of-fit\nstatistics from models of this class. You can specify the statistics you wish\nto compute by supplying a `metrics` argument to `modelsummary`, which will then\npush it forward to `performance`. Acceptable values are: \"all\", \"common\",\n\"none\", or a character vector of metrics names. For example: `modelsummary(mod,\nmetrics = c(\"RMSE\", \"R2\")` Note that some metrics are computationally\nexpensive. See `?performance::performance` for details.\n This warning appears once per session.\n\n\n\nTable 13.1: Model results for the divorce rate example.\n\n\n\n\n    \n\n      \n\n \n                (1)\n              \n\n\nb_Intercept        \n                  3.49 [1.98, 5.02]   \n                \n\nb_MedianAgeMarriage\n                  -0.93 [-1.43, -0.45]\n                \n\nb_Marriage         \n                  -0.04 [-0.20, 0.12] \n                \n\nsigma              \n                  0.15 [0.12, 0.19]   \n                \n\nNum.Obs.           \n                  50                  \n                \n\nR2                 \n                  0.349               \n                \n\nR2 Adj.            \n                  0.284               \n                \n\nELPD               \n                  21.0                \n                \n\nELPD s.e.          \n                  6.4                 \n                \n\nLOOIC              \n                  -42.0               \n                \n\nLOOIC s.e.         \n                  12.9                \n                \n\nWAIC               \n                  -42.2               \n                \n\nRMSE               \n                  0.14                \n                \n\n\n\n\n\n\n\n\n\nAs shown in the table, when holding constant the median marriage age of states, marriage rate has only a small effect on divorce rate.\n\n13.4.2 Posterior predictive checks\npp_check(m1, ndraws = 100) # density\npp_check(m1, type = \"intervals\", x = \"Marriage\") +\n    labs(x = \"Marriage\", y = \"Divorce\")\n\nUsing all posterior draws for ppc type 'intervals' by default.\n\npp_check(m1, type = \"intervals\", x = \"MedianAgeMarriage\") +\n    labs(x = \"MedianAgeMarriage\", y = \"Divorce\")\n\nUsing all posterior draws for ppc type 'intervals' by default.\n\n\n\n\n\n\n\n\n\n\n(a) Posterior predictive density of divorce rate.\n\n\n\n\n\n\n\n\n\n(b) Posterior predictive intervals of marriage rate predicting divorce rate.\n\n\n\n\n\n\n\n\n\n\n\n(c) Posterior predictive intervals of median marriage age predicting marriage rate.\n\n\n\n\n\n\nFigure 13.4: Posterior predictive checks for the multiple regression model.\n\n\nThe model does not fit every state (e.g., UT, ME, ID).",
    "crumbs": [
      "Week 9",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Causal Inference</span>"
    ]
  },
  {
    "objectID": "08-causal-inference.html#predicting-an-intervention",
    "href": "08-causal-inference.html#predicting-an-intervention",
    "title": "\n13  Causal Inference\n",
    "section": "\n13.5 Predicting an Intervention",
    "text": "13.5 Predicting an Intervention\nIf the causal assumption in our DAG is reasonable, we have obtained an estimate of the causal effect of marriage rate on divorce rate at the state level. This allows us to answer questions like\n\nWhat would happen to the divorce rate if we encouraged more people to get married (so the marriage rate would increase by 10 percentage points)?\n\nWe can use the Bayesian model, which is generative, to make such predictions. Consider a state with a marriage rate of 2 (per 10 adults). The predicted divorce rate is\n\\[\n\\beta_0 + \\beta_1 A + \\beta_2 (2)\n\\]\nConsider an intervention that increases the marriage rate from 2 to 3. The predicted divorce rate will be\n\\[\n\\beta_0 + \\beta_1 A + \\beta_2 (3)\n\\]\nThe change in divorce rate is\n\\[\n\\beta_0 + \\beta_1 A + \\beta_2 (3) - \\beta_0 + \\beta_1 A + \\beta_2 (2) = \\beta_2\n\\]\nHere is what the model would predict in terms of the change in the divorce rate (holding median marriage age to 25 years old), using R:\n\npred_df &lt;- data.frame(\n    Marriage = c(2, 3),\n    MedianAgeMarriage = c(2.5, 2.5)\n)\ncbind(pred_df, fitted(m1, newdata = pred_df)) %&gt;%\n    knitr::kable(digits = 3)\n\n\n\nMarriage\nMedianAgeMarriage\nEstimate\nEst.Error\nQ2.5\nQ97.5\n\n\n\n2\n2.5\n1.068\n0.035\n1.002\n1.138\n\n\n3\n2.5\n1.026\n0.067\n0.894\n1.160\n\n\n\n\n\nThe difference should be just the estimate of \\(\\beta_2\\), which has the following posterior distribution:\n\nmcmc_dens(m1, pars = \"b_Marriage\")\n\n\n\n\n\n\nFigure 13.5: Estimated “causal” effect of marriage rate on divorce rate, based on the specified DAG and a linear model.",
    "crumbs": [
      "Week 9",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Causal Inference</span>"
    ]
  },
  {
    "objectID": "08-causal-inference.html#collider",
    "href": "08-causal-inference.html#collider",
    "title": "\n13  Causal Inference\n",
    "section": "\n13.6 Collider",
    "text": "13.6 Collider\nA collider is a descendant of two parent nodes. When one holds the collider constant, it induces a spurious association between the parents. This leads to many unexpected results in data analysis and daily life. For example, consider people who are nice and who are good-looking. Is there an association between a person being nice and a person being good-looking? Maybe. But this association can be induced when we condition on a collider. Let’s say a friend of yours only dates people who are either nice or good-looking. So we have this colliding relation:\nNice → Dating ← Good looking\nSuppose you look at just the people that your friend dated. In that case, they are either nice or good-looking, but the fact that you select to look at (condition on) only the people that your friend dated would automatically eliminate people who are neither nice nor good-looking. This induces a spurious negative association between nice and good-looking, so your friend may believe that nice people would be less likely to have appearances that fit their taste, and vice versa.\nAs another example, is research that is newsworthy less trustworthy? There could be a negative association due to collider bias, because people who select research to be reported, funded, or published, consider both newsworthiness and trustworthiness. Assume that trustworthiness has no causal relation with newsworthiness, below shows what happens when we only focus on papers that are either high on newsworthiness or trustworthiness:\n\nCodeset.seed(2221) # different seed from the text\nnum_proposals &lt;- 200 # number of grant proposals\nprop_selected &lt;- 0.1 # proportion to select\n# Simulate independent newsworthiness and trustworthiness\nplot_dat &lt;- data.frame(\n    nw = rnorm(num_proposals),\n    tw = rnorm(num_proposals)\n)\nplot_dat &lt;- plot_dat |&gt;\n    mutate(total = nw + tw)\nsel_dat &lt;- plot_dat |&gt;\n    # select top 10% of combined scores\n    slice_max(order_by = total, prop = prop_selected)\nplot_dat |&gt;\n    ggplot(aes(x = nw, y = tw)) +\n    geom_point() +\n    geom_point(data = sel_dat, shape = 1, size = 3,\n               color = \"red\") +\n    geom_smooth(method = \"lm\", se = FALSE) +\n    geom_smooth(data = sel_dat, method = \"lm\", se = FALSE,\n                col = \"purple\") +\n    labs(x = \"newsworthiness\", y = \"trustworthiness\")\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\nFigure 13.6: Simulation of newsworthiness and trustworthiness.\n\n\n\n\nAs you can see, a negative correlation happens. This is collider bias: spurious correlation due to conditioning on the common descendant. This also goes by the name Berkson’s Paradox.\nIn the DAG below, X and Y have no causal association. Conditioning on S, however, induces a negative correlation between X and Y. With the DAG below,\n\n\n\n\n\n\nGenerally speaking, do not condition on a collider, unless you’re going to de-confound the spurious association using other variables.\n\n\n\n\nCodedag7 &lt;- dagitty(\n    \"dag{\n      X -&gt; Y; X -&gt; S; Y -&gt; S\n    }\"\n)\ncoordinates(dag7) &lt;- list(x = c(X = 0, S = 1, Y = 2),\n                          y = c(X = 0, S = -1, Y = 0))\nggdag(dag7) + theme_dag()\n\n\n\n\n\n\nFigure 13.7: DAG with collider bias.\n\n\n\n\n\n\n\n\n\n\nAge and Happiness, conditioned on Marital Status (Example from text)\n\n\n\nIn this example, we assume that age and happiness are not related, but as people age, they are more likely to get married.\n\nCode# Code adapted from the rethinking package (https://github.com/rmcelreath/rethinking/blob/master/R/sim_happiness.R)\nsim_happiness &lt;- function(seed = 1977, N_years = 100,\n                          max_age = 65, N_births = 50,\n                          aom = 18) {\n    set.seed(seed)\n    H &lt;- M &lt;- A &lt;- c()\n    for (t in seq_len(N_years)) {\n        A &lt;- A + 1 # age existing individuals\n        A &lt;- c(A, rep(1, N_births)) # newborns\n        H &lt;- c(H, seq(from = 1, to = 5, length.out = N_births)) # sim happiness trait - never changes\n        M &lt;- c(M, rep(0, N_births)) # not yet married\n        # for each person over 17, chance get married\n        M[A &gt;= aom & M == 0] &lt;- \n            rbinom(A[A &gt;= aom & M == 0], size = 1,\n                   prob = plogis(H[A &gt;= aom & M == 0] - 7.9))\n        # mortality\n        deaths &lt;- which(A &gt; max_age)\n        if (length(deaths) &gt; 0) {\n            A &lt;- A[-deaths]\n            H &lt;- H[-deaths]\n            M &lt;- M[-deaths]\n        }\n    }\n    d &lt;- data.frame(age = A, married = M, happiness = H)\n    return(d)\n}\ndd &lt;- sim_happiness(2024, N_years = 100)\n\n\n\nggplot(dd, aes(x = age, y = happiness)) +\n    geom_point(alpha = .1, size = .5)\n\n\n\n\n\n\nFigure 13.8: Age and happiness.\n\n\n\n\n\nggplot(dd[dd$married == 1, ], aes(x = age, y = happiness)) +\n    geom_point(alpha = .5, size = .5)\n\n\n\n\n\n\nFigure 13.9: Age and happiness, conditioned on married couples.\n\n\n\n\n\n\nSome other collider examples:\n\nimpulsivity → high-risk youth ← delinquency\nhealthcare worker → COVID-19 testing ← COVID-19 severity\nstandardized test → admission ← research skills\nmaternal smoking → birth weight → birth defect ← mortality",
    "crumbs": [
      "Week 9",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Causal Inference</span>"
    ]
  },
  {
    "objectID": "08-causal-inference.html#some-additional-references",
    "href": "08-causal-inference.html#some-additional-references",
    "title": "\n13  Causal Inference\n",
    "section": "\n13.7 Some Additional References",
    "text": "13.7 Some Additional References\n\nhttps://doi.org/10.1177/25152459221095823\nhttps://doi.org/10.1038/s41562-024-01939-z\n\n\n\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: a Bayesian course with examples in R and Stan (Second edition). CRC Press.",
    "crumbs": [
      "Week 9",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Causal Inference</span>"
    ]
  },
  {
    "objectID": "08-causal-inference.html#footnotes",
    "href": "08-causal-inference.html#footnotes",
    "title": "\n13  Causal Inference\n",
    "section": "",
    "text": "See this paper: https://doi.org/10.1177/1745691620921521 for an argument of how the taboo against causal inference has impeded the progress of psychology research.↩︎",
    "crumbs": [
      "Week 9",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Causal Inference</span>"
    ]
  },
  {
    "objectID": "08b-mediation.html",
    "href": "08b-mediation.html",
    "title": "\n14  Mediation\n",
    "section": "",
    "text": "14.1 Summary Statistics Tables\nI’ll take a quick detour to introduce you to some useful functions for tabulating your data. The functions will be from the modelsummary package.\ndata(framing, package = \"mediation\")\n# Subtract the `emo` variable by 3 so that it starts from 0-9\nframing$emo &lt;- framing$emo - 3\n# Quick summary of selected variables\ndatasummary_skim(framing)\n\n\n\n    \n\n      \n\n \n                Unique\n                Missing Pct.\n                Mean\n                SD\n                Min\n                Median\n                Max\n                Histogram\n              \n\n\nage\n                  63\n                  0\n                  47.8\n                  16.0\n                  18.0\n                  47.0\n                  85.0\n                  \n                \n\nincome\n                  19\n                  0\n                  10.8\n                  3.9\n                  1.0\n                  11.0\n                  19.0\n                  \n                \n\nemo\n                  10\n                  0\n                  4.0\n                  2.8\n                  0.0\n                  4.0\n                  9.0\n                  \n                \n\np_harm\n                  7\n                  0\n                  5.9\n                  1.8\n                  2.0\n                  6.0\n                  8.0\n                  \n                \n\ntone\n                  2\n                  0\n                  0.5\n                  0.5\n                  0.0\n                  1.0\n                  1.0\n                  \n                \n\neth\n                  2\n                  0\n                  0.5\n                  0.5\n                  0.0\n                  1.0\n                  1.0\n                  \n                \n\ntreat\n                  2\n                  0\n                  0.3\n                  0.4\n                  0.0\n                  0.0\n                  1.0\n                  \n                \n\nimmigr\n                  4\n                  0\n                  3.0\n                  1.0\n                  1.0\n                  3.0\n                  4.0\n                  \n                \n\nanti_info\n                  2\n                  0\n                  0.1\n                  0.3\n                  0.0\n                  0.0\n                  1.0\n                  \n                \n\ncong_mesg\n                  2\n                  0\n                  0.3\n                  0.5\n                  0.0\n                  0.0\n                  1.0\n                  \n                \n\n \n                    \n                  N\n                  %\n                  \n                  \n                  \n                  \n                  \n                \n\ncond\n                  not asked\n                  0\n                  0.0\n                  \n                  \n                  \n                  \n                  \n                \n\n\n                  refused\n                  0\n                  0.0\n                  \n                  \n                  \n                  \n                  \n                \n\n\n                  control\n                  0\n                  0.0\n                  \n                  \n                  \n                  \n                  \n                \n\n\n                  1\n                  68\n                  25.7\n                  \n                  \n                  \n                  \n                  \n                \n\n\n                  2\n                  67\n                  25.3\n                  \n                  \n                  \n                  \n                  \n                \n\n\n                  3\n                  67\n                  25.3\n                  \n                  \n                  \n                  \n                  \n                \n\n\n                  4\n                  63\n                  23.8\n                  \n                  \n                  \n                  \n                  \n                \n\nanx\n                  not asked\n                  0\n                  0.0\n                  \n                  \n                  \n                  \n                  \n                \n\n\n                  refused\n                  0\n                  0.0\n                  \n                  \n                  \n                  \n                  \n                \n\n\n                  very anxious\n                  60\n                  22.6\n                  \n                  \n                  \n                  \n                  \n                \n\n\n                  somewhat anxious\n                  86\n                  32.5\n                  \n                  \n                  \n                  \n                  \n                \n\n\n                  a little anxious\n                  74\n                  27.9\n                  \n                  \n                  \n                  \n                  \n                \n\n\n                  not anxious at all\n                  45\n                  17.0\n                  \n                  \n                  \n                  \n                  \n                \n\neduc\n                  not asked\n                  0\n                  0.0\n                  \n                  \n                  \n                  \n                  \n                \n\n\n                  refused\n                  0\n                  0.0\n                  \n                  \n                  \n                  \n                  \n                \n\n\n                  less than high school\n                  20\n                  7.5\n                  \n                  \n                  \n                  \n                  \n                \n\n\n                  high school\n                  92\n                  34.7\n                  \n                  \n                  \n                  \n                  \n                \n\n\n                  some college\n                  70\n                  26.4\n                  \n                  \n                  \n                  \n                  \n                \n\n\n                  bachelor's degree or higher\n                  83\n                  31.3\n                  \n                  \n                  \n                  \n                  \n                \n\ngender\n                  not asked\n                  0\n                  0.0\n                  \n                  \n                  \n                  \n                  \n                \n\n\n                  refused\n                  0\n                  0.0\n                  \n                  \n                  \n                  \n                  \n                \n\n\n                  male\n                  126\n                  47.5\n                  \n                  \n                  \n                  \n                  \n                \n\n\n                  female\n                  139\n                  52.5\n                  \n                  \n                  \n                  \n                  \n                \n\nenglish\n                  Strongly Favor\n                  7\n                  2.6\n                  \n                  \n                  \n                  \n                  \n                \n\n\n                  Favor\n                  25\n                  9.4\n                  \n                  \n                  \n                  \n                  \n                \n\n\n                  Oppose\n                  82\n                  30.9\n                  \n                  \n                  \n                  \n                  \n                \n\n\n                  Strongly Oppose\n                  151\n                  57.0\n                  \n                  \n                  \n                  \n                  \n                \n\n\n\n\n\n# Summary by treatment condition (`tone`)\ndatasummary_balance(~ tone, data = framing)\n\n\n\n    \n\n      \n\n\n \n \n0\n1\n \n \n\n\n \n                  \n                Mean\n                Std. Dev.\n                Mean\n                Std. Dev.\n                Diff. in Means\n                Std. Error\n              \n\n\n\nage      \n                                             \n                  48.4\n                  16.0\n                  47.1\n                  16.0\n                  -1.3\n                  2.0\n                \n\nincome   \n                                             \n                  11.0\n                  3.9 \n                  10.6\n                  3.9 \n                  -0.4\n                  0.5\n                \n\nemo      \n                                             \n                  3.4 \n                  2.6 \n                  4.5 \n                  2.8 \n                  1.1 \n                  0.3\n                \n\np_harm   \n                                             \n                  5.5 \n                  1.8 \n                  6.2 \n                  1.7 \n                  0.7 \n                  0.2\n                \n\neth      \n                                             \n                  0.5 \n                  0.5 \n                  0.5 \n                  0.5 \n                  0.0 \n                  0.1\n                \n\ntreat    \n                                             \n                  0.0 \n                  0.0 \n                  0.5 \n                  0.5 \n                  0.5 \n                  0.0\n                \n\nimmigr   \n                                             \n                  2.8 \n                  1.0 \n                  3.2 \n                  0.9 \n                  0.4 \n                  0.1\n                \n\nanti_info\n                                             \n                  0.1 \n                  0.3 \n                  0.1 \n                  0.3 \n                  0.0 \n                  0.0\n                \n\ncong_mesg\n                                             \n                  0.3 \n                  0.5 \n                  0.4 \n                  0.5 \n                  0.0 \n                  0.1\n                \n\n         \n                                             \n                  N   \n                  Pct.\n                  N   \n                  Pct.\n                      \n                     \n                \n\ncond     \n                  not asked                  \n                  0   \n                  0.0 \n                  0   \n                  0.0 \n                      \n                     \n                \n\n         \n                  refused                    \n                  0   \n                  0.0 \n                  0   \n                  0.0 \n                      \n                     \n                \n\n         \n                  control                    \n                  0   \n                  0.0 \n                  0   \n                  0.0 \n                      \n                     \n                \n\n         \n                  1                          \n                  0   \n                  0.0 \n                  68  \n                  50.4\n                      \n                     \n                \n\n         \n                  2                          \n                  0   \n                  0.0 \n                  67  \n                  49.6\n                      \n                     \n                \n\n         \n                  3                          \n                  67  \n                  51.5\n                  0   \n                  0.0 \n                      \n                     \n                \n\n         \n                  4                          \n                  63  \n                  48.5\n                  0   \n                  0.0 \n                      \n                     \n                \n\nanx      \n                  not asked                  \n                  0   \n                  0.0 \n                  0   \n                  0.0 \n                      \n                     \n                \n\n         \n                  refused                    \n                  0   \n                  0.0 \n                  0   \n                  0.0 \n                      \n                     \n                \n\n         \n                  very anxious               \n                  34  \n                  26.2\n                  26  \n                  19.3\n                      \n                     \n                \n\n         \n                  somewhat anxious           \n                  48  \n                  36.9\n                  38  \n                  28.1\n                      \n                     \n                \n\n         \n                  a little anxious           \n                  31  \n                  23.8\n                  43  \n                  31.9\n                      \n                     \n                \n\n         \n                  not anxious at all         \n                  17  \n                  13.1\n                  28  \n                  20.7\n                      \n                     \n                \n\neduc     \n                  not asked                  \n                  0   \n                  0.0 \n                  0   \n                  0.0 \n                      \n                     \n                \n\n         \n                  refused                    \n                  0   \n                  0.0 \n                  0   \n                  0.0 \n                      \n                     \n                \n\n         \n                  less than high school      \n                  6   \n                  4.6 \n                  14  \n                  10.4\n                      \n                     \n                \n\n         \n                  high school                \n                  48  \n                  36.9\n                  44  \n                  32.6\n                      \n                     \n                \n\n         \n                  some college               \n                  31  \n                  23.8\n                  39  \n                  28.9\n                      \n                     \n                \n\n         \n                  bachelor's degree or higher\n                  45  \n                  34.6\n                  38  \n                  28.1\n                      \n                     \n                \n\ngender   \n                  not asked                  \n                  0   \n                  0.0 \n                  0   \n                  0.0 \n                      \n                     \n                \n\n         \n                  refused                    \n                  0   \n                  0.0 \n                  0   \n                  0.0 \n                      \n                     \n                \n\n         \n                  male                       \n                  64  \n                  49.2\n                  62  \n                  45.9\n                      \n                     \n                \n\n         \n                  female                     \n                  66  \n                  50.8\n                  73  \n                  54.1\n                      \n                     \n                \n\nenglish  \n                  Strongly Favor             \n                  1   \n                  0.8 \n                  6   \n                  4.4 \n                      \n                     \n                \n\n         \n                  Favor                      \n                  15  \n                  11.5\n                  10  \n                  7.4 \n                      \n                     \n                \n\n         \n                  Oppose                     \n                  44  \n                  33.8\n                  38  \n                  28.1\n                      \n                     \n                \n\n         \n                  Strongly Oppose            \n                  70  \n                  53.8\n                  81  \n                  60.0\n                      \n                     \n                \n\n\n\n\n\n# More tailor-made table with selected variables by treatment condition\ndatasummary(emo + p_harm + cong_mesg ~ Factor(tone) * (Mean + SD + Histogram),\n            data = framing)\n\n\n\n    \n\n      \n\n\n \n0\n1\n\n\n \n                Mean\n                SD\n                Histogram\n                Mean\n                SD\n                Histogram\n              \n\n\n\nemo      \n                  3.39\n                  2.63\n                  ▇▅▇▆▆▃▃▂▂▂\n                  4.53\n                  2.81\n                  ▆▄▆▅▇▇▅▆▄▆\n                \n\np_harm   \n                  5.53\n                  1.77\n                  ▁▃▅▄▇▂▆   \n                  6.23\n                  1.69\n                  ▁▃▂▅▄▇    \n                \n\ncong_mesg\n                  0.31\n                  0.46\n                  ▇▃        \n                  0.36\n                  0.48\n                  ▇▄        \n                \n\n\n\n\n\n# Correlation table\nframing |&gt;\n    select(tone, emo, cong_mesg) |&gt;\n    datasummary_correlation(method = \"pearson\")\n\n\n\n    \n\n      \n\n \n                tone\n                emo\n                cong_mesg\n              \n\n\ntone     \n                  1  \n                  .  \n                  .\n                \n\nemo      \n                  .21\n                  1  \n                  .\n                \n\ncong_mesg\n                  .05\n                  .37\n                  1",
    "crumbs": [
      "Week 9",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Mediation</span>"
    ]
  },
  {
    "objectID": "08b-mediation.html#randomization-removes-incoming-paths-for-treatment",
    "href": "08b-mediation.html#randomization-removes-incoming-paths-for-treatment",
    "title": "\n14  Mediation\n",
    "section": "\n14.2 Randomization Removes Incoming Paths for Treatment",
    "text": "14.2 Randomization Removes Incoming Paths for Treatment\nLet’s consider a DAG without randomization, for the following two variables:\n\nX: Exposure to a negatively framed news story about immigrants\nY: Anti-immigration political action\n\nThere are many possible confounders when we observe these two variables in data (e.g., an individual’s political affiliation and the state in which a person resides). We can represent these unobserved confounders as U, so the DAG will be something like\n\ndag2 &lt;- dagitty(\n    \"dag{\n      X -&gt; Y; U -&gt; X; U -&gt; Y\n      U [unobserved]\n    }\"\n)\ncoordinates(dag2) &lt;- list(x = c(X = 0, U = 1, Y = 2),\n                          y = c(X = 0, U = 1, Y = 0))\n# Plot\nggdag(dag2) + theme_dag()\n\n\n\n\n\n\nFigure 14.1: DAG with an unobserved confounder\n\n\n\n\nThe magic of randomization—randomly assigning individuals to a manipulated level of X—is that it blocks the path U → X. Therefore, with randomization, the reason a person sees a negatively-framed news story about immigrants is not related to reasons that the person may have intentions for anti-immigration actions. The DAG becomes\n\ndag3 &lt;- dagitty(\n    \"dag{\n      X -&gt; Y; U -&gt; Y\n      U [unobserved]\n    }\"\n)\ncoordinates(dag3) &lt;- list(x = c(X = 0, U = 1, Y = 2),\n                          y = c(X = 0, U = 1, Y = 0))\n# Plot\nggdag(dag3) + theme_dag()\n\n\n\n\n\n\nFigure 14.2: DAG with randomization\n\n\n\n\nTherefore, when randomization is successful, the path coefficient of X → Y is the causal effect of X on Y. However, randomized experiments do not always rule out all confounding. For example, suppose participants are randomly assigned to different experimental conditions, but those who disagree with the presented news story drop out. In that case, such attrition can induce a non-zero correlation between X and Y in the remaining sample.",
    "crumbs": [
      "Week 9",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Mediation</span>"
    ]
  },
  {
    "objectID": "08b-mediation.html#causal-chains",
    "href": "08b-mediation.html#causal-chains",
    "title": "\n14  Mediation\n",
    "section": "\n14.3 Causal Chains",
    "text": "14.3 Causal Chains\n\n14.3.1 Post-Treatment Bias\nHere are some key variables from the framing data set:\n\n\ncong_mesg: binary variable indicating whether or not the participant agreed to send a letter about immigration policy to his or her member of Congress\n\nemo: posttest anxiety about increased immigration (0-9)\n\ntone: framing of news story (0 = positive, 1 = negative)\n\nWe can compare the results of two models:\n\n\ntone → cong_mesg\n\n\ntone → cong_mesg, adjusting for emo\n\n\nWhich model gives us the causal effect estimate for tone? Let’s run the two models.\n\nm_no_adjust &lt;- brm(cong_mesg ~ tone,\n                   data = framing,\n                   family = bernoulli(link = \"logit\"),\n                   file = \"08b_m_no_adjust\")\nm_adjust &lt;- brm(cong_mesg ~ tone + emo,\n                data = framing,\n                family = bernoulli(link = \"logit\"),\n                file = \"08b_m_adjust\")\n\nWe can combine the results in a table:\n\nmsummary(list(`No adjustment` = m_no_adjust,\n              `Adjusting for feeling` = m_adjust),\n         estimate = \"{estimate} [{conf.low}, {conf.high}]\",\n         statistic = NULL, fmt = 2\n)\n\nWarning: \n`modelsummary` uses the `performance` package to extract goodness-of-fit\nstatistics from models of this class. You can specify the statistics you wish\nto compute by supplying a `metrics` argument to `modelsummary`, which will then\npush it forward to `performance`. Acceptable values are: \"all\", \"common\",\n\"none\", or a character vector of metrics names. For example: `modelsummary(mod,\nmetrics = c(\"RMSE\", \"R2\")` Note that some metrics are computationally\nexpensive. See `?performance::performance` for details.\n This warning appears once per session.\n\n\n\n\n    \n\n      \n\n \n                No adjustment\n                Adjusting for feeling\n              \n\n\nb_Intercept\n                  -0.82 [-1.20, -0.45]\n                  -2.00 [-2.62, -1.43]\n                \n\nb_tone     \n                  0.22 [-0.27, 0.74]  \n                  -0.15 [-0.70, 0.41] \n                \n\nb_emo      \n                                      \n                  0.32 [0.21, 0.43]   \n                \n\nNum.Obs.   \n                  265                 \n                  265                 \n                \n\nR2         \n                  0.003               \n                  0.143               \n                \n\nELPD       \n                  -170.1              \n                  -152.5              \n                \n\nELPD s.e.  \n                  5.5                 \n                  7.4                 \n                \n\nLOOIC      \n                  340.2               \n                  305.0               \n                \n\nLOOIC s.e. \n                  11.0                \n                  14.7                \n                \n\nWAIC       \n                  340.2               \n                  305.0               \n                \n\nRMSE       \n                  0.47                \n                  0.44                \n                \n\n\n\n\n\n\nWe can see that the Bayes estimate of the coefficient for tone was positive without emo, but was negative with emo. Which one should we believe? The information criteria (LOOIC and WAIC) suggested that the model with emo was better for prediction, but just because something helps predict the outcome does not make it a causal variable. To repeat,\n\nCoefficients in a predictive model are not causal effects.\n\nAnd to emphasize again,\n\nCausal inference requires causal assumptions, and these assumptions are not in the data.\n\nSo instead, we need a DAG. Given that we know emo is measured after the intervention, it seems reasonable to think that a negatively framed story about immigrants would elicit some negative emotions about increased immigration, and that emotion may prompt people to take anti-immigrant actions. Therefore, we have the following DAG:\n\nCodedag5 &lt;- dagitty(\n    \"dag{\n      T -&gt; C; T -&gt; E; E -&gt; C\n    }\"\n)\ncoordinates(dag5) &lt;- list(x = c(T = 0, E = 1, C = 2),\n                          y = c(T = 0, E = 1, C = 0))\n# Plot\nggdag(dag5) + theme_dag()\n\n\nTable 14.1: DAG for a mediation model with emotion as a mediator.\n\n\n\n\n\n\n\n\n\n\n\nThis is an example of a pipe/chain. It is a causal chain going from T(one) → E(motion) → C(ongress message). If we are interested in the causal effect of T, we should not condition on E; conditioning on E would mean comparing those who saw the negatively-framed story and those who saw the positively-framed story but had the same negative emotion towards immigrants. In other words, adjusting for E would mean taking out part of the effect of T on C through E.\nAs another example, think about a drug that is supposed to lower the risk of a heart attack. Imagine someone conducting a study comparing drug/no drug conditions on their probability of getting heart attacks. Should we adjust for participants’ blood pressure after the intervention? If we want to know the drug’s effect, and that the drug works by lowering blood pressure, we should not adjust for posttest blood pressure. Otherwise, we would be asking the question: Does the drug help prevent heart attacks through something other than lowering one’s blood pressure?\nThe latter question can be answered in mediation analysis.",
    "crumbs": [
      "Week 9",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Mediation</span>"
    ]
  },
  {
    "objectID": "08b-mediation.html#causal-mediation",
    "href": "08b-mediation.html#causal-mediation",
    "title": "\n14  Mediation\n",
    "section": "\n14.4 Causal Mediation",
    "text": "14.4 Causal Mediation\nIn the DAG above, E is a post-treatment variable potentially influenced by T, which we call a mediator. Mediator is an important topic in causal inference, as it informs the mechanism of how a variable has a causal effect on an outcome.\nOne thing to be careful of is that, statistically speaking, a mediator behaves very much like a confounder, and their difference is based on causal assumptions.\nLet’s analyze the mediation model in Figure X. There are two variables that are on the receiving end of some causal effects: emo and cong_mesg. Whereas the generalized linear model handles one outcome, with brms, we can have a system of equations—one for each outcome—estimated simultaneously, as shown in the code below.\n\n14.4.1 Using brms\n\n\nm_med &lt;- brm(\n    # Two equations for two outcomes\n    bf(cong_mesg ~ tone + emo) +\n        bf(emo ~ tone) +\n        set_rescor(FALSE),\n    # A list of two family arguments for two outcomes\n    family = list(bernoulli(\"logit\"), gaussian(\"identity\")),\n    data = framing,\n    prior = prior(normal(0, 2), class = \"b\", resp = \"emo\") +\n        prior(student_t(4, 0, 5), class = \"sigma\", resp = \"emo\") +\n        prior(student_t(4, 0, 2.5), class = \"b\", resp = \"congmesg\"),\n    seed = 1338,\n    file = \"08b_m_med\"\n)\n\n\n14.4.2 Using Stan\nHere’s some Stan code for running the same mediation model\n\ndata {\n    int&lt;lower=0&gt; N0;  // number of observations (control)\n    int&lt;lower=0&gt; N1;  // number of observations (treatment)\n    array[N0] int y0; // outcome (control);\n    array[N1] int y1; // outcome (treatment);\n    vector[N0] m0;    // mediator (control);\n    vector[N1] m1;    // mediator (treatment);\n}\nparameters {\n    real alpham;  // regression intercept for M\n    real alphay;  // regression intercept for M\n    real beta1;   // X -&gt; M\n    real beta2;   // X -&gt; Y\n    real beta3;   // M -&gt; Y\n    real&lt;lower=0&gt; sigmam;  // SD of prediction error for M\n}\nmodel {\n    // model\n    m0 ~ normal(alpham, sigmam);\n    m1 ~ normal(alpham + beta1, sigmam);\n    y0 ~ bernoulli_logit(alphay + beta3 * m0);\n    y1 ~ bernoulli_logit(alphay + beta2 + beta3 * m1);\n    // prior\n    alpham ~ normal(4.5, 4.5);\n    alphay ~ normal(0, 5);\n    beta1 ~ std_normal();\n    beta2 ~ std_normal();\n    beta3 ~ std_normal();\n    sigmam ~ student_t(4, 0, 5);\n}\n\n\nmed_mod &lt;- cmdstan_model(\"stan_code/mediation_logit_normal.stan\")\n\n\n# 1. Form the data list for Stan\nstan_dat &lt;- with(\n    framing,\n    list(\n        N0 = sum(tone == 0),\n        N1 = sum(tone == 1),\n        m0 = emo[which(tone == 0)],\n        m1 = emo[which(tone == 1)],\n        y0 = cong_mesg[which(tone == 0)],\n        y1 = cong_mesg[which(tone == 1)]\n    )\n)\n# 2. Run Stan\nm_med_stan &lt;- med_mod$sample(\n    data = stan_dat,\n    seed = 1338,\n    refresh = 1000\n)\n\n\n14.4.3 Direct and Indirect Effects\nIn a mediation model, the effect of X on Y has two mechanisms: - Indirect effect: X causes Y because X causes M, and M causes Y - Direct effect: X causes Y without involving M\nMore specifically, the direct effect is the change in Y for one unit change in X, holding M constant. In our example, it means comparing subsets of the treatment and the control groups, under the condition that both subsets have the same level of negative emotion about increased immigration. The indirect effect takes more effort to understand: it is the change in Y for the control group (or the treatment group) if their mediator value is set to the same level as the treatment group. In our example, it would mean comparing the control group and the counterfactual where the control group had their negative emotion changed to the same level as the treatment group.\nThe causal mediation literature has more distinctions on the different types of direct and indirect effects. Below, I give codes for obtaining these effects without going into detail.1\n\n14.4.4 Controlled direct effect (CDE)\nCDE is the direct effect when the mediator is set to a specific level. Below is the CDE for emo = 0 and emo = 9, respectively.\n\ncond_df &lt;- data.frame(tone = c(0, 1, 0, 1),\n                      emo = c(0, 0, 9, 9))\ncond_df |&gt;\n    bind_cols(\n        fitted(m_med, newdata = cond_df)[ , , \"congmesg\"]\n    ) |&gt;\n    knitr::kable()\n\n\nTable 14.2: Estimated direct effect of tone on cong_mesg at two different levels of emo.\n\n\n\n\ntone\nemo\nEstimate\nEst.Error\nQ2.5\nQ97.5\n\n\n\n0\n0\n0.1212844\n0.0320367\n0.0662354\n0.1907005\n\n\n1\n0\n0.1084567\n0.0330696\n0.0538386\n0.1830547\n\n\n0\n9\n0.6982051\n0.0698306\n0.5559154\n0.8234034\n\n\n1\n9\n0.6702609\n0.0631406\n0.5418592\n0.7855347\n\n\n\n\n\n\n\n\n\n14.4.5 Natural direct effect (NDE)\nThe “natural” effects are quantities for some kind of population averages. NDE is the direct effect when the mediator is held constant at the level of the control group. As a first step, we need to obtain the potential outcome of emo when tone = 0. We call this potential outcome variable \\(M_0\\) (potential outcome of \\(M\\) if \\(X\\) = 0). This has already been observed for the control group but will be a counterfactual for the treatment group.\nWe will use a general approach by Imai et al. (2010) to simulate potential outcomes for each observation, before computing NDE (and NIE). For each observation, we will first simulate the potential outcome of emo when tone = 0 (\\(M_0\\)), and then simulate the potential outcome of emo when tone = 1 (\\(M_1\\)).\n\n# Simulate potential outcomes for mediator when T = 0\ndat0 &lt;- m_med$data\ndat0$tone &lt;- 0\n# Predicted emo when T = 0\npo_m0 &lt;- posterior_predict(m_med, newdata = dat0, resp = \"emo\")\n# Simulate potential outcomes for mediator when T = 1\ndat1 &lt;- m_med$data\ndat1$tone &lt;- 1\n# Predicted emo when T = 1\npo_m1 &lt;- posterior_predict(m_med, newdata = dat1, resp = \"emo\")\n\nNext, we will simulate four potential outcomes for cong_mesg (Y):\n\nY(T = 0, M = \\(M_0\\))\nY(T = 1, M = \\(M_0\\))\nY(T = 0, M = \\(M_1\\))\nY(T = 1, M = \\(M_1\\))\n\n\nm_med_draws &lt;- as_draws_df(m_med)\n# Predicted logit of congmesg when T = 0 and emo = po_m0\npo_y0_m0 &lt;- m_med_draws$b_congmesg_Intercept + m_med_draws$b_congmesg_emo * po_m0\n# Predicted logit of congmesg when T = 1 and emo = po_m0\npo_y1_m0 &lt;- m_med_draws$b_congmesg_Intercept +\n    m_med_draws$b_congmesg_tone +\n    m_med_draws$b_congmesg_emo * po_m0\n# Predicted logit of congmesg when T = 0 and emo = po_m1\npo_y0_m1 &lt;- m_med_draws$b_congmesg_Intercept + m_med_draws$b_congmesg_emo * po_m1\n# Predicted logit of congmesg when T = 1 and emo = po_m1\npo_y1_m1 &lt;- m_med_draws$b_congmesg_Intercept +\n    m_med_draws$b_congmesg_tone +\n    m_med_draws$b_congmesg_emo * po_m1\n\nThe NDE is defined as Y(T = 1, M = \\(M_0\\)) - Y(T = 0, M = \\(M_0\\)).\n\n# NDE = Y(1, M(0)) - Y(0, M(0))\nnde &lt;- rowMeans(plogis(po_y1_m0)) - rowMeans(plogis(po_y0_m0))\n\n\n14.4.5.1 Natural indirect effect (NIE)\nNIE is the difference in the outcome between the actual control group and a counterfactual control group. The counterfactual here is a control group that did not receive the treatment, but had their emo value set to be equal to the treatment group. The NIE is defined as Y(T = 0, M = \\(M_1\\)) - Y(T = 0, M = \\(M_0\\)).\n\n# NIE = Y(0, M(1)) - Y(0, M(0))\nnie &lt;- rowMeans(plogis(po_y0_m1)) - rowMeans(plogis(po_y0_m0))\n\n\ndraws_nde_nie &lt;- as_draws(list(NDE = nde, NIE = nie))\nposterior::summarise_draws(draws_nde_nie)\n\n\nTable 14.3: Estimated natural direct and indirect effects for the control group.\n\n\n\n  \n\n\n\n\n\n\n\nmcmc_areas(draws_nde_nie, bw = \"SJ\")\n\n\n\n\n\n\nFigure 14.3: Estimated natural direct and indirect effects for the control group.\n\n\n\n\n\n14.4.6 Sensitivity analysis\n\nCodedag6 &lt;- dagitty(\n    \"dag{\n      T -&gt; C; T -&gt; E; E -&gt; C; U -&gt; E; U -&gt; C\n    }\"\n)\ncoordinates(dag6) &lt;- list(x = c(T = 0, E = 1, C = 2, U = 2),\n                          y = c(T = 0, E = 1, C = 0, U = 1))\nggdag(dag6) + theme_dag()\n\n\n\n\n\n\nFigure 14.4: DAG for a mediation model with an unobserved mediator-outcome confounder.\n\n\n\n\n\n\n\n\n\n\nAssumptions of Causal Mediation\n\n\n\nMediation effects can be estimated properly when the causal diagram and the corresponding model are specified correctly. In our model, we assume\n\nNo unmeasured treatment-outcome confounding\nNo unmeasured mediator-outcome confounding\nNo unmeasured treatment-mediator confounding\nThe mediator-outcome path is not moderated by the treatment\n\nNote that randomization of the treatment does not rule out confounding for the mediator-outcome path.\n\n\nOne important assumption in mediation is that there is no unobserved confounding variable between the mediator and the outcome. This assumption requires researchers’ input, as usually we don’t have studies that randomly assign both the treatment variable and the mediator. An additional technique is to ask: what would the effect be if there were unobserved confounding variables of a certain magnitude? With Bayesian, we can represent the strength of the confounding effect by a prior distribution (see McCandless & Somers, 2019, p. 10.1177/0962280217729844). The following shows the mediation estimates assuming the effect of the confounding variable to the mediator is 1, and to the outcome has a prior of N(0.5, 0.2).\n\ndata {\n    int&lt;lower=0&gt; N0;  // number of observations (control)\n    int&lt;lower=0&gt; N1;  // number of observations (treatment)\n    array[N0] int y0; // outcome (control);\n    array[N1] int y1; // outcome (treatment);\n    vector[N0] m0;    // mediator (control);\n    vector[N1] m1;    // mediator (treatment);\n}\nparameters {\n    real alpham;  // regression intercept for M\n    real alphay;  // regression intercept for M\n    real beta1;   // X -&gt; M\n    real beta2;   // X -&gt; Y\n    real beta3;   // M -&gt; Y\n    vector[N0] u0;  // confounding variable\n    vector[N1] u1;  // confounding variable\n    real beta4;   // U -&gt; Y\n    real&lt;lower=0&gt; sigmam;  // SD of prediction error for M\n}\nmodel {\n    // model\n    u0 ~ std_normal();\n    u1 ~ std_normal();\n    m0 ~ normal(alpham + u0, sigmam);\n    m1 ~ normal(alpham + beta1 + u1, sigmam);\n    y0 ~ bernoulli_logit(alphay + beta3 * m0 + beta4 * u0);\n    y1 ~ bernoulli_logit(alphay + beta2 + beta3 * m1 + beta4 * u1);\n    // prior\n    alpham ~ normal(4.5, 4.5);\n    alphay ~ normal(0, 5);\n    beta1 ~ std_normal();\n    beta2 ~ std_normal();\n    beta3 ~ std_normal();\n    beta4 ~ normal(0.5, 0.2);\n    sigmam ~ student_t(4, 0, 5);\n}\n\n\nmed_mod_sens &lt;- cmdstan_model(\"stan_code/mediation_logit_normal_sensitivity.stan\")\n\n\n# 1. form the data list for Stan\nstan_dat &lt;- with(\n    framing,\n    list(\n        N0 = sum(tone == 0),\n        N1 = sum(tone == 1),\n        m0 = emo[which(tone == 0)],\n        m1 = emo[which(tone == 1)],\n        y0 = cong_mesg[which(tone == 0)],\n        y1 = cong_mesg[which(tone == 1)]\n    )\n)\n# 2. Run Stan\nm_med_sens &lt;- med_mod_sens$sample(\n    data = stan_dat,\n    seed = 1338,\n    refresh = 1000\n)\n\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 1.6 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 1.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 1.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 1.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 1.2 seconds.\nTotal execution time: 5.0 seconds.\n\n\nbeta1 = tone -&gt; emo; beta2 = tone -&gt; cong_mesg; beta3 = emo -&gt; cong_mesg\n\nm_med_sens$draws(\n    c(\"alpham\", \"alphay\",\n      \"beta1\", \"beta2\", \"beta3\")\n) |&gt;\n    mcmc_intervals()\n\n\n\n\n\n\nFigure 14.5: Estimated coefficients for the mediation model with the sensitivity analysis.\n\n\n\n\nAs you can see, the prior of the confounding effect attenuates the coefficients from the mediator to the outcome, but the path from the mediator to the outcome remains pretty much above zero.\nYou may also check out the BayesGmed package, which is also based on Stan. More descriptions are in the paper Yimer et al. (2023).\n\n\n\n\n\n\nImai, K., Keele, L., & Tingley, D. (2010). A general approach to causal mediation analysis. Psychological Methods, 15(4), 309–334. https://doi.org/10.1037/a0020761\n\n\nMcCandless, L. C., & Somers, J. M. (2019). Bayesian sensitivity analysis for unmeasured confounding in causal mediation analysis. Statistical Methods in Medical Research, 28(2), 515–531. https://doi.org/10.1177/0962280217729844\n\n\nYimer, B. B., Lunt, M., Beasley, M., Macfarlane, G. J., & McBeth, J. (2023). BayesGmed: An R-package for Bayesian causal mediation analysis. PLOS ONE, 18(6), e0287037. https://doi.org/10.1371/journal.pone.0287037",
    "crumbs": [
      "Week 9",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Mediation</span>"
    ]
  },
  {
    "objectID": "08b-mediation.html#footnotes",
    "href": "08b-mediation.html#footnotes",
    "title": "\n14  Mediation\n",
    "section": "",
    "text": "You can find more information about causal mediation in this paper: https://ftp.cs.ucla.edu/pub/stat_ser/r389.pdf↩︎",
    "crumbs": [
      "Week 9",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Mediation</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Carvalho, C. M., Polson, N. G., & Scott, J. G. (2010). The horseshoe\nestimator for sparse signals. Biometrika, 97(2),\n465–480. https://doi.org/10.1093/biomet/asq017\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other\nstories. Cambridge University Press.\n\n\nGigerenzer, G. (2004). Mindless statistics. The Journal of\nSocio-Economics, 33(5), 587–606. https://doi.org/10.1016/j.socec.2004.09.033\n\n\nHoeting, J. A., Madigan, D., Raftery, A. E., & Volinsky, C. T.\n(1999). Bayesian model averaging: A tutorial. Statistical\nScience, 14(4). https://doi.org/10.1214/ss/1009212519\n\n\nImai, K., Keele, L., & Tingley, D. (2010). A general approach to\ncausal mediation analysis. Psychological Methods,\n15(4), 309–334. https://doi.org/10.1037/a0020761\n\n\nJohnson, A. A., Ott, M. Q., & Dogucu, M. (2022). Bayes rules! An\nintroduction to Bayesian modeling with R. CRC Press.\n\n\nLambert, B. (2018). A student’s guide to Bayesian statistics.\nSAGE.\n\n\nMcCandless, L. C., & Somers, J. M. (2019). Bayesian sensitivity\nanalysis for unmeasured confounding in causal mediation analysis.\nStatistical Methods in Medical Research, 28(2),\n515–531. https://doi.org/10.1177/0962280217729844\n\n\nMcElreath, R. (2020). Statistical rethinking: a Bayesian course with\nexamples in R and Stan (Second edition). CRC Press.\n\n\nMcGrayne, S. B. (2011). The theory that would not die: How Bayes’\nrule cracked the enigma code, hunted down Russian submarines, &\nemerged triumphant from two centuries of controversy. Yale\nuniversity press.\n\n\nPiironen, J., Paasiniemi, M., & Vehtari, A. (2020). Projective\ninference in high-dimensional problems: Prediction and feature\nselection. Electronic Journal of Statistics, 14(1). https://doi.org/10.1214/20-EJS1711\n\n\nPiironen, J., & Vehtari, A. (2017). Sparsity information and\nregularization in the horseshoe and other shrinkage priors.\nElectronic Journal of Statistics, 11(2). https://doi.org/10.1214/17-EJS1337SI\n\n\nVan De Schoot, R., Winter, S. D., Ryan, O., Zondervan-Zwijnenburg, M.,\n& Depaoli, S. (2017). A systematic review of Bayesian articles in\npsychology: The last 25 years. Psychological Methods,\n22(2), 217–239. https://doi.org/10.1037/met0000100\n\n\nVehtari, A., Gelman, A., & Gabry, J. (2017). Practical Bayesian\nmodel evaluation using leave-one-out cross-validation and WAIC.\nStatistics and Computing, 27(5), 1413–1432. https://doi.org/10.1007/s11222-016-9696-4\n\n\nYao, Y., Vehtari, A., Simpson, D., & Gelman, A. (2018). Using\nstacking to average Bayesian predictive distributions (with discussion).\nBayesian Analysis, 13(3). https://doi.org/10.1214/17-BA1091\n\n\nYimer, B. B., Lunt, M., Beasley, M., Macfarlane, G. J., & McBeth, J.\n(2023). BayesGmed: An R-package for Bayesian causal mediation analysis.\nPLOS ONE, 18(6), e0287037. https://doi.org/10.1371/journal.pone.0287037",
    "crumbs": [
      "References"
    ]
  }
]